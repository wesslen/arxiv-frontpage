{"text":"The two levels are computed by the original model's self-attention, which means the proposed does not require any training.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"This work elicits LLMs' inherent ability to handle long contexts without fine-tuning.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.","cats":{"prompt-engineering":0,"security":0,"social-sciences":0,"architectures":1,"programming":0}}
{"text":"We propose Self-Extend to stimulate LLMs' long context handling potential.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"The basic idea is to construct bi-level attention information: the group level and the neighbor level.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning.","cats":{"prompt-engineering":0,"security":0,"social-sciences":0,"architectures":1,"programming":0}}
{"text":"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0}}
{"text":"Recently, the advent of large language models (LLMs) has revolutionized generative agents.","cats":{"robustness":0,"architectures":0}}
{"text":"It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike.","cats":{"robustness":0,"architectures":0}}
{"text":"Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation.","cats":{"robustness":0,"social-sciences":0,"architectures":0}}
{"text":"Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status.","cats":{"security":0,"social-sciences":0,"architectures":0}}
{"text":"Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.","cats":{"security":0,"architectures":0}}
{"text":"We use the Cartier operator on $H^0(\\mathcal{A}_2,\\Omega^1)$ to find a closed formula for the $a$-number of the form $\\mathcal{A}_2 = v(Y^{\\sqrt{q}}+Y-x^{\\frac{\\sqrt{q}+1}{2}})$ where $q=p^s$ over the finite field $\\mathbb{F}_{q^2}$. The application of the computed $a$-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it.","cats":{"security":0,"architectures":0}}
{"text":"(ii) Algorithms for the computation of commuting extensions of minimal size.","cats":{"security":0,"architectures":0}}
{"text":"Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention.","cats":{"hci":0,"architectures":0}}
{"text":"Our approach leverages the power of LLMs to understand and interpret user input, facilitating a more intuitive design process.","cats":{"hci":0,"architectures":0}}
{"text":"We address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates.","cats":{"hci":0,"architectures":0}}
{"text":"The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts.","cats":{"hci":0,"architectures":0}}
{"text":"We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information.","cats":{"hci":0,"architectures":0}}
{"text":"Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method.","cats":{"social-sciences":0,"architectures":0}}
{"text":"While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts.","cats":{"social-sciences":0,"architectures":0}}
{"text":"We share our approach to designing this new introductory socially responsible computing course and the students' reflections.","cats":{"education":0,"recommender":0,"architectures":0}}
{"text":"Large Language Models (LLMs) have shown excellent generalization capabilities that have led to the development of numerous models.","cats":{"recommender":0,"architectures":0}}
{"text":"We use a convolutional neural network to classify each frame of an ultrasound video recording.","cats":{"recommender":0,"architectures":0}}
{"text":"Finally, the paper summarizes significant findings from LLM research and consolidates essential architectural and training strategies for developing advanced LLMs.","cats":{"production":0,"architectures":0}}
{"text":"Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.","cats":{"production":0,"architectures":0}}
{"text":"Moreover, the paper also discusses the basic building blocks and concepts behind LLMs, followed by a complete overview of LLMs, including their important features and functions.","cats":{"production":0,"architectures":0}}
{"text":"As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial.","cats":{"production":0,"architectures":0}}
{"text":"One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language.","cats":{"production":0,"architectures":0}}
{"text":"In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages.","cats":{"production":0,"architectures":1}}
{"text":"We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning.","cats":{"production":0,"architectures":1}}
{"text":"Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning.","cats":{"production":0,"architectures":0}}
{"text":"Finally, we find that increasing the number of languages in the instruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual generalization.","cats":{"production":0,"architectures":0}}
{"text":"Our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses.","cats":{"production":0,"architectures":0}}
{"text":"The capabilities of the most recent language models have increased the interest in integrating them into real-world applications.","cats":{"production":0,"architectures":0}}
{"text":"However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains.","cats":{"production":0,"architectures":0}}
{"text":"However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary.","cats":{"architectures":0}}
{"text":"The entire alignment process can be accomplished within a single RRHF training session.","cats":{"architectures":0}}
{"text":"Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF).","cats":{"architectures":0}}
{"text":"Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT).","cats":{"architectures":1}}
{"text":"Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score.","cats":{"architectures":0}}
{"text":"To address this issue, we propose an improved alignment approach named FIGA.","cats":{"architectures":1}}
{"text":"Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment.","cats":{"architectures":0}}
{"text":"RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values.","cats":{"architectures":0}}
{"text":"We hereby leverage a loop closure based re-initialization process to achieve full alignment.","cats":{"architectures":0}}
{"text":"Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.","cats":{"architectures":0}}
{"text":"Our experimental results show SuperHF exceeds PPO-based RLHF on the training objective, easily and favorably trades off high reward with low reward hacking, improves downstream calibration, and performs the same on our GPT-4 based qualitative evaluation scheme all the while being significantly simpler to implement, highlighting SuperHF's potential as a competitive language model alignment technique.","cats":{"architectures":1}}
{"text":"In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments.","cats":{"architectures":1}}
{"text":"RRHF can efficiently align language model output probabilities with human preferences as robust as fine-tuning and it only needs 1 to 2 models during tuning.","cats":{"architectures":1}}
{"text":"In this work, we address the challenge of lyrics alignment, which involves aligning the lyrics and vocal components of songs.","cats":{"architectures":0}}
{"text":"Reinforcement learning from human feedback (RLHF) is a recent technique to improve the quality of the text generated by a language model, making it closer to what humans would generate.","cats":{"architectures":0}}
{"text":"Currently, targets for alignment remain underspecified and do not seem to be built from a philosophically robust structure.","cats":{"architectures":0}}
{"text":"3.5k aligned sentence pairs.","cats":{"architectures":0}}
{"text":"Existing methods for achieving this alignment often involves employing reinforcement learning from human feedback (RLHF) to fine-tune LLMs based on human labels assessing the relative quality of model responses.","cats":{"architectures":0}}
{"text":"Relational Hoare logics (RHL) provide compositional rules that embody various alignments of executions.","cats":{"architectures":0}}
{"text":"Based on such observations, we develop a new algorithm tailored for RLHF, called ReMax.","cats":{"architectures":1}}
{"text":"Then, we formulate the aligned Ref and LR center as value-key pairs, and the corner region of the LR is formulated as queries.","cats":{"architectures":0}}
{"text":"These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process.","cats":{"architectures":0}}
{"text":"Nevertheless, RLHF is susceptible to instability during fine-tuning and presents challenges in implementation.","cats":{"architectures":1}}
{"text":"To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment.","cats":{"architectures":1}}
{"text":"We identify three important properties in RLHF tasks: fast simulation, deterministic transitions, and trajectory-level rewards, which are not leveraged in PPO.","cats":{"architectures":1}}
{"text":"Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones.","cats":{"architectures":0}}
{"text":"For this alignment, current popular methods leverage a reinforcement learning (RL) approach with a reward model trained on feedback from humans.","cats":{"architectures":0}}
{"text":"In the first report, we dissect the framework of RLHF, re-evaluate the inner workings of PPO, and explore how the parts comprising PPO algorithms impact policy agent training.","cats":{"architectures":1}}
{"text":"A single degenerate alignment rule (self-composition), atop a complete Hoare logic, comprises a RHL for $\\forall\\forall$ properties that is complete in the ordinary logical sense.","cats":{"architectures":0}}
{"text":"The current work aims to highlight the importance of accurate alignments for good-quality synthesis.","cats":{"architectures":0}}
{"text":"Project page can be found at https://qinying-liu.github.io/Tag-Align/","cats":{"architectures":0}}
{"text":"This paper ultimately proposes that RLHF has potential to net positively impact areas of misinformation, AI value-alignment, bias, AI access, cross-cultural dialogue, industry, and workforce.","cats":{"architectures":1}}
{"text":"Our code can be found in https://github.com/skingorz/FD-Align.","cats":{"architectures":0}}
{"text":"In the case where more than two images are provided, we further propose a simple yet effective global alignment strategy that expresses all pairwise pointmaps in a common reference frame.","cats":{"architectures":0}}
{"text":"The notion of alignment completeness was previously proposed as a more satisfactory measure, and some rules were shown to be alignment complete with respect to a few ad hoc forms of alignment automata.","cats":{"architectures":0}}
{"text":"2k aligned sentence pairs).","cats":{"architectures":0}}
{"text":"Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible.","cats":{"architectures":1}}
{"text":"The alignment or 'fit' between a candidate and an organization is inferred in online photos through dress style and presentations of self.","cats":{"architectures":0}}
{"text":"This paper proves alignment completeness with respect to a general class of $\\forall\\forall$ alignment automata, for a RHL comprised of standard rules together with a rule of semantics-preserving rewrites based on Kleene algebra with tests.","cats":{"architectures":0}}
{"text":"RL4F produces critiques that help GPT-3 revise its outputs.","cats":{"architectures":0}}
{"text":"Using a single modality means our method is computationally inexpensive and can be utilized in conjunction with existing alignment techniques.","cats":{"architectures":0}}
{"text":"We find that the structural information becomes difficult to exploit but still valuable in aligning HHKGs.","cats":{"architectures":0}}
{"text":"By rethinking these keys of VI-ReID, we propose a simple and effective method, the Multi-level Cross-modality Joint Alignment (MCJA), bridging both modality and objective-level gap.","cats":{"architectures":0}}
{"text":"Although text-based applications of RLHF have received much attention, it is crucial to consider when evaluating its social implications the diverse range of areas to which it may be deployed.","cats":{"architectures":0}}
{"text":"Additionally, uncertainty regularization in UP-RLHF proves to be pivotal in mitigating overoptimization, thereby contributing to the overall performance.","cats":{"architectures":0}}
{"text":"To bridge this gap effectively, we propose R2GenGPT, which is a novel solution that aligns visual features with the word embedding space of LLMs using an efficient visual alignment module.","cats":{"architectures":1}}
{"text":"The stable training of RLHF has still been a puzzle.","cats":{"architectures":0}}
{"text":"We argue that the SFT of multi-view diffusion models resembles the instruction finetuning stage of the LLM alignment pipeline and can benefit from RL finetuning (RLFT) methods.","cats":{"architectures":1}}
{"text":"However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing.","cats":{"architectures":0}}
{"text":"The Cloud Migration LLM accepts input from the user specifying the parameters of their migration, and outputs a migration strategy with an architecture diagram.","cats":{"architectures":0}}
{"text":"To support further research and development, we have made the model's checkpoints and source codes accessible to the scientific community.","cats":{"architectures":0}}
{"text":"This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting.","cats":{"architectures":0}}
{"text":"Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another.","cats":{"architectures":0}}
{"text":"Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer.","cats":{"architectures":0}}
{"text":"[2023] introduced a constructive approach for exploring computational hardness, proving that SAT requires exhaustive search.","cats":{"architectures":0}}
{"text":"Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.","cats":{"architectures":0}}
{"text":"Monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts will be important directions for more robust model editing.","cats":{"architectures":0}}
{"text":"Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers.","cats":{"architectures":0}}
{"text":"An optimal behavior would be to query external resources only when the LLM is not confident about answers.","cats":{"architectures":0}}
{"text":"In addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data.","cats":{"architectures":1}}
{"text":"This results in the API being utilized only $62\\%$ of the time.","cats":{"architectures":0}}
{"text":"One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets.","cats":{"architectures":0}}
{"text":"In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge.","cats":{"architectures":0}}
{"text":"Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor.","cats":{"architectures":0}}
{"text":"Extensive experiments results demonstrate the superiority of MPPT against the state-of-the-art baseline methods.","cats":{"architectures":0}}
{"text":"By varying the game history revealed to LLMs-based players, we find that most of LLMs are rational in that they play strategies that can increase their payoffs, but not as rational as indicated by Nash Equilibria (NEs).","cats":{"architectures":0}}
{"text":"In this work, we provide an economics arena for the LLMs research community as a dynamic simulation to test the above-mentioned abilities of LLMs, i.e. rationality, strategic reasoning ability, and instruction-following capability.","cats":{"architectures":0}}
{"text":"Large languages models (LLMs) trained on datasets of publicly available source code have established a new state-of-the-art in code completion.","cats":{"architectures":0}}
{"text":"However, these models are mostly unaware of the code that already exists within a specific project, preventing the models from making good use of existing APIs.","cats":{"architectures":0}}
{"text":"Instead, LLMs often invent, or \"hallucinate\", non-existent APIs or produce variants of already existing code.","cats":{"architectures":0}}
{"text":"Although the API information is available to IDEs, the input size limit of LLMs prevents code completion techniques from including all relevant context into the prompt.","cats":{"architectures":0}}
{"text":"This paper presents De-Hallucinator, an LLM-based code completion technique that grounds the predictions of a model through a novel combination of retrieving suitable API references and iteratively querying the model with increasingly suitable context information in the prompt.","cats":{"architectures":0}}
{"text":"The approach exploits the observation that LLMs often predict code that resembles the desired completion, but that fails to correctly refer to already existing APIs.","cats":{"architectures":0}}
{"text":"De-Hallucinator automatically identifies project-specific API references related to the code prefix and to the model's initial predictions and adds these references into the prompt.","cats":{"architectures":0}}
{"text":"Our evaluation applies the approach to the task of predicting API usages in open-source Python projects.","cats":{"architectures":0}}
{"text":"We show that De-Hallucinator consistently improves the predicted code across four state-of-the-art LLMs compared to querying the model only with the code before the cursor.","cats":{"architectures":0}}
{"text":"In particular, the approach improves the edit distance of the predicted code by 23-51% and the recall of correctly predicted API usages by 24-61% relative to the baseline.","cats":{"architectures":0}}
{"text":"The paper provides an extensive discussion of the three approaches' performance for automated detection and support of students' challenge moments in collaborative learning activities.","cats":{"architectures":0}}
{"text":"Current open-source multimodal LLMs are not directly suited for this task.","cats":{"architectures":0}}
{"text":"In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website.","cats":{"architectures":0}}
{"text":"We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web.","cats":{"architectures":0}}
{"text":"We evaluate on the recent MIND2WEB benchmark.","cats":{"architectures":0}}
{"text":"In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites.","cats":{"architectures":0}}
{"text":"We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites.","cats":{"architectures":0}}
{"text":"This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs).","cats":{"architectures":1}}
{"text":"Instruction tuning refers to the process of further training LLMs on a dataset consisting of \\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions.","cats":{"architectures":1}}
{"text":"In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc).","cats":{"architectures":1}}
{"text":"We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies of existing strategies and suggest some avenues for fruitful research.","cats":{"architectures":1}}
{"text":" Instruction tuning refers to the process of further training LLMs on a dataset consisting of \\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the nextmodalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc).","cats":{"architectures":0}}
{"text":"We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out cur","cats":{"architectures":0}}
{"text":"This survey paper comprehensively analyses the LLMs architectures and their categorization, training strategies, training datasets, and performance evaluations and discusses future research directions.","cats":{"architectures":1}}
{"text":"These models propose various new architectures, tweaking existing architectures with refined training strategies, increasing context length, using high-quality training data, and increasing training time to outperform baselines.","cats":{"architectures":0}}
{"text":"Analyzing new developments is crucial for identifying changes that enhance training stability and improve generalization in LLMs.  ","cats":{"architectures":0}}
{"text":"Given the continuous advancements in","cats":{"architectures":0}}
{"text":"Due to resource and cost limitations, several researchers have employed parameter-efficient tuning techniques, such as LoRA, for instruction tuning, and have obtained encouraging results","cats":{"architectures":1}}
{"text":"In this study, we undertook experimental comparisons between full-parameter fine-tuning and LoRA-based tuning methods, utilizing LLaMA as the base model.","cats":{"architectures":0}}
{"text":"Recently, the instruction-tuning of large language models is a crucial area of research in the field of natural language processing.  ","cats":{"architectures":0}}
{"text":"In comparison to full-parameter fine-tuning, LoRA-based tuning demonstrates salient benefits in terms of training costs.","cats":{"architectures":0}}
{"text":"The experimental results show thope that the experimental conclusions of this paper can provide inspiration for training large language models, especially in the field of Chinese, and help researchers find a better trade-off strategy between training cost and model performance.","cats":{"architectures":0}}
{"text":"To facilitate the reproduction of the paper's results, the dataset, model and code will be released.","cats":{"architectures":0}}
{"text":"However, the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc.","cats":{"architectures":1}}
{"text":"Various large language models (LLMs) have been proposed in recent years, including closed- and open-source ones, continually setting new records on multiple benchmarks.  ","cats":{"architectures":0}}
{"text":"Although many such issues are addressed along the line of research on LLMs, an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data in training LLMs under cost-effective settings.","cats":{"architectures":0}}
{"text":"In this work, we propose Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation model, and further pre-trained on 700 billion tokens, where we focus on pre-training techniques and use data-centric optimization to enhance the learning process of Ziya2 on different stages.","cats":{"architectures":0}}
{"text":"Experiments show that Ziya2 significantly outperforms other models in multiple benchmarks especially with promising results compared to representative open-source ones.","cats":{"architectures":0}}
{"text":"Ziya2 (Base) is released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.","cats":{"architectures":0}}
{"text":"In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation.","cats":{"architectures":1}}
{"text":"Language is essentially a complex, intricate system of human expressions governed by grammatical rules.","cats":{"architectures":0}}
{"text":"It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language.","cats":{"architectures":0}}
{"text":"As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models.","cats":{"architectures":0}}
{"text":"Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks.","cats":{"architectures":0}}
{"text":"Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size.","cats":{"architectures":0}}
{"text":"Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models.","cats":{"architectures":0}}
{"text":"To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size.","cats":{"architectures":0}}
{"text":"Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society.","cats":{"architectures":0}}
{"text":"The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms.  ","cats":{"architectures":0}}
{"text":"Efficiently training large language models requires parallelizing across hundreds of hardware accelerators and invoking various compute and memory optimizations.","cats":{"architectures":1}}
{"text":"When combined, many of these strategies have complex interactions regarding the final training efficiency.","cats":{"architectures":0}}
{"text":"Prior work tackling this problem did not have access to the latest set of optimizations, such as FlashAttention or sequence parallelism.","cats":{"architectures":0}}
{"text":"In this work, we conduct a comprehensive ablation study of possible training configurations for large language models.","cats":{"architectures":0}}
{"text":"We distill this large study into several key recommendations for the most efficient training.","cats":{"architectures":0}}
{"text":"For instance, we find that using a micro-batch size of 1 usually enables the most efficient training layouts.","cats":{"architectures":0}}
{"text":"Larger micro-batch sizes necessitate activation checkpointing or higher degrees of model parallelism and also lead to larger pipeline bubbles.","cats":{"architectures":0}}
{"text":"Our most efficient configurations enable us to achieve state-of-the-art training efficiency results over a range of model sizes, most notably a Model FLOPs utilization of 70.5% when training a 13B model.","cats":{"architectures":0}}
{"text":"With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window wMs' context window's length.","cats":{"architectures":0}}
