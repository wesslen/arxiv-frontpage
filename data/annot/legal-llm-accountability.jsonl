{"text":"The rapidity with which generative AI has been adopted and advanced has raised legal and ethical questions related to the impact on artists rights, content production, data collection, privacy, accuracy of information, and intellectual property rights.","cats":{"legal-llm-accountability":1}}
{"text":"Recent administrative and case law challenges have shown that generative AI software systems do not have independent intellectual property rights in the content that they generate.","cats":{"legal-llm-accountability":1}}
{"text":"It remains to be seen whether human content creators can retain their intellectual property rights against generative AI software, its developers, operators, and owners for the misappropriation of the work of human creatives, given the metes and bounds of existing law.","cats":{"legal-llm-accountability":1}}
{"text":"Early signs from various courts are mixed as to whether and to what degree the results generated by AI models meet the legal standards of infringement under existing law.","cats":{"legal-llm-accountability":1}}
{"text":" Recent administrative and case law challenges have shown that generative AI software systems do not have independent intellectual property rights in the content that they generate.","cats":{"legal-llm-accountability":0}}
{"text":"It remains to be seen whether human content creators can retain their is of exist Early signs from various courts are mixed as to whether and to what degree the results generated by AI models meet the legal standards of infringement under exist","cats":{"legal-llm-accountability":0}}
{"text":"However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage.","cats":{"legal-llm-accountability":1}}
{"text":"These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union.","cats":{"legal-llm-accountability":0}}
{"text":"Our results suggest that it is possible to build high quality language models while mitigating their legal risk.","cats":{"legal-llm-accountability":0}}
{"text":"The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate.  ","cats":{"legal-llm-accountability":0}}
{"text":"We present SILO, a new language model that manages this risk-performance tradeoff during inference.","cats":{"legal-llm-accountability":0}}
{"text":"SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference.","cats":{"legal-llm-accountability":0}}
{"text":"The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store.","cats":{"legal-llm-accountability":0}}
{"text":"Our experiments show that the parametric ap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text.","cats":{"legal-llm-accountability":0}}
{"text":"We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size.","cats":{"legal-llm-accountability":0}}
{"text":"In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning.","cats":{"legal-llm-accountability":1}}
{"text":"More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments.","cats":{"legal-llm-accountability":1}}
{"text":"Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues.","cats":{"legal-llm-accountability":0}}
{"text":"However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have.","cats":{"legal-llm-accountability":0}}
{"text":"The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess.  ","cats":{"legal-llm-accountability":0}}
{"text":"More specifically, we investigate the similarities and differences between GPT-4 and humans when itdifferences between them.","cats":{"legal-llm-accountability":0}}
{"text":"We conclude with a discussion of the philosophical implications of our findings.","cats":{"legal-llm-accountability":0}}
{"text":"We also peripherally touch upon the array of issues raised by the relationship between AI and copyright.","cats":{"legal-llm-accountability":1}}
{"text":"The rise of Generative Artificial Intelligence systems (``AI systems'') has created unprecedented social engagement.","cats":{"legal-llm-accountability":0}}
{"text":"AI code generation systems provide responses (output) to questions or requests by accessing the vast library of open-source code created by developers over decades.","cats":{"legal-llm-accountability":0}}
{"text":"However, they do so by allegedly stealing the open-source code stored in virtual libraries, known as repositories.","cats":{"legal-llm-accountability":0}}
{"text":"How all this happens and whether there is a solution short of years of litigation that can protect innovation is the focus of this article.  ","cats":{"legal-llm-accountability":0}}
{"text":"Looking ahead, we propose the following: (a) immediate changes to the licenses for open-source code created by developers that will allow access and/or use of any open-source code to humans only; (b) we suggest revisions to the Massachusetts Institute of Technology (``MIT'') license so that AI systems procure appropriate licenses from open-source code developers, which we believe will harmonize standards and build social consensus for the benefit of all of humanity rather than profit-driven centers of innovation; (c) We call for urgent legislative action to protect the future of AI systems while also promoting innovation; and (d) we propose that there is a shift in the burden of proof to AI systems in obfuscation cases.","cats":{"legal-llm-accountability":0}}
