{"text":"However, instruction prompting involves designing crafted prompts for zero-shot learning or selecting appropriate samples for few-shot learning and requires users to have professional domain knowledge, while task-oriented fine-tuning requires high training costs.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"In this paper, we propose a novel prompt learning framework for code summarization called PromptCS.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"trains a prompt agent that can generate continuous prompts to unleash the potential for LLMs in code summarization.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"2) What defines an effective prompt?","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"We introduce k Nearest Neighbor In-Context Learning(kNN-ICL), which simplifies prompt engineering by allowing it to be built on top of any design strategy while providing access to all demo examples.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"The two levels are computed by the original model's self-attention, which means the proposed does not require any training.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"This work elicits LLMs' inherent ability to handle long contexts without fine-tuning.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"We propose Self-Extend to stimulate LLMs' long context handling potential.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"The basic idea is to construct bi-level attention information: the group level and the neighbor level.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning.","cats":{"prompt-engineering":0,"social-sciences":0,"programming":0}}
{"text":"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"However, it is important to recognize that an excessive reliance on this functionality raises the risk of manipulation by malicious actors who can exploit it with carefully crafted prompts.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"The results indicate the need for careful validation and tailored prompt engineering.","cats":{"robustness":0,"social-sciences":0}}
{"text":"However, the absence of a comprehensive benchmark impedes progress in this field.","cats":{"robustness":0,"social-sciences":0}}
{"text":"The emergence of ChatGPT and other large language models (LLMs) has greatly increased interest in utilizing LLMs as therapists to support individuals struggling with mental health challenges.","cats":{"robustness":0,"social-sciences":1}}
{"text":"In this paper, we propose BOLT, a novel computational framework to study the conversational behavior of LLMs when employed as therapists.","cats":{"robustness":0,"social-sciences":1}}
{"text":"The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code).","cats":{"robustness":0,"social-sciences":0,"education":0}}
{"text":"It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models.","cats":{"robustness":0,"social-sciences":0}}
{"text":"A tuple (Z_1,...,Z_p) of matrices of size r is said to be a commuting extension of a tuple (A_1,...,A_p) of matrices of size n <r if the Z_i pairwise commute and each A_i sits in the upper left corner of a block decomposition of Z_i.","cats":{"security":0,"social-sciences":0}}
{"text":"Notably, when fine-tuned with just 1% of data, Adaptor outperforms several Transformer-based methods trained on full datasets in medical image segmentation.","cats":{"security":0,"social-sciences":0}}
{"text":"Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security.","cats":{"security":1,"social-sciences":0}}
{"text":"Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have shown the potential to be integrated into human daily lives.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation.","cats":{"hci":0,"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks.","cats":{"hci":0,"social-sciences":0}}
{"text":"Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective.","cats":{"hci":0,"social-sciences":0}}
{"text":"Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse.","cats":{"hci":1,"social-sciences":0}}
{"text":"Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"We hope that this work provides a better guide for researchers working on the prompting of large language models.","cats":{"hci":0,"social-sciences":0}}
{"text":"Large language models have been demonstrated to be valuable in different fields.","cats":{"hci":0,"social-sciences":0,"programming":0}}
{"text":"Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI.","cats":{"hci":0,"social-sciences":0}}
{"text":"The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model.","cats":{"hci":0,"social-sciences":0}}
{"text":"Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction.","cats":{"hci":1,"social-sciences":1}}
{"text":"The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics.","cats":{"hci":0,"social-sciences":0}}
{"text":"We not only focus on the performance of LLMs, but also explores their features from a psychological perspective, acknowledging the importance of understanding their behavioral characteristics.","cats":{"hci":1,"social-sciences":1}}
{"text":"Our study examines the behavioral patterns displayed by LLMs by employing trait theory, a psychological framework.","cats":{"hci":1,"social-sciences":0}}
{"text":"Moreover, the study investigates whether ChatGPT can exhibit personality changes in response to instructions or contextual cues.","cats":{"hci":1,"social-sciences":1}}
{"text":"The findings show that ChatGPT consistently maintains its ENFJ personality regardless of instructions or contexts.","cats":{"hci":1,"social-sciences":1}}
{"text":"By shedding light on the personalization of LLMs, we anticipate that our study will serve as a catalyst for further research in this field.","cats":{"hci":0,"social-sciences":0}}
{"text":"The advancement of Large Language Models (LLMs) has led to their widespread use across a broad spectrum of tasks including decision making.","cats":{"hci":1,"social-sciences":1}}
{"text":"The emergence of Large Language Models (LLMs) has brought both excitement and concerns to social computing research.","cats":{"hci":1,"social-sciences":1}}
{"text":"On the other hand, concerns are emerging regarding the validity, privacy, and ethics of the research when LLMs are involved.","cats":{"hci":1,"social-sciences":0}}
{"text":"This SIG aims at offering an open space for social computing researchers who are interested in understanding the impacts of LLMs to discuss their current practices, perspectives, challenges when engaging with LLMs in their everyday work and collectively shaping the emerging norms of using LLMs in social computing research.","cats":{"hci":1,"social-sciences":1}}
{"text":"But to what extent is generative AI already in use in the public sector?","cats":{"hci":0,"social-sciences":0}}
{"text":"We find that higher-quality references lead to better metric correlations with humans at the segment-level.","cats":{"social-sciences":0,"recommender":0}}
{"text":"We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories.","cats":{"social-sciences":0}}
{"text":"Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference.","cats":{"social-sciences":0}}
{"text":"Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees.","cats":{"social-sciences":0}}
{"text":"A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers).","cats":{"social-sciences":0}}
{"text":"However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks.","cats":{"social-sciences":0}}
{"text":"To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework.","cats":{"social-sciences":0}}
{"text":"Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method.","cats":{"social-sciences":0}}
{"text":"We devise a novel diffusion model that can undertake the task of simultaneously face swapping and reenactment.","cats":{"social-sciences":0}}
{"text":"The current approach to fetal anomaly screening is based on biometric measurements derived from individually selected ultrasound images.","cats":{"social-sciences":0}}
{"text":"We use a Bayesian method to estimate the true value of each biometric from a large number of measurements and probabilistically reject outliers.","cats":{"social-sciences":0}}
{"text":"Our method holds significant potential for substantially improving forest management practices.","cats":{"social-sciences":0}}
{"text":"We evaluate the resulting models using both frequentist and Bayesian data analysis.","cats":{"social-sciences":0}}
{"text":"We consider a new setting in which the Searcher has some potentially erroneous information, or prediction on the Hider's position.","cats":{"social-sciences":0}}
{"text":"In this case, the accelerator requires 18,268 logic cells and 51 BRAM, with an overall power consumption of 430mW and a latency of 54 us for a complete inference on input data.","cats":{"social-sciences":0}}
{"text":"To select the optimal camera, we design an optimal camera matching approach and implement a classifier for original prompts capable of automatically matching.","cats":{"social-sciences":0}}
{"text":"We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer.","cats":{"social-sciences":0}}
{"text":"To assess the framework's efficacy, it was applied on two LLMs, namely Llama2 and ChatGLM.","cats":{"social-sciences":0}}
{"text":"LoRA usually offers the most favorable trade-off between cost and performance.","cats":{"social-sciences":0}}
{"text":"In this study, we use not only a nucleotide sequence-based language model but also a text language model based on PubMed articles to reflect more biological background knowledge in the model.","cats":{"social-sciences":0}}
{"text":"The pre-trained model is fine-tuned using a large-scale instruction dataset, covering four core document intelligence tasks.","cats":{"social-sciences":0}}
{"text":"Large language model (LLM) scaling laws are empirical formulas that estimate changes in model quality as a result of increasing parameter count and training data.","cats":{"social-sciences":0}}
{"text":"In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination.","cats":{"social-sciences":0}}
{"text":"Recognizing the expressiveness of the pre-trained large language models, especially the potential of being augmented with abilities to understand and execute intricate commands, we introduce Open-TI.","cats":{"social-sciences":0}}
{"text":"Alignment, which can be viewed as the superimposition of normative structure onto a statistical model, reveals a conflicted and complex interrelationship between language and technology.","cats":{"social-sciences":0}}
{"text":"Despite the proficiency of LLMs in a range of tasks, their potential for understanding causality requires further exploration.","cats":{"social-sciences":0}}
{"text":"Although planning is a crucial component of the autonomous driving stack, researchers have yet to develop robust planning algorithms that are capable of safely handling the diverse range of possible driving scenarios.","cats":{"social-sciences":0}}
{"text":"To address these limitations, we investigate the possibility of leveraging the common-sense reasoning capabilities of Large Language Models (LLMs) such as GPT4 and Llama2 to generate plans for self-driving vehicles.","cats":{"social-sciences":0}}
{"text":"Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern.","cats":{"social-sciences":0}}
{"text":"This work introduces an innovative architecture that combines the strengths of ChatGPT with a traditional information retrieval based chatbot framework to offer enhanced student support in higher education.","cats":{"social-sciences":0}}
{"text":"We first present an extensive overview by categorizing these works in terms of various IE subtasks and learning paradigms, then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs.","cats":{"social-sciences":0}}
{"text":"Our new classifier improves zeroshot performance by 9.4%.","cats":{"social-sciences":0}}
{"text":"Hence, we present a framework to enhance the quantitative reasoning ability of language models based on dimension perception.","cats":{"social-sciences":0}}
{"text":"Moreover, we introduce Random Peek, a systematic technique considering an extended range of positions within the sequence, reducing the gap between discerning and generating truth features in LLMs.","cats":{"social-sciences":0}}
{"text":"Our strategy unfolds in three steps: (1) We invert the diffusion model for camera pose estimation instead of synthesizing novel views.","cats":{"social-sciences":0}}
{"text":"Experiments demonstrate strong performance in both pose estimation and novel view synthesis.","cats":{"social-sciences":0}}
{"text":"The combination of these approaches is found to be particularly effective at adhering to an author-specific style in a variety of conditions, including unconditional generation and style transfer, and is applicable to any underlying language model without requiring fine-tuning.","cats":{"social-sciences":0}}
{"text":"Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have brought about significant transformations in human society.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have brought significant and transformative changes in human society.","cats":{"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored.","cats":{"social-sciences":1}}
{"text":"The emergence of Large language models (LLMs) is expected to have a major impact on education.","cats":{"social-sciences":0,"education":1}}
{"text":"Large language models (LLMs) have recently taken the world by storm.","cats":{"social-sciences":0,"education":0}}
{"text":"As the Large Language Model (LLM) becomes increasingly important in various domains.","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning.","cats":{"social-sciences":0,"education":0}}
{"text":"We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs).","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have emerged as powerful and general solutions to many natural language tasks.","cats":{"social-sciences":0,"recommender":0}}
{"text":"Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law.","cats":{"social-sciences":1}}
{"text":"The emergence of large language models (LLMs) has significantly accelerated the development of a wide range of applications across various fields.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) may not equitably represent diverse global perspectives on societal issues.","cats":{"social-sciences":1}}
{"text":"In recent years, Large Language Models (LLMs) have gained immense attention due to their notable emergent capabilities, surpassing those seen in earlier language models.","cats":{"social-sciences":0,"education":0}}
{"text":"There is growing interest in ensuring that large language models (LLMs) align with human values.","cats":{"social-sciences":1}}
{"text":"Large-scale corpora play a vital role in the construction of large language models (LLMs).","cats":{"social-sciences":0}}
{"text":"The development of large language models (LLMs) has seen rapid progress in recent years.","cats":{"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have exerted a considerable impact on diverse language-related tasks in recent years.","cats":{"social-sciences":0}}
{"text":"Recently, there has been a growing interest in utilizing large language models (LLMs) in mental health research, with studies showcasing their remarkable capabilities, such as disease detection.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans.","cats":{"social-sciences":0}}
{"text":"Large Language Models (LLMs) have garnered significant attention for their powerful ability in natural language understanding and reasoning.","cats":{"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are smart but forgetful.","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"The scope of this research method is now poised to grow dramatically as it absorbs the new affordances provided by Large Language Models (LLM)s.","cats":{"social-sciences":0}}
{"text":"Recently, the development and progress of Large Language Models (LLMs) have amazed the entire Artificial Intelligence community.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"Interest in Large Language Models (LLMs) has increased drastically since the emergence of ChatGPT and the outstanding positive societal response to the ease with which it performs tasks in Natural Language Processing (NLP).","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc.","cats":{"social-sciences":0,"education":0}}
{"text":"The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP).","cats":{"social-sciences":0}}
{"text":"Recent years have witnessed remarkable progress made in large language models (LLMs).","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have demonstrated impressive capabilities in natural language generation.","cats":{"social-sciences":0}}
{"text":"Recent large language models (LLMs) have revealed strong abilities to understand natural language.","cats":{"social-sciences":0}}
{"text":"Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation.","cats":{"social-sciences":0}}
{"text":"Do large language models (LLMs) exhibit sociodemographic biases, even when they decline to respond?","cats":{"social-sciences":1}}
{"text":"With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts.","cats":{"social-sciences":1}}
{"text":"Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field.","cats":{"social-sciences":0}}
{"text":"Consequently, the rise of large language models (LLMs) has erupted a wealth of discussion around healthcare applications among researchers and consumers alike.","cats":{"social-sciences":1}}
{"text":"With large language models (LLMs) poised to become embedded in our daily lives, questions are starting to be raised about the dataset(s) they learned from.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) are trained to imitate humans to explain human decisions.","cats":{"social-sciences":0}}
{"text":"As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in this domain.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have recently demonstrated their potential in clinical applications, providing valuable medical knowledge and advice.","cats":{"social-sciences":1}}
{"text":"Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning.","cats":{"social-sciences":0,"education":0}}
{"text":"However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences.","cats":{"social-sciences":0}}
{"text":"Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition.","cats":{"social-sciences":1}}
{"text":"Reliance on the inherent knowledge of Large Language Models (LLMs) can cause issues such as hallucinations, lack of control, and difficulties in integrating variable knowledge.","cats":{"social-sciences":0}}
{"text":"To cater to the diverse text processing preferences of researchers in digital humanities and linguistics, we have developed three distinct categories comprising a total of nine model variations.","cats":{"social-sciences":1}}
{"text":"The paper makes an important contribution to multiple domains of social sciences and bridges them with computer science and computational linguistics.","cats":{"social-sciences":1}}
{"text":"Toward the end of the paper, we propose a potential framework of using automatic translation to leverage language bias and argue that the task of piecing together a genuine depiction of the elephant is a challenging and important endeavor that deserves a new area of research in NLP and requires collaboration with scholars from the humanities to create ethically sound and socially responsible technology together.","cats":{"social-sciences":1}}
{"text":"There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis.","cats":{"social-sciences":0}}
{"text":"To our best knowledge, it is the largest language model for the geoscience domain.","cats":{"social-sciences":0}}
{"text":"The rapid advance in artificial intelligence technology has facilitated the prosperity of digital humanities research.","cats":{"social-sciences":1}}
{"text":"This paper explores the use of large language models (LLMs) to flexibly navigate the conceptual clutter inherent to social scientific measurement tasks.","cats":{"social-sciences":1}}
{"text":"Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability.","cats":{"social-sciences":1}}
{"text":"We suggest that enriching sociality and thickening \"reality\" are two promising vectors for enhancing the truth-evaluating capacities of future language models.","cats":{"social-sciences":1}}
{"text":"Revolutionary advancements in Large Language Models have drastically reshaped our interactions with artificial intelligence systems.","cats":{"social-sciences":0}}
{"text":"Large language models, e.g. ChatGPT are currently contributing enormously to make artificial intelligence even more popular, especially among the general population.","cats":{"social-sciences":0}}
{"text":"Large language models have made significant progress in the past few years.","cats":{"social-sciences":0}}
{"text":"Large language models of artificial intelligence (AI) such as ChatGPT find remarkable but controversial applicability in science and research.","cats":{"social-sciences":0}}
{"text":"Against such backdrop, research methods need to be transformed in the intelligent processing of ancient texts, which is a crucial component of digital humanities research, so as to adapt to new development trends in the wave of AIGC.","cats":{"social-sciences":1}}
{"text":"Large text corpora are the backbone of language models.","cats":{"social-sciences":0}}
{"text":"We are amidst an explosion of artificial intelligence research, particularly around large language models (LLMs).","cats":{"social-sciences":0}}
{"text":"We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks:","cats":{"social-sciences":1}}
{"text":"While it demonstrates state-of-the-art capabilities in a variety of language-generating tasks, it also raises widespread public concerns regarding its societal impact.","cats":{"social-sciences":1}}
{"text":"Crucially, the model opens new avenues for community engagement in making digital history more representative of documentary history.","cats":{"social-sciences":0}}
{"text":"Large language models (LLMs) such as those embedded in 'chatbots' are accelerating and democratizing research by providing comprehensible information and expertise from many different fields.","cats":{"social-sciences":0}}
{"text":"It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity.","cats":{"social-sciences":0}}
{"text":"Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users.","cats":{"social-sciences":0}}
{"text":"Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera.","cats":{"social-sciences":0}}
{"text":"The advancement of large language models (LLMs) brings notable improvements across various applications, while simultaneously raising concerns about potential private data exposure.","cats":{"social-sciences":0}}
{"text":"In this paper, we propose an original framework for probing language models for societal biases.","cats":{"social-sciences":1}}
{"text":"The rise of large language models (LLMs) had a transformative impact on search, ushering in a new era of search engines that are capable of generating search results in natural language text, imbued with citations for supporting sources.","cats":{"social-sciences":0}}
{"text":"Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns.","cats":{"social-sciences":0}}
{"text":"Current large language models, such as OpenAI's ChatGPT, have captured the public's attention because how remarkable they are in the use of language.","cats":{"social-sciences":0}}
{"text":"This paper aims to bridge this gap by introducing CMMLU, a comprehensive Chinese benchmark that covers various subjects, including natural science, social sciences, engineering, and humanities.","cats":{"social-sciences":1}}
{"text":"As the capabilities of large language models (LLMs) continue to advance, evaluating their performance becomes increasingly crucial and challenging.  ","cats":{"social-sciences":0}}
{"text":"We conduct a thorough evaluation of 18 advanced multilingual- and Chinese-oriented LLMs, assessing their performance across different subjects and settings.","cats":{"social-sciences":0}}
{"text":"The results reveal that most existing LLMs struggle to achieve an average accuracy of 50%, even when provided with in-context examples and chain-of-thought prompts, whereas the random baseline stands at 25%.","cats":{"social-sciences":0}}
{"text":"This highlights significant room for improvement in LLMs.","cats":{"social-sciences":0}}
{"text":"Additionally, we conduct extensive experiments to identify factors impacting the models' performance and propose directions for enhancing LLMs.","cats":{"social-sciences":0}}
{"text":"CMMLU fills the gap in evaluating the knowledge and reasoning capabilities of large language models within the Chinese context.","cats":{"social-sciences":0}}
{"text":"On the one hand, LLMs offer unprecedented capabilities in analyzing vast amounts of textual data and generating human-like responses, enabling researchers to delve into complex social phenomena.","cats":{"social-sciences":1}}
{"text":"The emergence of Large Language Models (LLMs) has brought both excitement and concerns to social computing research.  ","cats":{"social-sciences":0}}
{"text":"This SIG aims at offering an open space for social computing researchers who are interested in understanding the impacts of LLMs to discuss their current practices, perspectives, challenges when","cats":{"social-sciences":0}}
{"text":"This poses a potential issue for transformer language models (LMs): they often train only on text, and thus lack access to extralinguistic information from which humans learn about animacy.","cats":{"social-sciences":1}}
{"text":"We ask: how does this impact LMs' animacy processing - do they still behave as humans do?","cats":{"social-sciences":0}}
{"text":"We answer this question using open-source LMs. Like previous studies, we find that LMs behave much like humans when presented with entities whose animacy is typical.","cats":{"social-sciences":1}}
{"text":"Even when the context indicating atypical animacy is very short, LMs pick up on subtle clues and change their behavior.","cats":{"social-sciences":1}}
{"text":"Animacy - whether an entity is alive and sentient - is fundamental to cognitive processing, impacting areas such as memory, vision, and language.","cats":{"social-sciences":0}}
{"text":"However, animacy is not always expressed directly in language: in English it often manifests indirectly, in the form of selectional constraints on verbs and adjectives.  ","cats":{"social-sciences":0}}
{"text":"We answer this question using open-source LMs.","cats":{"social-sciences":0}}
{"text":"Like previous studies, we find that LMs behave much that even when presented with stories about atypically animate entities, such as a peanut , LMs pick up on subtle clues and change their behavior.","cats":{"social-sciences":0}}
{"text":"We conclude that despite the limited signal through which LMs can learn about animacy, they are indeed sensitive to the relevant lexical semantic nuances available in English.","cats":{"social-sciences":0}}
{"text":"We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors.","cats":{"social-sciences":1}}
{"text":"LLM research is also shaped by social dynamics: we document gender and academic/industry disparities in the topics LLM authors focus on, and a US/China schism in the collaboration network.","cats":{"social-sciences":0}}
{"text":"Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting to the necessity of sociotechnical lenses.","cats":{"social-sciences":1}}
{"text":"Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022.","cats":{"social-sciences":0}}
{"text":"We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors' research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration.  ","cats":{"social-sciences":0}}
{"text":"Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting","cats":{"social-sciences":0}}
{"text":"Therefore, we address this gap by introducing the first comprehensive benchmark tailored to the unique characteristics of the mental health domain.","cats":{"social-sciences":1}}
{"text":"This benchmark encompasses a total of six sub-tasks, covering three dimensions, to systematically assess the capabilities of LLMs in the realm of mental health.","cats":{"social-sciences":1}}
{"text":"Experiment results not only demonstrate significant room for improvement in current LLMs concerning mental health but also unveil potential directions for future model optimization.","cats":{"social-sciences":0}}
{"text":"However, there is currently a lack of a comprehensive benchmark for evaluating the capability of LLMs in this domain.  ","cats":{"social-sciences":0}}
{"text":"This benchmark encompasses a total of six sub-tasks, covering three dimensions, to systematically assess the capabilities of LLMs in the realm of mrk.","cats":{"social-sciences":0}}
{"text":"Next-word probabilities from language models have been shown to successfully simulate human reading behavior.","cats":{"social-sciences":1}}
{"text":"Building on this, we show that, interestingly, instruction-tuned large language models (LLMs) yield worse psychometric predictive power (PPP) for human reading behavior than base LLMs with equivalent perplexities.","cats":{"social-sciences":1}}
{"text":"In other words, instruction tuning, which helps LLMs provide human-preferred responses, does not always make them human-like from the computational psycholinguistics perspective.","cats":{"social-sciences":1}}
{"text":"In addition, we explore prompting methodologies in simulating human reading behavior with LLMs, showing that prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit better PPP but are still worse than base LLMs.","cats":{"social-sciences":1}}
{"text":"These highlight that recent instruction tuning and prompting do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling.","cats":{"social-sciences":1}}
{"text":" Building on this, we show that, interestingly, instruction-tuned large language models (LLMs) yield worse psy them human-like from the computational psycholinguistics perspective.","cats":{"social-sciences":0}}
{"text":"In addition, we explore prompting methodologies in simulating human reading behavior with LLMs, showing that prompts reflecting a particular li than direct probability measurements from base LLMs in cognitive modeling.","cats":{"social-sciences":0}}
{"text":"This paper explores the use of open generative Large Language Models (LLMs) for annotation tasks in the social sciences.","cats":{"social-sciences":1}}
{"text":"Two examples of annotation tasks, sentiment analysis in tweets and identification of leisure activities in childhood aspirational essays are provided.","cats":{"social-sciences":1}}
{"text":"The study highlights the challenges associated with proprietary models, such as limited reproducibility and privacy concerns, and advocates for the adoption of open (source) models that can be operated on independent devices.","cats":{"social-sciences":0}}
{"text":"Two examples of annotation tasks, sentiment analysis in tweets and identification of leisure activities in childhood asplpha, openchat_3.5, zephyr-7b-alpha and zephyr-7b-beta).","cats":{"social-sciences":0}}
{"text":"The study highlights the advantages of open models for data privacy and reproducibility.","cats":{"social-sciences":0}}
{"text":"We first focus on evaluating the consistency of personality types exhibited by ChatGPT.","cats":{"social-sciences":1}}
{"text":"Large Language Models (LLMs) have made remarkable advancements in the field of artificial intelligence, significantly reshaping the human-computer interaction.  ","cats":{"social-sciences":0}}
{"text":"We first focus on evaluating the consistency of personality types exhibited btion of four other LLMs.","cats":{"social-sciences":0}}
{"text":"Moreover, the study investigates whether ChatGPT can exhibit personality changes in respontains its ENFJ personality regardless of instructions or contexts.","cats":{"social-sciences":0}}
{"text":"This paper documents a year-long experiment to \"profile\" the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process.","cats":{"social-sciences":0}}
{"text":"We added interactive quizzes to The Rust Programming Language, the official textbook for learning Rust.","cats":{"social-sciences":0}}
{"text":"Over 13 months, 62,526 readers answered questions 1,140,202 times.","cats":{"social-sciences":0}}
{"text":"First, we analyze the trajectories of readers.","cats":{"social-sciences":0}}
{"text":"We find that many readers drop-out of the book early when faced with difficult language concepts like Rust's ownership types.","cats":{"social-sciences":0}}
{"text":"Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions.","cats":{"social-sciences":0}}
{"text":"We find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles.","cats":{"social-sciences":0}}
{"text":"Third, we performed 12 interventions into the book to help readers with difficult questions.","cats":{"social-sciences":0}}
{"text":"We find that on average, interventions improved quiz scores on the targeted questions by +20%.","cats":{"social-sciences":0}}
{"text":"Fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small N.","cats":{"social-sciences":0,"programming":0}}
{"text":"These results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales.","cats":{"social-sciences":0}}
{"text":"Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC.","cats":{"social-sciences":0}}
{"text":"Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention.","cats":{"social-sciences":0}}
{"text":"However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs.","cats":{"social-sciences":0}}
{"text":"Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment.","cats":{"social-sciences":0}}
{"text":"Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource.","cats":{"social-sciences":0}}
{"text":"Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works.","cats":{"social-sciences":0}}
{"text":"Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments of text-audio alignment in TTA.","cats":{"social-sciences":0}}
{"text":"Our findings reveal Auffusion's superior capability in generating audios that accurately match textual descriptions, which further demonstrated in several related tasks, such as audio style transfer, inpainting and other manipulations.","cats":{"social-sciences":0}}
{"text":"Our implementation and demos are available at https://auffusion.github.io.","cats":{"social-sciences":0}}
{"text":"Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities.","cats":{"social-sciences":0}}
{"text":"The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively.","cats":{"social-sciences":0}}
{"text":"In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout.","cats":{"social-sciences":0}}
{"text":"Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure.","cats":{"social-sciences":0}}
{"text":"Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices.","cats":{"social-sciences":0}}
{"text":"Furthermore, we devise a pre-training objective that learns to infill text segments.","cats":{"social-sciences":0}}
{"text":"This approach allows us to address irregular layouts and heterogeneous content frequently encountered in visual documents.","cats":{"social-sciences":0}}
{"text":"We demonstrate that our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.","cats":{"social-sciences":0}}
{"text":"In order not to reproduce corpus biases, after initial training models must be aligned with human values, preferencing certain continuations over others.","cats":{"social-sciences":1}}
{"text":"We examine this practice of structuration as a two-way interaction between users and models by analysing how ChatGPT4 redacts perceived `anomalous' language in fragments of Joyce's Ulysses and the new linguistic practice of prompt engineering.","cats":{"social-sciences":1}}
{"text":"We then situate this alignment problem historically, revisiting earlier postwar linguistic debates which counterposed two views of meaning: as discrete structures, and as continuous probability distributions.","cats":{"social-sciences":1}}
{"text":"Our attention to the Moscow School and later related arguments by Searle and Kristeva casts the problem of alignment in a new light: as one involving attention to the social structuration of linguistic practice, including structuration of anomalies that, like the Joycean text, exist in defiance of expressive conventions.","cats":{"social-sciences":1}}
{"text":"These debates around the communicative orientation toward language can help explain some of the contemporary behaviours and interdependencies that take place between users and LLMs.","cats":{"social-sciences":0}}
{"text":"Large Language Models produce sequences learned as statistical patterns from large corpora.  Alignment, which can be viewed as the superimposition of normative structure onto a statistical model, reveals a conflicted and complex interrelationship between language and technology.","cats":{"social-sciences":0}}
{"text":"This relationship shapes theories of language, linguistic practice and subjectivity, which are especially relevant to the current sophistication in artificially produced text.","cats":{"social-sciences":0}}
{"text":"We examine this practice of structuration as a two-way interaction between users and models by analysing how ChatGPT4 redacts perceived `anomalous' langustructures, and as continuous probability distributions.","cats":{"social-sciences":0}}
{"text":"We discuss the largely occluded work of the Moscow Linguistic School, which sought to reconcile this opposition.","cats":{"social-sciences":0}}
{"text":"Our attention to the Moscow School and later related arguments by Searle at in defiance of expressive conventions.","cats":{"social-sciences":0}}
{"text":"While LISA effectively bridges the gap between segmentation and large language models to enable reasoning segmentation, it poses certain limitations: unable to distinguish different instances of the target region, and constrained by the pre-defined textual response formats.","cats":{"social-sciences":0}}
{"text":"In this work, we introduce LISA++, an update to the existing LISA model, focusing on improving core functionalities while keeping the base architecture intact.","cats":{"social-sciences":0}}
{"text":"The main enhancements in LISA++ include: \\textbf{1) Enhanced Segmentation}:","cats":{"social-sciences":0}}
{"text":"The instance segmentation ability has been added, providing a more detailed scene analysis along with the existing multi-region semantic segmentation.","cats":{"social-sciences":0}}
{"text":"\\textbf{2) More Natural Conversation}: Improved capability for multi-turn dialogue, with the ability to incorporate segmentation results directly into text responses, i.e., Segmentation in Dialogue (SiD).","cats":{"social-sciences":0}}
{"text":"These improvements are achieved by curating the existing samples of generic segmentation datasets, aimed specifically at enhancing the segmentation and conversational skills without structural change and additional data sources.","cats":{"social-sciences":0}}
{"text":"Comparative analysis with the original LISA model shows significant advancements in these areas, positioning LISA++ as a notable upgrade in visual understanding and interaction.","cats":{"social-sciences":0}}
{"text":"LISA++'s adaptability and improved features highlight the versatility of the mask-as-embedding paradigm proposed by LISA, and the potential as a foundational model for diverse applications.","cats":{"social-sciences":0}}
{"text":"Temporal Sentence Grounding (TSG), which aims to localize moments from videos based on the given natural language queries, has attracted widespread attention.","cats":{"social-sciences":0}}
{"text":"Existing works are mainly designed for short videos, failing to handle TSG in long videos, which poses two challenges: i) complicated contexts in long videos require temporal reasoning over longer moment sequences, and ii) multiple modalities including textual speech with rich information require special designs for content understanding in long videos.","cats":{"social-sciences":0}}
{"text":"To tackle these challenges, in this work we propose a Grounding-Prompter method, which is capable of conducting TSG in long videos through prompting LLM with multimodal information.","cats":{"social-sciences":0}}
{"text":"In detail, we first transform the TSG task and its multimodal inputs including speech and visual, into compressed task textualization.","cats":{"social-sciences":0}}
{"text":"Furthermore, to enhance temporal reasoning under complicated contexts, a Boundary-Perceptive Prompting strategy is proposed, which contains three folds: i) we design a novel Multiscale Denoising Chain-of-Thought (CoT) to combine global and local semantics with noise filtering step by step, ii) we set up validity principles capable of constraining LLM to generate reasonable predictions following specific formats, and iii) we introduce one-shot In-Context-Learning (ICL) to boost reasoning through imitation, enhancing LLM in TSG task understanding.","cats":{"social-sciences":0}}
{"text":"Experiments demonstrate the state-of-the-art performance of our Grounding-Prompter method, revealing the benefits of prompting LLM with multimodal information for TSG in long videos.","cats":{"social-sciences":0}}
{"text":"To address this, we introduce Social-Transmotion, a generic model that exploits the power of transformers to handle diverse and numerous visual cues, capturing the multi-modal nature of human behavior.","cats":{"social-sciences":1}}
{"text":"We translate the idea of a prompt from Natural Language Processing (NLP) to the task of human trajectory prediction, where a prompt can be a sequence of x-y coordinates on the ground, bounding boxes or body poses.","cats":{"social-sciences":1}}
{"text":"Accurate human trajectory prediction is crucial for applications such as autonomous vehicles, robotics, and surveillance systems.","cats":{"social-sciences":0}}
{"text":"Yet, existing models often fail to fully leverage the non-verbal social cues human subconsciously communicate when navigating the space.  ","cats":{"social-sciences":0}}
{"text":"We translate the idea of a prompt from Natural Language Processing (NLP) to the task of human trajectory prediction, where a prompt can be a sequence of x-y coordinates on the ground, bounding boxes orased on the available visual cues, whether they are poses, bounding boxes, or a combination thereof.","cats":{"social-sciences":0}}
{"text":"By the masking technique, we ensure our model's effectiveness even when certain visual cues are unavailable, although performance is further boosted with the presence of comprehensive visual data.","cats":{"social-sciences":0}}
{"text":"We delve into the merits of using 2d versus 3d poses, and a limited set of poses.","cats":{"social-sciences":0}}
{"text":"Additionally, we investigate the spatial and temporal attention map to identify which keypoints and frames of poses are vital for optimizing human trajectory prediction.","cats":{"social-sciences":0}}
{"text":"Our approach is validated on multiple datasets, including JTA, JRDB, Pedestrians and Cyclists in Road Traffic, and ETH-UCY.","cats":{"social-sciences":0}}
{"text":"The code is publicly available: https://github.com/vita-epfl/social-transmotion","cats":{"social-sciences":0}}
{"text":"(Source) code summarization is the task of automatically generating natural language summaries for given code snippets.","cats":{"social-sciences":0}}
{"text":"Such summaries play a key role in helping developers understand and maintain source code.","cats":{"social-sciences":0}}
{"text":"Recently, with the successful application of large language models (LLMs) in numerous fields, software engineering researchers have also attempted to adapt LLMs to solve code summarization tasks.","cats":{"social-sciences":0}}
{"text":"The main adaptation schemes include instruction prompting and task-oriented fine-tuning.","cats":{"social-sciences":0}}
{"text":"PromptCS","cats":{"social-sciences":0}}
{"text":"Compared to the human-written discrete prompt, the continuous prompts are produced under the guidance of LLMs and are therefore easier to understand by LLMs.","cats":{"social-sciences":0}}
{"text":"freezes the parameters of LLMs when training the prompt agent, which can greatly reduce the requirements for training resources.","cats":{"social-sciences":0}}
{"text":"We evaluate PromptCS","cats":{"social-sciences":0}}
{"text":"on the CodeSearchNet dataset involving multiple programming languages.","cats":{"social-sciences":0}}
{"text":"The results show that PromptCS","cats":{"social-sciences":0}}
{"text":"significantly outperforms instruction prompting schemes on all four widely used metrics.","cats":{"social-sciences":0}}
{"text":"In some base LLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS","cats":{"social-sciences":0}}
{"text":"even outperforms the task-oriented fine-tuning scheme.","cats":{"social-sciences":0}}
{"text":"More importantly, the training efficiency of PromptCS is faster than the task-oriented fine-tuning scheme, with a more pronounced advantage on larger LLMs.","cats":{"social-sciences":0}}
{"text":"The results of the human evaluation demonstrate that PromptCS can generate more good summaries compared to baselines.","cats":{"social-sciences":0}}
{"text":"Existing human-human interaction datasets typically suffer from inaccurate body motions, lack of hand gestures and fine-grained textual descriptions.","cats":{"social-sciences":1}}
{"text":"To better perceive and generate human-human interactions, we propose Inter-X, a currently largest human-human interaction dataset with accurate body movements and diverse interaction patterns, together with detailed hand gestures.","cats":{"social-sciences":1}}
{"text":"We also equip Inter-X with versatile annotations of more than 34K fine-grained human part-level textual descriptions, semantic interaction categories, interaction order, and the relationship and personality of the subjects.","cats":{"social-sciences":1}}
{"text":"The analysis of the ubiquitous human-human interactions is pivotal for understanding humans as social beings.  ","cats":{"social-sciences":0}}
{"text":"To better perceive and generate human-human interactions, we propose Inter-X, a currently largest human-human interaction dataset with accurate body ained human part-level textual descriptions, semantic interaction categories, interaction order, and the relationship and personality of the subjects.","cats":{"social-sciences":0}}
{"text":"Based on the elaborate annotations, we propose a unified benchmark composed of 4 categories of downstream tasks from both the perceptual and generative dirle for research purposes.","cats":{"social-sciences":0}}
{"text":"Multimodal Sarcasm Understanding (MSU) has a wide range of applications in the news field such as public opinion analysis and forgery detection.","cats":{"social-sciences":0}}
{"text":"However, existing MSU benchmarks and approaches usually focus on sentence-level MSU.","cats":{"social-sciences":0}}
{"text":"In document-level news, sarcasm clues are sparse or small and are often concealed in long text.","cats":{"social-sciences":0}}
{"text":"Moreover, compared to sentence-level comments like tweets, which mainly focus on only a few trends or hot topics (e.g., sports events), content in the news is considerably diverse.","cats":{"social-sciences":0}}
{"text":"Models created for sentence-level MSU may fail to capture sarcasm clues in document-level news.","cats":{"social-sciences":0}}
{"text":"To fill this gap, we present a comprehensive benchmark for Document-level Multimodal Sarcasm Understanding (DocMSU).","cats":{"social-sciences":0}}
{"text":"Our dataset contains 102,588 pieces of news with text-image pairs, covering 9 diverse topics such as health, business, etc.","cats":{"social-sciences":0}}
{"text":"The proposed large-scale and diverse DocMSU significantly facilitates the research of document-level MSU in real-world scenarios.","cats":{"social-sciences":0}}
{"text":"To take on the new challenges posed by DocMSU, we introduce a fine-grained sarcasm comprehension method to properly align the pixel-level image features with word-level textual features in documents.","cats":{"social-sciences":0}}
{"text":"Experiments demonstrate the effectiveness of our method, showing that it can serve as a baseline approach to the challenging DocMSU.","cats":{"social-sciences":0}}
{"text":"Our code and dataset are available at https://github.com/Dulpy/DocMSU.","cats":{"social-sciences":0}}
{"text":"Recent progress in text-guided image inpainting, based on the unprecedented success of text-to-image diffusion models, has led to exceptionally realistic and visually plausible results.","cats":{"social-sciences":0}}
{"text":"However, there is still significant potential for improvement in current text-to-image inpainting models, particularly in better aligning the inpainted area with user prompts and performing high-resolution inpainting.","cats":{"social-sciences":0}}
{"text":"Therefore, in this paper we introduce HD-Painter, a completely training-free approach that accurately follows to prompts and coherently scales to high-resolution image inpainting.","cats":{"social-sciences":0}}
{"text":"To this end, we design the Prompt-Aware Introverted Attention (PAIntA) layer enhancing self-attention scores by prompt information and resulting in better text alignment generations.","cats":{"social-sciences":0}}
{"text":"To further improve the prompt coherence we introduce the Reweighting Attention Score Guidance (RASG) mechanism seamlessly integrating a post-hoc sampling strategy into general form of DDIM to prevent out-of-distribution latent shifts.","cats":{"social-sciences":0}}
{"text":"Moreover, HD-Painter allows extension to larger scales by introducing a specialized super-resolution technique customized for inpainting, enabling the completion of missing regions in images of up to 2K resolution.","cats":{"social-sciences":0}}
{"text":"Our experiments demonstrate that HD-Painter surpasses existing state-of-the-art approaches qualitatively and quantitatively, achieving an impressive generation accuracy improvement of 61.4% vs 51.9%.","cats":{"social-sciences":0}}
{"text":"We will make the codes publicly available at: https://github.com/Picsart-AI-Research/HD-Painter","cats":{"social-sciences":0}}
{"text":"In this paper, we consider the problem of temporally aligning the video and texts from instructional videos, specifically, given a long-term video, and associated text sentences, our goal is to determine their corresponding timestamps in the video.","cats":{"social-sciences":0}}
{"text":"To this end, we establish a simple, yet strong model that adopts a Transformer-based architecture with all texts as queries, iteratively attending to the visual features, to infer the optimal timestamp.","cats":{"social-sciences":0}}
{"text":"We conduct thorough experiments to investigate: (i) the effect of upgrading ASR systems to reduce errors from speech recognition, (ii) the effect of various visual-textual backbones, ranging from CLIP to S3D, to the more recent InternVideo, (iii) the effect of transforming noisy ASR transcripts into descriptive steps by prompting a large language model (LLM), to summarize the core activities within the ASR transcript as a new training dataset.","cats":{"social-sciences":0}}
{"text":"As a result, our proposed simple model demonstrates superior performance on both narration alignment and procedural step grounding tasks, surpassing existing state-of-the-art methods by a significant margin on three public benchmarks, namely, 9.3% on HT-Step, 3.4% on HTM-Align and 4.7% on CrossTask.","cats":{"social-sciences":0}}
{"text":"We believe the proposed model and dataset with descriptive steps can be treated as a strong baseline for future research in temporal video-text alignment.","cats":{"social-sciences":0}}
{"text":"All codes, models, and the resulting dataset will be publicly released to the research community.","cats":{"social-sciences":0}}
{"text":"In the field of audio and speech analysis, the ability to identify emotions from acoustic signals is essential.","cats":{"social-sciences":1}}
{"text":"Human-computer interaction (HCI) and behavioural analysis are only a few of the many areas where the capacity to distinguish emotions from speech signals has an extensive range of applications.","cats":{"social-sciences":1}}
{"text":"Here, we are introducing BanSpEmo, a corpus of emotional speech that only consists of audio recordings and has been created specifically for the Bangla language.","cats":{"social-sciences":1}}
{"text":"The data set consists of 12 Bangla sentences which are uttered in 6 emotions as Disgust, Happy, Sad, Surprised, Anger, and Fear.","cats":{"social-sciences":1}}
{"text":"BanSpEmo can be considered as a useful resource to promote emotion and speech recognition research and related applications in the Bangla language.","cats":{"social-sciences":1}}
{"text":" Human-computer interaction (HCI) and behavioural analysis are only a few of the many areas where the capacity t been created specifically for the Bangla language.","cats":{"social-sciences":0}}
{"text":"This corpus contains 792 audio recordings over a duration of more than 1 hour and 23 minutes.","cats":{"social-sciences":0}}
{"text":"22 native speakers took part in the recording ofad, Surprised, Anger, and Fear.","cats":{"social-sciences":0}}
{"text":"This corpus is not also gender balanced.","cats":{"social-sciences":0}}
{"text":"Ten individuals who either have experience in related field or have acting experience took part in the assessment of this corpus.","cats":{"social-sciences":0}}
{"text":"It has a balanced number of audio recordings in each emotion class.","cats":{"social-sciences":0}}
{"text":"BanSpEmo can be considered as a useful resource to promote emotion and speech recognition researcand might be employed for academic research.","cats":{"social-sciences":0}}
{"text":"Furthermore, we explore the ability of chatbots to evaluate statements according to political communication concepts of disinformation, misinformation, and conspiracy theory, using definition-oriented prompts.","cats":{"social-sciences":1}}
{"text":"We also systematically test how such evaluations are influenced by source bias which we model by attributing specific claims to various political and social actors.","cats":{"social-sciences":0}}
{"text":"These findings highlight the potential of LLM-based chatbots in tackling different forms of false information in online environments, but also points to the substantial variation in terms of how such potential is realized due to specific factors, such as language of the prompt or the topic.","cats":{"social-sciences":0}}
{"text":"This article presents a comparative analysis of the ability of two large language model (LLM)-based chatbots, ChatGPT and Bing Chat, recently rebranded to Microsoft Copilot, to detect veracity of political information.","cats":{"social-sciences":0}}
{"text":"We use AI auditing methodology to investigate how chatbots evaluate true, false, and borderline statements on five topics: COVID-19, Russian aggression against Ukraine, the Holocaust, climate change, and LGBTQ+ related debates.","cats":{"social-sciences":0}}
{"text":"We compare how the chatbots perform in high- and low-resource languages by using prompts in English, Russian, and Ukrainian.  ","cats":{"social-sciences":0}}
{"text":"The results show high performance of ChatGPTorse with a 67 percent accuracy.","cats":{"social-sciences":0}}
{"text":"We observe significant disparities in how chatbots evaluate prompts in high- and low-resource languages and how they adapt their evaluations to political communication concepts with ChatGPT providing more nuanced outputs than Bing Chat.","cats":{"social-sciences":0}}
{"text":"Finally, we find that for some veracity detection-related tasks, the performance of chatbots varied depending on the topic of the statement or the source to which it is attributed.","cats":{"social-sciences":0}}
{"text":"However, maintaining human-like discourse structure in the generated text remains a challenging research question.","cats":{"social-sciences":1}}
{"text":"Instruction-tuned large language models have shown remarkable performance in aligning generated text with user intentions across various tasks.  ","cats":{"social-sciences":0}}
{"text":"In this paper, we propose Instruct-SCTG, a flexible and effective sequential framework that harnesses instruction-tuned language models to generate structurally coherent text in both fine-tuned and zero-shot setups.","cats":{"social-sciences":0}}
{"text":"Our framework generates articles in a section-by-section manner, aligned with the desired human structure using natural language instructions.","cats":{"social-sciences":0}}
{"text":"Furthermore, we introduce a new automatic metric that measures discourse divergence in a fuzzy manner.","cats":{"social-sciences":0}}
{"text":"Extensive experiments on three datasets from representative domains of news and recipes demonstrate the state-of-the-art performance of our framework in imposing discourse structure during text generation, as verified by both automatic and human evaluation.","cats":{"social-sciences":0}}
{"text":"Our code will be available on Github.","cats":{"social-sciences":0}}
{"text":"Speech-driven 3D facial animation aims to synthesize vivid facial animations that accurately synchronize with speech and match the unique speaking style.","cats":{"social-sciences":0}}
{"text":"However, existing works primarily focus on achieving precise lip synchronization while neglecting to model the subject-specific speaking style, often resulting in unrealistic facial animations.","cats":{"social-sciences":0}}
{"text":"To the best of our knowledge, this work makes the first attempt to explore the coupled information between the speaking style and the semantic content in facial motions.","cats":{"social-sciences":0}}
{"text":"Specifically, we introduce an innovative speaking style disentanglement method, which enables arbitrary-subject speaking style encoding and leads to a more realistic synthesis of speech-driven facial animations.","cats":{"social-sciences":0}}
{"text":"Subsequently, we propose a novel framework called \\textbf{Mimic} to learn disentangled representations of the speaking style and content from facial motions by building two latent spaces for style and content, respectively.","cats":{"social-sciences":0}}
{"text":"Moreover, to facilitate disentangled representation learning, we introduce four well-designed constraints: an auxiliary style classifier, an auxiliary inverse classifier, a content contrastive loss, and a pair of latent cycle losses, which can effectively contribute to the construction of the identity-related style space and semantic-related content space.","cats":{"social-sciences":0}}
{"text":"Extensive qualitative and quantitative experiments conducted on three publicly available datasets demonstrate that our approach outperforms state-of-the-art methods and is capable of capturing diverse speaking styles for speech-driven 3D facial animation.","cats":{"social-sciences":0}}
{"text":"The source code and supplementary video are publicly available at: https://zeqing-wang.github.io/Mimic/","cats":{"social-sciences":0}}
{"text":"This study delves into the pervasive issue of gender issues in artificial intelligence (AI), specifically within automatic scoring systems for student-written responses.","cats":{"social-sciences":1}}
{"text":"The primary objective is to investigate the presence of gender biases, disparities, and fairness in generally targeted training samples with mixed-gender datasets in AI scoring outcomes.","cats":{"social-sciences":1}}
{"text":"Utilizing a fine-tuned version of BERT and GPT-3.5, this research analyzes more than 1000 human-graded student responses from male and female participants across six assessment items.","cats":{"social-sciences":1}}
{"text":"The study employs three distinct techniques for bias analysis: Scoring accuracy difference to evaluate bias, mean score gaps by gender (MSG) to evaluate disparity, and Equalized Odds (EO) to evaluate fairness.","cats":{"social-sciences":1}}
{"text":"Consistently with both BERT and GPT-3.5, we found that mixed-trained models generated fewer MSG and non-disparate predictions compared to humans.","cats":{"social-sciences":1}}
{"text":"In contrast, compared to humans, gender-specifically trained models yielded larger MSG, indicating that unbalanced training data may create algorithmic models to enlarge gender disparities.","cats":{"social-sciences":1}}
{"text":"Collectively, the findings suggest that gender-unbalanced data do not necessarily generate scoring bias but can enlarge gender disparities and reduce scoring fairness.","cats":{"social-sciences":0}}
{"text":" The primary objective is to investigate the presence of gender biases, disparities, and fairness in generally targeted training samples with mixed-gender datasets in AI sessment items.","cats":{"social-sciences":0}}
{"text":"The study employs three distinct techniques for bias analysis: Scoring accuracy difference to evaluate bias, mean score gaps by gender (MSG) to evaluate disparity, and Equ, suggesting no significant scoring bias.","cats":{"social-sciences":0}}
{"text":"Consistently with both BERT and GPT-3.5, we found that mixed-trained models generated fewer MSG and non-disparate predictions compared to huma suggests that mixed-trained models generated more fairness outcomes compared with gender-specifically trained models.","cats":{"social-sciences":0}}
{"text":"Task-Oriented Parsing (TOP) enables conversational assistants to interpret user commands expressed in natural language, transforming them into structured outputs that combine elements of both natural language and intent/slot tags.","cats":{"social-sciences":0}}
{"text":"Recently, Large Language Models (LLMs) have achieved impressive performance in synthesizing computer programs based on a natural language prompt, mitigating the gap between natural language and structured programs.","cats":{"social-sciences":0,"programming":1}}
{"text":"Our paper focuses on harnessing the capabilities of LLMs for semantic parsing tasks, addressing the following three key research questions: 1) How can LLMs be effectively utilized for semantic parsing tasks?","cats":{"social-sciences":0}}
{"text":"and 3) How can LLM overcome the length constraint and streamline prompt design by including all examples as prompts?","cats":{"social-sciences":0}}
{"text":"Extensive experiments show that: 1)Simple ICL without kNN search can achieve a comparable performance with strong supervised models on the TOP tasks, and 2) kNN-ICL significantly improves the comprehension of complex requests by seamlessly integrating ICL with a nearest-neighbor approach.","cats":{"social-sciences":0}}
{"text":"Notably, this enhancement is achieved without the need for additional data or specialized prompts.","cats":{"social-sciences":0}}
{"text":"The growing popularity of neural machine translation (NMT) and LLMs represented by ChatGPT underscores the need for a deeper understanding of their distinct characteristics and relationships.","cats":{"social-sciences":0}}
{"text":"Such understanding is crucial for language professionals and researchers to make informed decisions and tactful use of these cutting-edge translation technology, but remains underexplored.","cats":{"social-sciences":0}}
{"text":"This study aims to fill this gap by investigating three key questions: (1) the distinguishability of ChatGPT-generated translations from NMT and human translation (HT), (2) the linguistic characteristics of each translation type, and (3) the degree of resemblance between ChatGPT-produced translations and HT or NMT.","cats":{"social-sciences":0}}
{"text":"To achieve these objectives, we employ statistical testing, machine learning algorithms, and multidimensional analysis (MDA) to analyze Spokesperson's Remarks and their translations.","cats":{"social-sciences":0}}
{"text":"After extracting a wide range of linguistic features, supervised classifiers demonstrate high accuracy in distinguishing the three translation types, whereas unsupervised clustering techniques do not yield satisfactory results.","cats":{"social-sciences":0}}
{"text":"Another major finding is that ChatGPT-produced translations exhibit greater similarity with NMT than HT in most MDA dimensions, which is further corroborated by distance computing and visualization.","cats":{"social-sciences":0}}
{"text":"These novel insights shed light on the interrelationships among the three translation types and have implications for the future advancements of NMT and generative AI.","cats":{"social-sciences":0}}
{"text":"This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria.","cats":{"social-sciences":1}}
{"text":"Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function.","cats":{"social-sciences":0}}
{"text":"In practice, preference learning from human feedback depends on incomplete data with hidden context.","cats":{"social-sciences":0}}
{"text":"Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model.  ","cats":{"social-sciences":0}}
{"text":"We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count.","cats":{"social-sciences":0}}
{"text":"We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility.","cats":{"social-sciences":0}}
{"text":"A key implication of this result is that annotators have an incentive to misreport te problems, we introduce a class of methods called distributional preference learning (DPL).","cats":{"social-sciences":0}}
{"text":"DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context.","cats":{"social-sciences":0}}
{"text":"Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.","cats":{"social-sciences":0}}
{"text":"Our code and data are available at https://github.com/cassidylaidlaw/hidden-context","cats":{"social-sciences":0}}
