{"text":"We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"We assume that the number of rows in decision tables from the closed class is not bounded from above by a constant.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"education":0}}
{"text":"Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0,"social-sciences":0,"education":0}}
{"text":"Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"recommender":0,"programming":0}}
{"text":"Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"social-sciences":0,"education":0,"programming":0}}
{"text":"Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts.","cats":{"prompt-engineering":1,"education":1,"programming":1}}
{"text":"These advances may enable students to interact with code in new ways while helping instructors scale their learning materials.","cats":{"prompt-engineering":1,"education":0,"programming":1}}
{"text":"However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers.","cats":{"prompt-engineering":1,"education":1}}
{"text":"Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.","cats":{"prompt-engineering":1,"education":1}}
{"text":"The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research.","cats":{"prompt-engineering":0,"education":1}}
{"text":"Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","cats":{"prompt-engineering":0,"education":1}}
{"text":"These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond.","cats":{"prompt-engineering":0,"education":1}}
{"text":"(4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations.","cats":{"robustness":1,"hci":0,"social-sciences":0,"education":0}}
{"text":"CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions.","cats":{"robustness":0,"hci":0,"education":0}}
{"text":"The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code).","cats":{"robustness":0,"hci":0,"social-sciences":0,"education":0,"programming":1}}
{"text":"Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work.","cats":{"security":0,"hci":0,"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria.","cats":{"hci":0,"education":0}}
{"text":"Large language models (LLMs) have shown the potential to be integrated into human daily lives.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are powerful tools for natural language processing, enabling novel applications and user experiences.","cats":{"hci":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have shown impressive success in various applications.","cats":{"hci":0,"education":0,"recommender":0,"production":0}}
{"text":"The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation.","cats":{"hci":0,"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks.","cats":{"hci":0,"social-sciences":0,"education":0,"programming":0}}
{"text":"Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like reasoning and long-context understanding.","cats":{"hci":0,"education":0}}
{"text":"The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change.","cats":{"hci":0,"education":0}}
{"text":"This work introduces an innovative architecture that combines the strengths of ChatGPT with a traditional information retrieval based chatbot framework to offer enhanced student support in higher education.","cats":{"social-sciences":0,"education":1}}
{"text":"Large language models (LLMs) have brought about significant transformations in human society.","cats":{"social-sciences":0,"education":0}}
{"text":"The emergence of Large language models (LLMs) is expected to have a major impact on education.","cats":{"social-sciences":0,"education":1}}
{"text":"Large language models (LLMs) have recently taken the world by storm.","cats":{"social-sciences":0,"education":0}}
{"text":"As the Large Language Model (LLM) becomes increasingly important in various domains.","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs).","cats":{"social-sciences":0,"education":0,"production":0}}
{"text":"In recent years, Large Language Models (LLMs) have gained immense attention due to their notable emergent capabilities, surpassing those seen in earlier language models.","cats":{"social-sciences":0,"education":0}}
{"text":"The development of large language models (LLMs) has seen rapid progress in recent years.","cats":{"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) have garnered significant attention for their powerful ability in natural language understanding and reasoning.","cats":{"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are smart but forgetful.","cats":{"social-sciences":0,"education":0,"recommender":0,"production":0}}
{"text":"Recently, the development and progress of Large Language Models (LLMs) have amazed the entire Artificial Intelligence community.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc.","cats":{"social-sciences":0,"education":0}}
{"text":"Recent years have witnessed remarkable progress made in large language models (LLMs).","cats":{"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability.","cats":{"social-sciences":0,"education":0}}
{"text":"Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning.","cats":{"social-sciences":0,"education":0}}
{"text":"Also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging.","cats":{"social-sciences":0,"education":0}}
{"text":"Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules.","cats":{"social-sciences":0,"education":0}}
{"text":"Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions.","cats":{"social-sciences":0,"education":0}}
{"text":"Extensive experiments are conducted on four widely used crowd counting datasets.","cats":{"social-sciences":0,"education":0}}
{"text":"This study delves into the pervasive issue of gender issues in artificial intelligence (AI), specifically within automatic scoring systems for student-written responses.","cats":{"social-sciences":1,"education":0}}
{"text":"Utilizing a fine-tuned version of BERT and GPT-3.5, this research analyzes more than 1000 human-graded student responses from male and female participants across six assessment items.","cats":{"social-sciences":1,"education":0}}
{"text":"Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students.","cats":{"education":1}}
{"text":"Large language models have shown success as a tutor in education in various fields.","cats":{"education":1}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text.","cats":{"education":0}}
{"text":"The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences.","cats":{"education":1}}
{"text":"Large Language Models (LLMs), trained predominantly on extensive English data, often exhibit limitations when applied to other languages.","cats":{"education":0,"recommender":0}}
{"text":"Large Language Models (LLMs) have shown remarkable abilities recently, including passing advanced professional exams and demanding benchmark tests.","cats":{"education":0}}
{"text":"Large language models (LLMs) have been applied in various applications due to their astonishing capabilities.","cats":{"education":0,"recommender":0}}
{"text":"In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions.","cats":{"education":0}}
{"text":"Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields.","cats":{"education":0,"recommender":0}}
{"text":"Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific instructions.","cats":{"education":0}}
{"text":"The past year has seen rapid acceleration in the development of large language models (LLMs).","cats":{"education":0}}
{"text":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization.","cats":{"education":0}}
{"text":"Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback...","cats":{"education":0}}
{"text":"As the capabilities of large language models (LLMs) continue to advance, evaluating their performance becomes increasingly crucial and challenging.","cats":{"education":0}}
{"text":"We share our approach to designing this new introductory socially responsible computing course and the students' reflections.","cats":{"education":0,"recommender":0,"architectures":0}}
{"text":"In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs).","cats":{"education":0}}
{"text":"Our experiments also shed light on how different various simple configurations can affect the True Positive (TP) and False Positive (FP) rates.","cats":{"education":0,"programming":0}}
{"text":"As a result of the search, EfficientDet-Lite4, an efficient and lightweight model for object detection, was selected.","cats":{"education":0}}
{"text":"On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously?","cats":{"education":0}}
{"text":"Graphs are typical non-Euclidean data of complex structures.","cats":{"education":0}}
{"text":"The proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use).","cats":{"education":0}}
{"text":"Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input.","cats":{"education":0}}
{"text":"However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps.","cats":{"education":0}}
{"text":"Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals.","cats":{"education":0}}
{"text":"Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping.","cats":{"education":0}}
{"text":"Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum.","cats":{"education":0}}
{"text":"Our students need to be able to examine the social complexities in which technology development and use are situated.","cats":{"education":0}}
{"text":"Grounded in theory of multimedia learning, this paper explores the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios.","cats":{"education":1}}
{"text":"This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educator's role, ensuring thus an effective and ethical use of AI in science education.","cats":{"education":1}}
{"text":"It calls for further research to explore the nuanced implications of MLLMs on the evolving role of educators and to extend the discourse beyond science education to other disciplines.","cats":{"education":1}}
{"text":"However, LLMs trained with SFT sometimes make simple mistakes and result in hallucinations on reasoning tasks such as question-answering.","cats":{"education":0}}
{"text":"However, the possibility of generating incorrect, biased, or unhelpful answers are a key challenge to resolve when deploying LLMs in an education context.","cats":{"education":1}}
{"text":"Through a comprehensive evaluation of the entire dataset using LLM assessment and a rigorous manual evaluation of 64 instances, we showcase the potential of LLMs in patient education.","cats":{"education":1}}
{"text":"We share results from user studies conducted on graduate students from <removed for double blind review>.","cats":{"education":0}}
{"text":"The student does not \"own\" their credentials, as the only way their accomplishments are directly linked to their person and considered valuable is by verification through a stamp of an expensive, prestigious institution.","cats":{"education":0}}
{"text":"However, going to a university is no longer the only way to acquire an education; open-source learning material is widely available and accessible through the internet.","cats":{"education":0}}
{"text":"However, our society does not deem these methods of education as verifiable if they do not include a degree or certificate.","cats":{"education":0}}
{"text":"Additionally, a valid certificate for the vast majority of open-source courses costs a few hundred dollars to obtain.","cats":{"education":0}}
{"text":"The centralized nature of education inadvertently places students in underprivileged communities at a disadvantage in comparison to students in economically advantaged communities, thus a decentralized approach to education would eliminate the vast majority of such discrepancies.","cats":{"education":0}}
{"text":"While several powerful distillation methods were recently proposed, the overall quality of student samples is typically lower compared to the teacher ones, which hinders their practical usage.","cats":{"education":0}}
{"text":"As our main empirical finding, we discover that a noticeable portion of student samples exhibit superior fidelity compared to the teacher ones, despite the ``approximate'' nature of the student.","cats":{"education":0}}
{"text":"Learning analytics research increasingly studies classroom learning with AI-based systems through rich contextual data from outside these systems, especially student-teacher interactions.","cats":{"education":1}}
{"text":"One key challenge in leveraging such data is generating meaningful insights into effective teacher practices.","cats":{"education":0}}
{"text":"The present study uses transmodal ordered network analysis to understand effective teacher practices in relationship to traditional metrics of in-system learning in a mathematics classroom working with AI tutors.","cats":{"education":1}}
{"text":"Comparing teacher practices by student learning rates, we find that students with low learning rates exhibited more hint use after monitoring.","cats":{"education":0}}
{"text":"However, after an extended visit, students with low learning rates showed learning behavior similar to their high learning rate peers, achieving repeated correct attempts in the tutor.","cats":{"education":0}}
{"text":"Taken together, offering early conceptual support to students with low learning rates could make classroom practice with AI tutors more effective.","cats":{"education":1}}
{"text":"This study advances the scientific understanding of effective teacher practice in classrooms learning with AI tutors and methodologies to make such practices visible.","cats":{"education":1}}
{"text":"We compare how teaching in AR differs from teaching through videoconferencing-based communication.","cats":{"education":0}}
{"text":"Therefore, in this study, we delve into LLMs' susceptibility to persuasive conversations, particularly on factual questions that they can answer correctly.","cats":{"education":0}}
{"text":"However, a major challenge in online learning is whether students are as engaged as they are in face-to-face classes.","cats":{"education":0}}
{"text":"An engagement recognition system can significantly improve the learning experience in online classes.","cats":{"education":0}}
{"text":"This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India.","cats":{"education":1}}
{"text":" Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","cats":{"education":0}}
{"text":"ound the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs amonuate engineering education and beyond.","cats":{"education":0}}
{"text":"This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.","cats":{"education":1}}
{"text":"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt.  ","cats":{"education":0}}
{"text":"However, LLMs also introduce new implications f LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research.","cats":{"education":0}}
{"text":"We will also engage","cats":{"education":0}}
{"text":"We explore the feasibility of using large language models (LLMs), a remarkable achievement in AI, to simulate student learning behaviors.","cats":{"education":1}}
{"text":"Unlike conventional machine learning based prediction, we leverage LLMs to instantiate virtual students with specific demographics and uncover intricate correlations among learning experiences, course materials, understanding levels, and engagement.","cats":{"education":1}}
{"text":"Collectively, these findings deepen our understanding of LLMs and demonstrate its viability for student simulation, empowering more adaptable curricula design to enhance inclusivity and educational effectiveness.","cats":{"education":0}}
{"text":"Student simulation presents a transformative approach to enhance learning outcomes, advance educational research, and ultimately shape the future of effective pedagogy.  ","cats":{"education":0}}
{"text":"Unlike conventional machine learning based prediction, we leverage LLMs to instantiate virtual students with specific demographics and unthis hypothesis through three experiments.","cats":{"education":0}}
{"text":"The first experiment, based on a dataset of N = 145, simulates student learning outcomes from demographic data, revealing parallels with actual students concerning various demographic factors.","cats":{"education":0}}
{"text":"The second experiment (N = 4524) results in increasingly realistic simulated behaviors with more assessment history for virtual students modelling.","cats":{"education":0}}
{"text":"The third experiment (N = 27), incorporating prior knowledge and course interactions, indicates a strong link between virtual students' learning behaviors and fine-grained mappings from test questions, course materials, engagement and understanding levels.","cats":{"education":0}}
{"text":"The use of deep learning methods for automatic detection of students' classroom behavior is a promising approach to analyze their class performance and enhance teaching effectiveness.","cats":{"education":1}}
{"text":"To address this issue, we propose a Student Classroom Behavior dataset (SCB-dataset) that reflects real-life scenarios.","cats":{"education":0}}
{"text":"Our dataset includes 11,248 labels and 4,003 images, with a focus on hand-raising behavior.","cats":{"education":1}}
{"text":" However, the lack of publicly available datasets on student behavior poses a challenge for researchers in this field.","cats":{"education":0}}
{"text":"Our dataset includes 11,248 labels and 4,003 images, with a focap) of up to 85.3%.","cats":{"education":0}}
{"text":"We believe that our dataset can serve as a robust foundation for future research in the field of stue downloaded from: https://github.com/Whiffe/SCB-dataset","cats":{"education":0}}
{"text":"The promise and difficulties of language model-based approaches for physics teaching were assessed in this study.","cats":{"education":1}}
{"text":"This study evaluates how well ChatGPT and BingChat, two state-of-the-art (SOTA) large language models (LLMs), perform when answering high school physics questions on Vietnamese exams from 2019 to 2023.","cats":{"education":1}}
{"text":"When we compared the results of the LLMs with the scores of Vietnamese students, we discovered that ChatGPT and BingChat both perform worse than Vietnamese students, proving that LLMs are not yet capable of fully replacing human intellect in the field of physics teaching.","cats":{"education":1}}
{"text":"The outcomes also showed that neither LLM is capable of responding to questions at the high application levels.","cats":{"education":1}}
{"text":"Our research suggests that LLMs can help students and teachers during learning and teaching activities, particularly by offering immediate feedback and individualized learning experiences.","cats":{"education":1}}
{"text":"This study evaluates how well ChatGPT and BingChat, two state-of-the-art (SOTA) large language models (LLMs), perBingChat both perform worse than Vietnamese students, proving that LLMs are not yet capable of fully replacing human intellect in the field of physics teaching.","cats":{"education":0}}
{"text":"The outcomes also showed that neither LLMs, particularly by offering immediate feedback and individualized learning experiences.","cats":{"education":0}}
{"text":"To address this issue and investigate the applicability of large language models (LLMs) in CQA simulation, we propose a simulation framework that employs zero-shot learner LLMs for simulating teacher-student interactions.","cats":{"education":1}}
{"text":"Our framework involves two LLMs interacting on a specific topic, with the first LLM acting as a student, generating questions to explore a given search topic.","cats":{"education":0}}
{"text":"The second LLM plays the role of a teacher by answering questions and is equipped with additional information, including a text on the given topic.","cats":{"education":1}}
{"text":"We implement both the student and teacher by zero-shot prompting the GPT-4 model.","cats":{"education":1}}
{"text":"To assess the effectiveness of LLMs in simulating CQA interactions and understand the disparities between LLM- and human-generated conversations, we evaluate the simulated data from various perspectives.","cats":{"education":1}}
{"text":"Next, we evaluate the performance of the student, analyzing and comparing the disparities between questions generated by the LLM and those generated by humans.","cats":{"education":1}}
{"text":"Furthermore, we conduct extensive analyses to thoroughly examine the LLM performance by benchmarking state-of-the-art reading comprehension models on both datasets.","cats":{"education":1}}
{"text":"Our results reveal that the teacher LLM generates lengthier answers that tend to be more accurate and complete.","cats":{"education":1}}
{"text":"The student LLM generates more diverse questions, covering more aspects of a given topic.","cats":{"education":1}}
{"text":"Conversational question-answering (CQA) systems aim to create interactive search systems that effectively retrieve information by interacting with users.","cats":{"education":0}}
{"text":"To replicate human-to-human conversations, existing work uses human annotators to play the roles of the questioner (student) and the answerer (teacher).","cats":{"education":0}}
{"text":"Despite its effectiveness, challenges exist as human annotation is time-consuming, inconsistent, and not scalable.  ","cats":{"education":0}}
{"text":"The second LLM plays the role of a teacher by answering questi-4 model.","cats":{"education":0}}
{"text":"To assess the effectiveness of LLMs in simulating CQA interactions and understand the disparities between LLM- and human-generated conversations, we .","cats":{"education":0}}
{"text":"Next, we evaluate the performance of the student, analyzing and comparing the disparities between questions generated by the LLM and those generate LLM performance by benchmarking state-of-the-art reading comprehension models ona given topic.","cats":{"education":0}}
{"text":"First, we contribute a dataset for studying this problem: SIGHT is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel.","cats":{"education":1}}
{"text":"To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale.","cats":{"education":0}}
{"text":"We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.","cats":{"education":0}}
{"text":"Lectures are a learning experience for both students and teachers.","cats":{"education":0}}
{"text":"Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction.","cats":{"education":0}}
{"text":"However, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve.","cats":{"education":0}}
{"text":"We take a step towards tackling this challenge.  ","cats":{"education":0}}
{"text":"Second, we develop a rubric for categorizing feedback types using qualitative analysis.","cats":{"education":0}}
{"text":"Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources.","cats":{"education":0}}
{"text":"We observe a striking correlation between the model's and humans' annotation: Categoriesth less consistent human annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower human-model agreement ($0.3$-$0.5$).","cats":{"education":0}}
{"text":"These techniques uncover useful student feedback from thousands of comments, costing around $\\$0.002$ per comment.","cats":{"education":0}}
