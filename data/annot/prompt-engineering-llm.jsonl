{"text":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT.","cats":{"prompt-engineering-llm":1}}
{"text":"Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output.","cats":{"prompt-engineering-llm":1}}
{"text":"This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","cats":{"prompt-engineering-llm":1}}
{"text":"This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks.","cats":{"prompt-engineering-llm":1}}
{"text":"First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains.","cats":{"prompt-engineering-llm":0}}
{"text":"Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations.","cats":{"prompt-engineering-llm":0}}
{"text":"Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","cats":{"prompt-engineering-llm":1}}
{"text":" Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated ot engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","cats":{"prompt-engineering-llm":0}}
{"text":"Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to cearch on prompt engineering that apply LLMs to automate software development tasks.","cats":{"prompt-engineering-llm":0}}
{"text":"Third, it explains how prompts","cats":{"prompt-engineering-llm":0}}
{"text":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented.","cats":{"prompt-engineering-llm":1}}
{"text":"Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","cats":{"prompt-engineering-llm":0}}
{"text":"This paper provides two contributions to research on using LLMs for software engineering.","cats":{"prompt-engineering-llm":0}}
{"text":"First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve.","cats":{"prompt-engineering-llm":0}}
{"text":"Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts.","cats":{"prompt-engineering-llm":1}}
{"text":"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt.  ","cats":{"prompt-engineering-llm":0}}
{"text":"These advances may enable students to interact with code in new ways while helping instructors scale their learning materials.","cats":{"prompt-engineering-llm":0}}
{"text":"However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers.","cats":{"prompt-engineering-llm":0}}
{"text":"This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research.","cats":{"prompt-engineering-llm":0}}
{"text":"We will also engage attendees in brainstorming to consider how LLMs will impact our field.","cats":{"prompt-engineering-llm":0}}
{"text":"Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities.","cats":{"prompt-engineering-llm":1}}
{"text":"As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident.","cats":{"prompt-engineering-llm":1}}
{"text":"This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering.","cats":{"prompt-engineering-llm":1}}
{"text":"We present influential large models in the visual domain and a range of prompt engineering methods employed on these models.","cats":{"prompt-engineering-llm":1}}
{"text":" As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident.","cats":{"prompt-engineering-llm":0}}
{"text":"Designing suitable prompts for specific visual tasks has emergeor large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering.","cats":{"prompt-engineering-llm":0}}
{"text":"We present influential large models in the visual domain and a range of prompt engineering methods emploure researchers in their exploration of this field.","cats":{"prompt-engineering-llm":0}}
{"text":"Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research.","cats":{"prompt-engineering-llm":1}}
{"text":"We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges.","cats":{"prompt-engineering-llm":1}}
{"text":"GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization.","cats":{"prompt-engineering-llm":0}}
{"text":"Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text.","cats":{"prompt-engineering-llm":0}}
{"text":"This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data.","cats":{"prompt-engineering-llm":0}}
{"text":"A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them.  ","cats":{"prompt-engineering-llm":0}}
{"text":"We use this position paper to develop a research agenda for the use of prompt engineering for BPM research","cats":{"prompt-engineering-llm":0}}
{"text":"This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images.","cats":{"prompt-engineering-llm":1}}
{"text":"In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art.","cats":{"prompt-engineering-llm":0}}
{"text":"Our results suggest that prompt engineering is a learned skill that requires expertise and practice.","cats":{"prompt-engineering-llm":0}}
{"text":"Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering.","cats":{"prompt-engineering-llm":0}}
{"text":"We conclude by speculating on four possible futures of prompt engineering.","cats":{"prompt-engineering-llm":0}}
{"text":"Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content.","cats":{"prompt-engineering-llm":0}}
{"text":"The paradigm under which this revolution takes place is prompt-based learning (or in-context learning).","cats":{"prompt-engineering-llm":0}}
{"text":"This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art.  ","cats":{"prompt-engineering-llm":0}}
{"text":"In three studies with pecognize the quality of prompts, 2) write prompts, and 3) improve their prompts.","cats":{"prompt-engineering-llm":0}}
{"text":"Our results indicate that participants could assess the quality of prompts and respective images.","cats":{"prompt-engineering-llm":0}}
{"text":"This ability increased with the participants' experience and interest in art.","cats":{"prompt-engineering-llm":0}}
{"text":"Participants further were able to write prompts in rich descriptive language.","cats":{"prompt-engineering-llm":0}}
{"text":"However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images.","cats":{"prompt-engineering-llm":0}}
{"text":"Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide teering with a paid crowd.","cats":{"prompt-engineering-llm":0}}
{"text":"Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.","cats":{"prompt-engineering-llm":1}}
{"text":"The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research.","cats":{"prompt-engineering-llm":0}}
{"text":"Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","cats":{"prompt-engineering-llm":0}}
{"text":"This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India.  ","cats":{"prompt-engineering-llm":0}}
{"text":"These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond.","cats":{"prompt-engineering-llm":0}}
{"text":"While LLMs are powerful, it is also crucial to best use their power where \"prompt'' plays a core role.","cats":{"prompt-engineering-llm":1}}
{"text":"Therefore, in this work, we survey related prompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models.","cats":{"prompt-engineering-llm":1}}
{"text":"Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant advancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas.  ","cats":{"prompt-engineering-llm":0}}
{"text":"However, the booming LLMs themselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2) the lack of physical capabilities to perform external actions.","cats":{"prompt-engineering-llm":0}}
{"text":"Recently, we have observed the trend of utilizing prompt-based tools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology, partly due to the rapid evolution of this field.","cats":{"prompt-engineering-llm":0}}
{"text":"Therefore, in this work, we survey related prompting tools and promote the concept of the \"Prompting F, Base Level, Execute Level, and Service Level.","cats":{"prompt-engineering-llm":0}}
{"text":"We also systematically depict the overall landscape of the emerging PF field and discuss potential future research and challenges.","cats":{"prompt-engineering-llm":0}}
{"text":"To continuously track the developments in this area, we maintain a repository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for both academic and industry in this field.","cats":{"prompt-engineering-llm":0}}
{"text":"Specifically, the framework begins by composing task descriptions, current traffic conditions, and prior knowledge into a prompt.","cats":{"prompt-engineering-llm":1}}
{"text":"Subsequently, we utilize LLM's chain-of-thought (CoT) reasoning ability to identify the next traffic signal phase, ensuring optimal efficiency in the road network.","cats":{"prompt-engineering-llm":1}}
{"text":"Notably, LLMLight showcases remarkable generalization, interpretability, and zero-shot reasoning abilities, even without any training for transportation management tasks.","cats":{"prompt-engineering-llm":1}}
{"text":"Traffic signal control is crucial for optimizing the efficiency of road network by regulating traffic light phases.","cats":{"prompt-engineering-llm":0}}
{"text":"Existing research predominantly focuses on heuristic or reinforcement learning (RL)-based methods, which often lack transferability across diverse traffic scenarios and suffer from poor interpretability.","cats":{"prompt-engineering-llm":0}}
{"text":"This paper introduces a novel approach, LLMLight, utilizing large language models (LLMs) for traffic signal control tasks.","cats":{"prompt-engineering-llm":0}}
{"text":"By leveraging LLMs' impressive generalization and zero-shot reasoning capabilities, LLMLight executes a human-like decision-making process for efficient traffic management.  ","cats":{"prompt-engineering-llm":0}}
{"text":"Subsequently, we utilize LLM's chain-of-thought (CoT) reasoning ability to identify the next traffic signal phase, ensuring optimcases remarkable generalization, interpretability, and zero-shot reasoning abilities, even without any training for transportation management tasks.","cats":{"prompt-engineering-llm":0}}
{"text":"Our project is available at https://github.com/usail-hkust/LLMTSCS.","cats":{"prompt-engineering-llm":0}}
{"text":"Augmenting LMs by retrieving information from external knowledge resources is one promising solution.","cats":{"prompt-engineering-llm":1}}
{"text":"Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input.","cats":{"prompt-engineering-llm":1}}
{"text":"In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation.","cats":{"prompt-engineering-llm":0}}
{"text":"We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic retrieval-augmented generation method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.","cats":{"prompt-engineering-llm":1}}
{"text":"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output.  ","cats":{"prompt-engineering-llm":0}}
{"text":"Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves informnually gathering information throughout the generation process is essential.","cats":{"prompt-engineering-llm":0}}
{"text":"There have been some past efforts to retrieve information multiple times while generating outputs, which mostly retrieve documents at fixed intervals using the previous context as queries.","cats":{"prompt-engineering-llm":0}}
{"text":"We propose Forward-Looking Active REtrieval augmented ized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.","cats":{"prompt-engineering-llm":0}}
{"text":"We test FLARE along with baselines comprehensively over 4 long-for","cats":{"prompt-engineering-llm":0}}
{"text":"Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs.","cats":{"prompt-engineering-llm":1}}
{"text":"Applications of RAG in the field of medical education are discussed in this paper.","cats":{"prompt-engineering-llm":0}}
{"text":"Large Language Models are increasingly being used for various tasks including content generation and as chatbots.","cats":{"prompt-engineering-llm":0}}
{"text":"Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers.  ","cats":{"prompt-engineering-llm":0}}
{"text":"A combined extractive and abstrac vectors is proposed.","cats":{"prompt-engineering-llm":0}}
{"text":"Retrieval-augmented language models (RALMs) represent a substantial advancement in the capabilities of large language models, notably in reducing factual hallucination by leveraging external knowledge sources.","cats":{"prompt-engineering-llm":1}}
{"text":"In response to these challenges, we introduces Chain-of-Noting (CoN), a novel approach aimed at improving the robustness of RALMs in facing noisy, irrelevant documents and in handling unknown scenarios.","cats":{"prompt-engineering-llm":0}}
{"text":"The core idea of CoN is to generate sequential reading notes for retrieved documents, enabling a thorough evaluation of their relevance to the given question and integrating this information to formulate the final answer.","cats":{"prompt-engineering-llm":1}}
{"text":" However, the reliability of the retrieved information is not always guaranteed.","cats":{"prompt-engineering-llm":0}}
{"text":"The retrieval of irrelevant data can lead to misguided responses, and potentially causing the model to overlook its inherent knowledge, even when it possesses adequate information to address the query.","cats":{"prompt-engineering-llm":0}}
{"text":"Moreover, standard RALMs often struggle to assess whether they possess adequate knowledge, both intrinsic and retrieved, to provide an accurate answer.","cats":{"prompt-engineering-llm":0}}
{"text":"In situations where knowledge is lacking, these systems should ideally respond with \"unknown\" when the answer is unattainable.","cats":{"prompt-engineering-llm":0}}
{"text":"The cofinal answer.","cats":{"prompt-engineering-llm":0}}
{"text":"We employed ChatGPT to create training data for CoN, which was subsequently trained on an LLaMa-2 7B model.","cats":{"prompt-engineering-llm":0}}
{"text":"Our experiments across four open-domain QA benchmarks show that RALMs equipped wiide the pre-training knowledge scope.","cats":{"prompt-engineering-llm":0}}
{"text":"Finding and refining prompts that produce a desired image has become the art of prompt engineering.","cats":{"prompt-engineering-llm":1}}
{"text":"In light of an extensive literature review, we reframe prompt engineering for generative models as interactive text-based retrieval on a novel kind of \"infinite index\".","cats":{"prompt-engineering-llm":1}}
{"text":"Finally, we envision how active learning may help to guide the retrieval of generated images.","cats":{"prompt-engineering-llm":0}}
{"text":"Conditional generative models such as DALL-E and Stable Diffusion generate images based on a user-defined text, the prompt.  ","cats":{"prompt-engineering-llm":0}}
{"text":"Generative models do not provide a built-in retrieval model for a user's information need expressed through prompts.","cats":{"prompt-engineering-llm":0}}
{"text":"In light of an extensive literature review, we reframe prompt engineering for generative models as h an expert.","cats":{"prompt-engineering-llm":0}}
{"text":"Retrieval-augmented language models show promise in addressing issues like outdated information and hallucinations in language models (LMs).","cats":{"prompt-engineering-llm":1}}
{"text":"Therefore, we introduce RegaVAE, a retrieval-augmented language model built upon the variational auto-encoder (VAE).","cats":{"prompt-engineering-llm":0}}
{"text":" However, current research faces two main problems: 1) determining what information to retrieve, and 2) effectively combining retrieved information during generation.","cats":{"prompt-engineering-llm":0}}
{"text":"We argue that valuable retrieved information should not only be related to the current source text but also consider the future target text, given the nature of LMs that model future tokens.","cats":{"prompt-engineering-llm":0}}
{"text":"Moreover, we propose that aggregation using latent variables derived from a compact latent space is more efficient than utilizing explicit raw text, which is limited by context length and susceptible to noise.","cats":{"prompt-engineering-llm":0}}
{"text":"It encodes the text cor leverage the VAE to initialize the latent space and adopt the probabilistic form of the retrieval generation paradigm by expanding the Gaussian prior distribution into a Gaussian mixture distribution.","cats":{"prompt-engineering-llm":0}}
{"text":"Theoretical analysis provides an optimizable upper bound for RegaVAE.","cats":{"prompt-engineering-llm":0}}
{"text":"Experimental results on various datasets demonstrate significant improvements in text generation quality and hallucination removal.","cats":{"prompt-engineering-llm":0}}
{"text":"In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance.","cats":{"prompt-engineering-llm":1}}
{"text":"We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs.","cats":{"prompt-engineering-llm":1}}
{"text":"Large Language Models (LLMs) are smart but forgetful.","cats":{"prompt-engineering-llm":0}}
{"text":"Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence.","cats":{"prompt-engineering-llm":0}}
{"text":"However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures.","cats":{"prompt-engineering-llm":0}}
{"text":"Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023).","cats":{"prompt-engineering-llm":0}}
{"text":"However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models.  ","cats":{"prompt-engineering-llm":0}}
{"text":"We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high s.","cats":{"prompt-engineering-llm":0}}
{"text":"This report examines the effectiveness of Chain-of-Thought (CoT) prompting in improving the multi-step reasoning abilities of large language models (LLMs).","cats":{"prompt-engineering-llm":1}}
{"text":"Inspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the impact of three types of CoT prompt perturbations, namely CoT order, CoT values, and CoT operators on the performance of GPT-3 on various tasks.","cats":{"prompt-engineering-llm":1}}
{"text":"Moreover, incorrect demonstrations, where the CoT operators or the CoT order are wrong, do not affect the performance as drastically when compared to the value based perturbations.","cats":{"prompt-engineering-llm":0}}
{"text":"This research deepens our understanding of CoT prompting and opens some new questions regarding the capability of LLMs to learn reasoning in context.","cats":{"prompt-engineering-llm":0}}
{"text":" Inspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the impact of three types of CoT prompt perturbations, namely CoT order, CoT values, answers.","cats":{"prompt-engineering-llm":0}}
{"text":"Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues.","cats":{"prompt-engineering-llm":1}}
{"text":"Here we present the first release of ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning.","cats":{"prompt-engineering-llm":0}}
{"text":"The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data.","cats":{"prompt-engineering-llm":1}}
{"text":"Large language models (LLMs) such as GPT-3 and ChatGPT have recently demonstrated impressive results across a wide range of tasks.","cats":{"prompt-engineering-llm":0}}
{"text":"LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases.  ","cats":{"prompt-engineering-llm":0}}
{"text":"The goal of ThoughtSource is to improve future artifiaining data.","cats":{"prompt-engineering-llm":0}}
{"text":"This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word qu","cats":{"prompt-engineering-llm":0}}
{"text":"Certain statistical models are capable of interpreting input strings as instructions, or prompts, and carry out tasks based on them.","cats":{"prompt-engineering-llm":1}}
{"text":"Many approaches to prompting and pre-training these models involve the automated generation of these prompts.","cats":{"prompt-engineering-llm":1}}
{"text":"We call these approaches meta-prompting, or prompting to obtain prompts.","cats":{"prompt-engineering-llm":1}}
{"text":"This framework is flexible enough to account for LLM stochasticity; and allows us to obtain formal results around task agnosticity and equivalence of various meta-prompting approaches.","cats":{"prompt-engineering-llm":1}}
{"text":"Using our framework, we argue that meta-prompting is more effective than basic prompting at generating desirable outputs.","cats":{"prompt-engineering-llm":1}}
{"text":" Many approaches to prompting and pre-training these models involve the automated generation of these prompts.","cats":{"prompt-engineering-llm":0}}
{"text":"We call these approachy to generalize and describe them.","cats":{"prompt-engineering-llm":0}}
{"text":"This framework is flexible enough to account for LLM stochasticity; and allof various meta-prompting approaches.","cats":{"prompt-engineering-llm":0}}
{"text":"We experiment with meta-prompting in two active areas of model research: creativity and ideation.","cats":{"prompt-engineering-llm":0}}
{"text":"We find that user preference fUsing our framework, we argue that meta-prompting is more effective than basic prompting at generating desirable outputs.","cats":{"prompt-engineering-llm":0}}
{"text":"The study explores the effectiveness of the Chain-of-Thought approach, known for its proficiency in language tasks by breaking them down into sub-tasks and intermediate steps, in improving vision-language tasks that demand sophisticated perception and reasoning.","cats":{"prompt-engineering-llm":1}}
{"text":"We present the \"Description then Decision\" strategy, which is inspired by how humans process signals.","cats":{"prompt-engineering-llm":0}}
{"text":"This strategy significantly improves probing task performance by 50%, establishing the groundwork for future research on reasoning paradigms in complex vision-language tasks.","cats":{"prompt-engineering-llm":0}}
{"text":"Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored.","cats":{"prompt-engineering-llm":1}}
{"text":"This strategy of process of elimination (PoE), when used with COT, has the potential to enhance interpretability in tasks like medical diagnoses of exclusion.","cats":{"prompt-engineering-llm":1}}
{"text":"Thus, we propose PoE with COT, a new task where LLMs must reason toward incorrect options on multiple-choice questions.","cats":{"prompt-engineering-llm":1}}
{"text":"We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice commonsense and scientific reasoning datasets.","cats":{"prompt-engineering-llm":1}}
{"text":" This strategy of process of elimination (PoE), when used with COT, has the potential to enhance interpretability in tasks like medical diagnoses of exclusion.","cats":{"prompt-engineering-llm":0}}
{"text":"Thus, we proalcon to perform PoE with COT on 2-choice commonsense and scientific reasoning datasets.","cats":{"prompt-engineering-llm":0}}
{"text":"We show that PoE consistently underperforms directly choosing the corrissues further, we conduct an error analysis and give suggestions for future work.","cats":{"prompt-engineering-llm":0}}
{"text":"We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action.","cats":{"prompt-engineering-llm":1}}
{"text":"To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos.","cats":{"prompt-engineering-llm":1}}
{"text":"MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts.","cats":{"prompt-engineering-llm":1}}
{"text":" In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models.","cats":{"prompt-engineering-llm":0}}
{"text":"To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualirgetic combination of ChatGPT and various vision experts.","cats":{"prompt-engineering-llm":0}}
{"text":"Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advauning.","cats":{"prompt-engineering-llm":0}}
{"text":"Code, demo, video, and visualization are available at https://multimodal-react.github.io/","cats":{"prompt-engineering-llm":0}}
{"text":"Recent efforts have incorporated large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning.","cats":{"prompt-engineering-llm":1}}
{"text":"To address this challenge, we draw on the rich history of agent design in symbolic artificial intelligence to develop a blueprint for a new wave of cognitive language agents.","cats":{"prompt-engineering-llm":0}}
{"text":"We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework.","cats":{"prompt-engineering-llm":0}}
{"text":" However, these efforts have largely been piecemeal, lacking a systematic framework for constructing a fully-fledged language agent.","cats":{"prompt-engineering-llm":0}}
{"text":"We first show that LLMs hnd production systems.","cats":{"prompt-engineering-llm":0}}
{"text":"Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the","cats":{"prompt-engineering-llm":0}}
