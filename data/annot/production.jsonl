{"text":"Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions.","cats":{"prompt-engineering":0,"security":0,"production":0}}
{"text":"We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development.","cats":{"prompt-engineering":0,"security":0,"production":0}}
{"text":"The study concludes by addressing the challenges faced and suggesting potential research directions in this field.","cats":{"prompt-engineering":0,"social-sciences":0,"production":0}}
{"text":"This paper provides two contributions to research on using LLMs for software engineering.","cats":{"prompt-engineering":0,"production":0}}
{"text":"The research addresses concerns related to hallucinations and false research articles by introducing a custom workflow developed with a detection algorithm to filter out inaccuracies.","cats":{"robustness":1,"production":0}}
{"text":"This research explores the integration of large language models (LLMs) into scientific data assimilation, focusing on combustion science as a case study.","cats":{"robustness":0,"production":0}}
{"text":"Leveraging foundational models integrated with Retrieval-Augmented Generation (RAG) framework, the study introduces an approach to process diverse combustion research data, spanning experimental studies, simulations, and literature.","cats":{"robustness":0,"production":0}}
{"text":"The developed approach minimizes computational and economic expenses while optimizing data privacy and accuracy.","cats":{"robustness":0,"production":1}}
{"text":"It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models.","cats":{"robustness":0,"social-sciences":0,"production":1}}
{"text":"By incorporating an external database, the framework outperforms a conventional LLM in generating accurate responses and constructing robust arguments.","cats":{"robustness":0,"production":0}}
{"text":"Despite identified areas for improvement, the framework consistently delivers accurate domain-specific responses with minimal human oversight.","cats":{"robustness":0,"production":0}}
{"text":"The prompt-agnostic approach introduced holds promise for future deliberations.","cats":{"robustness":0,"production":0}}
{"text":"The study underscores the significance of integrating LLMs and knowledge processing techniques in scientific research, providing a foundation for advancements in data assimilation and utilization.","cats":{"robustness":0,"production":0}}
{"text":"For this purpose, data from low-cost in-vehicle inertial sensors such as the accelerometer and gyroscope sensor are fused and fed into a long short-term memory (LSTM) neural network.","cats":{"security":0,"production":0}}
{"text":"Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus.","cats":{"security":0,"production":0}}
{"text":"With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus.","cats":{"security":0,"production":0}}
{"text":"Our method achieves human-level performance in estimating fetal biometrics and estimates well-calibrated credible intervals in which the true biometric value is expected to lie.","cats":{"security":0,"social-sciences":0,"production":0}}
{"text":"To collect data, a vehicle equipped with a GNSS receiver, along with Inertial Measurement Unit (IMU) is used.","cats":{"security":0,"production":0}}
{"text":"The detection framework incorporates two strategies: The first strategy involves comparing the predicted location shift, which is the distance traveled between two consecutive timestamps, with the inertial sensor-based location shift.","cats":{"security":0,"production":0}}
{"text":"The second strategy employs a Random-Forest supervised machine learning model to detect and classify turns, distinguishing between left and right turns using the output from the steering angle sensor.","cats":{"security":0,"production":0}}
{"text":"Importantly, the IMU data remains uncompromised throughout the spoofing attack.","cats":{"security":0,"hci":0,"production":0}}
{"text":"To test the effectiveness of the detection framework, experiments are conducted in Tuscaloosa, AL, mimicking urban road structures.","cats":{"security":0,"production":0}}
{"text":"In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations.","cats":{"security":0,"production":0}}
{"text":"Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area.","cats":{"security":0,"production":0}}
{"text":"Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness.","cats":{"security":0,"recommender":0,"production":0}}
{"text":"A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented.","cats":{"security":0,"production":0}}
{"text":"Large language models (LLMs) have shown impressive success in various applications.","cats":{"hci":0,"education":0,"recommender":0,"production":0}}
{"text":"In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration.","cats":{"hci":0,"production":0}}
{"text":"The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading.","cats":{"hci":0,"production":0}}
{"text":"In this work, we revisit this topic in the context of large language models.","cats":{"hci":0,"production":0}}
{"text":"These digital companions often lack memory of past interactions, while relying heavily on the internet for speech processing, raising privacy concerns.","cats":{"hci":0,"production":0}}
{"text":"RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving.","cats":{"hci":0,"production":0}}
{"text":"Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results.","cats":{"hci":0,"production":0}}
{"text":"However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training.","cats":{"hci":0,"production":0}}
{"text":"The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information.","cats":{"hci":0,"social-sciences":0,"production":0}}
{"text":"To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack.","cats":{"hci":0,"production":0}}
{"text":"TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively.","cats":{"hci":0,"production":0}}
{"text":"TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization.","cats":{"hci":0,"production":0}}
{"text":"In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales.","cats":{"hci":0,"production":0}}
{"text":"Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.","cats":{"hci":0,"production":0}}
{"text":"In the age of personal voice assistants, the question of privacy arises.","cats":{"hci":0,"production":0}}
{"text":"Modern smartphones now enable on-device speech processing, making cloud-based solutions unnecessary.","cats":{"hci":0,"production":0}}
{"text":"Personal assistants for the elderly should excel at memory recall, especially in medical examinations.","cats":{"hci":0,"production":0}}
{"text":"The e-ViTA project developed a versatile conversational application with local processing and speaker recognition.","cats":{"hci":0,"production":0}}
{"text":"This paper highlights the importance of speaker diarization enriched with sensor data fusion for contextualized conversation preservation.","cats":{"hci":0,"production":0}}
{"text":"The use cases applied to the e-VITA project have shown that truly personalized dialogue is pivotal for individual voice assistants.","cats":{"hci":0,"production":0}}
{"text":"Secure local processing and sensor data fusion ensure virtual companions meet individual user needs without compromising privacy or data security.","cats":{"hci":0,"production":0}}
{"text":"As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial.","cats":{"hci":0,"production":0,"architectures":0,"programming":0}}
{"text":"One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language.","cats":{"hci":0,"production":0,"architectures":0,"programming":0}}
{"text":"In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages.","cats":{"hci":0,"production":0,"architectures":1,"programming":0}}
{"text":"We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning.","cats":{"hci":0,"production":0,"architectures":1,"programming":0}}
{"text":"Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning.","cats":{"hci":0,"production":0,"architectures":0,"programming":0}}
{"text":"In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those languages.","cats":{"hci":0,"production":0,"programming":0}}
{"text":"Finally, we find that increasing the number of languages in the instruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual generalization.","cats":{"hci":0,"production":0,"architectures":0,"programming":0}}
{"text":"Our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses.","cats":{"hci":0,"production":0,"architectures":0,"programming":0}}
{"text":"To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework.","cats":{"social-sciences":0,"production":0}}
{"text":"The current approach to fetal anomaly screening is based on biometric measurements derived from individually selected ultrasound images.","cats":{"social-sciences":0,"production":0}}
{"text":"We use a Bayesian method to estimate the true value of each biometric from a large number of measurements and probabilistically reject outliers.","cats":{"social-sciences":0,"production":0}}
{"text":"In this case, the accelerator requires 18,268 logic cells and 51 BRAM, with an overall power consumption of 430mW and a latency of 54 us for a complete inference on input data.","cats":{"social-sciences":0,"production":0}}
{"text":"Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern.","cats":{"social-sciences":0,"production":0}}
{"text":"Our new classifier improves zeroshot performance by 9.4%.","cats":{"social-sciences":0,"production":0}}
{"text":"We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs).","cats":{"social-sciences":0,"education":0,"production":0}}
{"text":"Large Language Models (LLMs) are smart but forgetful.","cats":{"social-sciences":0,"education":0,"recommender":0,"production":0}}
{"text":"This highlights significant room for improvement in LLMs.","cats":{"social-sciences":0,"production":0}}
{"text":"Furthermore, we explore the ability of chatbots to evaluate statements according to political communication concepts of disinformation, misinformation, and conspiracy theory, using definition-oriented prompts.","cats":{"social-sciences":1,"production":0}}
{"text":"We also systematically test how such evaluations are influenced by source bias which we model by attributing specific claims to various political and social actors.","cats":{"social-sciences":0,"production":0}}
{"text":"These findings highlight the potential of LLM-based chatbots in tackling different forms of false information in online environments, but also points to the substantial variation in terms of how such potential is realized due to specific factors, such as language of the prompt or the topic.","cats":{"social-sciences":0,"production":0}}
{"text":"This article presents a comparative analysis of the ability of two large language model (LLM)-based chatbots, ChatGPT and Bing Chat, recently rebranded to Microsoft Copilot, to detect veracity of political information.","cats":{"social-sciences":0,"production":0}}
{"text":"We use AI auditing methodology to investigate how chatbots evaluate true, false, and borderline statements on five topics: COVID-19, Russian aggression against Ukraine, the Holocaust, climate change, and LGBTQ+ related debates.","cats":{"social-sciences":0,"production":0}}
{"text":"We observe significant disparities in how chatbots evaluate prompts in high- and low-resource languages and how they adapt their evaluations to political communication concepts with ChatGPT providing more nuanced outputs than Bing Chat.","cats":{"social-sciences":0,"production":0}}
{"text":"Finally, we find that for some veracity detection-related tasks, the performance of chatbots varied depending on the topic of the statement or the source to which it is attributed.","cats":{"social-sciences":0,"production":0}}
{"text":"We share results from user studies conducted on graduate students from <removed for double blind review>.","cats":{"education":0,"production":0}}
{"text":"Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively.","cats":{"recommender":0,"production":0}}
{"text":"We thoroughly analyze the performance of several large language models (LLMs) and identify areas where further improvement is needed.","cats":{"recommender":0,"production":0}}
{"text":"Large language models (LLMs) with memory are computationally universal.","cats":{"recommender":0,"production":0}}
{"text":"As more IoT applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge.","cats":{"recommender":0,"production":0}}
{"text":"Through a customized IoT application workflow instance, experimental results show that KCES is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks.","cats":{"recommender":0,"production":0,"programming":0}}
{"text":"We use a convolutional neural network to classify each frame of an ultrasound video recording.","cats":{"recommender":0,"production":0,"architectures":0}}
{"text":"The latency is comparable to the ones observed in the state-of-the-art, with 780us/img.","cats":{"recommender":0,"production":0}}
{"text":"In this paper, we propose an effective approach that can make the deployment of LLMs more efficiently.","cats":{"production":1}}
{"text":"Moreover, the high run-time cost of LLMs may hinder their deployments in production.","cats":{"production":0}}
{"text":"This work shall be treated as the initial effort to systematic evaluation of LLMs in NetOps, and a more rigorous study is required for production use.","cats":{"production":1}}
{"text":"Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment.","cats":{"production":0}}
{"text":"Meanwhile, we have also organized and presented papers with evaluation content to reveal the performance and effectiveness of LLMs in various software engineering tasks, providing guidance for researchers and developers to optimize.","cats":{"production":0,"programming":1}}
{"text":"We have categorized these papers in detail and reviewed the current research status of LLMs from the perspective of seven major software engineering tasks, hoping this will help researchers better grasp the research trends and address the issues when applying LLMs.","cats":{"production":0,"programming":1}}
{"text":"We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component.","cats":{"production":1}}
{"text":"Yet, how to evaluate and analyze the tool-utilization capability of LLMs is still under-explored.","cats":{"production":0}}
{"text":"We show that, without extensive configuration or prompt engineering, LLMs perform comparably to or better than existing solutions and discuss implications for future BPM research as well as practical usage.","cats":{"production":0}}
{"text":"It implies the creation of a great variety of LLMs with different capabilities.","cats":{"production":0}}
{"text":"As a result, there is a growing need to develop LLM that are specifically tailored to the unique requirements of the media domain.","cats":{"production":0}}
{"text":"This paper aims to explore the challenges and opportunities of developing LLM for media applications and to propose potential solutions for addressing these challenges.","cats":{"production":0}}
{"text":"However, it remains under-explored how well LLMs perform in various NetOps tasks.","cats":{"production":0}}
{"text":"Our findings show the potential of LLMs while also surfacing challenges and fruitful avenues for future research.","cats":{"production":0}}
{"text":"Overall, our findings shows that the behavior of the same LLM service can change substantially in a relatively short amount of time, highlighting the need for continuous monitoring of LLM quality.","cats":{"production":1}}
{"text":"We are committed to continually pushing the boundaries of LLMs through this open-source effort.","cats":{"production":0}}
{"text":"(2) Can LLMs effectively handle software engineering tasks?","cats":{"production":0}}
{"text":"Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.","cats":{"production":0,"architectures":0}}
{"text":"The results of our investigation emphasize the immense potential of FP quantization for LLMs, paving the way for high-efficiency deployment in resource-limited settings.","cats":{"production":1}}
{"text":"We are still learning how to best \"program\" these LLMs to help developers.","cats":{"production":0}}
{"text":"Meanwhile, the evaluation and optimization of LLMs in software engineering tasks, such as code generation, have become a research focus.","cats":{"production":0}}
{"text":"Recently, there has been escalating interest in deploying LLMs for robotics, aiming to harness the power of foundation models in real-world settings.","cats":{"production":0}}
{"text":"As a result, the LLMs have proliferated.","cats":{"production":0}}
{"text":"For industry applications, it is imperative to assess the performance of the LLM on unlabeled production data from time to time to validate for a real-world setting.","cats":{"production":0}}
{"text":"Therefore, this paper is the first to comprehensively investigate and collate the research and products combining LLMs with software engineering, aiming to answer two questions: (1) What are the current integrations of LLMs with software engineering?","cats":{"production":0}}
{"text":"We perform comparisons and analyses of different settings and conduct 10 conclusions that can provide some insights for evaluating LLM in the future.","cats":{"production":0}}
{"text":"The LLM landscape can be divided into two primary categories: proprietary and open-source.","cats":{"production":0}}
{"text":"Our findings include that (1) the best performing LLM outperforms existing approaches by 9.1--13.7% with a few similar examples, (2) the two dominant root causes combined (ineffective prompts and missing domain knowledge) result in 57--60% of LLM failures, and (3) most of the 11 LLMs achieve better or comparable performance compared to traditional techniques.","cats":{"production":0}}
{"text":"By doing so, we aim to bridge the gap between the general-purpose LLM and the requirements of the media domain, and to pave the way for more effective and efficient use of LLM in this field.","cats":{"production":0}}
{"text":"This work studies post-training parameter quantization in large language models (LLMs).","cats":{"production":1}}
{"text":"We confirm that the W4A8 quantization is achievable for the deployment of large language models, fostering their wide-spreading real-world applications.","cats":{"production":1}}
{"text":"Our results also highlight the challenges of quantizing multilingual models, which must generalize to languages they were not fine-tuned on.","cats":{"production":0}}
{"text":"We investigate the effects of post-training quantization and quantization-aware training on the generalization of Transformer language models.","cats":{"production":1}}
{"text":"The usage of Large Language Models (LLMs) has increased recently, not only due to the significant improvements in their accuracy but also because of the use of the quantization that allows running these models without intense hardware requirements.","cats":{"production":1}}
{"text":"This study represents a significant step forward in the evolution of efficient, scalable, and high-performing large language models, setting a precedent for future exploration and optimization in this domain.","cats":{"production":0}}
{"text":"Large Language Models have many methods for solving the same problem.","cats":{"production":0}}
{"text":"Large language models have demonstrated impressive capabilities in enabling this shift.","cats":{"production":0}}
{"text":"We also covered some recent advancements in calibrating large models, particularly large language models (LLMs).","cats":{"production":0}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks.","cats":{"production":0}}
{"text":"The training corpus of large language models often includes some algorithmic components, which allows them to achieve certain effects on some graph data-related problems.","cats":{"production":0}}
{"text":"We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner.","cats":{"production":1}}
{"text":"We use PIE to evaluate and improve the capacity of large language models.","cats":{"production":0}}
{"text":"Large Language Models work quite well with general-purpose data and many tasks in Natural Language Processing.","cats":{"production":0}}
{"text":"Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks.","cats":{"production":0}}
{"text":"Second, we continue training the model with a large-scale parallel dataset that covers 102 natural languages.","cats":{"production":0}}
{"text":"Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks.","cats":{"production":0,"programming":1}}
{"text":"Quantization has emerged as a promising direction for model compression.","cats":{"production":1}}
{"text":"Reasoning presents a significant and challenging issue for Large Language Models (LLMs).","cats":{"production":0}}
{"text":"Extensive experiments on popular models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing post-training quantization methods for large models.","cats":{"production":1}}
{"text":"Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models.","cats":{"production":0}}
{"text":"Our work investigates whether recent advances in Large Language Models, and in particular ChatGPT, can address this issue.","cats":{"production":0}}
{"text":"The results demonstrate the framework's ability to detect various sophisticated GNSS spoofing attacks, even including slow position drifting attacks.","cats":{"production":0}}
{"text":"Overall, the experimental results showcase the robustness and efficacy of the sensor fusion-based spoofing attack detection approach in safeguarding AVs against GNSS spoofing threats.","cats":{"production":0}}
{"text":"Vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation.","cats":{"production":0}}
{"text":"We also integrate a residual vector quantization (RVQ) mechanism for effective multilevel communication.","cats":{"production":0}}
{"text":"In this paper, we delve into the neighborhood propagation mechanism of GNNs and discover that the real root cause of GNNs' performance degradation in deep layers lies in ineffective neighborhood feature propagation.","cats":{"production":0}}
{"text":"This paper proposes a novel NeRF steganography method based on trainable noise: Noise-NeRF.","cats":{"production":0}}
{"text":"Furthermore, we propose the Adaptive Pixel Selection strategy and Pixel Perturbation strategy to improve the steganography quality and efficiency.","cats":{"production":0}}
{"text":"The extensive experiments on open-source datasets show that Noise-NeRF provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography.","cats":{"production":0}}
{"text":"Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training.","cats":{"production":0}}
{"text":"A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning.","cats":{"production":0}}
{"text":"Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training clients.","cats":{"production":0}}
{"text":"Based on this, we design a time-frequency convolutional neural network (TF-CNN) to diagnose various faults in rolling-element bearings.","cats":{"production":0}}
{"text":"Altogether, the TF-CNN achieves substantial accuracy improvements up to 15%, in severe noise conditions.","cats":{"production":0}}
{"text":"Video compression has long been regarded as the primary means of efficiently managing the substantial multimedia traffic generated by video-capturing devices.","cats":{"production":0}}
{"text":"This complexity presents a formidable challenge when implementing efficient video coding standards in resource-constrained embedded systems, such as IoT edge node cameras.","cats":{"production":0}}
{"text":"To tackle this challenge, this paper introduces NU-Class Net, an innovative deep-learning model designed to mitigate compression artifacts stemming from lossy compression codecs.","cats":{"production":0}}
{"text":"This enhancement significantly elevates the perceptible quality of low-bit-rate videos.","cats":{"production":0}}
{"text":"By employing the NU-Class Net, the video encoder within the video-capturing node can reduce output quality, thereby generating low-bit-rate videos and effectively curtailing both computation and bandwidth requirements at the edge.","cats":{"production":0}}
{"text":"This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications.","cats":{"production":0}}
{"text":"This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs.","cats":{"production":0}}
{"text":"This paper introduces HPC-Net, a high-precision and rapidly convergent object detection network.","cats":{"production":0}}
{"text":"To achieve fairness in serving, we propose a novel scheduling algorithm, the Virtual Token Counter (VTC), a fair scheduler based on the continuous batching mechanism.","cats":{"production":0}}
{"text":"To mitigate this limitation, we scrutinize the RLHF objective in the offline dataset and propose uncertainty-penalized RLHF (UP-RLHF), which incorporates uncertainty regularization during RL-finetuning.","cats":{"production":1}}
{"text":"Its key features include in-band error detection for real-time error identification without extra overhead, a dynamic cost-aware plan generation mechanism for optimal reconfiguration, and an efficient transition strategy to reduce downtime during state changes.","cats":{"production":1}}
{"text":"Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources.","cats":{"production":0}}
{"text":"A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields.","cats":{"production":0}}
{"text":"Motivated by this, we investigate how data privacy can be ensured in LLM fine-tuning through practical federated learning approaches, enabling secure contributions from multiple parties to enhance LLMs.","cats":{"production":0}}
{"text":"DP-LoRA preserves data privacy by employing a Gaussian mechanism that adds noise in weight updates, maintaining individual data privacy while facilitating collaborative model training.","cats":{"production":0}}
{"text":"In contrast, we use 3D data to establish an automatic pipeline to determine authentic ground truth amodal masks for partially occluded objects in real images.","cats":{"production":0}}
{"text":"Using this strategy, we build can run Mixtral-8x7B with mixed quantization on desktop hardware and free-tier Google Colab instances.","cats":{"production":1}}
{"text":"This approach ensures that personalization does not interfere with the restoration process, resulting in a natural appearance with high fidelity to the person's identity and the attributes of the degraded image.","cats":{"production":0}}
{"text":"Later, we survey adversarial works within simpler network settings, specifically in one-hop and two-hop configurations, and delve into adversarial robustness concerning challenges posed by jamming, timestomping, and issues related to privacy leakage.","cats":{"production":0}}
{"text":"To produce such a massive dataset, we utilize a novel and meticulous dataset processing pipeline to curate two publicly available datasets, VFHQ and CelebV-HQ, which contain many high-resolution face videos captured in various settings.","cats":{"production":0}}
{"text":"What does learning to model relationships between strings teach large language models (LLMs) about the visual world?","cats":{"production":0}}
{"text":"We systematically evaluate LLMs' abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text.","cats":{"production":0}}
{"text":"As language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study.","cats":{"production":0}}
{"text":"Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world.","cats":{"production":0}}
{"text":"The capabilities of the most recent language models have increased the interest in integrating them into real-world applications.","cats":{"production":0,"architectures":0}}
{"text":"However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains.","cats":{"production":0,"architectures":0}}
{"text":"Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being.","cats":{"production":0}}
{"text":"In this paper, we present Physio, a chat-based application for physical rehabilitation.","cats":{"production":0}}
{"text":"Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided.","cats":{"production":0}}
{"text":"Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief.","cats":{"production":0}}
{"text":"By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources.","cats":{"production":0}}
{"text":"A live demo of Physio is available at https://physio.inesctec.pt.","cats":{"production":0}}
{"text":"The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks.","cats":{"production":0}}
{"text":"Building upon UltraChat, we fine-tune a LLaMA model to create a powerful conversational model, UltraLLaMA.","cats":{"production":0}}
{"text":"We fine-tune LLaMA on ToolBench and obtain ToolLLaMA.","cats":{"production":0}}
{"text":"Falcon-180B significantly outperforms models such as PaLM or Chinchilla, and improves upon concurrently developed models such as LLaMA 2 or Inflection-1.","cats":{"production":0}}
{"text":"We report detailed evaluations, as well as a deep dive into the methods and custom tooling employed to pretrain Falcon.","cats":{"production":0}}
{"text":"Then we fine-tune the LLaMA-2 models on MetaMathQA.","cats":{"production":0}}
{"text":"However, concerns regarding data privacy have emerged, especially when multiple stakeholders aim to collaboratively enhance LLMs using sensitive data. In this scenario, federated learning becomes a natural choice, allowing decentralized fine-tuning without exposing raw data to central servers.","cats":{"production":1}}
{"text":"To address these challenges, this article introduces DP-LoRA, a novel federated learning algorithm tailored for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that adds noise in weight updates, maintaining individual data privacy while facilitating collaborative model training.","cats":{"production":1}}
{"text":"The surge in interest and application of large language models (LLMs) has sparked a drive to fine-tune these models to suit specific applications, such as finance and medical science.  ","cats":{"production":0}}
{"text":"Yet, challenges arise: 1) despite avoiding raw data exposure, there is a risk of inferring ng algorithm tailored for LLMs.","cats":{"production":0}}
{"text":"Moreover, DP-LoRA optimizes communication efficiency via low-rank adaptation, minimizing the transmission of updated weights during distributed training.","cats":{"production":0}}
{"text":"The experimental results across medical","cats":{"production":0}}
{"text":"To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP).","cats":{"production":1}}
{"text":"In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs.","cats":{"production":1}}
{"text":"The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users.","cats":{"production":0}}
{"text":"On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks.","cats":{"production":0}}
{"text":"On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage.  ","cats":{"production":0}}
{"text":"Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs.","cats":{"production":0}}
{"text":"In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify tted inference data privacy during actual usage.","cats":{"production":0}}
{"text":"P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning.","cats":{"production":0}}
{"text":"Then, P-Bench constructs a unified pipeline to perform private fine-tuning.","cats":{"production":0}}
{"text":"Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results.","cats":{"production":0}}
{"text":"The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs.","cats":{"production":0}}
{"text":"We conduct extensive experiments on three datasets of GLUE for mainstream LMs.","cats":{"production":0}}
{"text":"To contrast this shortcoming, this paper introduces Context-Aware Differentially Private Language Model (CADP-LM) , a privacy-preserving LM framework that relies on two key insights:","cats":{"production":1}}
{"text":"A unique characteristic of CADP-LM is its ability to target the protection of sensitive sentences and contexts only, providing a highly accurate private model.","cats":{"production":0}}
{"text":"The remarkable ability of language models (LMs) has also brought challenges at the interface of AI and security.","cats":{"production":0}}
{"text":"A critical challenge pertains to how much information these models retain and leak about the training data.","cats":{"production":0}}
{"text":"This is particularly urgent as the typical development of LMs relies on huge, often highly sensitive data, such as emails and chat logs.  ","cats":{"production":0}}
{"text":"First, it utilizes the notion of \\emph{context} to define and audit the potentially sensitive information.","cats":{"production":0}}
{"text":"Second, it adopts the notion of Differential Privacy to protect sensitive information and characterize the privacy leakage.","cats":{"production":0}}
{"text":"Experiments on a varie","cats":{"production":0}}
{"text":"In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead.","cats":{"production":1}}
{"text":"Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider.","cats":{"production":0}}
{"text":"Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature.","cats":{"production":0}}
{"text":"While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results.  ","cats":{"production":0}}
{"text":"We introduce the HaS framework, where \"H(ide)\" and \"S(eek)\" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively.","cats":{"production":0}}
{"text":"To quantitatively assess HaS's privacy protection performance, we propose both black-box and white-box adversarial models.","cats":{"production":0}}
{"text":"Furthermore, we conduct experiments to evaluate HaS's usability in translation and classification tasks.","cats":{"production":0}}
{"text":"The experimental findings demonstrate that the HaS framework achieves an optimal balance between privacy protection and utility.","cats":{"production":0}}
{"text":"In this paper, we validate the performance of the a sensor fusion-based Global Navigation Satellite System (GNSS) spoofing attack detection framework for Autonomous Vehicles (AVs).","cats":{"production":0}}
{"text":"In experiments, two types of spoofing attack models: turn-by-turn and wrong turn are simulated.","cats":{"production":0}}
{"text":"These spoofing attacks are modeled as SQL injection attacks, where, upon successful implementation, the navigation system perceives injected spoofed location information as legitimate while being unable to detect legitimate GNSS signals.","cats":{"production":0}}
{"text":"Traditional codebooks need a wide index range, while modulation favors few discrete states.","cats":{"production":0}}
{"text":"To address this, we propose a multilevel generative semantic communication system with a two-stage training framework.","cats":{"production":0,"programming":0}}
{"text":"In the first stage, we train a high-quality codebook, using a multi-head octonary codebook (MOC) to compress the index range.","cats":{"production":0}}
{"text":"Experimental results highlight MOC-RVQ's superior performance over methods like BPG or JPEG, even without channel error correction coding.","cats":{"production":0}}
{"text":"Graph Neural Networks (GNNs) are widely applied across various domains, yet they perform poorly in deep layers.","cats":{"production":0}}
{"text":"Existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation.","cats":{"production":0}}
{"text":"This propagation leads to an exponential growth of a node's current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes.","cats":{"production":0}}
{"text":"To address this issue, we introduce Graph Elimination Networks (GENs), which employ a specific algorithm to eliminate redundancies during neighborhood propagation.","cats":{"production":0}}
{"text":"We demonstrate that GENs can enhance nodes' perception of distant neighborhoods and extend the depth of network propagation.","cats":{"production":0}}
{"text":"Extensive experiments show that GENs outperform the state-of-the-art methods on various graph-level and node-level datasets.","cats":{"production":0}}
{"text":"However, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management.","cats":{"production":0}}
{"text":"Considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay.","cats":{"production":0}}
{"text":"A cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration.","cats":{"production":0}}
{"text":"Based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration.","cats":{"production":0}}
{"text":"In this paper, we introduce a paradigm shift that attains human-level performance in biometric measurement by aggregating automatically extracted biometrics from every frame across an entire scan, with no need for operator intervention.","cats":{"production":0}}
{"text":"We then measure fetal biometrics in every frame where appropriate anatomy is visible.","cats":{"production":0}}
{"text":"We performed a retrospective experiment on 1457 recordings (comprising 48 million frames) of 20-week ultrasound scans, estimated fetal biometrics in those scans and compared our estimates to the measurements sonographers took during the scan.","cats":{"production":0}}
{"text":"Buffer-aided cooperative networks (BACNs) have garnered significant attention due to their potential applications in beyond fifth generation (B5G) or sixth generation (6G) critical scenarios.","cats":{"production":0}}
{"text":"This article explores various typical application scenarios of buffer-aided relaying in B5G/6G networks to emphasize the importance of incorporating BACN.","cats":{"production":0}}
{"text":"Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture.","cats":{"production":0}}
{"text":"To address the challenges, we propose leveraging deep learning-based methods for the design and operation of B5G/6G networks with BACN, deviating from conventional buffer-aided relay selection approaches.","cats":{"production":0}}
{"text":"In particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (DRL) and decentralized DRL in buffer-aided non-terrestrial networks.","cats":{"production":0}}
{"text":"Finally, we outline future research directions in B5G/6G that pertain to the utilization of BACN.","cats":{"production":0}}
{"text":"Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels.","cats":{"production":0}}
{"text":"A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular.","cats":{"production":0}}
{"text":"In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules.","cats":{"production":0}}
{"text":"In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections.","cats":{"production":0}}
{"text":"Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one's true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods.","cats":{"production":0}}
{"text":"Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FedQV against poisoning attacks.","cats":{"production":0}}
{"text":"It also shows that combining FedQV with unequal voting ``budgets'' according to a reputation score increases its performance benefits even further.","cats":{"production":0}}
{"text":"Finally, we show that FedQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.","cats":{"production":0}}
{"text":"Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery.","cats":{"production":0}}
{"text":"This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge.","cats":{"production":0}}
{"text":"Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code.","cats":{"production":0}}
{"text":"Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD).","cats":{"production":0}}
{"text":"On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators.","cats":{"production":0}}
{"text":"It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption, draining only 180mW for a complete inference on an input image.","cats":{"production":0}}
{"text":"To the authors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD.","cats":{"production":0}}
{"text":"In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms.","cats":{"production":0}}
{"text":"The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs).","cats":{"production":0}}
{"text":"The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs).","cats":{"production":0}}
{"text":"With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN.","cats":{"production":0}}
{"text":"A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL.","cats":{"production":0}}
{"text":"Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.","cats":{"production":0}}
{"text":"This paper introduces the definition of LLM serving fairness based on a cost function that accounts for the number of input and output tokens processed.","cats":{"production":1}}
{"text":"High-demand LLM inference services (e.g., ChatGPT and BARD) support a wide range of requests from short chat conversations to long document reading.","cats":{"production":0}}
{"text":"To ensure that all client requests are processed fairly, most major LLM inference services have request rate limits, to ensure that no client can dominate the request queue.","cats":{"production":0}}
{"text":"However, this rudimentary notion of fairness also results in under-utilization of the resources and poor client experience when there is spare capacity.","cats":{"production":0}}
{"text":"While there is a rich literature on fair scheduling, serving LLMs presents new challenges due to their unpredictable request lengths and their unique batching characteristics on parallel accelerators.  ","cats":{"production":0}}
{"text":"We prove a 2x tight upper bound on the service difference between two backlogged clients, adhering to the requirement of work-conserving.","cats":{"production":0}}
{"text":"Through extensive experiments, we demonstrate the superior performance of VTC in ensuring fairness, especially in contrast to other baseline methods, which exhibit shortcomings under various conditions.","cats":{"production":0}}
{"text":"The multifaceted nature of combustion research emphasizes the critical role of knowledge processing in navigating and extracting valuable information from a vast and diverse pool of sources.  ","cats":{"production":0}}
{"text":"It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models LLMs, and explores various optimized prompts to demonstrate the effectiveness of the framework.","cats":{"production":0}}
{"text":"Additionally, the study delves into the investigation of optimized prompt templates for the purpose of efficient extraction of scientific literature.","cats":{"production":0}}
{"text":"In this paper, we observe the weakness of KL regularization which is commonly employed in existing RLHF methods to address overoptimization.","cats":{"production":1}}
{"text":"To enhance the uncertainty quantification abilities for reward models, we first propose a diverse low-rank adaptation (LoRA) ensemble by maximizing the nuclear norm of LoRA matrix concatenations.","cats":{"production":1}}
{"text":"Reinforcement learning from human feedback (RLHF) emerges as a promising paradigm for aligning large language models (LLMs).","cats":{"production":0}}
{"text":"However, a notable challenge in RLHF is overoptimization, where beyond a certain threshold, the pursuit of higher rewards leads to a decline in human preferences.  ","cats":{"production":0}}
{"text":"To mitigate this limitation, we scrutinize the RLHF objective in the offline dataset and propose uncertainty-penalized RLHF (UP-RLHF), whichximizing the nuclear norm of LoRA matrix concatenations.","cats":{"production":0}}
{"text":"Then we optimize policy models utilizing penalized rewards, determined by both rewards and uncertainties provided by the diverse reward LoRA ensemty regularization in UP-RLHF proves to be pivotal in mitigating overoptimization, thereby contributing to the overall performance.","cats":{"production":0}}
{"text":"We introduce Unicron, a workload manager designed for efficient self-healing in large-scale language model training.","cats":{"production":1}}
{"text":"Unicron optimizes the training process by minimizing failure-related costs across multiple concurrent tasks within a cluster.","cats":{"production":1}}
{"text":"Deployed on a 128-GPU distributed cluster, Unicron demonstrates up to a 1.9x improvement in training efficiency over state-of-the-art methods, significantly reducing failure recovery costs and enhancing the reliability of large-scale language model training.","cats":{"production":1}}
{"text":"Training large-scale language models is increasingly critical in various domains, but it is hindered by frequent failures, leading to significant time and economic costs.","cats":{"production":0}}
{"text":"Current failure recovery methods in cloud-based settings inadequately address the diverse and complex scenarios that arise, focusing narrowly on erasing downtime for individual tasks without considering the overall cost impact on a cluster.  ","cats":{"production":0}}
{"text":"Unicron optimizes the training process by minimizing failure-related costs across multiple concurrent tasks within aic cost-aware plan generation mechanism for optimal reconfiguration, and an efficient transition strategy to reduce downtime dge model training.","cats":{"production":0}}
{"text":"We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget.","cats":{"production":0}}
{"text":"The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model's memory of the original input.","cats":{"production":0}}
{"text":"P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments.","cats":{"production":0}}
{"text":"Experimental results indicate P2F's robust capability to obfuscate LLM's memory, attaining a forgetfulness score of around 90\\% without any utility loss.","cats":{"production":0}}
{"text":"This represents an enhancement of up to 63\\% when contrasted with the naive direct instruction technique, highlighting P2F's efficacy in mitigating memory retention of sensitive information within LLMs.","cats":{"production":0}}
{"text":"Our findings establish the first benchmark in the novel field of the LLM forgetting task, representing a meaningful advancement in privacy preservation in the emerging LLM domain.","cats":{"production":0}}
{"text":"Smaller BERT-like models can also learn universal tasks, which allow them to do any text classification task without requiring fine-tuning (zeroshot classification) or to learn new tasks with only a few examples (fewshot), while being significantly more efficient than generative LLMs.","cats":{"production":1}}
{"text":"Generative Large Language Models (LLMs) have become the mainstream choice for fewshot and zeroshot learning thanks to the universality of text generation.","cats":{"production":0}}
{"text":"Many users, however, do not need the broad capabilities of generative LLMs when they only want to automate a classification task.  ","cats":{"production":0}}
{"text":"This paper (1) explains how Natural Language Inference (NLI) can be used as a universal classification task that follows similar principles as instruction fine-tuning of generative LLMs, (2) provides a step-by-step guide with reusable Jupyter notebooks for building a universal classifier, and (3) shares the resulting universal classifier that is trained on 33 datasets with 389 diverse classes.","cats":{"production":0}}
{"text":"Parts of the code we share has been used to train our older zeroshot classifiers that have been downloaded more than 55 million times via the Hugging Face Hub as of December 2023.","cats":{"production":0}}
{"text":"The problem we study in this paper is amodal image segmentation: predicting entire object segmentation masks including both visible and invisible (occluded) parts.","cats":{"production":0}}
{"text":"In previous work, the amodal segmentation ground truth on real images is usually predicted by manual annotaton and thus is subjective.","cats":{"production":0}}
{"text":"This pipeline is used to construct an amodal completion evaluation benchmark, MP3D-Amodal, consisting of a variety of object categories and labels.","cats":{"production":0}}
{"text":"To better handle the amodal completion task in the wild, we explore two architecture variants: a two-stage model that first infers the occluder, followed by amodal mask completion; and a one-stage model that exploits the representation power of Stable Diffusion for amodal segmentation across many categories.","cats":{"production":0}}
{"text":"Without bells and whistles, our method achieves a new state-of-the-art performance on Amodal segmentation datasets that cover a large variety of objects, including COCOA and our new MP3D-Amodal dataset.","cats":{"production":0}}
{"text":"The dataset, model, and code are available at https://www.robots.ox.ac.uk/~vgg/research/amodal/.","cats":{"production":0}}
{"text":"In this work, we study the problem of running large MoE language models on consumer hardware with limited accelerator memory.","cats":{"production":1}}
{"text":"We build upon parameter offloading algorithms and propose a novel strategy that accelerates offloading by taking advantage of innate properties of MoE LLMs.","cats":{"production":1}}
{"text":"With the widespread adoption of Large Language Models (LLMs), many deep learning practitioners are looking for strategies of running these models more efficiently.","cats":{"production":0}}
{"text":"One such strategy is to use sparse Mixture-of-Experts (MoE) - a type of model architectures where only a fraction of model layers are active for any given input.","cats":{"production":0}}
{"text":"This property allows MoE-based language models to generate tokens faster than their dense counterparts, but it also increases model size due to having multiple experts.","cats":{"production":0}}
{"text":"Unfortunately, this makes state-of-the-art MoE language models difficult to run without high-end GPUs.  ","cats":{"production":0}}
{"text":"We build upon parameter offloading algorithms and propose a novel strategy that accelerates offloading by taking advantage ofstances.","cats":{"production":0}}
{"text":"Generative diffusion models can serve as a prior which ensures that solutions of image restoration systems adhere to the manifold of natural images.","cats":{"production":0}}
{"text":"However, for restoring facial images, a personalized prior is necessary to accurately represent and reconstruct unique facial features of a given individual.","cats":{"production":0}}
{"text":"In this paper, we propose a simple, yet effective, method for personalized restoration, called Dual-Pivot Tuning - a two-stage approach that personalize a blind restoration system while maintaining the integrity of the general prior and the distinct role of each component.","cats":{"production":0}}
{"text":"Our key observation is that for optimal personalization, the generative model should be tuned around a fixed text pivot, while the guiding network should be tuned in a generic (non-personalized) manner, using the personalized generative model as a fixed ``pivot\".","cats":{"production":0}}
{"text":"We evaluated our approach both qualitatively and quantitatively through extensive experiments with images of widely recognized individuals, comparing it against relevant baselines.","cats":{"production":0}}
{"text":"Surprisingly, we found that our personalized prior not only achieves higher fidelity to identity with respect to the person's identity, but also outperforms state-of-the-art generic priors in terms of general image quality.","cats":{"production":0}}
{"text":"Project webpage: https://personalized-restoration.github.io","cats":{"production":0}}
{"text":"As the landscape of time-sensitive applications gains prominence in 5G/6G communications, timeliness of information updates at network nodes has become crucial, which is popularly quantified in the literature by the age of information metric.","cats":{"production":0}}
{"text":"However, as we devise policies to improve age of information of our systems, we inadvertently introduce a new vulnerability for adversaries to exploit.","cats":{"production":0}}
{"text":"In this article, we comprehensively discuss the diverse threats that age-based systems are vulnerable to.","cats":{"production":0}}
{"text":"We begin with discussion on densely interconnected networks that employ gossiping between nodes to expedite dissemination of dynamic information in the network, and show how the age-based nature of gossiping renders these networks uniquely susceptible to threats such as timestomping attacks, jamming attacks, and the propagation of misinformation.","cats":{"production":0}}
{"text":"We conclude this article with future directions that aim to address challenges posed by more intelligent adversaries and robustness of networks to them.","cats":{"production":0}}
{"text":"The existing facial datasets, while having plentiful images at near frontal views, lack images with extreme head poses, leading to the downgraded performance of deep learning models when dealing with profile or pitched faces.","cats":{"production":0}}
{"text":"This work aims to address this gap by introducing a novel dataset named Extreme Pose Face High-Quality Dataset (EFHQ), which includes a maximum of 450k high-quality images of faces at extreme poses.","cats":{"production":0}}
{"text":"Our dataset can complement existing datasets on various facial-related tasks, such as facial synthesis with 2D/3D-aware GAN, diffusion-based text-to-image face generation, and face reenactment.","cats":{"production":0}}
{"text":"Specifically, training with EFHQ helps models generalize well across diverse poses, significantly improving performance in scenarios involving extreme views, confirmed by extensive experiments.","cats":{"production":0}}
{"text":"Additionally, we utilize EFHQ to define a challenging cross-view face verification benchmark, in which the performance of SOTA face recognition models drops 5-37\\% compared to frontal-to-frontal scenarios, aiming to stimulate studies on face recognition under severe pose conditions in the wild.","cats":{"production":0}}
{"text":"Network slicing is essential for transforming future telecommunication networks into versatile service platforms, but it also presents challenges for sustainable network operations.","cats":{"production":0}}
{"text":"While meeting the requirements of network slices incurs additional energy consumption compared to non-sliced networks, operators strive to offer diverse 5G and beyond services while maintaining energy efficiency.","cats":{"production":0}}
{"text":"In this study, we address the issue of slice activation/deactivation to reduce energy consumption while maintaining the user quality of service (QoS).","cats":{"production":0}}
{"text":"We employ Deep Contextual Multi-Armed Bandit and Thompson Sampling Contextual Multi-Armed Bandit agents to make activation/deactivation decisions for individual clusters.","cats":{"production":0}}
{"text":"Evaluations are performed using the NetMob23 dataset, which captures the spatio-temporal consumption of various mobile services in France.","cats":{"production":0}}
{"text":"Our simulation results demonstrate that our proposed solutions provide significant reductions in network energy consumption while ensuring the QoS remains at a similar level compared to a scenario where all slice instances are active.","cats":{"production":0}}
{"text":"This paper studies the poisoning attack and defense interactions in a federated learning (FL) system, specifically in the context of wireless signal classification using deep learning for next-generation (NextG) communications.","cats":{"production":0}}
{"text":"FL collectively trains a global model without the need for clients to exchange their data samples.","cats":{"production":0}}
{"text":"By leveraging geographically dispersed clients, the trained global model can be used for incumbent user identification, facilitating spectrum sharing.","cats":{"production":0}}
{"text":"However, in this distributed learning system, the presence of malicious clients introduces the risk of poisoning the training data to manipulate the global model through falsified local model exchanges.","cats":{"production":0}}
{"text":"To address this challenge, a proactive defense mechanism is employed in this paper to make informed decisions regarding the admission or rejection of clients participating in FL systems.","cats":{"production":0}}
{"text":"Consequently, the attack-defense interactions are modeled as a game, centered around the underlying admission and poisoning decisions.","cats":{"production":0}}
{"text":"First, performance bounds are established, encompassing the best and worst strategies for attackers and defenders.","cats":{"production":0}}
{"text":"Subsequently, the attack and defense utilities are characterized within the Nash equilibrium, where no player can unilaterally improve its performance given the fixed strategies of others.","cats":{"production":0}}
{"text":"The results offer insights into novel operational modes that safeguard FL systems against poisoning attacks by quantifying the performance of both attacks and defenses in the context of NextG communications.","cats":{"production":0}}
{"text":"The inherent generative power of denoising diffusion models makes them well-suited for image restoration tasks where the objective is to find the optimal high-quality image within the generative space that closely resembles the input image.","cats":{"production":0}}
{"text":"We propose a method to adapt a pretrained diffusion model for image restoration by simply adding noise to the input image to be restored and then denoise.","cats":{"production":0}}
{"text":"Our method is based on the observation that the space of a generative model needs to be constrained.","cats":{"production":0}}
{"text":"We impose this constraint by finetuning the generative model with a set of anchor images that capture the characteristics of the input image.","cats":{"production":0}}
{"text":"With the constrained space, we can then leverage the sampling strategy used for generation to do image restoration.","cats":{"production":0}}
{"text":"We evaluate against previous methods and show superior performances on multiple real-world restoration datasets in preserving identity and image quality.","cats":{"production":0}}
{"text":"We also demonstrate an important and practical application on personalized restoration, where we use a personal album as the anchor images to constrain the generative space.","cats":{"production":0}}
{"text":"This approach allows us to produce results that accurately preserve high-frequency details, which previous works are unable to do.","cats":{"production":0}}
{"text":"Project webpage: https://gen2res.github.io.","cats":{"production":0}}
{"text":"In this paper, we propose BEAt tracking Streaming Transformer (BEAST), an online joint beat and downbeat tracking system based on the streaming Transformer.","cats":{"production":1}}
{"text":"To deal with online scenarios, BEAST applies contextual block processing in the Transformer encoder.","cats":{"production":0}}
{"text":"Carrying out beat and downbeat experiments on benchmark datasets for a low latency scenario with maximum latency under 50 ms, BEAST achieves an F1-measure of 80.04% in beat and 52.73% in downbeat, which is a substantial improvement of about 5 and 13 percentage points over the state-of-the-art online beat and downbeat tracking model.","cats":{"production":1}}
{"text":"Many deep learning models have achieved dominant performance on the offline beat tracking task.","cats":{"production":0}}
{"text":"However, online beat tracking, in which only the past and present input features are available, still remains challenging.  ","cats":{"production":0}}
{"text":"Moreover, we adopt relative positional encoding in the itically important information in music.","cats":{"production":0}}
{"text":"Carrying out beat and downbeat experiments on benchmark datasets for a low latency scenario with maximum latency under 50 ms, BEAST achieves an F1-measure of 80.04% in beat and 52.73% in downbeat, which is a substantial improvement of about 5 and 13 percen","cats":{"production":0}}
{"text":"Remarkable progress has been made in 4D content generation recently.","cats":{"production":0}}
{"text":"However, existing methods suffer from long optimization time, lack of motion controllability, and a low level of detail.","cats":{"production":0}}
{"text":"In this paper, we introduce DreamGaussian4D, an efficient 4D generation framework that builds on 4D Gaussian Splatting representation.","cats":{"production":0}}
{"text":"Our key insight is that the explicit modeling of spatial transformations in Gaussian Splatting makes it more suitable for the 4D generation setting compared with implicit representations.","cats":{"production":0}}
{"text":"DreamGaussian4D reduces the optimization time from several hours to just a few minutes, allows flexible control of the generated 3D motion, and produces animated meshes that can be efficiently rendered in 3D engines.","cats":{"production":0}}
{"text":"We address the challenges in estimating 3D human poses from multiple views under occlusion and with limited overlapping views.","cats":{"production":0}}
{"text":"We approach multi-view, single-person 3D human pose reconstruction as a regression problem and propose a novel encoder-decoder Transformer architecture to estimate 3D poses from multi-view 2D pose sequences.","cats":{"production":0}}
{"text":"The encoder refines 2D skeleton joints detected across different views and times, fusing multi-view and temporal information through global self-attention.","cats":{"production":0}}
{"text":"We enhance the encoder by incorporating a geometry-biased attention mechanism, effectively leveraging geometric relationships between views.","cats":{"production":0}}
{"text":"Additionally, we use detection scores provided by the 2D pose detector to further guide the encoder's attention based on the reliability of the 2D detections.","cats":{"production":0}}
{"text":"The decoder subsequently regresses the 3D pose sequence from these refined tokens, using pre-defined queries for each joint.","cats":{"production":0}}
{"text":"To enhance the generalization of our method to unseen scenes and improve resilience to missing joints, we implement strategies including scene centering, synthetic views, and token dropout.","cats":{"production":0}}
{"text":"We conduct extensive experiments on three benchmark public datasets, Human3.6M, CMU Panoptic and Occlusion-Persons.","cats":{"production":0}}
{"text":"Our results demonstrate the efficacy of our approach, particularly in occluded scenes and when few views are available, which are traditionally challenging scenarios for triangulation-based methods.","cats":{"production":0}}
{"text":"To eliminate this dilemma, we propose SCTNet, a single branch CNN with transformer semantic information for real-time segmentation.","cats":{"production":1}}
{"text":"During the inference, only the single branch CNN needs to be deployed.","cats":{"production":0}}
{"text":"Recent real-time semantic segmentation methods usually adopt an additional semantic branch to pursue rich long-range context.","cats":{"production":0}}
{"text":"However, the additional branch incurs undesirable computational overhead and slows inference speed.  ","cats":{"production":0}}
{"text":"SCTNet enjoys the rich semantic representations of an inference-free semantic branch while retaining the high efficiency of lightweight single branch CNN.","cats":{"production":0}}
{"text":"SCTNet utilizes a transformer as the training-only semantic branch considering its superb ability to extract long-range context.","cats":{"production":0}}
{"text":"With the help of the proposed transformer-like CNN block CFBlock and the semantic information alignment module, SCTNet could capture the rich semantic information from the transformer branch in training.","cats":{"production":0}}
{"text":"We conduct extensive experiments on Cityscapes, ADE20K, and state-of-the-art performance.","cats":{"production":0}}
{"text":"The code and model is available at https://github.com/xzz777/SCTNet","cats":{"production":0}}
{"text":"In particular, we derive a compression bound that is valid for the unbounded log-likelihood loss using prediction smoothing, and we extend the bound to handle subsampling, accelerating bound computation on massive datasets.","cats":{"production":1}}
{"text":"Modern language models can contain billions of parameters, raising the question of whether they can generalize beyond the training data or simply regurgitate their training corpora.","cats":{"production":0}}
{"text":"We provide the first non-vacuous generalization bounds for pretrained large language models (LLMs), indicating that language models are capable of discovering regularities that generalize to unseen data.  ","cats":{"production":0}}
{"text":"To achieve the extreme level of compression required for non-vacuous generalization bounds, we devise SubLoRA, a low-dimensional non-linear parameterization.","cats":{"production":0}}
{"text":"Using this approach, we find that larger models have better generalization bounds and are more compressible than smaller models.","cats":{"production":0}}
{"text":"In recent times, there has been a notable surge in multimodal approaches that decorates raw LiDAR point clouds with camera-derived features to improve object detection performance.","cats":{"production":0}}
{"text":"However, we found that these methods still grapple with the inherent sparsity of LiDAR point cloud data, primarily because fewer points are enriched with camera-derived features for sparsely distributed objects.","cats":{"production":0}}
{"text":"We present an innovative approach that involves the generation of virtual LiDAR points using camera images and enhancing these virtual points with semantic labels obtained from image-based segmentation networks to tackle this issue and facilitate the detection of sparsely distributed objects, particularly those that are occluded or distant.","cats":{"production":0}}
{"text":"Furthermore, we integrate a distance aware data augmentation (DADA) technique to enhance the models capability to recognize these sparsely distributed objects by generating specialized training samples.","cats":{"production":0}}
{"text":"Our approach offers a versatile solution that can be seamlessly integrated into various 3D frameworks and 2D semantic segmentation methods, resulting in significantly improved overall detection accuracy.","cats":{"production":0}}
{"text":"Evaluation on the KITTI and nuScenes datasets demonstrates substantial enhancements in both 3D and birds eye view (BEV) detection benchmarks","cats":{"production":0}}
{"text":"In this paper, we present the findings of a study conducted to assess the coexistence of Fifth Generation (5G) wireless networks and Fixed Satellite Station (FSS) receivers in the C-Band (3300-4200 MHz) in India.","cats":{"production":0}}
{"text":"Through simulations, we evaluate the coexistence feasibility and calculate the minimum separation distances required to mitigate interference, consider-ing factors such as 5G Base Station power, off-axis angle, clutter, filtering, and shielding.","cats":{"production":0}}
{"text":"Next, we present various interference mitigation techniques, including distance, antenna tilt and height, power control, antenna design, coordination, filtering, and others, aiming for balanced coexistence.","cats":{"production":0}}
{"text":"The simulation results corroborate the efficacy of these solutions in containing interference from 5G in the C-Band FSS receivers.","cats":{"production":0}}
{"text":"The paper offers valuable insights into frequency allocation in India and considerations for 5G network design, including site selection and antenna orientation.","cats":{"production":0}}
{"text":"The insights provided are relevant to other regions facing similar coexistence challenges.","cats":{"production":0}}
{"text":"Overall, this paper offers a comprehensive overview of 5G and FSS coexistence in the C-band, emphasising the importance of addressing this issue during network design and deployment.","cats":{"production":0}}
{"text":"Driven by the development goal of network paradigm and demand for various functions in the sixth-generation (6G) mission-critical Internet-of-Things (MC-IoT), we foresee a goal-oriented integration of sensing, communication, computing, and control (GIS3C) in this paper.","cats":{"production":0}}
{"text":"We first provide an overview of the tasks, requirements, and challenges of MC-IoT. Then we introduce an end-to-end GIS3C architecture, in which goal-oriented communication is leveraged to bridge and empower sensing, communication, control, and computing functionalities.","cats":{"production":0}}
{"text":"By revealing the interplay among multiple subsystems in terms of key performance indicators and parameters, this paper introduces unified metrics, i.e., task completion effectiveness and cost, to facilitate S3C co-design in MC-IoT.","cats":{"production":0}}
{"text":"The preliminary results demonstrate the benefits of GIS3C in improving task completion effectiveness while reducing costs.","cats":{"production":0}}
{"text":"We also identify and highlight the gaps and challenges in applying GIS3C in the future 6G networks.","cats":{"production":0}}
{"text":"Semantic communication, as a novel communication paradigm, has attracted the interest of many scholars, with multi-user, multi-input multi-output (MIMO) scenarios being one of the critical contexts.","cats":{"production":0}}
{"text":"This paper presents a semantic importance-aware based communication system (SIA-SC) over MIMO Rayleigh fading channels.","cats":{"production":0}}
{"text":"Combining the semantic symbols' inequality and the equivalent subchannels of MIMO channels based on Singular Value Decomposition (SVD) maximizes the end-to-end semantic performance through the new layer mapping method.","cats":{"production":0}}
{"text":"For multi-user scenarios, a method of semantic interference cancellation is proposed.","cats":{"production":0}}
{"text":"Furthermore, a new metric, namely semantic information distortion (SID), is established to unify the expressions of semantic performance, which is affected by channel bandwidth ratio (CBR) and signal-to-noise ratio (SNR).","cats":{"production":0}}
{"text":"With the help of the proposed metric, we derived performance expressions and Semantic Outage Probability (SOP) of SIA-SC for Single-User Single-Input Single-Output (SU-SISO), Single-User MIMO (SU-MIMO), Multi-Users SISO (MU-MIMO) and Multi-Users MIMO (MU-MIMO) scenarios.","cats":{"production":0}}
{"text":"Numerical experiments show that SIA-SC can significantly improve semantic performance across various scenarios.","cats":{"production":0}}
{"text":"Previous post-processing studies on rainfall forecasts using numerical weather prediction (NWP) mainly focus on statistics-based aspects, while learning-based aspects are rarely investigated.","cats":{"production":0}}
{"text":"Although some manually-designed models are proposed to raise accuracy, they are customized networks, which need to be repeatedly tried and verified, at a huge cost in time and labor.","cats":{"production":0}}
{"text":"Therefore, a self-supervised neural architecture search (NAS) method without significant manual efforts called AdaNAS is proposed in this study to perform rainfall forecast post-processing and predict rainfall with high accuracy.","cats":{"production":0}}
{"text":"In addition, we design a rainfall-aware search space to significantly improve forecasts for high-rainfall areas.","cats":{"production":0}}
{"text":"Furthermore, we propose a rainfall-level regularization function to eliminate the effect of noise data during the training.","cats":{"production":0}}
{"text":"Validation experiments have been performed under the cases of \\emph{None}, \\emph{Light}, \\emph{Moderate}, \\emph{Heavy} and \\emph{Violent} on a large-scale precipitation benchmark named TIGGE.","cats":{"production":0}}
{"text":"Finally, the average mean-absolute error (MAE) and average root-mean-square error (RMSE) of the proposed AdaNAS model are 0.98 and 2.04 mm/day, respectively.","cats":{"production":0}}
{"text":"Additionally, the proposed AdaNAS model is compared with other neural architecture search methods and previous studies.","cats":{"production":0}}
{"text":"Compared results reveal the satisfactory performance and superiority of the proposed AdaNAS model in terms of precipitation amount prediction and intensity classification.","cats":{"production":0}}
{"text":"Concretely, the proposed AdaNAS model outperformed previous best-performing manual methods with MAE and RMSE improving by 80.5\\% and 80.3\\%, respectively.","cats":{"production":0}}
{"text":"NIR-to-RGB spectral domain translation is a challenging task due to the mapping ambiguities, and existing methods show limited learning capacities.","cats":{"production":0}}
{"text":"To address these challenges, we propose to colorize NIR images via a multi-scale progressive feature embedding network (MPFNet), with the guidance of grayscale image colorization.","cats":{"production":0}}
{"text":"Specifically, we first introduce a domain translation module that translates NIR source images into the grayscale target domain.","cats":{"production":0}}
{"text":"By incorporating a progressive training strategy, the statistical and semantic knowledge from both task domains are efficiently aligned with a series of pixel- and feature-level consistency constraints.","cats":{"production":0}}
{"text":"Besides, a multi-scale progressive feature embedding network is designed to improve learning capabilities.","cats":{"production":0}}
{"text":"Experiments show that our MPFNet outperforms state-of-the-art counterparts by 2.55 dB in the NIR-to-RGB spectral domain translation task in terms of PSNR.","cats":{"production":0}}
{"text":"Automatic polyp segmentation plays a crucial role in the early diagnosis and treatment of colorectal cancer (CRC).","cats":{"production":0}}
{"text":"However, existing methods heavily rely on fully supervised training, which requires a large amount of labeled data with time-consuming pixel-wise annotations.","cats":{"production":0}}
{"text":"Moreover, accurately segmenting polyps poses challenges due to variations in shape, size, and location.","cats":{"production":0}}
{"text":"To address these issues, we propose a novel Dual-scale Enhanced and Cross-generative consistency learning framework for semi-supervised polyp Segmentation (DEC-Seg) from colonoscopy images.","cats":{"production":0}}
{"text":"First, we propose a Cross-level Feature Aggregation (CFA) module that integrates cross-level adjacent layers to enhance the feature representation ability across different resolutions.","cats":{"production":0}}
{"text":"To address scale variation, we present a scale-enhanced consistency constraint, which ensures consistency in the segmentation maps generated from the same input image at different scales.","cats":{"production":0}}
{"text":"This constraint helps handle variations in polyp sizes and improves the robustness of the model.","cats":{"production":0}}
{"text":"Additionally, we design a scale-aware perturbation consistency scheme to enhance the robustness of the mean teacher model.","cats":{"production":0}}
{"text":"Furthermore, we propose a cross-generative consistency scheme, in which the original and perturbed images can be reconstructed using cross-segmentation maps.","cats":{"production":0}}
{"text":"This consistency constraint allows us to mine effective feature representations and boost the segmentation performance.","cats":{"production":0}}
{"text":"To produce more accurate segmentation maps, we propose a Dual-scale Complementary Fusion (DCF) module that integrates features from two scale-specific decoders operating at different scales.","cats":{"production":0}}
{"text":"Extensive experimental results on five benchmark datasets demonstrate the effectiveness of our DEC-Seg against other state-of-the-art semi-supervised segmentation approaches.","cats":{"production":0}}
{"text":"The implementation code will be released at https://github.com/taozh2017/DECSeg.","cats":{"production":0}}
{"text":"Passive non-line-of-sight (NLOS) imaging has witnessed rapid development in recent years, due to its ability to image objects that are out of sight.","cats":{"production":0}}
{"text":"The light transport condition plays an important role in this task since changing the conditions will lead to different imaging models.","cats":{"production":0}}
{"text":"Existing learning-based NLOS methods usually train independent models for different light transport conditions, which is computationally inefficient and impairs the practicality of the models.","cats":{"production":0}}
{"text":"In this work, we propose NLOS-LTM, a novel passive NLOS imaging method that effectively handles multiple light transport conditions with a single network.","cats":{"production":0}}
{"text":"We achieve this by inferring a latent light transport representation from the projection image and using this representation to modulate the network that reconstructs the hidden image from the projection image.","cats":{"production":0}}
{"text":"We train a light transport encoder together with a vector quantizer to obtain the light transport representation.","cats":{"production":0}}
{"text":"To further regulate this representation, we jointly learn both the reconstruction network and the reprojection network during training.","cats":{"production":0}}
{"text":"A set of light transport modulation blocks is used to modulate the two jointly trained networks in a multi-scale way.","cats":{"production":0}}
{"text":"Extensive experiments on a large-scale passive NLOS dataset demonstrate the superiority of the proposed method.","cats":{"production":0}}
{"text":"The code is available at https://github.com/JerryOctopus/NLOS-LTM.","cats":{"production":0}}
{"text":"Edge storage presents a viable data storage alternative for application vendors (AV), offering benefits such as reduced bandwidth overhead and latency compared to cloud storage.","cats":{"production":0}}
{"text":"However, data cached in edge computing systems is susceptible to intentional or accidental disturbances.","cats":{"production":0}}
{"text":"This paper proposes a decentralized integrity auditing scheme to safeguard data integrity and counter the traditional reliance on centralized third-party auditors (TPA), which are unfit for distributed systems.","cats":{"production":0}}
{"text":"Our novel approach employs edge servers (ES) as mutual auditors, eliminating the need for a centralized entity.","cats":{"production":0}}
{"text":"This decentralization minimizes potential collusion with malicious auditors and biases in audit outcomes.","cats":{"production":0}}
{"text":"Using a strategic game model, we demonstrate that ESs are more motivated to audit each other than TPAs.","cats":{"production":0}}
{"text":"The auditing process is addressed as a Nash Equilibrium problem, assuring accurate integrity proof through incentives for ESs.","cats":{"production":0}}
{"text":"Our scheme's security and performance are rigorously assessed, showing it is secure within the random oracle model, offers improved speed, and is cost-effective compared to existing methods.","cats":{"production":0}}
{"text":"Most of existing correspondence pruning methods only concentrate on gathering the context information as much as possible while neglecting effective ways to utilize such information.","cats":{"production":0}}
{"text":"In order to tackle this dilemma, in this paper we propose Graph Context Transformation Network (GCT-Net) enhancing context information to conduct consensus guidance for progressive correspondence pruning.","cats":{"production":0}}
{"text":"Specifically, we design the Graph Context Enhance Transformer which first generates the graph network and then transforms it into multi-branch graph contexts.","cats":{"production":0}}
{"text":"Moreover, it employs self-attention and cross-attention to magnify characteristics of each graph context for emphasizing the unique as well as shared essential information.","cats":{"production":0}}
{"text":"To further apply the recalibrated graph contexts to the global domain, we propose the Graph Context Guidance Transformer.","cats":{"production":0}}
{"text":"This module adopts a confident-based sampling strategy to temporarily screen high-confidence vertices for guiding accurate classification by searching global consensus between screened vertices and remaining ones.","cats":{"production":0}}
{"text":"The extensive experimental results on outlier removal and relative pose estimation clearly demonstrate the superior performance of GCT-Net compared to state-of-the-art methods across outdoor and indoor datasets.","cats":{"production":0}}
{"text":"The source code will be available at: https://github.com/guobaoxiao/GCT-Net/.","cats":{"production":0}}
{"text":"This paper introduces a learnable Deformable Hypothesis Sampler (DeformSampler) to address the challenging issue of noisy depth estimation for accurate PatchMatch Multi-View Stereo (MVS).","cats":{"production":0}}
{"text":"We observe that the heuristic depth hypothesis sampling modes employed by PatchMatch MVS solvers are insensitive to (i) the piece-wise smooth distribution of depths across the object surface, and (ii) the implicit multi-modal distribution of depth prediction probabilities along the ray direction on the surface points.","cats":{"production":0}}
{"text":"Accordingly, we develop DeformSampler to learn distribution-sensitive sample spaces to (i) propagate depths consistent with the scene's geometry across the object surface, and (ii) fit a Laplace Mixture model that approaches the point-wise probabilities distribution of the actual depths along the ray direction.","cats":{"production":0}}
{"text":"We integrate DeformSampler into a learnable PatchMatch MVS system to enhance depth estimation in challenging areas, such as piece-wise discontinuous surface boundaries and weakly-textured regions.","cats":{"production":0}}
{"text":"Experimental results on DTU and Tanks \\& Temples datasets demonstrate its superior performance and generalization capabilities compared to state-of-the-art competitors.","cats":{"production":0}}
{"text":"Code is available at https://github.com/Geo-Tell/DS-PMNet.","cats":{"production":0}}
{"text":"We base our network architecture on standard Transformer encoders and decoders, allowing us to leverage powerful pretrained models.","cats":{"production":1}}
{"text":"Multi-view stereo reconstruction (MVS) in the wild requires to first estimate the camera parameters e.g. intrinsic and extrinsic parameters.","cats":{"production":0}}
{"text":"These are usually tedious and cumbersome to obtain, yet they are mandatory to triangulate corresponding pixels in 3D space, which is the core of all best performing MVS algorithms.","cats":{"production":0}}
{"text":"In this work, we take an opposite stance and introduce DUSt3R, a radically novel paradigm for Dense and Unconstrained Stereo 3D Reconstruction of arbitrary image collections, i.e. operating without prior information about camera calibration nor viewpoint poses.","cats":{"production":0}}
{"text":"We cast the pairwise reconstruction problem as a regression of pointmaps, relaxing the hard constraints of usual projective camera models.","cats":{"production":0}}
{"text":"We show that this formulation smoothly unifies the monocular and binocular reconstruction cases.","cats":{"production":0}}
{"text":"In the case where more than two images are provided, we further propose a simple yet effective global alignment strategy that expresses all pairwise pointmaps in a common reference frame.  ","cats":{"production":0}}
{"text":"Our formulation directly provides a 3D model of the scene as well as depth information, but interestingly, we can seamlessly recover from it, pixel matches, relative and absolute camera.","cats":{"production":0}}
{"text":"Exhaustive experiments on all these tasks showcase that the proposed DUSt3R can unify various 3D vision tasks and set new SoTAs on monocular/multi-view depth estimation as well as relative pose estimation.","cats":{"production":0}}
{"text":"In summary, DUSt3R makes many geometric 3D vision tasks easy.","cats":{"production":0}}
{"text":"The use of reactive detection technologies such as passive and active sensors for avoiding car accidents involving pedestrians and other Vulnerable Road Users (VRU) is one of the cornerstones of Cooperative, Connected, and Automated Mobility (CCAM).","cats":{"production":0}}
{"text":"However, CCAM systems are not yet present in all roads at all times.","cats":{"production":0}}
{"text":"The use of currently available technologies that are embedded in smartphones, such as location services and Internet access, are enablers for the early detection of VRUs.","cats":{"production":0}}
{"text":"This paper presents the proof-of-concept of a system that provides vehicles with enough information about the presence of VRUs by using public cellular networks, an MQTT broker, and IEEE 802.11p-enabled hardware (a roadside unit and an on-board unit).","cats":{"production":0}}
{"text":"The system was tested in an urban environment and in a test track, where its feasibility was evaluated.","cats":{"production":0}}
{"text":"Results were satisfactory, proving the system is reliable enough to alert of the sudden appearance of a VRU in time for the driver to react.","cats":{"production":0}}
{"text":"The proposed architecture, Dual Attentive U-Net with Feature Infusion (DAU-FI Net), addresses challenges in semantic segmentation, particularly on multiclass imbalanced datasets with limited samples.","cats":{"production":0}}
{"text":"DAU-FI Net integrates multiscale spatial-channel attention mechanisms and feature injection to enhance precision in object localization.","cats":{"production":0}}
{"text":"The core employs a multiscale depth-separable convolution block, capturing localized patterns across scales.","cats":{"production":0}}
{"text":"This block is complemented by a spatial-channel squeeze and excitation (scSE) attention unit, modeling inter-dependencies between channels and spatial regions in feature maps.","cats":{"production":0}}
{"text":"Additionally, additive attention gates refine segmentation by connecting encoder-decoder pathways.   ","cats":{"production":0}}
{"text":"To augment the model, engineered features using Gabor filters for textural analysis, Sobel and Canny filters for edge detection are injected guided by semantic masks to expand the feature space strategically.","cats":{"production":0}}
{"text":"Comprehensive experiments on a challenging sewer pipe and culvert defect dataset and a benchmark dataset validate DAU-FI Net's capabilities.","cats":{"production":0}}
{"text":"Ablation studies highlight incremental benefits from attention blocks and feature injection.","cats":{"production":0}}
{"text":"DAU-FI Net achieves state-of-the-art mean Intersection over Union (IoU) of 95.6% and 98.8% on the defect test set and benchmark respectively, surpassing prior methods by 8.9% and 12.6%, respectively.","cats":{"production":0}}
{"text":"The proposed architecture provides a robust solution, advancing semantic segmentation for multiclass problems with limited training data.","cats":{"production":0}}
{"text":"Our sewer-culvert defects dataset, featuring pixel-level annotations, opens avenues for further research in this crucial domain.","cats":{"production":0}}
{"text":"Overall, this work delivers key innovations in architecture, attention, and feature engineering to elevate semantic segmentation efficacy.","cats":{"production":0}}
{"text":"Aligning a template to 3D human point clouds is a long-standing problem crucial for tasks like animation, reconstruction, and enabling supervised learning pipelines.","cats":{"production":0}}
{"text":"Recent data-driven methods leverage predicted surface correspondences; however, they are not robust to varied poses or distributions.","cats":{"production":0}}
{"text":"In contrast, industrial solutions often rely on expensive manual annotations or multi-view capturing systems.","cats":{"production":0}}
{"text":"Recently, neural fields have shown promising results, but their purely data-driven nature lacks geometric awareness, often resulting in a trivial misalignment of the template registration.","cats":{"production":0}}
{"text":"In this work, we propose two solutions: LoVD, a novel neural field model that predicts the direction towards the localized SMPL vertices on the target surface; and INT, the first self-supervised task dedicated to neural fields that, at test time, refines the backbone, exploiting the target geometry.","cats":{"production":0}}
{"text":"We combine them into INLoVD, a robust 3D Human body registration pipeline trained on a large MoCap dataset.","cats":{"production":0}}
{"text":"INLoVD is efficient (takes less than a minute), solidly achieves the state of the art over public benchmarks, and provides unprecedented generalization on out-of-distribution data.","cats":{"production":0}}
{"text":"We will release code and checkpoints in \\url{url}.","cats":{"production":0}}
{"text":"The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication.","cats":{"production":0}}
{"text":"Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services.","cats":{"production":0}}
{"text":"Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation.","cats":{"production":0}}
{"text":"The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable.","cats":{"production":0}}
{"text":"This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems.","cats":{"production":0}}
{"text":"Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63% points for print attacks and a loss of 0.29% for screen capture attacks.","cats":{"production":0}}
{"text":"Pufferfish privacy is a flexible generalization of differential privacy that allows to model arbitrary secrets and adversary's prior knowledge about the data.","cats":{"production":0}}
{"text":"Unfortunately, designing general and tractable Pufferfish mechanisms that do not compromise utility is challenging.","cats":{"production":0}}
{"text":"Furthermore, this framework does not provide the composition guarantees needed for a direct use in iterative machine learning algorithms.","cats":{"production":0}}
{"text":"To mitigate these issues, we introduce a R\\'enyi divergence-based variant of Pufferfish and show that it allows us to extend the applicability of the Pufferfish framework.","cats":{"production":0}}
{"text":"We first generalize the Wasserstein mechanism to cover a wide range of noise distributions and introduce several ways to improve its utility.","cats":{"production":0}}
{"text":"We also derive stronger guarantees against out-of-distribution adversaries.","cats":{"production":0}}
{"text":"Finally, as an alternative to composition, we prove privacy amplification results for contractive noisy iterations and showcase the first use of Pufferfish in private convex optimization.","cats":{"production":0}}
{"text":"A common ingredient underlying our results is the use and extension of shift reduction lemmas.","cats":{"production":0}}
{"text":"Long Range-Frequency Hopping Spread Spectrum (LR-FHSS) is a new physical layer option that has been recently added to the LoRa family with the promise of achieving much higher network capacity than the previous versions of LoRa.","cats":{"production":0}}
{"text":"In this paper, we present our evaluation of LR-FHSS based on real-world packet traces collected with an LR-FHSS device and a receiver we designed and implemented in software.","cats":{"production":0}}
{"text":"We overcame challenges due to the lack of documentations of LR-FHSS and our study is the first of its kind that processes signals transmitted by an actual LR-FHSS device with practical issues such as frequency error.","cats":{"production":0}}
{"text":"Our results show that LR-FHSS meets its expectations in communication range and network capacity.","cats":{"production":0}}
{"text":"We also propose customized methods for LR-FHSS that improve its performance significantly, allowing our receiver to achieve higher network capacity than those reported earlier.","cats":{"production":0}}
{"text":"Software debloating tools seek to improve the program security and performance by removing unnecessary code, called bloat.","cats":{"production":0}}
{"text":"While many techniques have been proposed, several barriers to their adoption have emerged.","cats":{"production":0}}
{"text":"Namely, debloating tools are highly specialized, making it difficult for adopters to find the right type of tool for their needs.","cats":{"production":0}}
{"text":"This is further hindered by a lack of established metrics and comparative evaluations between tools.","cats":{"production":0}}
{"text":"To close this gap, we surveyed of 10 years of debloating literature and several tools currently under commercial development to systematize the debloating ecosystem's knowledge.","cats":{"production":0}}
{"text":"We then conducted a broad comparative evaluation of 10 debloating tools to determine their relative strengths and weaknesses.","cats":{"production":0}}
{"text":"Our evaluation, conducted on a diverse set of 20 benchmark programs, measures tools across 16 performance, security, correctness, and usability metrics.   ","cats":{"production":0}}
{"text":"Our evaluation surfaces several concerning findings that contradict the prevailing narrative in debloating literature.","cats":{"production":0}}
{"text":"First, debloating tools lack the required maturity to be used on real-world software, evidenced by a slim 21% overall success rate for creating passable debloated versions of medium- and high-complexity benchmarks.","cats":{"production":0}}
{"text":"Second, debloating tools struggle to produce sound and robust programs.","cats":{"production":0}}
{"text":"Using our novel differential fuzzing tool, DIFFER, we discovered that only 13% of our debloating attempts produced a sound and robust debloated program.","cats":{"production":0}}
{"text":"Finally, our results indicate that debloating tools typically do not improve the performance or security posture of debloated programs by a significant degree.","cats":{"production":0}}
{"text":"We believe that our contributions in this paper will help potential adopters better understand the landscape of tools and will motivate future research and development of more capable debloating tools.","cats":{"production":0}}
{"text":"To this end, we have made our benchmark set, data, and custom tools publicly available.","cats":{"production":0}}
{"text":"While methods for monocular depth estimation have made significant strides on standard benchmarks, zero-shot metric depth estimation remains unsolved.","cats":{"production":0}}
{"text":"Challenges include the joint modeling of indoor and outdoor scenes, which often exhibit significantly different distributions of RGB and depth, and the depth-scale ambiguity due to unknown camera intrinsics.","cats":{"production":0}}
{"text":"Recent work has proposed specialized multi-head architectures for jointly modeling indoor and outdoor scenes.","cats":{"production":0}}
{"text":"In contrast, we advocate a generic, task-agnostic diffusion model, with several advancements such as log-scale depth parameterization to enable joint modeling of indoor and outdoor scenes, conditioning on the field-of-view (FOV) to handle scale ambiguity and synthetically augmenting FOV during training to generalize beyond the limited camera intrinsics in training datasets.","cats":{"production":0}}
{"text":"Furthermore, by employing a more diverse training mixture than is common, and an efficient diffusion parameterization, our method, DMD (Diffusion for Metric Depth) achieves a 25\\% reduction in relative error (REL) on zero-shot indoor and 33\\% reduction on zero-shot outdoor datasets over the current SOTA using only a small number of denoising steps.","cats":{"production":0}}
{"text":"For an overview see https://diffusion-vision.github.io/dmd","cats":{"production":0}}
{"text":"Diffusion models have gained traction as powerful algorithms for synthesizing high-quality images.","cats":{"production":0}}
{"text":"Central to these algorithms is the diffusion process, which maps data to noise according to equations inspired by thermodynamics and can significantly impact performance.","cats":{"production":0}}
{"text":"A widely held assumption is that the ELBO objective of a diffusion model is invariant to the noise process (Kingma et al.,2021).","cats":{"production":0}}
{"text":"In this work, we dispel this assumption -- we propose multivariate learned adaptive noise (MuLAN), a learned diffusion process that applies Gaussian noise at different rates across an image.","cats":{"production":0}}
{"text":"Our method consists of three components -- a multivariate noise schedule, instance-conditional diffusion, and auxiliary variables -- which ensure that the learning objective is no longer invariant to the choice of the noise schedule as in previous works.","cats":{"production":0}}
{"text":"Our work is grounded in Bayesian inference and casts the learned diffusion process as an approximate variational posterior that yields a tighter lower bound on marginal likelihood.","cats":{"production":0}}
{"text":"Empirically, MuLAN sets a new state-of-the-art in density estimation on CIFAR-10 and ImageNet compared to classical diffusion.","cats":{"production":0}}
{"text":"Code is available at https://github.com/s-sahoo/MuLAN","cats":{"production":0}}
{"text":"Recent studies have explored the low-rank weight factorization techniques which are efficient to train, and apply out-of-the-box to any transformer architecture.","cats":{"production":1}}
{"text":"The resulting approximation is more faithful to the weight distribution in transformers and therefore achieves a stronger efficiency-accuracy trade-off.","cats":{"production":0}}
{"text":"Our approach is also orthogonal to mainstream compressors and offers up to 50% additional compression when added to popular distilled, layer-shared and quantized transformers.","cats":{"production":0}}
{"text":"With the tremendous success of large transformer models in natural language understanding, down-sizing them for cost-effective deployments has become critical.  ","cats":{"production":0}}
{"text":"Unfortunately, the low-rank assumption tends to be over-restrictive and hinders the expressiveness of the compressed model.","cats":{"production":0}}
{"text":"This paper proposes, DSFormer, a simple alternative factorization scheme which expresses a target weight matrix as the product of a small dense and a semi-structured sparse matrix.","cats":{"production":0}}
{"text":"Another  addresses this issue through a novel Straight-Through Factorizer (STF) algorithm that jointly learns all the weight factorizations to directly maximize the final task accuracy.","cats":{"production":0}}
{"text":"Extensive experiments on multiple natural language understanding benchmarks demonstrate that DSFormer obtains up to 40% better compression than the state-of-the-art low-rank factorizers, leading semi-structured sparsity baselines and popular knowledge distillation approaches.","cats":{"production":0}}
{"text":"We empirically evaluate the benefits of STF over conventional optimization practices.","cats":{"production":0}}
{"text":"Reconfigurable Intelligent Surfaces (RIS) have emerged as a disruptive technology with the potential to revolutionize wireless communication systems.","cats":{"production":0}}
{"text":"In this paper, we present RIShield, a novel application of RIS technology specifically designed for radiation-sensitive environments.","cats":{"production":0}}
{"text":"The aim of RIShield is to enable electromagnetic blackouts, preventing radiation leakage from target areas.","cats":{"production":0}}
{"text":"We propose a comprehensive framework for RIShield deployment, considering the unique challenges and requirements of radiation-sensitive environments.","cats":{"production":0}}
{"text":"By strategically positioning RIS panels, we create an intelligent shielding mechanism that selectively absorbs and reflects electromagnetic waves, effectively blocking radiation transmission.","cats":{"production":0}}
{"text":"To achieve optimal performance, we model the corresponding channel and design a dynamic control that adjusts the RIS configuration based on real-time radiation monitoring.","cats":{"production":0}}
{"text":"By leveraging the principles of reconfiguration and intelligent control, RIShield ensures adaptive and efficient protection while minimizing signal degradation.","cats":{"production":0}}
{"text":"Through full-wave and ray-tracing simulations, we demonstrate the effectiveness of RIShield in achieving significant electromagnetic attenuation.","cats":{"production":0}}
{"text":"Our results highlight the potential of RIS technology to address critical concerns in radiation-sensitive environments, paving the way for safer and more secure operations in industries such as healthcare, nuclear facilities, and defense.","cats":{"production":0}}
{"text":"To answer this question, we derive \\emph{scaling laws for adversarial robustness} which can be extrapolated in the future to provide an estimate of how much cost we would need to pay to reach a desired level of robustness.","cats":{"production":1}}
{"text":"We show that increasing the FLOPs needed for adversarial training does not bring as much advantage as it does for standard training in terms of performance improvements.","cats":{"production":0}}
{"text":"The last six years have witnessed significant progress in adversarially robust deep learning.","cats":{"production":0}}
{"text":"As evidenced by the CIFAR-10 dataset category in RobustBench benchmark, the accuracy under $\\ell_\\infty$ adversarial perturbations improved from 44\\% in \\citet{Madry2018Towards} to 71\\% in \\citet{peng2023robust}.","cats":{"production":0}}
{"text":"Although impressive, existing state-of-the-art is still far from satisfactory.","cats":{"production":0}}
{"text":"It is further observed that best-performing models are often very large models adversarially trained by industrial labs with significant computational budgets.","cats":{"production":0}}
{"text":"In this paper, we aim to understand: ``how much longer can computing power drive adversarial robustness advances?\"  ","cats":{"production":0}}
{"text":"Moreover, we find that some of the top-performing teorthwhile directions to pursue in future research.","cats":{"production":0}}
{"text":"Finally, we make our benchmarking framework (built on top of \\texttt{timm}~\\citep{rw2019timm}) publicly available to facilitate future analysis in efficient robust deep learning.","cats":{"production":0}}
{"text":"The transferability of adversarial examples is of central importance to transfer-based black-box adversarial attacks.","cats":{"production":0}}
{"text":"Previous works for generating transferable adversarial examples focus on attacking \\emph{given} pretrained surrogate models while the connections between surrogate models and adversarial trasferability have been overlooked.","cats":{"production":0}}
{"text":"In this paper, we propose {\\em Lipschitz Regularized Surrogate} (LRS) for transfer-based black-box attacks, a novel approach that transforms surrogate models towards favorable adversarial transferability.","cats":{"production":0}}
{"text":"Using such transformed surrogate models, any existing transfer-based black-box attack can run without any change, yet achieving much better performance.","cats":{"production":0}}
{"text":"Specifically, we impose Lipschitz regularization on the loss landscape of surrogate models to enable a smoother and more controlled optimization process for generating more transferable adversarial examples.","cats":{"production":0}}
{"text":"In addition, this paper also sheds light on the connection between the inner properties of surrogate models and adversarial transferability, where three factors are identified: smaller local Lipschitz constant, smoother loss landscape, and stronger adversarial robustness.","cats":{"production":0}}
{"text":"We evaluate our proposed LRS approach by attacking state-of-the-art standard deep neural networks and defense models.","cats":{"production":0}}
{"text":"The results demonstrate significant improvement on the attack success rates and transferability.","cats":{"production":0}}
{"text":"Our code is available at https://github.com/TrustAIoT/LRS.","cats":{"production":0}}
{"text":"Decentralized finance revolutionizes traditional financial systems by leveraging blockchain technology to reduce trust.","cats":{"production":0}}
{"text":"However, some vulnerabilities persist, notably front-running by malicious actors who exploit transaction information to gain financial advantage.","cats":{"production":0}}
{"text":"Consensus with a fair order aims at preventing such attacks, and in particular, the differential order fairness property addresses this problem and connects fair ordering to the validity of consensus.","cats":{"production":0}}
{"text":"The notion is implemented by the Quick Order-Fair Atomic Broadcast (QOF) protocol (Cachin et al., FC '22).","cats":{"production":0}}
{"text":"This paper revisits the QOF protocol and describes a modular implementation that uses a generic consensus component.","cats":{"production":0}}
{"text":"Moreover, an empirical evaluation is performed to compare the performance of QOF to a consensus protocol without fairness.","cats":{"production":0}}
{"text":"Measurements show that the increased complexity comes at a cost, throughput decreases by at most 5%, and latency increases by roughly 50ms, using an emulated ideal network.","cats":{"production":0}}
{"text":"This paper contributes to a comprehensive understanding of practical aspects regarding differential order fairness with the QOF protocol and also connects this with similar fairness-imposing protocols like Themis and Pompe.","cats":{"production":0}}
{"text":"We compare how the chatbots perform in high- and low-resource languages by using prompts in English, Russian, and Ukrainian.","cats":{"production":0}}
{"text":"The results show high performance of ChatGPT for the baseline veracity evaluation task, with 72 percent of the cases evaluated correctly on average across languages without pre-training.","cats":{"production":0}}
{"text":"Bing Chat performed worse with a 67 percent accuracy.","cats":{"production":0}}
{"text":"Denoising Probabilistic Models (DPMs) represent an emerging domain of generative models that excel in generating diverse and high-quality images.","cats":{"production":0}}
{"text":"However, most current training methods for DPMs often neglect the correlation between timesteps, limiting the model's performance in generating images effectively.","cats":{"production":0}}
{"text":"Notably, we theoretically point out that this issue can be caused by the cumulative estimation gap between the predicted and the actual trajectory.","cats":{"production":0}}
{"text":"To minimize that gap, we propose a novel \\textit{sequence-aware} loss that aims to reduce the estimation gap to enhance the sampling quality.","cats":{"production":0}}
{"text":"Furthermore, we theoretically show that our proposed loss function is a tighter upper bound of the estimation loss in comparison with the conventional loss in DPMs.","cats":{"production":0}}
{"text":"Experimental results on several benchmark datasets including CIFAR10, CelebA, and CelebA-HQ consistently show a remarkable improvement of our proposed method regarding the image generalization quality measured by FID and Inception Score compared to several DPM baselines.","cats":{"production":0}}
{"text":"Our code and pre-trained checkpoints are available at \\url{https://github.com/viettmab/SA-DPM}.","cats":{"production":0}}
{"text":"In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models.","cats":{"production":0}}
{"text":"We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process.","cats":{"production":0}}
{"text":"As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps.","cats":{"production":0}}
{"text":"Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process.","cats":{"production":0}}
{"text":"By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner.","cats":{"production":0}}
{"text":"To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation.","cats":{"production":0}}
{"text":"The results demonstrate the superiority of our SegRefiner from multiple aspects.","cats":{"production":0}}
{"text":"Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks.","cats":{"production":0}}
{"text":"Secondly, it outperforms previous model-agnostic refinement methods by a significant margin.","cats":{"production":0}}
{"text":"Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images.","cats":{"production":0}}
{"text":"The source code and trained models are available at https://github.com/MengyuWang826/SegRefiner.","cats":{"production":0}}
{"text":"The popular CLIP model displays impressive zero-shot capabilities thanks to its seamless interaction with arbitrary text prompts.","cats":{"production":0}}
{"text":"However, its lack of spatial awareness makes it unsuitable for dense computer vision tasks, e.g., semantic segmentation, without an additional fine-tuning step that often uses annotations and can potentially suppress its original open-vocabulary properties.","cats":{"production":0}}
{"text":"Meanwhile, self-supervised representation methods have demonstrated good localization properties without human-made annotations nor explicit supervision.","cats":{"production":0}}
{"text":"In this work, we take the best of both worlds and propose a zero-shot open-vocabulary semantic segmentation method, which does not require any annotations.","cats":{"production":0}}
{"text":"We propose to locally improve dense MaskCLIP features, computed with a simple modification of CLIP's last pooling layer, by integrating localization priors extracted from self-supervised features.","cats":{"production":0}}
{"text":"By doing so, we greatly improve the performance of MaskCLIP and produce smooth outputs.","cats":{"production":0}}
{"text":"Moreover, we show that the used self-supervised feature properties can directly be learnt from CLIP features therefore allowing us to obtain the best results with a single pass through CLIP model.","cats":{"production":0}}
{"text":"Our method CLIP-DINOiser needs only a single forward pass of CLIP and two light convolutional layers at inference, no extra supervision nor extra memory and reaches state-of-the-art results on challenging and fine-grained benchmarks such as COCO, Pascal Context, Cityscapes and ADE20k.","cats":{"production":0}}
{"text":"The code to reproduce our results is available at https://github.com/wysoczanska/clip_dinoiser.","cats":{"production":0}}
{"text":"Geometric fracture assembly presents a challenging practical task in archaeology and 3D computer vision.","cats":{"production":0}}
{"text":"Previous methods have focused solely on assembling fragments based on semantic information, which has limited the quantity of objects that can be effectively assembled.","cats":{"production":0}}
{"text":"Therefore, there is a need to develop a scalable framework for geometric fracture assembly without relying on semantic information.","cats":{"production":0}}
{"text":"To improve the effectiveness of assembling geometric fractures without semantic information, we propose a co-creation space comprising several assemblers capable of gradually and unambiguously assembling fractures.","cats":{"production":0}}
{"text":"Additionally, we introduce a novel loss function, i.e., the geometric-based collision loss, to address collision issues during the fracture assembly process and enhance the results.","cats":{"production":0}}
{"text":"Our framework exhibits better performance on both PartNet and Breaking Bad datasets compared to existing state-of-the-art frameworks.","cats":{"production":0}}
{"text":"Extensive experiments and quantitative comparisons demonstrate the effectiveness of our proposed framework, which features linear computational complexity, enhanced abstraction, and improved generalization.","cats":{"production":0}}
{"text":"Our code is publicly available at https://github.com/Ruiyuan-Zhang/CCS.","cats":{"production":0}}
{"text":"We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images.","cats":{"production":0}}
{"text":"Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time.","cats":{"production":0}}
{"text":"To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution.","cats":{"production":0}}
{"text":"We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation.","cats":{"production":0}}
{"text":"We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance field.","cats":{"production":0}}
{"text":"This study investigates the application of single and two-stage 2D-object detection algorithms like You Only Look Once (YOLO), Real-Time DEtection TRansformer (RT-DETR) algorithm for automated object detection to enhance road safety for autonomous driving on Austrian roads.","cats":{"production":0}}
{"text":"The YOLO algorithm is a state-of-the-art real-time object detection system known for its efficiency and accuracy.","cats":{"production":0}}
{"text":"In the context of driving, its potential to rapidly identify and track objects is crucial for advanced driver assistance systems (ADAS) and autonomous vehicles.","cats":{"production":0}}
{"text":"The research focuses on the unique challenges posed by the road conditions and traffic scenarios in Austria.","cats":{"production":0}}
{"text":"The country's diverse landscape, varying weather conditions, and specific traffic regulations necessitate a tailored approach for reliable object detection.","cats":{"production":0}}
{"text":"The study utilizes a selective dataset comprising images and videos captured on Austrian roads, encompassing urban, rural, and alpine environments.","cats":{"production":0}}
{"text":"Remote collaboration is a common reality of spatial design processes, but tools for computer aided design were made for single users.","cats":{"production":0}}
{"text":"Via TeamCAD, we introduce a user experience where online remote collaboration experience is more like working on a table.","cats":{"production":0}}
{"text":"Using speech and gesture recognition based on state of the art machine learning through webcam and microphone input, TeamCAD plugs into existing software through API's, keybindings, and mouse input.","cats":{"production":0}}
{"text":"Our user tests were run on Blender animation software, making simultaneous use of both modalities for given tasks.","cats":{"production":0}}
{"text":"We mitigated challenges in terms of robustness and latency in readily available voice recognition models.","cats":{"production":0}}
{"text":"Our prototype has proven to be an intuitive interface, providing a suitable denominator for collaborators with or without previous experience in three-dimensional modeling applications.","cats":{"production":0}}
{"text":"We present Intrinsic Image Diffusion, a generative model for appearance decomposition of indoor scenes.","cats":{"production":0}}
{"text":"Given a single input view, we sample multiple possible material explanations represented as albedo, roughness, and metallic maps.","cats":{"production":0}}
{"text":"Appearance decomposition poses a considerable challenge in computer vision due to the inherent ambiguity between lighting and material properties and the lack of real datasets.","cats":{"production":0}}
{"text":"To address this issue, we advocate for a probabilistic formulation, where instead of attempting to directly predict the true material properties, we employ a conditional generative model to sample from the solution space.","cats":{"production":0}}
{"text":"Furthermore, we show that utilizing the strong learned prior of recent diffusion models trained on large-scale real-world images can be adapted to material estimation and highly improves the generalization to real images.","cats":{"production":0}}
{"text":"Our method produces significantly sharper, more consistent, and more detailed materials, outperforming state-of-the-art methods by $1.5dB$ on PSNR and by $45\\%$ better FID score on albedo prediction.","cats":{"production":0}}
{"text":"We demonstrate the effectiveness of our approach through experiments on both synthetic and real-world datasets.","cats":{"production":0}}
{"text":"While semi-supervised learning (SSL) has yielded promising results, the more realistic SSL scenario remains to be explored, in which the unlabeled data exhibits extremely high recognition difficulty, e.g., fine-grained visual classification in the context of SSL (SS-FGVC).","cats":{"production":0}}
{"text":"The increased recognition difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling accuracy, resulting in poor performance of the SSL model.","cats":{"production":0}}
{"text":"To tackle this challenge, we propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC) by reconstructing the pseudo-label selection process by jointly optimizing Expansion Objective and Shrinkage Objective, which is based on a soft label manner.","cats":{"production":0}}
{"text":"Respectively, the former objective encourages soft labels to absorb more candidate classes to ensure the attendance of ground-truth class, while the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization.","cats":{"production":0}}
{"text":"In comparisons with various state-of-the-art methods, our approach demonstrates its superior performance in SS-FGVC.","cats":{"production":0}}
{"text":"Checkpoints and source code are available at https://github.com/NJUyued/SoC4SS-FGVC.","cats":{"production":0}}
{"text":"With the rise of real-time rendering and the evolution of display devices, there is a growing demand for post-processing methods that offer high-resolution content in a high frame rate.","cats":{"production":0}}
{"text":"Existing techniques often suffer from quality and latency issues due to the disjointed treatment of frame supersampling and extrapolation.","cats":{"production":0}}
{"text":"In this paper, we recognize the shared context and mechanisms between frame supersampling and extrapolation, and present a novel framework, Space-time Supersampling (STSS).","cats":{"production":0}}
{"text":"By integrating them into a unified framework, STSS can improve the overall quality with lower latency.","cats":{"production":0}}
{"text":"To implement an efficient architecture, we treat the aliasing and warping holes unified as reshading regions and put forth two key components to compensate the regions, namely Random Reshading Masking (RRM) and Efficient Reshading Module (ERM).","cats":{"production":0}}
{"text":"Extensive experiments demonstrate that our approach achieves superior visual fidelity compared to state-of-the-art (SOTA) methods.","cats":{"production":0}}
{"text":"Notably, the performance is achieved within only 4ms, saving up to 75\\% of time against the conventional two-stage pipeline that necessitates 17ms.","cats":{"production":0}}
{"text":"We optimize the Age of Information (AoI) in mobile networks using the age-threshold slotted ALOHA (TSA) protocol.","cats":{"production":0}}
{"text":"The network comprises multiple source-destination pairs, where each source sends a sequence of status update packets to its destination over a shared spectrum.","cats":{"production":0}}
{"text":"The TSA protocol stipulates that a source node must remain silent until its AoI reaches a predefined threshold, after which the node accesses the radio channel with a certain probability.","cats":{"production":0}}
{"text":"Using stochastic geometry tools, we derive analytical expressions for the transmission success probability, mean peak AoI, and time-average AoI. Subsequently, we obtain closed-form expressions for the optimal update rate and age threshold that minimize the mean peak and time-average AoI, respectively.","cats":{"production":0}}
{"text":"In addition, we establish a scaling law for the mean peak AoI and time-average AoI in mobile networks, revealing that the optimal mean peak AoI and time-average AoI increase linearly with the deployment density.","cats":{"production":0}}
{"text":"Notably, the growth rate of time-average AoI under TSA is half of that under conventional slotted ALOHA.","cats":{"production":0}}
{"text":"When considering the optimal mean peak AoI, the TSA protocol exhibits comparable performance to the traditional slotted ALOHA protocol.","cats":{"production":0}}
{"text":"These findings conclusively affirm the advantage of TSA in reducing higher-order AoI, particularly in densely deployed networks.","cats":{"production":0}}
{"text":"Ocean and climate research benefits from global ocean observation initiatives such as Argo, GLOSS, and EMSO.","cats":{"production":0}}
{"text":"The Argo network, dedicated to ocean profiling, generates a vast volume of observatory data.","cats":{"production":0}}
{"text":"However, data quality issues from sensor malfunctions and transmission errors necessitate stringent quality assessment.","cats":{"production":0}}
{"text":"Existing methods, including machine learning, fall short due to limited labeled data and imbalanced datasets.","cats":{"production":0}}
{"text":"To address these challenges, we propose an ODEAL framework for ocean data quality assessment, employing AL to reduce human experts' workload in the quality assessment workflow and leveraging outlier detection algorithms for effective model initialization.","cats":{"production":0}}
{"text":"We also conduct extensive experiments on five large-scale realistic Argo datasets to gain insights into our proposed method, including the effectiveness of AL query strategies and the initial set construction approach.","cats":{"production":0}}
{"text":"The results suggest that our framework enhances quality assessment efficiency by up to 465.5% with the uncertainty-based query strategy compared to random sampling and minimizes overall annotation costs by up to 76.9% using the initial set built with outlier detectors.","cats":{"production":0}}
{"text":"Large Language Models and Multi-Modal LLMs have become pervasive, and so does the importance of their security; yet, modern LLMs are known to be vulnerable to jailbreaking attacks.","cats":{"production":0}}
{"text":"These attacks can allow malicious users to exploit the models, making the case for effective jailbreak detection mechanisms an essential aspect of maintaining the integrity and trustworthiness of LLM-based applications.","cats":{"production":0}}
{"text":"However, existing detection works on jailbreak attacks have limitations.","cats":{"production":0}}
{"text":"Existing post-query-based strategies require target domain knowledge, and pre-query-based methods mainly focus on text-level attacks and fail to meet the increasingly complex multi-modal security requirements placed upon contemporary LLMs.","cats":{"production":0}}
{"text":"This gap underscores the need for a more comprehensive approach to safeguarding these influential systems.   ","cats":{"production":0}}
{"text":"In this work, we propose JailGuard, the first mutation-based jailbreaking detection framework which supports both image and text modalities.","cats":{"production":0}}
{"text":"Our key observation is that attack queries inherently possess less robustness compared to benign queries.","cats":{"production":0}}
{"text":"Specifically, to confuse the model, attack queries are usually crafted with well-designed templates or complicate perturbations, leading to a fact that a slight disturbance in input may result in a drastic change in the response.","cats":{"production":0}}
{"text":"This lack of robustness can be utilized in attack detection.","cats":{"production":0}}
{"text":"Based on this intuition, we designed and implemented a detection framework comprising 19 different mutators and a divergence-based detection formula.","cats":{"production":0}}
{"text":"To fully understand the effectiveness of our framework, we built the first multi-modal LLM jailbreaking attack dataset, which has 304 items of data, covering ten types of known jailbreaking attacks on image and text modalities.","cats":{"production":0}}
{"text":"The evaluation suggests that JailGuard achieves the best detection accuracy of 89.38%/85.42% on image and text inputs, outperforming state-of-the-art defense methods by 15.28%.","cats":{"production":0}}
{"text":"High-resolution representation is essential for achieving good performance in human pose estimation models.","cats":{"production":0}}
{"text":"To obtain such features, existing works utilize high-resolution input images or fine-grained image tokens.","cats":{"production":0}}
{"text":"However, this dense high-resolution representation brings a significant computational burden.","cats":{"production":0}}
{"text":"In this paper, we address the following question: \"Only sparse human keypoint locations are detected for human pose estimation, is it really necessary to describe the whole image in a dense, high-resolution manner?\"","cats":{"production":0}}
{"text":"Based on dynamic transformer models, we propose a framework that only uses Sparse High-resolution Representations for human Pose estimation (SHaRPose).","cats":{"production":0}}
{"text":"In detail, SHaRPose consists of two stages.","cats":{"production":0}}
{"text":"At the coarse stage, the relations between image regions and keypoints are dynamically mined while a coarse estimation is generated.","cats":{"production":0}}
{"text":"Then, a quality predictor is applied to decide whether the coarse estimation results should be refined.","cats":{"production":0}}
{"text":"At the fine stage, SHaRPose builds sparse high-resolution representations only on the regions related to the keypoints and provides refined high-precision human pose estimations.","cats":{"production":0}}
{"text":"Extensive experiments demonstrate the outstanding performance of the proposed method.","cats":{"production":0}}
{"text":"Specifically, compared to the state-of-the-art method ViTPose, our model SHaRPose-Base achieves 77.4 AP (+0.5 AP) on the COCO validation set and 76.7 AP (+0.5 AP) on the COCO test-dev set, and infers at a speed of $1.4\\times$ faster than ViTPose-Base.","cats":{"production":0}}
{"text":"Specifically, to learn more compact features, a share-parameter Transformer encoder is introduced to extract point features from the global and local unmasked patches obtained by global random and local block mask strategies, followed by a specific decoder to reconstruct.","cats":{"production":1}}
{"text":"Learning 3D representation plays a critical role in masked autoencoder (MAE) based pre-training methods for point cloud, including single-modal and cross-modal based MAE.","cats":{"production":0}}
{"text":"Specifically, although cross-modal MAE methods learn strong 3D representations via the auxiliary of other modal knowledge, they often suffer from heavy computational burdens and heavily rely on massive cross-modal data pairs that are often unavailable, which hinders their applications in practice.","cats":{"production":0}}
{"text":"Instead, single-modal methods with solely point clouds as input are preferred in real applications due to their simplicity and efficiency.","cats":{"production":0}}
{"text":"However, such methods easily suffer from limited 3D representations with global random mask input.","cats":{"production":0}}
{"text":"To learn compact 3D representations, we propose a simple yet effective Point Feature Enhancement Masked Autoencoders (Point-FEMAE), which mainly consists of a global branch and a local branch to capture latent semantic features.  ","cats":{"production":0}}
{"text":"Meanwhile, to further enhance features in the local branch, we propose a Local Enhancement Module with local patch convolution to perceive fine-grained local context at larger scales.","cats":{"production":0}}
{"text":"Our method significantly improves the pre-training efficiency compared to cross-modal alternatives, and extensive downstream experiments underscore the state-of-the-art effectiveness, particularly outperforming our baseline (Point-MAE) by 5.16%, 5.00%, and 5.04% in three variants of ScanObjectNN, respectively.","cats":{"production":0}}
{"text":"The code is available at https://github.com/zyh16143998882/AAAI24-PointFEMAE.","cats":{"production":0}}
{"text":"DeepFake, an AI technology for creating facial forgeries, has garnered global attention.","cats":{"production":0}}
{"text":"Amid such circumstances, forensics researchers focus on developing defensive algorithms to counter these threats.","cats":{"production":0}}
{"text":"In contrast, there are techniques developed for enhancing the aggressiveness of DeepFake, e.g., through anti-forensics attacks, to disrupt forensic detectors.","cats":{"production":0}}
{"text":"However, such attacks often sacrifice image visual quality for improved undetectability.","cats":{"production":0}}
{"text":"To address this issue, we propose a method to generate novel adversarial sharpening masks for launching black-box anti-forensics attacks.","cats":{"production":0}}
{"text":"Unlike many existing arts, with such perturbations injected, DeepFakes could achieve high anti-forensics performance while exhibiting pleasant sharpening visual effects.","cats":{"production":0}}
{"text":"After experimental evaluations, we prove that the proposed method could successfully disrupt the state-of-the-art DeepFake detectors.","cats":{"production":0}}
{"text":"Besides, compared with the images processed by existing DeepFake anti-forensics methods, the visual qualities of anti-forensics DeepFakes rendered by the proposed method are significantly refined.","cats":{"production":0}}
{"text":"This paper proposes a new framework for depth completion robust against domain-shifting issues.","cats":{"production":0}}
{"text":"It exploits the generalization capability of modern stereo networks to face depth completion, by processing fictitious stereo pairs obtained through a virtual pattern projection paradigm.","cats":{"production":0}}
{"text":"Any stereo network or traditional stereo matcher can be seamlessly plugged into our framework, allowing for the deployment of a virtual stereo setup that is future-proof against advancement in the stereo field.","cats":{"production":0}}
{"text":"Exhaustive experiments on cross-domain generalization support our claims.","cats":{"production":0}}
{"text":"Hence, we argue that our framework can help depth completion to reach new deployment scenarios.","cats":{"production":0}}
