{"text":"As far as we know, our work is the first to create prompts based on testing results to improve LLMs' formal reasoning ability effectively.","cats":{"prompt-engineering":1}}
{"text":"Our survey findings provide a basis for developing the concept of linear and non-linear contexts, which we define and use to enable an agent-centric projection of prompting techniques providing a lens through which prompting techniques can be viewed as multi-agent systems.","cats":{"prompt-engineering":1}}
{"text":"The paper discusses the implications of this lens, for the cross-pollination of research between LLM prompting and LLM-based multi-agent systems; and also, for the generation of synthetic training data based on existing prompting techniques in research.","cats":{"prompt-engineering":1}}
{"text":"Current prompting approach for language model inference mainly rely on Language Model's (LLM) autonomous exploration of reasoning paths, confronts an inevitable retracing operation when erroneous routes are encountered.","cats":{"prompt-engineering":1}}
{"text":"However, instruction prompting involves designing crafted prompts for zero-shot learning or selecting appropriate samples for few-shot learning and requires users to have professional domain knowledge, while task-oriented fine-tuning requires high training costs.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"In this paper, we propose a novel prompt learning framework for code summarization called PromptCS.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"trains a prompt agent that can generate continuous prompts to unleash the potential for LLMs in code summarization.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"To enhance the prompt, we introduce position shifting strategy to mitigate position bias and augment the prompt with auxiliary information from conventional recommendation models, thereby enriching the contextual understanding of the LLM.","cats":{"prompt-engineering":1}}
{"text":"Specifically, Prompt Builder dynamically generated comprehensive prompts to enhance model generation performance.","cats":{"prompt-engineering":1}}
{"text":"Instead, this work focuses on inverting the diffusion model to obtain interpretable language prompts directly.","cats":{"prompt-engineering":1}}
{"text":"The challenge of doing this lies in the fact that the resulting optimization problem is fundamentally discrete and the space of prompts is exponentially large; this makes using standard optimization techniques, such as stochastic gradient descent, difficult.","cats":{"prompt-engineering":1}}
{"text":"Recently, prompt tuning has become a popular solution.","cats":{"prompt-engineering":1}}
{"text":"2) What defines an effective prompt?","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"We introduce k Nearest Neighbor In-Context Learning(kNN-ICL), which simplifies prompt engineering by allowing it to be built on top of any design strategy while providing access to all demo examples.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos.","cats":{"prompt-engineering":0}}
{"text":"Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes.","cats":{"prompt-engineering":0}}
{"text":"However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses.","cats":{"prompt-engineering":0}}
{"text":"We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations.","cats":{"prompt-engineering":0}}
{"text":"Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background.","cats":{"prompt-engineering":0}}
{"text":"To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance.","cats":{"prompt-engineering":0}}
{"text":"The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066$\\times$1600 resolution) within half an hour of training.","cats":{"prompt-engineering":0}}
{"text":"The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets.","cats":{"prompt-engineering":0}}
{"text":"Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker.","cats":{"prompt-engineering":0}}
{"text":"The code is available at https://zju3dv.github.io/street_gaussians/.","cats":{"prompt-engineering":0}}
{"text":"In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.","cats":{"prompt-engineering":0,"education":0}}
{"text":"At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself.","cats":{"prompt-engineering":0,"recommender":0}}
{"text":"Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench.","cats":{"prompt-engineering":0}}
{"text":"Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data.","cats":{"prompt-engineering":0,"education":0}}
{"text":"The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT).","cats":{"prompt-engineering":0,"security":0}}
{"text":"iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action.","cats":{"prompt-engineering":0,"recommender":0}}
{"text":"In this paper, we report on the first year of TREC iKAT, describing the task, topics, data collection, and evaluation framework.","cats":{"prompt-engineering":0}}
{"text":"We further review the submissions and summarize the findings.","cats":{"prompt-engineering":0}}
{"text":"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem.","cats":{"prompt-engineering":0,"hci":0,"education":0}}
{"text":"It generates a linearized graph where nodes represent text spans and edges represent relation triplets.","cats":{"prompt-engineering":0,"recommender":0}}
{"text":"Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results.","cats":{"prompt-engineering":0,"security":0}}
{"text":"Code is available at https://github.com/urchade/ATG.","cats":{"prompt-engineering":0}}
{"text":"The two levels are computed by the original model's self-attention, which means the proposed does not require any training.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"In this paper, we consider classes of decision tables closed under removal of attributes (columns) and changing of decisions attached to rows.","cats":{"prompt-engineering":0}}
{"text":"For decision tables from closed classes, we study lower bounds on the minimum cardinality of reducts, which are minimal sets of attributes that allow us to recognize, for a given row, the decision attached to it.","cats":{"prompt-engineering":0,"recommender":0}}
{"text":"We assume that the number of rows in decision tables from the closed class is not bounded from above by a constant.","cats":{"prompt-engineering":0,"education":0}}
{"text":"We divide the set of such closed classes into two families.","cats":{"prompt-engineering":0}}
{"text":"In one family, only standard lower bounds $\\Omega (\\log $ ${\\rm cl}(T))$ on the minimum cardinality of reducts for decision tables hold, where ${\\rm cl}(T)$ is the number of decision classes in the table $T$. In another family, these bounds can be essentially tightened up to $\\Omega ({\\rm cl}(T)^{1/q})$ for some natural $q$.","cats":{"prompt-engineering":0}}
{"text":"In this paper, we consider a number of models for inferring a non-deterministic finite automaton (NFA) with 3 sorts of states, that must accept some words, and reject some other words from a given sample.","cats":{"prompt-engineering":0}}
{"text":"We then propose a transformation from this 3-sort NFA into weighted-frequency and probabilistic NFA, and we apply the latter to a classification task.","cats":{"prompt-engineering":0,"recommender":0}}
{"text":"The experimental evaluation of our approach shows that the probabilistic NFAs can be successfully applied for classification tasks on both real-life and superficial benchmark data sets.","cats":{"prompt-engineering":0}}
{"text":"This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives.","cats":{"prompt-engineering":0,"security":0}}
{"text":"The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations.","cats":{"prompt-engineering":0}}
{"text":"Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training.","cats":{"prompt-engineering":0}}
{"text":"This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs.","cats":{"prompt-engineering":0}}
{"text":"Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023).","cats":{"prompt-engineering":1}}
{"text":"Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs.","cats":{"prompt-engineering":0}}
{"text":"Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.","cats":{"prompt-engineering":0,"education":0}}
{"text":"The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios.","cats":{"prompt-engineering":0}}
{"text":"Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs).","cats":{"prompt-engineering":0}}
{"text":"More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data.","cats":{"prompt-engineering":0}}
{"text":"Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution.","cats":{"prompt-engineering":0,"education":0,"recommender":0}}
{"text":"This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.","cats":{"prompt-engineering":0}}
{"text":"Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works.","cats":{"prompt-engineering":0,"education":0}}
{"text":"However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context.","cats":{"prompt-engineering":0}}
{"text":"The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them.","cats":{"prompt-engineering":0}}
{"text":"These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions about the information space include: finding options, comparing options, identifying the pros and cons of options, etc.","cats":{"prompt-engineering":0}}
{"text":"Given the different personas and their information need (expressed through the sequence of questions), diverse conversation trajectories will arise -- because the answers to these similar queries will be very different.","cats":{"prompt-engineering":0}}
{"text":"In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}.","cats":{"prompt-engineering":0}}
{"text":"This work elicits LLMs' inherent ability to handle long contexts without fine-tuning.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"We propose Self-Extend to stimulate LLMs' long context handling potential.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"The basic idea is to construct bi-level attention information: the group level and the neighbor level.","cats":{"prompt-engineering":0,"social-sciences":0}}
{"text":"With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning.","cats":{"prompt-engineering":0,"social-sciences":0,"programming":0}}
{"text":"Grammatical inference consists in learning a language or a grammar from data.","cats":{"prompt-engineering":0}}
{"text":"As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input.","cats":{"prompt-engineering":1,"recommender":0}}
{"text":"This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc.","cats":{"prompt-engineering":0,"security":0}}
{"text":"Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving.","cats":{"prompt-engineering":1}}
{"text":"Traditional techniques like chain-of-thought prompting necessitate explicit human guidance.","cats":{"prompt-engineering":1}}
{"text":"This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities.","cats":{"prompt-engineering":0}}
{"text":"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system.","cats":{"prompt-engineering":0,"hci":1}}
{"text":"Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%).","cats":{"prompt-engineering":0,"hci":0}}
{"text":"While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines.","cats":{"prompt-engineering":0,"hci":0}}
{"text":"The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology.","cats":{"prompt-engineering":0}}
{"text":"Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions.","cats":{"prompt-engineering":0}}
{"text":"We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development.","cats":{"prompt-engineering":0}}
{"text":"The study concludes by addressing the challenges faced and suggesting potential research directions in this field.","cats":{"prompt-engineering":0}}
{"text":"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization.","cats":{"prompt-engineering":0,"robustness":0,"hci":0}}
{"text":"This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance.","cats":{"prompt-engineering":0}}
{"text":"To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs.","cats":{"prompt-engineering":0,"robustness":1}}
{"text":"In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches.","cats":{"prompt-engineering":0}}
{"text":"Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT.","cats":{"prompt-engineering":1}}
{"text":"Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output.","cats":{"prompt-engineering":1}}
{"text":"Prompts are also a form of programming that can customize the outputs and interactions with an LLM.","cats":{"prompt-engineering":1}}
{"text":"This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","cats":{"prompt-engineering":1}}
{"text":"Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs.","cats":{"prompt-engineering":1}}
{"text":"This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks.","cats":{"prompt-engineering":1}}
{"text":"First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains.","cats":{"prompt-engineering":1}}
{"text":"Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations.","cats":{"prompt-engineering":1}}
{"text":"Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.","cats":{"prompt-engineering":1}}
{"text":" Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated ot engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs.","cats":{"prompt-engineering":0}}
{"text":"Prompt patterns are acommon problems faced in a particular context, i.e., output generation and interaction when working des a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains.","cats":{"prompt-engineering":0}}
{"text":"Second, it presents a with other prompt patterns.","cats":{"prompt-engineering":0}}
{"text":"This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented.","cats":{"prompt-engineering":1}}
{"text":"This paper provides two contributions to research on using LLMs for software engineering.","cats":{"prompt-engineering":0}}
{"text":"First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve.","cats":{"prompt-engineering":0}}
{"text":"Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.","cats":{"prompt-engineering":1}}
{"text":"Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, cod","cats":{"prompt-engineering":0}}
{"text":"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt.","cats":{"prompt-engineering":1,"programming":1}}
{"text":"Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts.","cats":{"prompt-engineering":1,"education":1,"programming":1}}
{"text":"These advances may enable students to interact with code in new ways while helping instructors scale their learning materials.","cats":{"prompt-engineering":1,"education":0,"programming":1}}
{"text":"However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers.","cats":{"prompt-engineering":1,"education":1}}
{"text":"This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research.","cats":{"prompt-engineering":1}}
{"text":"We will also engage attendees in brainstorming to consider how LLMs will impact our field.","cats":{"prompt-engineering":1}}
{"text":" Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafmplications for academic integrity, curriculum design, and software engineering careers.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"This workshop will demonstrate the capabilities of LLMs to help attendees evaluate wheider how LLMs will impact our field.","cats":{"prompt-engineering":0,"programming":0}}
{"text":"Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities.","cats":{"prompt-engineering":1}}
{"text":"As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident.","cats":{"prompt-engineering":1}}
{"text":"Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction.","cats":{"prompt-engineering":1}}
{"text":"This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering.","cats":{"prompt-engineering":1}}
{"text":"We present influential large models in the visual domain and a range of prompt engineering methods employed on these models.","cats":{"prompt-engineering":1}}
{"text":"It is our hope that this review provides a comprehensive and systematic description of prompt engineering methods based on large visual models, offering valuable insights for future researchers in their exploration of this field.","cats":{"prompt-engineering":1}}
{"text":" As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident.","cats":{"prompt-engineering":0}}
{"text":"Designing suitable prompts for specific visual tasks has emergeor large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering.","cats":{"prompt-engineering":0}}
{"text":"We oyed on these models.","cats":{"prompt-engineering":0}}
{"text":"It is our hope that this review provides a comprehensive and systematic descrip","cats":{"prompt-engineering":0}}
{"text":"Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application.","cats":{"prompt-engineering":1}}
{"text":"A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application.","cats":{"prompt-engineering":0}}
{"text":"The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor.  ","cats":{"prompt-engineering":0}}
{"text":"A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them.","cats":{"prompt-engineering":1}}
{"text":"Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research. We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges.","cats":{"prompt-engineering":1}}
{"text":"GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization.","cats":{"prompt-engineering":0}}
{"text":"Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text.","cats":{"prompt-engineering":0}}
{"text":"This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data.  ","cats":{"prompt-engineering":0}}
{"text":"Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research.","cats":{"prompt-engineering":0}}
{"text":"We use this position","cats":{"prompt-engineering":0}}
{"text":"The paradigm under which this revolution takes place is prompt-based learning (or in-context learning).","cats":{"prompt-engineering":1}}
{"text":"This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art.","cats":{"prompt-engineering":1}}
{"text":"This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images.","cats":{"prompt-engineering":1}}
{"text":"In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art.","cats":{"prompt-engineering":0}}
{"text":"In three studies with participants recruited from a crowdsourcing platform, we explore whether untrained participants could 1) recognize the quality of prompts, 2) write prompts, and 3) improve their prompts.","cats":{"prompt-engineering":1}}
{"text":"Our results indicate that participants could assess the quality of prompts and respective images.","cats":{"prompt-engineering":0}}
{"text":"Participants further were able to write prompts in rich descriptive language.","cats":{"prompt-engineering":1}}
{"text":"However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images.","cats":{"prompt-engineering":1}}
{"text":"Our results suggest that prompt engineering is a learned skill that requires expertise and practice.","cats":{"prompt-engineering":1}}
{"text":"Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-to-image generation and prompt engineering with a paid crowd.","cats":{"prompt-engineering":1}}
{"text":"Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering.","cats":{"prompt-engineering":1}}
{"text":"We conclude by speculating on four possible futures of prompt engineering.","cats":{"prompt-engineering":1}}
{"text":"Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content.  ","cats":{"prompt-engineering":0}}
{"text":"This paradigm has found fruitful application in text-to-image generation where it is being used to syntenerate and improve images.","cats":{"prompt-engineering":0}}
{"text":"In three studies with participants recruited from a crowdsourcing platform,pts.","cats":{"prompt-engineering":0}}
{"text":"This ability increased withh descriptive language.","cats":{"prompt-engineering":0}}
{"text":"However, even though participants were specifically instructed to generate artworkd practice.","cats":{"prompt-engineering":0}}
{"text":"Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-nding of prompt engineering thereby opening up avenues for research on the future of prompt engineeri We conclude by speculating on four possible futures of prompt engineeri","cats":{"prompt-engineering":0}}
{"text":"Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.","cats":{"prompt-engineering":1,"education":1}}
{"text":"The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research.","cats":{"prompt-engineering":0,"education":1}}
{"text":"Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","cats":{"prompt-engineering":0,"education":1}}
{"text":"This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India.  ","cats":{"prompt-engineering":0}}
{"text":"These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond.","cats":{"prompt-engineering":0,"education":1}}
{"text":"While LLMs are powerful, it is also crucial to best use their power where \"prompt'' plays a core role.","cats":{"prompt-engineering":1}}
{"text":"Recently, we have observed the trend of utilizing prompt-based tools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology, partly due to the rapid evolution of this field.","cats":{"prompt-engineering":1}}
{"text":"Therefore, in this work, we survey related prompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models.","cats":{"prompt-engineering":1}}
{"text":"We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level, Base Level, Execute Level, and Service Level.","cats":{"prompt-engineering":1}}
{"text":"We also systematically depict the overall landscape of the emerging PF field and discuss potential future research and challenges.","cats":{"prompt-engineering":1}}
{"text":"Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant advancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas.  ","cats":{"prompt-engineering":0}}
{"text":"However, the booming LLMs themselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2) the lack of physical capabilities to perform external actions.","cats":{"prompt-engineering":0}}
{"text":"Recently, we have observed the trend of utilizing prompt-based tools to better utilize the power of LLFramework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models.","cats":{"prompt-engineering":0}}
{"text":"We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level, Base Level, Executein a repository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for both academic and industry in this field.","cats":{"prompt-engineering":0}}
{"text":"However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans.","cats":{"prompt-engineering":1}}
{"text":"Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection.","cats":{"prompt-engineering":1}}
{"text":"In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function.","cats":{"prompt-engineering":1}}
{"text":"To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction.","cats":{"prompt-engineering":0}}
{"text":"Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks.","cats":{"prompt-engineering":1}}
{"text":"We conduct extensive qualitative and quantitative analyses to explore the performance of APE.","cats":{"prompt-engineering":0}}
{"text":"We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts.","cats":{"prompt-engineering":1}}
{"text":"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers.  ","cats":{"prompt-engineering":0}}
{"text":"Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction genera chosen score function.","cats":{"prompt-engineering":0}}
{"text":"Experiments on nerated by human annotators on 19/24 tasks.","cats":{"prompt-engineering":0}}
{"text":"We show that APE-engineered prompts can be appm to standard in-context learning prompts.","cats":{"prompt-engineering":0}}
{"text":"Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.","cats":{"prompt-engineering":0}}
{"text":"However, it is important to recognize that an excessive reliance on this functionality raises the risk of manipulation by malicious actors who can exploit it with carefully crafted prompts.","cats":{"prompt-engineering":1,"social-sciences":0}}
{"text":"The emergence of LLM (Large Language Model) integrated virtual assistants has brought about a rapid transformation in communication dynamics.","cats":{"prompt-engineering":0}}
{"text":"During virtual assistant development, some developers prefer to leverage the system message, also known as an initial prompt or custom prompt, for preconditioning purposes.  ","cats":{"prompt-engineering":0}}
{"text":"Such malicious manipulation poses a significant threat, potentially compromising the accuracy and reliability of the virtual assistant's responses.","cats":{"prompt-engineering":0}}
{"text":"Consequently, safeguarding the virtual assistants with detection and defense mechanisms becomes of paramount importance to ensure their safety and integrity.","cats":{"prompt-engineering":0}}
{"text":"In this study, we explored three detection and defense mechanisms aimed at countering attacks that target the system message.","cats":{"prompt-engineering":0}}
{"text":"These mechanisms include inserting a reference key, utilizing an LLM evaluator, and implementing a Self-Reminder.","cats":{"prompt-engineering":0}}
{"text":"To showcase the efficacy of these mechanisms, they were tested against prominent attack techniques.","cats":{"prompt-engineering":0}}
{"text":"Our findings demonstrate that the investigated mechanisms are capable of accurately identifying and counteracting the attacks.","cats":{"prompt-engineering":0}}
{"text":"The effectiveness of these mechanisms underscores their potential in safeguarding the integrity and reliability of virtual assistants, reinforcing the importance of their implementation in real-world scenarios.","cats":{"prompt-engineering":0}}
{"text":"By prioritizing the security of virtual assistants, organizations can maintain user trust, preserve the integrity of the application, and uphold the high standards expected in this era of transformative technologies.","cats":{"prompt-engineering":0}}
{"text":"This paper presents an overview of the PromptCBLUE shared task (http://cips-chip.org.cn/2023/eval1) held in the CHIP-2023 Conference.","cats":{"prompt-engineering":1}}
{"text":"Two different tracks are held: (a) prompt tuning track, investigating the multitask prompt tuning of LLMs, (b) probing the in-context learning capabilities of open-sourced LLMs.","cats":{"prompt-engineering":1}}
{"text":" This shared task reformualtes the CBLUE benchmark, and provide a good testbed for Chinese open-domain or medical-domain large language models (LLMs) in general medical natural language processing.","cats":{"prompt-engineering":0}}
{"text":"Two different tracks are held: (a) prompt tuning track, investigating the multitask prompt tuning of LLMs, (b) probing the in-contextis paper describes the tasks, the datasets, evaluation metrics, and the top systems for both tasks.","cats":{"prompt-engineering":0}}
{"text":"Finally, the paper summarizes the techniques and results of the evaluation of the various approaches explored by the participating teams.","cats":{"prompt-engineering":0}}
{"text":"This is followed by the pursuit of alternative reasoning paths.","cats":{"prompt-engineering":0}}
{"text":"In light of this, we delves into the potential of harnessing expert knowledge to enhance problem-solving within LLMs.","cats":{"prompt-engineering":1}}
{"text":"We introduce a novel paradigm, the State Machine of Thought (SMoT), which employs predefined state machines to furnish LLMs with efficient reasoning paths, thereby eliminating fruitless exploration.","cats":{"prompt-engineering":1}}
{"text":"Furthermore, we propose a multi-agent mechanism that assigns different objectives to agents, aiming to enhance the accuracy of SMoT reasoning.","cats":{"prompt-engineering":1}}
{"text":"The experimental results, derived from an array reasoning task, reveal that SMoT realizes an extraordinary accuracy of 95\\%, surpassing the performance of the state-of-the-art baselines.","cats":{"prompt-engineering":1}}
{"text":"However, humans are adept at abstracting optimal solutions from problems, thereby facilitating swift and precise reasoning for similar problems resolution.xpert knowledge to enhance problem-solving within LLMs.","cats":{"prompt-engineering":0}}
{"text":"We introduce a novel paradigm, the State Machine of Thought (SMoT), which employs predefined state machines to furnish LLMs with efficient reasoning paths, thereby to agents, aiming to enhance the accuracy of SMoT reasoning.","cats":{"prompt-engineering":0}}
{"text":"The experimental results, derived from an array reasoning","cats":{"prompt-engineering":0}}
{"text":"The emergent capabilities of Vid-LLMs are surprisingly advanced, particularly their ability for open-ended spatial-temporal reasoning combined with commonsense knowledge, suggesting a promising path for future video understanding.","cats":{"prompt-engineering":1}}
{"text":"With the burgeoning growth of online video platforms and the escalating volume of video content, the demand for proficient video understanding tools has intensified markedly.","cats":{"prompt-engineering":0}}
{"text":"With Large Language Models (LLMs) showcasing remarkable capabilities in key language tasks, this survey provides a detailed overview of the recent advancements in video understanding harnessing the power of LLMs (Vid-LLMs).  ","cats":{"prompt-engineering":0}}
{"text":"We examine the unique characteristics and capabilities of Vid-LLMs, categorizing the approaches into four main types: LLM-based Video Agents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods.","cats":{"prompt-engineering":0}}
{"text":"Furthermore, this survey also presents a comprehensive study of the tasks and datasets for Vid-LLMs, along with the methodologies employed for evaluation.","cats":{"prompt-engineering":0}}
{"text":"Additionally, the survey explores the expansive applications of Vid-LLMs across various domains, thereby showcasing their remarkable scalability and versatility in addressing challenges in real-world video understanding.","cats":{"prompt-engineering":0}}
{"text":"Finally, the survey summarizes the limitations of existing Vid-LLMs and the directions for future research.","cats":{"prompt-engineering":0}}
{"text":"For more information, we recommend readers visit the repository at https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.","cats":{"prompt-engineering":0}}
