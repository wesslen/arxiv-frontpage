{"text":"This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes.","cats":{"prompt-engineering":0,"security":0,"hci":0,"programming":0}}
{"text":"However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066$\\times$1600 resolution) within half an hour of training.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"The code is available at https://zju3dv.github.io/street_gaussians/.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"recommender":0,"programming":0}}
{"text":"In this paper, we report on the first year of TREC iKAT, describing the task, topics, data collection, and evaluation framework.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"programming":0}}
{"text":"Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Code is available at https://github.com/urchade/ATG.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0}}
{"text":"The two levels are computed by the original model's self-attention, which means the proposed does not require any training.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"In this paper, we consider classes of decision tables closed under removal of attributes (columns) and changing of decisions attached to rows.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0}}
{"text":"For decision tables from closed classes, we study lower bounds on the minimum cardinality of reducts, which are minimal sets of attributes that allow us to recognize, for a given row, the decision attached to it.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"recommender":0}}
{"text":"This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0}}
{"text":"The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0,"social-sciences":0}}
{"text":"Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0}}
{"text":"This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0}}
{"text":"Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023).","cats":{"prompt-engineering":1,"robustness":0,"security":0,"hci":0}}
{"text":"Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0}}
{"text":"This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0,"social-sciences":0}}
{"text":"Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.","cats":{"prompt-engineering":0,"robustness":1,"security":0,"hci":0,"social-sciences":0,"education":0}}
{"text":"Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs).","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"education":0,"recommender":0,"programming":0}}
{"text":"In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"The basic idea is to construct bi-level attention information: the group level and the neighbor level.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0,"programming":0}}
{"text":"As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded.","cats":{"prompt-engineering":0,"security":0,"hci":0,"social-sciences":0,"programming":0}}
{"text":"While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input.","cats":{"prompt-engineering":1,"robustness":1,"security":0,"hci":0,"social-sciences":1,"recommender":0}}
{"text":"This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc.","cats":{"prompt-engineering":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy.","cats":{"prompt-engineering":0,"security":0,"hci":0}}
{"text":"We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system.","cats":{"prompt-engineering":0,"security":0,"hci":1,"social-sciences":0}}
{"text":"Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future.","cats":{"prompt-engineering":0,"security":0,"hci":0}}
{"text":"Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%).","cats":{"prompt-engineering":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces.","cats":{"prompt-engineering":0,"security":0,"hci":0}}
{"text":"In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines.","cats":{"prompt-engineering":0,"security":0,"hci":0}}
{"text":"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication.","cats":{"prompt-engineering":0,"robustness":0,"security":0,"hci":0,"social-sciences":0,"architectures":0}}
{"text":"However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization.","cats":{"prompt-engineering":0,"robustness":0,"hci":0}}
{"text":"We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency.","cats":{"robustness":0,"security":0,"hci":0,"programming":0}}
{"text":"Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area.","cats":{"robustness":0,"security":0,"hci":0,"social-sciences":0}}
{"text":"(2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases.","cats":{"robustness":1,"security":0,"hci":0,"social-sciences":0}}
{"text":"(4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations.","cats":{"robustness":1,"hci":0,"social-sciences":0,"education":0}}
{"text":"Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources.","cats":{"robustness":0,"hci":0}}
{"text":"The outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of LLMs, highlighting the need for more transparent and responsible data management practices in this field.","cats":{"robustness":1,"hci":0}}
{"text":"The emergence of ChatGPT and other large language models (LLMs) has greatly increased interest in utilizing LLMs as therapists to support individuals struggling with mental health challenges.","cats":{"robustness":0,"hci":1,"social-sciences":1}}
{"text":"Understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences.","cats":{"robustness":0,"hci":0}}
{"text":"Our analysis of GPT and Llama-variants reveals that these LLMs often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions, which is against typical recommendations.","cats":{"robustness":0,"hci":1,"recommender":0}}
{"text":"This study focuses on emotion-sensitive spoken dialogue in human-machine speech interaction.","cats":{"robustness":0,"hci":1}}
{"text":"Recent models have enhanced the understanding of complex audio signals through the integration of various audio events.","cats":{"robustness":0,"hci":0}}
{"text":"However, they are unable to generate appropriate responses based on emotional speech.","cats":{"robustness":0,"hci":0}}
{"text":"To address this, we introduce the Emotional chat Model (E-chat), a novel spoken dialogue system capable of comprehending and responding to emotions conveyed from speech.","cats":{"robustness":0,"hci":0}}
{"text":"This model leverages an emotion embedding extracted by a speech encoder, combined with LLMs, enabling it to respond according to different emotional contexts.","cats":{"robustness":0,"hci":0}}
{"text":"Additionally, we introduce the E-chat200 dataset, designed explicitly for emotion-sensitive spoken dialogue.","cats":{"robustness":0,"hci":0}}
{"text":"In various evaluation metrics, E-chat consistently outperforms baseline LLMs, demonstrating its potential in emotional comprehension and human-machine interaction.","cats":{"robustness":0,"hci":1}}
{"text":"The state-of-the-art LLMs have shown to be prone to hallucination by providing inaccurate information, which is problematic in critical domains like cybersecurity.","cats":{"robustness":1,"hci":0}}
{"text":"Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use to exploit vulnerabilities.","cats":{"robustness":0,"hci":0}}
{"text":"The interpretation of TTPs in the MITRE ATT&CK framework can be challenging for cybersecurity practitioners due to presumed expertise, complex dependencies, and inherent ambiguity.","cats":{"robustness":0,"hci":0}}
{"text":"Meanwhile, advancements with Large Language Models (LLMs) have led to recent surge in studies exploring its uses in cybersecurity operations.","cats":{"robustness":0,"hci":0}}
{"text":"Therefore, we propose the use of Retrieval Augmented Generation (RAG) techniques to extract relevant contexts for each cyberattack procedure for decoder-only LLMs (without fine-tuning).","cats":{"robustness":0,"hci":0}}
{"text":"We further contrast such approach against supervised fine-tuning (SFT) of encoder-only LLMs.","cats":{"robustness":0,"hci":0}}
{"text":"Our results reveal that both the direct-use of decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only LLMs offer inaccurate interpretation of cyberattack procedures.","cats":{"robustness":0,"hci":0}}
{"text":"Significant improvements are shown when RAG is used for decoder-only LLMs, particularly when directly relevant context is found.","cats":{"robustness":0,"hci":0}}
{"text":"This study further sheds insights on the limitations and capabilities of using RAG for LLMs in interpreting TTPs.","cats":{"robustness":0,"hci":0}}
{"text":"Through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers.","cats":{"security":0,"hci":0,"social-sciences":1}}
{"text":"In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction.","cats":{"security":0,"hci":0}}
{"text":"Importantly, the IMU data remains uncompromised throughout the spoofing attack.","cats":{"security":0,"hci":0}}
{"text":"Commuting extensions have also attracted the attention of the linear algebra community.","cats":{"security":0,"hci":0,"recommender":0}}
{"text":"Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks.","cats":{"security":0,"hci":0,"social-sciences":0}}
{"text":"Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work.","cats":{"security":0,"hci":0,"social-sciences":0,"education":0}}
{"text":"But to what extent is generative AI already in use in the public sector?","cats":{"security":0,"hci":0,"social-sciences":0}}
{"text":"For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact).","cats":{"security":0,"hci":0,"social-sciences":1}}
{"text":"This strategy extends directly to the case where the searcher has no knowledge of the terrain beforehand.","cats":{"security":0,"hci":0}}
{"text":"Large language models (LLMs) have skyrocketed in popularity in recent years due to their ability to generate high-quality text in response to human prompting.","cats":{"security":0,"hci":0}}
{"text":"However, LLMs are vulnerable to prompt-injection attacks: a class of attacks that hijack the model's instruction-following abilities, changing responses to prompts to undesired, possibly malicious ones.","cats":{"security":1,"hci":0}}
{"text":"Large Language Models (LLMs) have made remarkable advancements in the field of artificial intelligence, significantly reshaping the human-computer interaction.","cats":{"hci":1}}
{"text":"Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria.","cats":{"hci":0,"education":0}}
{"text":"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers.","cats":{"hci":0}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines.","cats":{"hci":0}}
{"text":"Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks.","cats":{"hci":0}}
{"text":"Large language models (LLMs) have shown the potential to be integrated into human daily lives.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools.","cats":{"hci":0}}
{"text":"Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Large Language Models (LLMs) are powerful tools for natural language processing, enabling novel applications and user experiences.","cats":{"hci":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have shown impressive success in various applications.","cats":{"hci":0,"education":0,"recommender":0,"production":0}}
{"text":"Recently, prompting Large Language Models (LLMs) to generate actions iteratively has become a prevalent paradigm due to its superior performance and user-friendliness.","cats":{"hci":0}}
{"text":"Large Language Models~(LLMs) have demonstrated incredible capabilities in understanding, generating, and manipulating languages.","cats":{"hci":0,"programming":0}}
{"text":"Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT.","cats":{"hci":0}}
{"text":"The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation.","cats":{"hci":0,"social-sciences":0,"education":0,"recommender":0}}
{"text":"Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks.","cats":{"hci":0,"social-sciences":0}}
{"text":"Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models.","cats":{"hci":0}}
{"text":"In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration.","cats":{"hci":0}}
{"text":"Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective.","cats":{"hci":0,"social-sciences":0}}
{"text":"The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading.","cats":{"hci":0}}
{"text":"The hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features.","cats":{"hci":0}}
{"text":"To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet).","cats":{"hci":0}}
{"text":"The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual.","cats":{"hci":0}}
{"text":"Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture.","cats":{"hci":0}}
{"text":"Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse.","cats":{"hci":0,"social-sciences":0}}
{"text":"Within this work, we propose a hybrid approach, Deep-ELA, which combines (the benefits of) deep learning and ELA features.","cats":{"hci":0,"recommender":0}}
{"text":"To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer.","cats":{"hci":0}}
{"text":"In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account.","cats":{"hci":0}}
{"text":"Experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively.","cats":{"hci":0}}
{"text":"Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns.","cats":{"hci":0}}
{"text":"Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces.","cats":{"hci":0}}
{"text":"With the recent introduction of large language models (LLMs), which can generate text in response to a natural language prompt, there are new opportunities to consider how to integrate LLMs into UIs.","cats":{"hci":1}}
{"text":"Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks.","cats":{"hci":0,"social-sciences":0,"education":0,"programming":0}}
{"text":"Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications.","cats":{"hci":0}}
{"text":"Large Language Models (LLMs) have impressive capabilities on a wide range of tasks, such as question answering and the generation of coherent text and code.","cats":{"hci":0}}
{"text":"Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions.","cats":{"hci":0}}
{"text":"Large language models (LLMs) are used to generate content for a wide range of tasks, and are set to reach a growing audience in coming years due to integration in product interfaces like ChatGPT or search engines like Bing.","cats":{"hci":0}}
{"text":"Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like reasoning and long-context understanding.","cats":{"hci":0,"education":0}}
{"text":"The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario.","cats":{"hci":0,"social-sciences":0,"education":0}}
{"text":"Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this.","cats":{"hci":0}}
{"text":"Large language models (LLMs) power a new generation of interactive AI applications exemplified by ChatGPT.","cats":{"hci":0}}
{"text":"We hope that this work provides a better guide for researchers working on the prompting of large language models.","cats":{"hci":0,"social-sciences":0}}
{"text":"Large language models have been demonstrated to be valuable in different fields.","cats":{"hci":0,"social-sciences":0,"production":0,"programming":0}}
{"text":"We identify several challenges associated with prompting large language models, categorized into data- and model-specific, linguistic, and socio-linguistic challenges.","cats":{"hci":1}}
{"text":"Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems.","cats":{"hci":0}}
{"text":"We leverage large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content.","cats":{"hci":0}}
{"text":"As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern.","cats":{"hci":0}}
{"text":"Recently, the evaluation of Large Language Models has emerged as a popular area of research.","cats":{"hci":0}}
{"text":"Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI.","cats":{"hci":0,"social-sciences":0}}
{"text":"Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false.","cats":{"hci":1}}
{"text":"The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model.","cats":{"hci":0,"social-sciences":0}}
{"text":"In light of these findings, we conclude by proposing potential research trajectories to further enhance the development and performance of Large Language Models in their current stage.","cats":{"hci":0}}
{"text":"We further outline the challenges of estimating the confidence for large language models and we suggest some promising directions for future work.","cats":{"hci":0}}
{"text":"In this work, we revisit this topic in the context of large language models.","cats":{"hci":0,"production":0}}
{"text":"Effectively using a given context is paramount for large language models.","cats":{"hci":0}}
{"text":"We present VOICE, a novel approach for connecting large language models' (LLM) conversational capabilities with interactive exploratory visualization.","cats":{"hci":1}}
{"text":"Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data.","cats":{"hci":1}}
{"text":"With recent advances in multi-modal foundation models, the previously text-only large language models (LLM) have evolved to incorporate visual input, opening up unprecedented opportunities for various applications in visualization.","cats":{"hci":1}}
{"text":"Our work explores the capabilities of LLMs for creating and refining visualizations via conversational interfaces.","cats":{"hci":1}}
{"text":"They endow Large Language Models (LLMs) with powerful capabilities in visual understanding, enabling them to tackle diverse multi-modal tasks.","cats":{"hci":1}}
{"text":"Multi-modal large language models (LLM) have achieved powerful capabilities for visual semantic understanding in recent years.","cats":{"hci":0}}
{"text":"Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified.","cats":{"hci":1}}
{"text":"This paper studies Large Language Models (LLMs) for structured data--particularly graphs--a crucial data modality that remains underexplored in the LLM literature.","cats":{"hci":1}}
{"text":"Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction.","cats":{"hci":1,"social-sciences":1}}
{"text":"These models enhance Large Language Models (LLMs) with advanced visual understanding capabilities, facilitating their application in a variety of multimodal tasks.","cats":{"hci":0}}
{"text":"Generative Large Language Models (LLMs) show potential in data analysis, yet their full capabilities remain uncharted.","cats":{"hci":0}}
{"text":"Large Language Models (LLMs) have shown to be capable of various tasks, yet their capability in interpreting and reasoning over tabular data remains an underexplored area.","cats":{"hci":0}}
{"text":"In this paper, we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better.","cats":{"hci":0}}
{"text":"Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations.","cats":{"hci":1}}
{"text":"The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics.","cats":{"hci":0,"social-sciences":0}}
{"text":"(3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup.","cats":{"hci":0,"social-sciences":0}}
{"text":"The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change.","cats":{"hci":0,"education":0}}
{"text":"We address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers.","cats":{"hci":0}}
{"text":"Previous inquiries on the effectiveness of this intervention are inconclusive because 1) they consider only few deplatforming events; 2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views); 3) they do not consider all the potential places users impacted by the deplatforming event might migrate to.","cats":{"hci":0,"social-sciences":1}}
{"text":"Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention.","cats":{"hci":0,"architectures":0}}
{"text":"Notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers; Overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation.","cats":{"hci":0,"social-sciences":0}}
{"text":"These digital companions often lack memory of past interactions, while relying heavily on the internet for speech processing, raising privacy concerns.","cats":{"hci":0}}
{"text":"Despite this, they are prone to generating factual and commonsense errors, raising concerns in critical areas like healthcare, journalism, and education to mislead users.","cats":{"hci":0}}
{"text":"A significant distinction of advanced LLMs, such as ChatGPT, is their demonstrated ability to \"reason.\"","cats":{"hci":0}}
{"text":"The results provide insights into LLMs' reasoning abilities and reveal the logical rules the LLMs did not learn well.","cats":{"hci":0}}
{"text":"The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively.","cats":{"hci":0,"social-sciences":0}}
{"text":"This paper presents RAGTruth, a corpus tailored for analyzing word-level hallucinations in various domains and tasks within the standard RAG frameworks for LLM applications.","cats":{"hci":0}}
{"text":"We examine this practice of structuration as a two-way interaction between users and models by analysing how ChatGPT4 redacts perceived `anomalous' language in fragments of Joyce's Ulysses and the new linguistic practice of prompt engineering.","cats":{"hci":1,"social-sciences":1}}
{"text":"These debates around the communicative orientation toward language can help explain some of the contemporary behaviours and interdependencies that take place between users and LLMs.","cats":{"hci":1,"social-sciences":0}}
{"text":"Our newly developed experimental setup assesses LLMs' reliance on contextual information and inherent knowledge across various domains.","cats":{"hci":1}}
{"text":"This is particularly crucial for practical applications like mental health support, nutrition planning, culturally sensitive conversations, or reducing toxic behavior in conversational agents.","cats":{"hci":0}}
{"text":"Our findings reveal the potential of LLM agents in team collaboration, highlighting issues related to hallucinations in communication.","cats":{"hci":1}}
{"text":"However, concerns regarding data privacy have emerged, especially when multiple stakeholders aim to collaboratively enhance LLMs using sensitive data.","cats":{"hci":0}}
{"text":"In this study, various prompts are designed and compared across mainstream LLMs using two distinct datasets from human reviewers and automated checkers.","cats":{"hci":0}}
{"text":"Prior studies have compared the decision making abilities of LLMs with those of humans from a psychological perspective.","cats":{"hci":1}}
{"text":"To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience.","cats":{"hci":1}}
{"text":"The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design.","cats":{"hci":0}}
{"text":"This study aims to examine the capabilities of ChatGPT in a human-centered design process.  ","cats":{"hci":0}}
{"text":"The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses.","cats":{"hci":0}}
{"text":"The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity.","cats":{"hci":0}}
{"text":"The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area.","cats":{"hci":0}}
{"text":"We not only focus on the performance of LLMs, but also explores their features from a psychological perspective, acknowledging the importance of understanding their behavioral characteristics.","cats":{"hci":1,"social-sciences":1}}
{"text":"Our study examines the behavioral patterns displayed by LLMs by employing trait theory, a psychological framework.","cats":{"hci":1,"social-sciences":0}}
{"text":"Moreover, the study investigates whether ChatGPT can exhibit personality changes in response to instructions or contextual cues.","cats":{"hci":1,"social-sciences":1}}
{"text":"The findings show that ChatGPT consistently maintains its ENFJ personality regardless of instructions or contexts.","cats":{"hci":1,"social-sciences":1}}
{"text":" We not only focus on the performance of LLMs, but also explores their features from a psychological perspective, acknowledging the importance of understanding y of personality types exhibited by ChatGPT.","cats":{"hci":0}}
{"text":"Furthermore, experiments include cross-lingual effects on seven additional languages, and the investigation of four other LLMs.","cats":{"hci":0}}
{"text":"Moreover, the study indings show that ChatGPT consistently maintains its ENFJ personality regardless of instructions or contexts.","cats":{"hci":0}}
{"text":"By shedding light on the personalization of LLMs, we anticipate that our study will serve as a catalyst for further research in this field.","cats":{"hci":0,"social-sciences":0}}
{"text":"The advancement of Large Language Models (LLMs) has led to their widespread use across a broad spectrum of tasks including decision making.","cats":{"hci":1,"social-sciences":1}}
{"text":"By experimenting on three OpenAI language models possessing different capabilities, we observe that the decision making abilities fluctuate based on the input prompts and temperature settings.","cats":{"hci":0}}
{"text":"Contrary to previous findings language models display a human-like exploration exploitation tradeoff after simple adjustments to the prompt.","cats":{"hci":1}}
{"text":" Prior studies have compared the decision making abilities of LLMs with those of humans from a psychological perspective.","cats":{"hci":0}}
{"text":"However, these sturompt.","cats":{"hci":0}}
{"text":"In this study, we examine LLMs' performance on the Horizon decision making task studied by Binz and Schulz (2023) analyzing how LLMs respond to variations in prompts and hyperparameters.","cats":{"hci":0}}
{"text":"Contrary to previous findings language models display a human-like","cats":{"hci":0}}
{"text":"The emergence of Large Language Models (LLMs) has brought both excitement and concerns to social computing research.","cats":{"hci":1,"social-sciences":1}}
{"text":"On the other hand, concerns are emerging regarding the validity, privacy, and ethics of the research when LLMs are involved.","cats":{"hci":1,"social-sciences":0}}
{"text":"This SIG aims at offering an open space for social computing researchers who are interested in understanding the impacts of LLMs to discuss their current practices, perspectives, challenges when engaging with LLMs in their everyday work and collectively shaping the emerging norms of using LLMs in social computing research.","cats":{"hci":1,"social-sciences":1}}
{"text":" On the one hand, LLMs offer unprecedented capabilities in analyzing vast amounts of textual data and generating human-like responses, enabling researchers to delve into complex social phenomena.","cats":{"hci":0}}
{"text":"On the other hand, concerns are emerging regarding the validity, privacy, and ethics of the research when LLMs are ipacts of LLMs to discuss their current practices, perspectives, challenges when engaging with LLMs in their everyday work and","cats":{"hci":0}}
{"text":"Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes.","cats":{"hci":1}}
{"text":"Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.","cats":{"hci":0}}
{"text":"These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors.","cats":{"hci":0}}
{"text":"But are we harnessing their full potential?","cats":{"hci":0}}
{"text":"We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models.","cats":{"hci":0}}
{"text":"To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses.","cats":{"hci":0}}
{"text":"We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 8 professional writers.","cats":{"hci":0}}
{"text":"The goal of this paper is establishing if we can satisfactorily perform a Thematic Analysis (TA) of semi-structured interviews using a Large Language Model (more precisely GPT3.5-Turbo).","cats":{"hci":1}}
{"text":"In particular, the focus will be on using the results of a TA done with the LLM on a dataset of user interviews, for writing user personas, with the model building on the TA to produce the personas narratives.","cats":{"hci":1}}
{"text":" Building on previous work by the author, which established an embryonal process for conducting a TA with the model, this paper will perform a further analysis and then cover the last phase of a TA (phase 6), which entails the writing up of the result.","cats":{"hci":0}}
{"text":"This phase was not covered by the previous work.","cats":{"hci":0}}
{"text":"In particular, the focus will be on using the results of a TA done with the LLM on a dataset of user interviews, for writing user personas, with the model building on the TA to produce tThe paper shows that the model can build basic user personas with an acceptable quality deriving them from themes, and that the model can serve for the generation of ideas for user personas.","cats":{"hci":0}}
{"text":"Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question.  ","cats":{"hci":0}}
{"text":"The UK's public sector ur","cats":{"hci":0}}
{"text":"The significance of this new paradigm lies in its ability to reveal potential cognitive deficiencies in LLMs that current benchmarks, such as GSM8K, fail to uncover due to their saturation and lack of effective differentiation among varying reasoning abilities.","cats":{"hci":1}}
{"text":"By promoting the adoption of meta-reasoning evaluation methods similar to ours, we aim to facilitate a more accurate assessment of the true cognitive abilities of LLMs.","cats":{"hci":0}}
{"text":"In this work, we introduce a novel evaluation paradigm for Large Language Models, one that challenges them to engage in meta-reasoning.","cats":{"hci":0}}
{"text":"This approach addresses critical shortcomings in existing math problem-solving benchmarks, traditionally used to evaluate the cognitive capabilities of agents.","cats":{"hci":0}}
{"text":"Our paradigm shifts the focus from result-oriented assessments, which often overlook the reasoning process, to a more holistic evaluation that effectively differentiates the cognitive capabilities among models.","cats":{"hci":0}}
{"text":"For example, in our benchmark, GPT-4 demonstrates a performance ten times more accurate than GPT3-5.  ","cats":{"hci":0}}
{"text":"Our comprehensive analysis includes several state-of-the-art math models from both open-source and closed-source communities, uncovering fundamental deficiencies in their training and evaluation approaches.","cats":{"hci":0}}
{"text":"This paper not only advocates for a paradigm shift in the assessment of LLMs but also contributes to the ongoing discourse on the trajectory towards Artificial General Intelligence (AGI).","cats":{"hci":0}}
{"text":"This paper introduces the WordArt Designer API, a novel framework for user-driven artistic typography synthesis utilizing Large Language Models (LLMs) on ModelScope.","cats":{"hci":1}}
{"text":"Our approach leverages the power of LLMs to understand and interpret user input, facilitating a more intuitive design process.","cats":{"hci":0,"architectures":0}}
{"text":"We address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates.","cats":{"hci":0,"architectures":0}}
{"text":"We demonstrate through various case stunique and creative typographic designs.","cats":{"hci":0}}
{"text":"Our evaluations indicate significant improvements in user satisfaction, design flexibility, and creative expression over existing systems.","cats":{"hci":0}}
{"text":"The WordArt Designer API not only democratizes the art of typography but also opens up new possibilities for personalized digital communication and design.","cats":{"hci":0}}
{"text":"It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation.","cats":{"hci":1}}
{"text":"Effective collaboration requires groups to strategically regulate themselves to overcome challenges.","cats":{"hci":0}}
{"text":"Research has shown that groups may fail to regulate due to differences in members' perceptions of challenges which may benefit from external support.","cats":{"hci":0}}
{"text":"In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated.","cats":{"hci":0}}
{"text":"The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts.","cats":{"hci":0,"architectures":0}}
{"text":"The paper provides an extensive discussion of the three approaches' performance for automated detection and support of students' challenge moments in collaborative learning activities.  ","cats":{"hci":0}}
{"text":"We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.","cats":{"hci":0}}
{"text":"Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided.","cats":{"hci":0}}
{"text":"However, they struggle to assess ambiguous or context-deficient statements accurately.","cats":{"hci":0,"social-sciences":0}}
{"text":"This work introduces a new method to resolve uncertainty in such statements.","cats":{"hci":0}}
{"text":"We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information.","cats":{"hci":0,"architectures":0}}
{"text":"We then leverage this framework to generate effective user queries for missing context.","cats":{"hci":0}}
{"text":"Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1.","cats":{"hci":0}}
{"text":"Thus, this approach may provide a valuable component for future misinformation mitigation pipelines.","cats":{"hci":0,"programming":0}}
{"text":"RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving.","cats":{"hci":0}}
{"text":"Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results.","cats":{"hci":0}}
{"text":"However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training.","cats":{"hci":0}}
{"text":"The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information.","cats":{"hci":0,"social-sciences":0}}
{"text":"To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack.","cats":{"hci":0}}
{"text":"TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively.","cats":{"hci":0}}
{"text":"TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization.","cats":{"hci":0}}
{"text":"In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales.","cats":{"hci":0}}
{"text":"Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.","cats":{"hci":0,"production":0}}
{"text":"In the age of personal voice assistants, the question of privacy arises.","cats":{"hci":0}}
{"text":"Modern smartphones now enable on-device speech processing, making cloud-based solutions unnecessary.","cats":{"hci":0}}
{"text":"Personal assistants for the elderly should excel at memory recall, especially in medical examinations.","cats":{"hci":0}}
{"text":"The e-ViTA project developed a versatile conversational application with local processing and speaker recognition.","cats":{"hci":0}}
{"text":"This paper highlights the importance of speaker diarization enriched with sensor data fusion for contextualized conversation preservation.","cats":{"hci":0}}
{"text":"The use cases applied to the e-VITA project have shown that truly personalized dialogue is pivotal for individual voice assistants.","cats":{"hci":0}}
{"text":"Secure local processing and sensor data fusion ensure virtual companions meet individual user needs without compromising privacy or data security.","cats":{"hci":0,"production":0}}
{"text":"Large Language Models (LLMs) like ChatGPT are foundational in various applications due to their extensive knowledge from pre-training and fine-tuning.","cats":{"hci":0}}
{"text":"Current methods for evaluating LLMs' veracity are limited by test data leakage or the need for extensive human labor, hindering efficient and accurate error detection.","cats":{"hci":0}}
{"text":"To tackle this problem, we introduce a novel, automatic testing framework, FactChecker, aimed at uncovering factual inaccuracies in LLMs.","cats":{"hci":0}}
{"text":"This framework involves three main steps:","cats":{"hci":0}}
{"text":"First, it constructs a factual knowledge graph by retrieving fact triplets from a large-scale knowledge database.","cats":{"hci":0}}
{"text":"Then, leveraging the knowledge graph, FactChecker employs a rule-based approach to generates three types of questions (Yes-No, Multiple-Choice, and WH questions) that involve single-hop and multi-hop relations, along with correct answers.","cats":{"hci":0}}
{"text":"Lastly, it assesses the LLMs' responses for accuracy using tailored matching strategies for each question type.","cats":{"hci":0}}
{"text":"Our extensive tests on six prominent LLMs, including text-davinci-002, text-davinci-003, ChatGPT~(gpt-3.5-turbo, gpt-4), Vicuna, and LLaMA-2, reveal that FactChecker can trigger factual errors in up to 45\\% of questions in these models.","cats":{"hci":0}}
{"text":"Moreover, we demonstrate that FactChecker's test cases can improve LLMs' factual accuracy through in-context learning and fine-tuning (e.g., llama-2-13b-chat's accuracy increase from 35.3\\% to 68.5\\%).","cats":{"hci":0}}
{"text":"We are making all code, data, and results available for future research endeavors.","cats":{"hci":0,"recommender":0}}
{"text":" With the advancement of Large Language Models (LLMs), dialogue systems can handle multimodal data, including audio.","cats":{"hci":0}}
{"text":"In various evaluation metrics, E-chat consistently outperforms baseline LLMs, demonstrating","cats":{"hci":0}}
{"text":"Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs).","cats":{"hci":0}}
{"text":"Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents.","cats":{"hci":0}}
{"text":"In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination.","cats":{"hci":0,"social-sciences":0}}
{"text":"RAGTruth comprises nearly 18,000 naturally generated responses from diverse LLMs using RAG.","cats":{"hci":0}}
{"text":"These responses have undergone meticulous manual annotations at both the individual cases and word levels, incorporating evaluations of hallucination intensity.","cats":{"hci":0}}
{"text":"We not only benchmark hallucination frequencies across different LLMs, but also critically assess the effectiveness of several existing hallucination detection methodologies.","cats":{"hci":0}}
{"text":"Furthermore, we show that using a high-quality dataset such as RAGTruth, it is possible to finetune a relatively small LLM and achieve a competitive level of performance in hallucination detection when compared to the existing prompt-based approaches using state-of-the-art large language models such as GPT-4.","cats":{"hci":0}}
{"text":"This leads us to question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5) LLMs can comprehend and summarize TTPs to inform analysts of the intended purposes (i.e., tactics) of a cyberattack procedure.","cats":{"hci":0}}
