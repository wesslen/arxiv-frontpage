{"created":"2024-07-31 17:50:54","title":"Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries","abstract":"We introduce tulip agent, an architecture for autonomous LLM-based agents with Create, Read, Update, and Delete access to a tool library containing a potentially large number of tools. In contrast to state-of-the-art implementations, tulip agent does not encode the descriptions of all available tools in the system prompt, which counts against the model's context window, or embed the entire prompt for retrieving suitable tools. Instead, the tulip agent can recursively search for suitable tools in its extensible tool library, implemented exemplarily as a vector store. The tulip agent architecture significantly reduces inference costs, allows using even large tool libraries, and enables the agent to adapt and extend its set of tools. We evaluate the architecture with several ablation studies in a mathematics context and demonstrate its generalizability with an application to robotics. A reference implementation and the benchmark are available at github.com/HRI-EU/tulip_agent.","sentences":["We introduce tulip agent, an architecture for autonomous LLM-based agents with Create, Read, Update, and Delete access to a tool library containing a potentially large number of tools.","In contrast to state-of-the-art implementations, tulip agent does not encode the descriptions of all available tools in the system prompt, which counts against the model's context window, or embed the entire prompt for retrieving suitable tools.","Instead, the tulip agent can recursively search for suitable tools in its extensible tool library, implemented exemplarily as a vector store.","The tulip agent architecture significantly reduces inference costs, allows using even large tool libraries, and enables the agent to adapt and extend its set of tools.","We evaluate the architecture with several ablation studies in a mathematics context and demonstrate its generalizability with an application to robotics.","A reference implementation and the benchmark are available at github.com/HRI-EU/tulip_agent."],"url":"http://arxiv.org/abs/2407.21778v1"}
{"created":"2024-07-31 17:48:14","title":"ShieldGemma: Generative AI Content Moderation Based on Gemma","abstract":"We present ShieldGemma, a comprehensive suite of LLM-based safety content moderation models built upon Gemma2. These models provide robust, state-of-the-art predictions of safety risks across key harm types (sexually explicit, dangerous content, harassment, hate speech) in both user input and LLM-generated output. By evaluating on both public and internal benchmarks, we demonstrate superior performance compared to existing models, such as Llama Guard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%). Additionally, we present a novel LLM-based data curation pipeline, adaptable to a variety of safety-related tasks and beyond. We have shown strong generalization performance for model trained mainly on synthetic data. By releasing ShieldGemma, we provide a valuable resource to the research community, advancing LLM safety and enabling the creation of more effective content moderation solutions for developers.","sentences":["We present ShieldGemma, a comprehensive suite of LLM-based safety content moderation models built upon Gemma2.","These models provide robust, state-of-the-art predictions of safety risks across key harm types (sexually explicit, dangerous content, harassment, hate speech) in both user input and LLM-generated output.","By evaluating on both public and internal benchmarks, we demonstrate superior performance compared to existing models, such as Llama Guard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).","Additionally, we present a novel LLM-based data curation pipeline, adaptable to a variety of safety-related tasks and beyond.","We have shown strong generalization performance for model trained mainly on synthetic data.","By releasing ShieldGemma, we provide a valuable resource to the research community, advancing LLM safety and enabling the creation of more effective content moderation solutions for developers."],"url":"http://arxiv.org/abs/2407.21772v1"}
{"created":"2024-07-31 17:46:57","title":"Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs","abstract":"Existing Large Vision-Language Models (LVLMs) primarily align image features of vision encoder with Large Language Models (LLMs) to leverage their superior text generation capabilities. However, the scale disparity between vision encoder and language model may led to LLMs assuming a predominant role in multi-modal comprehension. This imbalance in LVLMs may result in the instances of hallucinatory. Concretely, LVLMs may generate consistent descriptions with or without visual input, indicating that certain outputs are influenced solely by context text. We refer to this phenomenon as \"text inertia.\" To counteract this issue, we introduce a training-free algorithm to find an equilibrium point between image comprehension and language inference. Specifically, we adaptively involve adjusting and amplifying the attention weights assigned to image tokens, thereby granting greater prominence to visual elements. Meanwhile, we subtract the logits of multi-modal inputs from ones of pure text input, which can help LVLMs be not biased towards LLMs. By enhancing images tokens and reducing the stubborn output of LLM, we can let LVLM pay more attention to images, towards alleviating text inertia and reducing the hallucination in LVLMs. Our extensive experiments shows that this method substantially reduces the frequency of hallucinatory outputs in various LVLMs in terms of different metrics. Project page is available at https://lalbj.github.io/projects/PAI/.","sentences":["Existing Large Vision-Language Models (LVLMs) primarily align image features of vision encoder with Large Language Models (LLMs) to leverage their superior text generation capabilities.","However, the scale disparity between vision encoder and language model may led to LLMs assuming a predominant role in multi-modal comprehension.","This imbalance in LVLMs may result in the instances of hallucinatory.","Concretely, LVLMs may generate consistent descriptions with or without visual input, indicating that certain outputs are influenced solely by context text.","We refer to this phenomenon as \"text inertia.\"","To counteract this issue, we introduce a training-free algorithm to find an equilibrium point between image comprehension and language inference.","Specifically, we adaptively involve adjusting and amplifying the attention weights assigned to image tokens, thereby granting greater prominence to visual elements.","Meanwhile, we subtract the logits of multi-modal inputs from ones of pure text input, which can help LVLMs be not biased towards LLMs.","By enhancing images tokens and reducing the stubborn output of LLM, we can let LVLM pay more attention to images, towards alleviating text inertia and reducing the hallucination in LVLMs.","Our extensive experiments shows that this method substantially reduces the frequency of hallucinatory outputs in various LVLMs in terms of different metrics.","Project page is available at https://lalbj.github.io/projects/PAI/."],"url":"http://arxiv.org/abs/2407.21771v1"}
{"created":"2024-07-31 17:31:01","title":"ReplanVLM: Replanning Robotic Tasks with Visual Language Models","abstract":"Large language models (LLMs) have gained increasing popularity in robotic task planning due to their exceptional abilities in text analytics and generation, as well as their broad knowledge of the world. However, they fall short in decoding visual cues. LLMs have limited direct perception of the world, which leads to a deficient grasp of the current state of the world. By contrast, the emergence of visual language models (VLMs) fills this gap by integrating visual perception modules, which can enhance the autonomy of robotic task planning. Despite these advancements, VLMs still face challenges, such as the potential for task execution errors, even when provided with accurate instructions. To address such issues, this paper proposes a ReplanVLM framework for robotic task planning. In this study, we focus on error correction interventions. An internal error correction mechanism and an external error correction mechanism are presented to correct errors under corresponding phases. A replan strategy is developed to replan tasks or correct error codes when task execution fails. Experimental results on real robots and in simulation environments have demonstrated the superiority of the proposed framework, with higher success rates and robust error correction capabilities in open-world tasks. Videos of our experiments are available at https://youtu.be/NPk2pWKazJc.","sentences":["Large language models (LLMs) have gained increasing popularity in robotic task planning due to their exceptional abilities in text analytics and generation, as well as their broad knowledge of the world.","However, they fall short in decoding visual cues.","LLMs have limited direct perception of the world, which leads to a deficient grasp of the current state of the world.","By contrast, the emergence of visual language models (VLMs) fills this gap by integrating visual perception modules, which can enhance the autonomy of robotic task planning.","Despite these advancements, VLMs still face challenges, such as the potential for task execution errors, even when provided with accurate instructions.","To address such issues, this paper proposes a ReplanVLM framework for robotic task planning.","In this study, we focus on error correction interventions.","An internal error correction mechanism and an external error correction mechanism are presented to correct errors under corresponding phases.","A replan strategy is developed to replan tasks or correct error codes when task execution fails.","Experimental results on real robots and in simulation environments have demonstrated the superiority of the proposed framework, with higher success rates and robust error correction capabilities in open-world tasks.","Videos of our experiments are available at https://youtu.be/NPk2pWKazJc."],"url":"http://arxiv.org/abs/2407.21762v1"}
{"created":"2024-07-31 15:56:06","title":"CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature","abstract":"Ontologies are formal representations of knowledge in specific domains that provide a structured framework for organizing and understanding complex information. Creating ontologies, however, is a complex and time-consuming endeavor. ChEBI is a well-known ontology in the field of chemistry, which provides a comprehensive resource for defining chemical entities and their properties. However, it covers only a small fraction of the rapidly growing knowledge in chemistry and does not provide references to the scientific literature. To address this, we propose a methodology that involves augmenting existing annotated text corpora with knowledge from Chebi and fine-tuning a large language model (LLM) to recognize chemical entities and their roles in scientific text. Our experiments demonstrate the effectiveness of our approach. By combining ontological knowledge and the language understanding capabilities of LLMs, we achieve high precision and recall rates in identifying both the chemical entities and roles in scientific literature. Furthermore, we extract them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a knowledge graph (KG) of chemical entities and roles (CEAR), which provides complementary information to ChEBI, and can help to extend it.","sentences":["Ontologies are formal representations of knowledge in specific domains that provide a structured framework for organizing and understanding complex information.","Creating ontologies, however, is a complex and time-consuming endeavor.","ChEBI is a well-known ontology in the field of chemistry, which provides a comprehensive resource for defining chemical entities and their properties.","However, it covers only a small fraction of the rapidly growing knowledge in chemistry and does not provide references to the scientific literature.","To address this, we propose a methodology that involves augmenting existing annotated text corpora with knowledge from Chebi and fine-tuning a large language model (LLM) to recognize chemical entities and their roles in scientific text.","Our experiments demonstrate the effectiveness of our approach.","By combining ontological knowledge and the language understanding capabilities of LLMs, we achieve high precision and recall rates in identifying both the chemical entities and roles in scientific literature.","Furthermore, we extract them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a knowledge graph (KG) of chemical entities and roles (CEAR), which provides complementary information to ChEBI, and can help to extend it."],"url":"http://arxiv.org/abs/2407.21708v1"}
{"created":"2024-07-31 15:38:15","title":"TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities","abstract":"Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented conversations, including information gathering. How to utilize ToD accurately, efficiently and effectively for information gathering has always been a critical and challenging task. Recent studies have demonstrated that Large Language Models (LLMs) excel in dialogue, instruction generation, and reasoning, and can significantly enhance the performance of TOD through fine-tuning. However, current datasets primarily cater to user-led systems and are limited to predefined specific scenarios and slots, thereby necessitating improvements in the proactiveness, diversity, and capabilities of TOD. In this study, we present a detailed multi-domain task-oriented data construction process for conversations, and a Chinese dialogue dataset generated based on this process, \\textbf{TransferTOD}, which authentically simulates human-machine dialogues in 30 popular life service scenarios. Leveraging this dataset, we trained a \\textbf{TransferTOD-7B} model using full-parameter fine-tuning, showcasing notable abilities in slot filling and questioning. Our work has demonstrated its strong generalization capabilities in various downstream scenarios, significantly enhancing both data utilization efficiency and system performance. The data is released in https://github.com/KongLongGeFDU/TransferTOD.","sentences":["Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented conversations, including information gathering.","How to utilize ToD accurately, efficiently and effectively for information gathering has always been a critical and challenging task.","Recent studies have demonstrated that Large Language Models (LLMs) excel in dialogue, instruction generation, and reasoning, and can significantly enhance the performance of TOD through fine-tuning.","However, current datasets primarily cater to user-led systems and are limited to predefined specific scenarios and slots, thereby necessitating improvements in the proactiveness, diversity, and capabilities of TOD.","In this study, we present a detailed multi-domain task-oriented data construction process for conversations, and a Chinese dialogue dataset generated based on this process, \\textbf{TransferTOD}, which authentically simulates human-machine dialogues in 30 popular life service scenarios.","Leveraging this dataset, we trained a \\textbf{TransferTOD-7B} model using full-parameter fine-tuning, showcasing notable abilities in slot filling and questioning.","Our work has demonstrated its strong generalization capabilities in various downstream scenarios, significantly enhancing both data utilization efficiency and system performance.","The data is released in https://github.com/KongLongGeFDU/TransferTOD."],"url":"http://arxiv.org/abs/2407.21693v1"}
{"created":"2024-07-31 15:12:24","title":"Synth-Empathy: Towards High-Quality Synthetic Empathy Data","abstract":"In recent years, with the rapid advancements in large language models (LLMs), achieving excellent empathetic response capabilities has become a crucial prerequisite. Consequently, managing and understanding empathetic datasets have gained increasing significance. However, empathetic data are typically human-labeled, leading to insufficient datasets and wasted human labor. In this work, we present Synth-Empathy, an LLM-based data generation and quality and diversity selection pipeline that automatically generates high-quality empathetic data while discarding low-quality data. With the data generated from a low empathetic model, we are able to further improve empathetic response performance and achieve state-of-the-art (SoTA) results across multiple benchmarks. Moreover, our model achieves SoTA performance on various human evaluation benchmarks, demonstrating its effectiveness and robustness in real-world applications. Furthermore, we show the trade-off between data quantity and quality, providing insights into empathetic data generation and selection.","sentences":["In recent years, with the rapid advancements in large language models (LLMs), achieving excellent empathetic response capabilities has become a crucial prerequisite.","Consequently, managing and understanding empathetic datasets have gained increasing significance.","However, empathetic data are typically human-labeled, leading to insufficient datasets and wasted human labor.","In this work, we present Synth-Empathy, an LLM-based data generation and quality and diversity selection pipeline that automatically generates high-quality empathetic data while discarding low-quality data.","With the data generated from a low empathetic model, we are able to further improve empathetic response performance and achieve state-of-the-art (SoTA) results across multiple benchmarks.","Moreover, our model achieves SoTA performance on various human evaluation benchmarks, demonstrating its effectiveness and robustness in real-world applications.","Furthermore, we show the trade-off between data quantity and quality, providing insights into empathetic data generation and selection."],"url":"http://arxiv.org/abs/2407.21669v1"}
{"created":"2024-07-31 15:02:46","title":"Defending Jailbreak Attack in VLMs via Cross-modality Information Detector","abstract":"Vision Language Models (VLMs) extend the capacity of LLMs to comprehensively understand vision information, achieving remarkable performance in many vision-centric tasks. Despite that, recent studies have shown that these models are susceptible to jailbreak attacks, which refer to an exploitative technique where malicious users can break the safety alignment of the target model and generate misleading and harmful answers. This potential threat is caused by both the inherent vulnerabilities of LLM and the larger attack scope introduced by vision input. To enhance the security of VLMs against jailbreak attacks, researchers have developed various defense techniques. However, these methods either require modifications to the model's internal structure or demand significant computational resources during the inference phase. Multimodal information is a double-edged sword. While it increases the risk of attacks, it also provides additional data that can enhance safeguards. Inspired by this, we propose $\\underline{\\textbf{C}}$ross-modality $\\underline{\\textbf{I}}$nformation $\\underline{\\textbf{DE}}$tecto$\\underline{\\textbf{R}}$ ($\\textit{CIDER})$, a plug-and-play jailbreaking detector designed to identify maliciously perturbed image inputs, utilizing the cross-modal similarity between harmful queries and adversarial images. This simple yet effective cross-modality information detector, $\\textit{CIDER}$, is independent of the target VLMs and requires less computation cost. Extensive experimental results demonstrate the effectiveness and efficiency of $\\textit{CIDER}$, as well as its transferability to both white-box and black-box VLMs.","sentences":["Vision Language Models (VLMs) extend the capacity of LLMs to comprehensively understand vision information, achieving remarkable performance in many vision-centric tasks.","Despite that, recent studies have shown that these models are susceptible to jailbreak attacks, which refer to an exploitative technique where malicious users can break the safety alignment of the target model and generate misleading and harmful answers.","This potential threat is caused by both the inherent vulnerabilities of LLM and the larger attack scope introduced by vision input.","To enhance the security of VLMs against jailbreak attacks, researchers have developed various defense techniques.","However, these methods either require modifications to the model's internal structure or demand significant computational resources during the inference phase.","Multimodal information is a double-edged sword.","While it increases the risk of attacks, it also provides additional data that can enhance safeguards.","Inspired by this, we propose $\\underline{\\textbf{C}}$ross-modality $\\underline{\\textbf{I}}$nformation $\\underline{\\textbf{DE}}$tecto$\\underline{\\textbf{R}}$ ($\\textit{CIDER})$, a plug-and-play jailbreaking detector designed to identify maliciously perturbed image inputs, utilizing the cross-modal similarity between harmful queries and adversarial images.","This simple yet effective cross-modality information detector, $\\textit{CIDER}$, is independent of the target VLMs and requires less computation cost.","Extensive experimental results demonstrate the effectiveness and efficiency of $\\textit{CIDER}$, as well as its transferability to both white-box and black-box VLMs."],"url":"http://arxiv.org/abs/2407.21659v1"}
{"created":"2024-07-31 14:50:11","title":"Human interaction classifier for LLM based chatbot","abstract":"This study investigates different approaches to classify human interactions in an artificial intelligence-based environment, specifically for Applus+ IDIADA's intelligent agent AIDA. The main objective is to develop a classifier that accurately identifies the type of interaction received (Conversation, Services, or Document Translation) to direct requests to the appropriate channel and provide a more specialized and efficient service. Various models are compared, including LLM-based classifiers, KNN using Titan and Cohere embeddings, SVM, and artificial neural networks. Results show that SVM and ANN models with Cohere embeddings achieve the best overall performance, with superior F1 scores and faster execution times compared to LLM-based approaches. The study concludes that the SVM model with Cohere embeddings is the most suitable option for classifying human interactions in the AIDA environment, offering an optimal balance between accuracy and computational efficiency.","sentences":["This study investigates different approaches to classify human interactions in an artificial intelligence-based environment, specifically for Applus+ IDIADA's intelligent agent AIDA.","The main objective is to develop a classifier that accurately identifies the type of interaction received (Conversation, Services, or Document Translation) to direct requests to the appropriate channel and provide a more specialized and efficient service.","Various models are compared, including LLM-based classifiers, KNN using Titan and Cohere embeddings, SVM, and artificial neural networks.","Results show that SVM and ANN models with Cohere embeddings achieve the best overall performance, with superior F1 scores and faster execution times compared to LLM-based approaches.","The study concludes that the SVM model with Cohere embeddings is the most suitable option for classifying human interactions in the AIDA environment, offering an optimal balance between accuracy and computational efficiency."],"url":"http://arxiv.org/abs/2407.21647v1"}
{"created":"2024-07-31 14:48:27","title":"Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agent","abstract":"In this paper, we present Cross Language Agent -- Simultaneous Interpretation, CLASI, a high-quality and human-like Simultaneous Speech Translation (SiST) System. Inspired by professional human interpreters, we utilize a novel data-driven read-write strategy to balance the translation quality and latency. To address the challenge of translating in-domain terminologies, CLASI employs a multi-modal retrieving module to obtain relevant information to augment the translation. Supported by LLMs, our approach can generate error-tolerated translation by considering the input audio, historical context, and retrieved information. Experimental results show that our system outperforms other systems by significant margins. Aligned with professional human interpreters, we evaluate CLASI with a better human evaluation metric, valid information proportion (VIP), which measures the amount of information that can be successfully conveyed to the listeners. In the real-world scenarios, where the speeches are often disfluent, informal, and unclear, CLASI achieves VIP of 81.3% and 78.0% for Chinese-to-English and English-to-Chinese translation directions, respectively. In contrast, state-of-the-art commercial or open-source systems only achieve 35.4% and 41.6%. On the extremely hard dataset, where other systems achieve under 13% VIP, CLASI can still achieve 70% VIP.","sentences":["In this paper, we present Cross Language Agent -- Simultaneous Interpretation, CLASI, a high-quality and human-like Simultaneous Speech Translation (SiST) System.","Inspired by professional human interpreters, we utilize a novel data-driven read-write strategy to balance the translation quality and latency.","To address the challenge of translating in-domain terminologies, CLASI employs a multi-modal retrieving module to obtain relevant information to augment the translation.","Supported by LLMs, our approach can generate error-tolerated translation by considering the input audio, historical context, and retrieved information.","Experimental results show that our system outperforms other systems by significant margins.","Aligned with professional human interpreters, we evaluate CLASI with a better human evaluation metric, valid information proportion (VIP), which measures the amount of information that can be successfully conveyed to the listeners.","In the real-world scenarios, where the speeches are often disfluent, informal, and unclear, CLASI achieves VIP of 81.3% and 78.0% for Chinese-to-English and English-to-Chinese translation directions, respectively.","In contrast, state-of-the-art commercial or open-source systems only achieve 35.4% and 41.6%.","On the extremely hard dataset, where other systems achieve under 13% VIP, CLASI can still achieve 70% VIP."],"url":"http://arxiv.org/abs/2407.21646v1"}
{"created":"2024-07-31 13:29:22","title":"LLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows","abstract":"To enhance productivity and to streamline workflows, there is a growing trend to embed large language model (LLM) functionality into applications, from browser-based web apps to native apps that run on personal computers. Here, we introduce LLM-for-X, a system-wide shortcut layer that seamlessly augments any application with LLM services through a lightweight popup dialog. Our native layer seamlessly connects front-end applications to popular LLM backends, such as ChatGPT and Gemini, using their uniform chat front-ends as the programming interface or their custom API calls. We demonstrate the benefits of LLM-for-X across a wide variety of applications, including Microsoft Office, VSCode, and Adobe Acrobat as well as popular web apps such as Overleaf. In our evaluation, we compared LLM-for-X with ChatGPT's web interface in a series of tasks, showing that our approach can provide users with quick, efficient, and easy-to-use LLM assistance without context switching to support writing and reading tasks that is agnostic of the specific application.","sentences":["To enhance productivity and to streamline workflows, there is a growing trend to embed large language model (LLM) functionality into applications, from browser-based web apps to native apps that run on personal computers.","Here, we introduce LLM-for-X, a system-wide shortcut layer that seamlessly augments any application with LLM services through a lightweight popup dialog.","Our native layer seamlessly connects front-end applications to popular LLM backends, such as ChatGPT and Gemini, using their uniform chat front-ends as the programming interface or their custom API calls.","We demonstrate the benefits of LLM-for-X across a wide variety of applications, including Microsoft Office, VSCode, and Adobe Acrobat as well as popular web apps such as Overleaf.","In our evaluation, we compared LLM-for-X with ChatGPT's web interface in a series of tasks, showing that our approach can provide users with quick, efficient, and easy-to-use LLM assistance without context switching to support writing and reading tasks that is agnostic of the specific application."],"url":"http://arxiv.org/abs/2407.21593v1"}
{"created":"2024-07-31 13:10:03","title":"A Performance Study of LLM-Generated Code on Leetcode","abstract":"This study evaluates the efficiency of code generation by Large Language Models (LLMs) and measures their performance against human-crafted solutions using a dataset from Leetcode. We compare 18 LLMs, considering factors such as model temperature and success rate, and their impact on code performance. This research introduces a novel method for measuring and comparing the speed of LLM-generated code, revealing that LLMs produce code with comparable performance, irrespective of the adopted LLM. We also find that LLMs are capable of generating code that is, on average, more efficient than the code written by humans. The paper further discusses the use of Leetcode as a benchmarking dataset, the limitations imposed by potential data contamination, and the platform's measurement reliability. We believe that our findings contribute to a better understanding of LLM capabilities in code generation and set the stage for future optimizations in the field.","sentences":["This study evaluates the efficiency of code generation by Large Language Models (LLMs) and measures their performance against human-crafted solutions using a dataset from Leetcode.","We compare 18 LLMs, considering factors such as model temperature and success rate, and their impact on code performance.","This research introduces a novel method for measuring and comparing the speed of LLM-generated code, revealing that LLMs produce code with comparable performance, irrespective of the adopted LLM.","We also find that LLMs are capable of generating code that is, on average, more efficient than the code written by humans.","The paper further discusses the use of Leetcode as a benchmarking dataset, the limitations imposed by potential data contamination, and the platform's measurement reliability.","We believe that our findings contribute to a better understanding of LLM capabilities in code generation and set the stage for future optimizations in the field."],"url":"http://arxiv.org/abs/2407.21579v1"}
{"created":"2024-07-31 12:56:14","title":"PMoE: Progressive Mixture of Experts with Asymmetric Transformer for Continual Learning","abstract":"Large Language Models (LLMs) encounter significant challenges in continual learning due to catastrophic forgetting, where new information overwrites previously acquired knowledge. This limitation leads to substantial environmental and economic waste. In this study, we introduce the PMoE, Progressive Mixture of Experts with Asymmetric Transformer, which aims to minimize forgetting by utilizing an asymmetric design with shallow layers dedicated to general knowledge and deep layers for new knowledge. PMoE incorporates progressively added experts in deep layers and a router that allocates new knowledge to the appropriate experts efficiently. The router, positioned adjacent to the deep layers, utilizes deep features aggregating consolidated information. This enables the router to perform efficiently, allocating new knowledge to the appropriate experts, which progressively increase in the deep layers. Extensive experiments on TRACE datasets and general language understanding datasets demonstrate that the proposed PMoE outperforms previous state-of-the-art approaches.","sentences":["Large Language Models (LLMs) encounter significant challenges in continual learning due to catastrophic forgetting, where new information overwrites previously acquired knowledge.","This limitation leads to substantial environmental and economic waste.","In this study, we introduce the PMoE, Progressive Mixture of Experts with Asymmetric Transformer, which aims to minimize forgetting by utilizing an asymmetric design with shallow layers dedicated to general knowledge and deep layers for new knowledge.","PMoE incorporates progressively added experts in deep layers and a router that allocates new knowledge to the appropriate experts efficiently.","The router, positioned adjacent to the deep layers, utilizes deep features aggregating consolidated information.","This enables the router to perform efficiently, allocating new knowledge to the appropriate experts, which progressively increase in the deep layers.","Extensive experiments on TRACE datasets and general language understanding datasets demonstrate that the proposed PMoE outperforms previous state-of-the-art approaches."],"url":"http://arxiv.org/abs/2407.21571v1"}
{"created":"2024-07-31 12:22:40","title":"CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment","abstract":"This paper presents the Customer Experience (CX) Simulator, a novel framework designed to assess the effects of untested web-marketing campaigns through user behavior simulations. The proposed framework leverages large language models (LLMs) to represent various events in a user's behavioral history, such as viewing an item, applying a coupon, or purchasing an item, as semantic embedding vectors. We train a model to predict transitions between events from their LLM embeddings, which can even generalize to unseen events by learning from diverse training data. In web-marketing applications, we leverage this transition prediction model to simulate how users might react differently when new campaigns or products are presented to them. This allows us to eliminate the need for costly online testing and enhance the marketers' abilities to reveal insights. Our numerical evaluation and user study, utilizing BigQuery Public Datasets from the Google Merchandise Store, demonstrate the effectiveness of our framework.","sentences":["This paper presents the Customer Experience (CX) Simulator, a novel framework designed to assess the effects of untested web-marketing campaigns through user behavior simulations.","The proposed framework leverages large language models (LLMs) to represent various events in a user's behavioral history, such as viewing an item, applying a coupon, or purchasing an item, as semantic embedding vectors.","We train a model to predict transitions between events from their LLM embeddings, which can even generalize to unseen events by learning from diverse training data.","In web-marketing applications, we leverage this transition prediction model to simulate how users might react differently when new campaigns or products are presented to them.","This allows us to eliminate the need for costly online testing and enhance the marketers' abilities to reveal insights.","Our numerical evaluation and user study, utilizing BigQuery Public Datasets from the Google Merchandise Store, demonstrate the effectiveness of our framework."],"url":"http://arxiv.org/abs/2407.21553v1"}
{"created":"2024-07-31 11:29:46","title":"Can LLMs \"Reason\" in Music? An Evaluation of LLMs' Capability of Music Understanding and Generation","abstract":"Symbolic Music, akin to language, can be encoded in discrete symbols. Recent research has extended the application of large language models (LLMs) such as GPT-4 and Llama2 to the symbolic music domain including understanding and generation. Yet scant research explores the details of how these LLMs perform on advanced music understanding and conditioned generation, especially from the multi-step reasoning perspective, which is a critical aspect in the conditioned, editable, and interactive human-computer co-creation process. This study conducts a thorough investigation of LLMs' capability and limitations in symbolic music processing. We identify that current LLMs exhibit poor performance in song-level multi-step music reasoning, and typically fail to leverage learned music knowledge when addressing complex musical tasks. An analysis of LLMs' responses highlights distinctly their pros and cons. Our findings suggest achieving advanced musical capability is not intrinsically obtained by LLMs, and future research should focus more on bridging the gap between music knowledge and reasoning, to improve the co-creation experience for musicians.","sentences":["Symbolic Music, akin to language, can be encoded in discrete symbols.","Recent research has extended the application of large language models (LLMs) such as GPT-4 and Llama2 to the symbolic music domain including understanding and generation.","Yet scant research explores the details of how these LLMs perform on advanced music understanding and conditioned generation, especially from the multi-step reasoning perspective, which is a critical aspect in the conditioned, editable, and interactive human-computer co-creation process.","This study conducts a thorough investigation of LLMs' capability and limitations in symbolic music processing.","We identify that current LLMs exhibit poor performance in song-level multi-step music reasoning, and typically fail to leverage learned music knowledge when addressing complex musical tasks.","An analysis of LLMs' responses highlights distinctly their pros and cons.","Our findings suggest achieving advanced musical capability is not intrinsically obtained by LLMs, and future research should focus more on bridging the gap between music knowledge and reasoning, to improve the co-creation experience for musicians."],"url":"http://arxiv.org/abs/2407.21531v1"}
{"created":"2024-07-31 10:30:31","title":"Interpreting and learning voice commands with a Large Language Model for a robot system","abstract":"Robots are increasingly common in industry and daily life, such as in nursing homes where they can assist staff. A key challenge is developing intuitive interfaces for easy communication. The use of Large Language Models (LLMs) like GPT-4 has enhanced robot capabilities, allowing for real-time interaction and decision-making. This integration improves robots' adaptability and functionality. This project focuses on merging LLMs with databases to improve decision-making and enable knowledge acquisition for request interpretation problems.","sentences":["Robots are increasingly common in industry and daily life, such as in nursing homes where they can assist staff.","A key challenge is developing intuitive interfaces for easy communication.","The use of Large Language Models (LLMs) like GPT-4 has enhanced robot capabilities, allowing for real-time interaction and decision-making.","This integration improves robots' adaptability and functionality.","This project focuses on merging LLMs with databases to improve decision-making and enable knowledge acquisition for request interpretation problems."],"url":"http://arxiv.org/abs/2407.21512v1"}
{"created":"2024-07-31 09:16:33","title":"KemenkeuGPT: Leveraging a Large Language Model on Indonesia's Government Financial Data and Regulations to Enhance Decision Making","abstract":"Data is crucial for evidence-based policymaking and enhancing public services, including those at the Ministry of Finance of the Republic of Indonesia. However, the complexity and dynamic nature of governmental financial data and regulations can hinder decision-making. This study investigates the potential of Large Language Models (LLMs) to address these challenges, focusing on Indonesia's financial data and regulations. While LLMs are effective in the financial sector, their use in the public sector in Indonesia is unexplored. This study undertakes an iterative process to develop KemenkeuGPT using the LangChain with Retrieval-Augmented Generation (RAG), prompt engineering and fine-tuning. The dataset from 2003 to 2023 was collected from the Ministry of Finance, Statistics Indonesia and the International Monetary Fund (IMF). Surveys and interviews with Ministry officials informed, enhanced and fine-tuned the model. We evaluated the model using human feedback, LLM-based evaluation and benchmarking. The model's accuracy improved from 35% to 61%, with correctness increasing from 48% to 64%. The Retrieval-Augmented Generation Assessment (RAGAS) framework showed that KemenkeuGPT achieved 44% correctness with 73% faithfulness, 40% precision and 60% recall, outperforming several other base models. An interview with an expert from the Ministry of Finance indicated that KemenkeuGPT has the potential to become an essential tool for decision-making. These results are expected to improve with continuous human feedback.","sentences":["Data is crucial for evidence-based policymaking and enhancing public services, including those at the Ministry of Finance of the Republic of Indonesia.","However, the complexity and dynamic nature of governmental financial data and regulations can hinder decision-making.","This study investigates the potential of Large Language Models (LLMs) to address these challenges, focusing on Indonesia's financial data and regulations.","While LLMs are effective in the financial sector, their use in the public sector in Indonesia is unexplored.","This study undertakes an iterative process to develop KemenkeuGPT using the LangChain with Retrieval-Augmented Generation (RAG), prompt engineering and fine-tuning.","The dataset from 2003 to 2023 was collected from the Ministry of Finance, Statistics Indonesia and the International Monetary Fund (IMF).","Surveys and interviews with Ministry officials informed, enhanced and fine-tuned the model.","We evaluated the model using human feedback, LLM-based evaluation and benchmarking.","The model's accuracy improved from 35% to 61%, with correctness increasing from 48% to 64%.","The Retrieval-Augmented Generation Assessment (RAGAS) framework showed that KemenkeuGPT achieved 44% correctness with 73% faithfulness, 40% precision and 60% recall, outperforming several other base models.","An interview with an expert from the Ministry of Finance indicated that KemenkeuGPT has the potential to become an essential tool for decision-making.","These results are expected to improve with continuous human feedback."],"url":"http://arxiv.org/abs/2407.21459v1"}
{"created":"2024-07-31 08:48:48","title":"Improving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency","abstract":"Despite large language models (LLMs) have demonstrated impressive performance in various tasks, they are still suffering from the factual inconsistency problem called hallucinations. For instance, LLMs occasionally generate content that diverges from source article, and prefer to extract information that appears at the beginning and end of the context, especially in long document summarization. Inspired by these findings, we propose to improve the faithfulness of LLMs in summarization by impelling them to process the entire article more fairly and faithfully. We present a novel summary generation strategy, namely SliSum, which exploits the ideas of sliding windows and self-consistency. Specifically, SliSum divides the source article into overlapping windows, and utilizes LLM to generate local summaries for the content in the windows. Finally, SliSum aggregates all local summaries using clustering and majority voting algorithm to produce more faithful summary of entire article. Extensive experiments demonstrate that SliSum significantly improves the faithfulness of diverse LLMs including LLaMA-2, Claude-2 and GPT-3.5 in both short and long text summarization, while maintaining their fluency and informativeness and without additional fine-tuning and resources. We further conduct qualitative and quantitative studies to investigate why SliSum works and impacts of hyperparameters in SliSum on performance.","sentences":["Despite large language models (LLMs) have demonstrated impressive performance in various tasks, they are still suffering from the factual inconsistency problem called hallucinations.","For instance, LLMs occasionally generate content that diverges from source article, and prefer to extract information that appears at the beginning and end of the context, especially in long document summarization.","Inspired by these findings, we propose to improve the faithfulness of LLMs in summarization by impelling them to process the entire article more fairly and faithfully.","We present a novel summary generation strategy, namely SliSum, which exploits the ideas of sliding windows and self-consistency.","Specifically, SliSum divides the source article into overlapping windows, and utilizes LLM to generate local summaries for the content in the windows.","Finally, SliSum aggregates all local summaries using clustering and majority voting algorithm to produce more faithful summary of entire article.","Extensive experiments demonstrate that SliSum significantly improves the faithfulness of diverse LLMs including LLaMA-2, Claude-2 and GPT-3.5 in both short and long text summarization, while maintaining their fluency and informativeness and without additional fine-tuning and resources.","We further conduct qualitative and quantitative studies to investigate why SliSum works and impacts of hyperparameters in SliSum on performance."],"url":"http://arxiv.org/abs/2407.21443v1"}
{"created":"2024-07-31 08:27:03","title":"Chat-like Asserts Prediction with the Support of Large Language Model","abstract":"Unit testing is an essential component of software testing, with the assert statements playing an important role in determining whether the tested function operates as expected. Although research has explored automated test case generation, generating meaningful assert statements remains an ongoing challenge. While several studies have investigated assert statement generation in Java, limited work addresses this task in popular dynamically-typed programming languages like Python. In this paper, we introduce Chat-like execution-based Asserts Prediction (\\tool), a novel Large Language Model-based approach for generating meaningful assert statements for Python projects. \\tool utilizes the persona, Chain-of-Thought, and one-shot learning techniques in the prompt design, and conducts rounds of communication with LLM and Python interpreter to generate meaningful assert statements. We also present a Python assert statement dataset mined from GitHub. Our evaluation demonstrates that \\tool achieves 64.7\\% accuracy for single assert statement generation and 62\\% for overall assert statement generation, outperforming the existing approaches. We also analyze the mismatched assert statements, which may still share the same functionality and discuss the potential help \\tool could offer to the automated Python unit test generation. The findings indicate that \\tool has the potential to benefit the SE community through more practical usage scenarios.","sentences":["Unit testing is an essential component of software testing, with the assert statements playing an important role in determining whether the tested function operates as expected.","Although research has explored automated test case generation, generating meaningful assert statements remains an ongoing challenge.","While several studies have investigated assert statement generation in Java, limited work addresses this task in popular dynamically-typed programming languages like Python.","In this paper, we introduce Chat-like execution-based Asserts Prediction (\\tool), a novel Large Language Model-based approach for generating meaningful assert statements for Python projects.","\\tool utilizes the persona, Chain-of-Thought, and one-shot learning techniques in the prompt design, and conducts rounds of communication with LLM and Python interpreter to generate meaningful assert statements.","We also present a Python assert statement dataset mined from GitHub.","Our evaluation demonstrates that \\tool achieves 64.7\\% accuracy for single assert statement generation and 62\\% for overall assert statement generation, outperforming the existing approaches.","We also analyze the mismatched assert statements, which may still share the same functionality and discuss the potential help \\tool could offer to the automated Python unit test generation.","The findings indicate that \\tool has the potential to benefit the SE community through more practical usage scenarios."],"url":"http://arxiv.org/abs/2407.21429v1"}
{"created":"2024-07-31 08:19:06","title":"Cost-Effective Hallucination Detection for LLMs","abstract":"Large language models (LLMs) can be prone to hallucinations - generating unreliable outputs that are unfaithful to their inputs, external facts or internally inconsistent. In this work, we address several challenges for post-hoc hallucination detection in production settings. Our pipeline for hallucination detection entails: first, producing a confidence score representing the likelihood that a generated answer is a hallucination; second, calibrating the score conditional on attributes of the inputs and candidate response; finally, performing detection by thresholding the calibrated score. We benchmark a variety of state-of-the-art scoring methods on different datasets, encompassing question answering, fact checking, and summarization tasks. We employ diverse LLMs to ensure a comprehensive assessment of performance. We show that calibrating individual scoring methods is critical for ensuring risk-aware downstream decision making. Based on findings that no individual score performs best in all situations, we propose a multi-scoring framework, which combines different scores and achieves top performance across all datasets. We further introduce cost-effective multi-scoring, which can match or even outperform more expensive detection methods, while significantly reducing computational overhead.","sentences":["Large language models (LLMs) can be prone to hallucinations - generating unreliable outputs that are unfaithful to their inputs, external facts or internally inconsistent.","In this work, we address several challenges for post-hoc hallucination detection in production settings.","Our pipeline for hallucination detection entails: first, producing a confidence score representing the likelihood that a generated answer is a hallucination; second, calibrating the score conditional on attributes of the inputs and candidate response; finally, performing detection by thresholding the calibrated score.","We benchmark a variety of state-of-the-art scoring methods on different datasets, encompassing question answering, fact checking, and summarization tasks.","We employ diverse LLMs to ensure a comprehensive assessment of performance.","We show that calibrating individual scoring methods is critical for ensuring risk-aware downstream decision making.","Based on findings that no individual score performs best in all situations, we propose a multi-scoring framework, which combines different scores and achieves top performance across all datasets.","We further introduce cost-effective multi-scoring, which can match or even outperform more expensive detection methods, while significantly reducing computational overhead."],"url":"http://arxiv.org/abs/2407.21424v1"}
{"created":"2024-07-31 08:00:41","title":"Towards interfacing large language models with ASR systems using confidence measures and prompting","abstract":"As large language models (LLMs) grow in parameter size and capabilities, such as interaction through prompting, they open up new ways of interfacing with automatic speech recognition (ASR) systems beyond rescoring n-best lists. This work investigates post-hoc correction of ASR transcripts with LLMs. To avoid introducing errors into likely accurate transcripts, we propose a range of confidence-based filtering methods. Our results indicate that this can improve the performance of less competitive ASR systems.","sentences":["As large language models (LLMs) grow in parameter size and capabilities, such as interaction through prompting, they open up new ways of interfacing with automatic speech recognition (ASR) systems beyond rescoring n-best lists.","This work investigates post-hoc correction of ASR transcripts with LLMs.","To avoid introducing errors into likely accurate transcripts, we propose a range of confidence-based filtering methods.","Our results indicate that this can improve the performance of less competitive ASR systems."],"url":"http://arxiv.org/abs/2407.21414v1"}
{"created":"2024-07-31 06:35:15","title":"An LLM-based Readability Measurement for Unit Tests' Context-aware Inputs","abstract":"Automated test techniques usually generate unit tests with higher code coverage than manual tests. However, the readability of automated tests is crucial for code comprehension and maintenance. The readability of unit tests involves many aspects. In this paper, we focus on test inputs. The central limitation of existing studies on input readability is that they focus on test codes alone without taking the tested source codes into consideration, making them either ignore different source codes' different readability requirements or require manual efforts to write readable inputs. However, we observe that the source codes specify the contexts that test inputs must satisfy. Based on such observation, we introduce the \\underline{C}ontext \\underline{C}onsistency \\underline{C}riterion (a.k.a, C3), which is a readability measurement tool that leverages Large Language Models to extract primitive-type (including string-type) parameters' readability contexts from the source codes and checks whether test inputs are consistent with those contexts. We have also proposed EvoSuiteC3. It leverages C3's extracted contexts to help EvoSuite generate readable test inputs. We have evaluated C3's performance on $409$ \\java{} classes and compared manual and automated tests' readability under C3 measurement. The results are two-fold. First, The Precision, Recall, and F1-Score of C3's mined readability contexts are \\precision{}, \\recall{}, and \\fone{}, respectively. Second, under C3's measurement, the string-type input readability scores of EvoSuiteC3, ChatUniTest (an LLM-based test generation tool), manual tests, and two traditional tools (EvoSuite and Randoop) are $90\\%$, $83\\%$, $68\\%$, $8\\%$, and $8\\%$, showing the traditional tools' inability in generating readable string-type inputs.","sentences":["Automated test techniques usually generate unit tests with higher code coverage than manual tests.","However, the readability of automated tests is crucial for code comprehension and maintenance.","The readability of unit tests involves many aspects.","In this paper, we focus on test inputs.","The central limitation of existing studies on input readability is that they focus on test codes alone without taking the tested source codes into consideration, making them either ignore different source codes' different readability requirements or require manual efforts to write readable inputs.","However, we observe that the source codes specify the contexts that test inputs must satisfy.","Based on such observation, we introduce the \\underline{C}ontext \\underline{C}onsistency \\underline{C}riterion (a.k.a, C3), which is a readability measurement tool that leverages Large Language Models to extract primitive-type (including string-type) parameters' readability contexts from the source codes and checks whether test inputs are consistent with those contexts.","We have also proposed EvoSuiteC3.","It leverages C3's extracted contexts to help EvoSuite generate readable test inputs.","We have evaluated C3's performance on $409$ \\java{} classes and compared manual and automated tests' readability under C3 measurement.","The results are two-fold.","First, The Precision, Recall, and F1-Score of C3's mined readability contexts are \\precision{}, \\recall{}, and \\fone{}, respectively.","Second, under C3's measurement, the string-type input readability scores of EvoSuiteC3, ChatUniTest (an LLM-based test generation tool), manual tests, and two traditional tools (EvoSuite and Randoop) are $90\\%$, $83\\%$, $68\\%$, $8\\%$, and $8\\%$, showing the traditional tools' inability in generating readable string-type inputs."],"url":"http://arxiv.org/abs/2407.21369v1"}
{"created":"2024-07-31 06:01:24","title":"Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs","abstract":"Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning algorithm that enables augmentation of black-box LLMs with one or more KGs. The algorithm equips a LLM with actions for interfacing a KG and enables the LLM to perform tree search over possible thoughts and actions to find high confidence reasoning paths. We evaluate on two popular benchmark datasets. Our results show that Tree-of-Traversals significantly improves performance on question answering and KG question answering tasks. Code is available at \\url{https://github.com/amazon-science/tree-of-traversals}","sentences":["Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge.","However, KGs and LLMs are often developed separately and must be integrated after training.","We introduce Tree-of-Traversals, a novel zero-shot reasoning algorithm that enables augmentation of black-box LLMs with one or more KGs.","The algorithm equips a LLM with actions for interfacing a KG and enables the LLM to perform tree search over possible thoughts and actions to find high confidence reasoning paths.","We evaluate on two popular benchmark datasets.","Our results show that Tree-of-Traversals significantly improves performance on question answering and KG question answering tasks.","Code is available at \\url{https://github.com/amazon-science/tree-of-traversals}"],"url":"http://arxiv.org/abs/2407.21358v1"}
{"created":"2024-07-31 04:49:46","title":"Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM","abstract":"Automatic furniture layout is long desired for convenient interior design. Leveraging the remarkable visual reasoning capabilities of multimodal large language models (MLLMs), recent methods address layout generation in a static manner, lacking the feedback-driven refinement essential for interactive user engagement. We introduce Chat2Layout, a novel interactive furniture layout generation system that extends the functionality of MLLMs into the realm of interactive layout design. To achieve this, we establish a unified vision-question paradigm for in-context learning, enabling seamless communication with MLLMs to steer their behavior without altering model weights. Within this framework, we present a novel training-free visual prompting mechanism. This involves a visual-text prompting technique that assist MLLMs in reasoning about plausible layout plans, followed by an Offline-to-Online search (O2O-Search) method, which automatically identifies the minimal set of informative references to provide exemplars for visual-text prompting. By employing an agent system with MLLMs as the core controller, we enable bidirectional interaction. The agent not only comprehends the 3D environment and user requirements through linguistic and visual perception but also plans tasks and reasons about actions to generate and arrange furniture within the virtual space. Furthermore, the agent iteratively updates based on visual feedback from execution results. Experimental results demonstrate that our approach facilitates language-interactive generation and arrangement for diverse and complex 3D furniture.","sentences":["Automatic furniture layout is long desired for convenient interior design.","Leveraging the remarkable visual reasoning capabilities of multimodal large language models (MLLMs), recent methods address layout generation in a static manner, lacking the feedback-driven refinement essential for interactive user engagement.","We introduce Chat2Layout, a novel interactive furniture layout generation system that extends the functionality of MLLMs into the realm of interactive layout design.","To achieve this, we establish a unified vision-question paradigm for in-context learning, enabling seamless communication with MLLMs to steer their behavior without altering model weights.","Within this framework, we present a novel training-free visual prompting mechanism.","This involves a visual-text prompting technique that assist MLLMs in reasoning about plausible layout plans, followed by an Offline-to-Online search (O2O-Search) method, which automatically identifies the minimal set of informative references to provide exemplars for visual-text prompting.","By employing an agent system with MLLMs as the core controller, we enable bidirectional interaction.","The agent not only comprehends the 3D environment and user requirements through linguistic and visual perception but also plans tasks and reasons about actions to generate and arrange furniture within the virtual space.","Furthermore, the agent iteratively updates based on visual feedback from execution results.","Experimental results demonstrate that our approach facilitates language-interactive generation and arrangement for diverse and complex 3D furniture."],"url":"http://arxiv.org/abs/2407.21333v1"}
{"created":"2024-07-31 04:38:07","title":"Performance of Recent Large Language Models for a Low-Resourced Language","abstract":"Large Language Models (LLMs) have shown significant advances in the past year. In addition to new versions of GPT and Llama, several other LLMs have been introduced recently. Some of these are open models available for download and modification.   Although multilingual large language models have been available for some time, their performance on low-resourced languages such as Sinhala has been poor. We evaluated four recent LLMs on their performance directly in the Sinhala language, and by translation to and from English. We also evaluated their fine-tunability with a small amount of fine-tuning data. Claude and GPT 4o perform well out-of-the-box and do significantly better than previous versions. Llama and Mistral perform poorly but show some promise of improvement with fine tuning.","sentences":["Large Language Models (LLMs) have shown significant advances in the past year.","In addition to new versions of GPT and Llama, several other LLMs have been introduced recently.","Some of these are open models available for download and modification.   ","Although multilingual large language models have been available for some time, their performance on low-resourced languages such as Sinhala has been poor.","We evaluated four recent LLMs on their performance directly in the Sinhala language, and by translation to and from English.","We also evaluated their fine-tunability with a small amount of fine-tuning data.","Claude and GPT 4o perform well out-of-the-box and do significantly better than previous versions.","Llama and Mistral perform poorly but show some promise of improvement with fine tuning."],"url":"http://arxiv.org/abs/2407.21330v1"}
{"created":"2024-07-31 04:16:37","title":"EdgeLLM: A Highly Efficient CPU-FPGA Heterogeneous Edge Accelerator for Large Language Models","abstract":"The rapid advancements in artificial intelligence (AI), particularly the Large Language Models (LLMs), have profoundly affected our daily work and communication forms. However, the colossal scale of LLM presents significant operational challenges, particularly when attempting to deploy them on resource-constrained edge devices such as smartphones, robots, and embedded systems. In this work, we proposed EdgeLLM, an efficient CPU-FPGA heterogeneous acceleration framework, to markedly enhance the computational efficiency of LLMs on edge. We first analyzed the whole operators within AI models and developed a universal data parallelism scheme, which is generic and can be adapted to any type of AI algorithm. Then, we developed fully-customized hardware operators according to the designated data formats. A multitude of optimization techniques have been integrated in the design, such as approximate FP16*INT4 and FP16*FP16 computation engines, group vector systolic arrays, log-scale structured sparsity, asynchronous between data transfer and processing. Finally, we proposed an end-to-end compilation scheme that can dynamically compile all of the operators and map the whole model on CPU-FPGA heterogeneous system. The design has been deployed on AMD Xilinx VCU128 FPGA, our accelerator achieves 1.67x higher throughput and 7.4x higher energy efficiency than the commercial GPU (NVIDIA A100-SXM4-80G) on ChatGLM2-6B, and shows 10%~20% better performance than state-of-the-art FPGA accelerator of FlightLLM in terms of HBM bandwidth utilization and LLM throughput.","sentences":["The rapid advancements in artificial intelligence (AI), particularly the Large Language Models (LLMs), have profoundly affected our daily work and communication forms.","However, the colossal scale of LLM presents significant operational challenges, particularly when attempting to deploy them on resource-constrained edge devices such as smartphones, robots, and embedded systems.","In this work, we proposed EdgeLLM, an efficient CPU-FPGA heterogeneous acceleration framework, to markedly enhance the computational efficiency of LLMs on edge.","We first analyzed the whole operators within AI models and developed a universal data parallelism scheme, which is generic and can be adapted to any type of AI algorithm.","Then, we developed fully-customized hardware operators according to the designated data formats.","A multitude of optimization techniques have been integrated in the design, such as approximate FP16*INT4 and FP16*FP16 computation engines, group vector systolic arrays, log-scale structured sparsity, asynchronous between data transfer and processing.","Finally, we proposed an end-to-end compilation scheme that can dynamically compile all of the operators and map the whole model on CPU-FPGA heterogeneous system.","The design has been deployed on AMD Xilinx VCU128 FPGA, our accelerator achieves 1.67x higher throughput and 7.4x higher energy efficiency than the commercial GPU (NVIDIA A100-SXM4-80G) on ChatGLM2-6B, and shows 10%~20% better performance than state-of-the-art FPGA accelerator of FlightLLM in terms of HBM bandwidth utilization and LLM throughput."],"url":"http://arxiv.org/abs/2407.21325v1"}
{"created":"2024-07-31 04:01:08","title":"MetaOpenFOAM: an LLM-based multi-agent framework for CFD","abstract":"Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs). Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions. MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input. These simulation tasks include mesh pre-processing, simulation and post-processing, etc. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks. Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs. Tests on a benchmark for natural language-based CFD solver, consisting of 8 CFD simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per test (85%), with each test case costing only $0.22 on average. The 8 CFD simulation tasks include compressible and incompressible flows, 2D and 3D flows, heat transfer, and combustion, demonstrating the ability to automate CFD simulations using only natural language input and iteratively correct errors to achieve the desired simulation at a low cost. An ablation study was conducted to verify the necessity of each component in the multi-agent system and the RAG technology. A sensitivity study on the randomness of LLM showed that LLM with low randomness can obtain more stable and accurate results. Additionally, MetaOpenFOAM own the ability to identify and modify key parameters in user requirements and excels in correcting bugs when failures occur, with or without human participation, which demonstrates the generalization of MetaOpenFOAM.","sentences":["Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs).","Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions.","MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input.","These simulation tasks include mesh pre-processing, simulation and post-processing, etc. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks.","Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs.","Tests on a benchmark for natural language-based CFD solver, consisting of 8 CFD simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per test (85%), with each test case costing only $0.22 on average.","The 8 CFD simulation tasks include compressible and incompressible flows, 2D and 3D flows, heat transfer, and combustion, demonstrating the ability to automate CFD simulations using only natural language input and iteratively correct errors to achieve the desired simulation at a low cost.","An ablation study was conducted to verify the necessity of each component in the multi-agent system and the RAG technology.","A sensitivity study on the randomness of LLM showed that LLM with low randomness can obtain more stable and accurate results.","Additionally, MetaOpenFOAM own the ability to identify and modify key parameters in user requirements and excels in correcting bugs when failures occur, with or without human participation, which demonstrates the generalization of MetaOpenFOAM."],"url":"http://arxiv.org/abs/2407.21320v1"}
{"created":"2024-07-31 03:53:14","title":"Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances","abstract":"This paper introduces a novel approach to emotion detection in speech using Large Language Models (LLMs). We address the limitation of LLMs in processing audio inputs by translating speech characteristics into natural language descriptions. Our method integrates these descriptions into text prompts, enabling LLMs to perform multimodal emotion analysis without architectural modifications. We evaluate our approach on two datasets: IEMOCAP and MELD, demonstrating significant improvements in emotion recognition accuracy, particularly for high-quality audio data. Our experiments show that incorporating speech descriptions yields a 2 percentage point increase in weighted F1 score on IEMOCAP (from 70.111\\% to 72.596\\%). We also compare various LLM architectures and explore the effectiveness of different feature representations. Our findings highlight the potential of this approach in enhancing emotion detection capabilities of LLMs and underscore the importance of audio quality in speech-based emotion recognition tasks. We'll release the source code on Github.","sentences":["This paper introduces a novel approach to emotion detection in speech using Large Language Models (LLMs).","We address the limitation of LLMs in processing audio inputs by translating speech characteristics into natural language descriptions.","Our method integrates these descriptions into text prompts, enabling LLMs to perform multimodal emotion analysis without architectural modifications.","We evaluate our approach on two datasets: IEMOCAP and MELD, demonstrating significant improvements in emotion recognition accuracy, particularly for high-quality audio data.","Our experiments show that incorporating speech descriptions yields a 2 percentage point increase in weighted F1 score on IEMOCAP (from 70.111\\% to 72.596\\%).","We also compare various LLM architectures and explore the effectiveness of different feature representations.","Our findings highlight the potential of this approach in enhancing emotion detection capabilities of LLMs and underscore the importance of audio quality in speech-based emotion recognition tasks.","We'll release the source code on Github."],"url":"http://arxiv.org/abs/2407.21315v1"}
{"created":"2024-07-31 02:35:33","title":"SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving","abstract":"Many fields could benefit from the rapid development of the large language models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the typically fields facing new opportunities as the LLMs have supported more and more modalities. Here, by utilizing vision-language model (VLM), we proposed an e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided into four stages, which are perception, prediction, planning, and behavior. Each stage consists of several visual question answering (VQA) pairs and VQA pairs interconnect with each other constructing a graph called Graph VQA (GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our method could achieve e2e driving with language. In our method, vision transformers (ViT) models are employed to process nuScenes visual data, while VLM are utilized to interpret and reason about the information extracted from the visual inputs. In the perception stage, the system identifies and classifies objects from the driving environment. The prediction stage involves forecasting the potential movements of these objects. The planning stage utilizes the gathered information to develop a driving strategy, ensuring the safety and efficiency of the autonomous vehicle. Finally, the behavior stage translates the planned actions into executable commands for the vehicle. Our experiments demonstrate that SimpleLLM4AD achieves competitive performance in complex driving scenarios.","sentences":["Many fields could benefit from the rapid development of the large language models (LLMs).","The end-to-end autonomous driving (e2eAD) is one of the typically fields facing new opportunities as the LLMs have supported more and more modalities.","Here, by utilizing vision-language model (VLM), we proposed an e2eAD method called SimpleLLM4AD.","In our method, the e2eAD task are divided into four stages, which are perception, prediction, planning, and behavior.","Each stage consists of several visual question answering (VQA) pairs and VQA pairs interconnect with each other constructing a graph called Graph VQA (GVQA).","By reasoning each VQA pair in the GVQA through VLM stage by stage, our method could achieve e2e driving with language.","In our method, vision transformers (ViT) models are employed to process nuScenes visual data, while VLM are utilized to interpret and reason about the information extracted from the visual inputs.","In the perception stage, the system identifies and classifies objects from the driving environment.","The prediction stage involves forecasting the potential movements of these objects.","The planning stage utilizes the gathered information to develop a driving strategy, ensuring the safety and efficiency of the autonomous vehicle.","Finally, the behavior stage translates the planned actions into executable commands for the vehicle.","Our experiments demonstrate that SimpleLLM4AD achieves competitive performance in complex driving scenarios."],"url":"http://arxiv.org/abs/2407.21293v1"}
{"created":"2024-07-31 00:56:09","title":"Model Attribution in Machine-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning","abstract":"Model attribution for machine-generated disinformation poses a significant challenge in understanding its origins and mitigating its spread. This task is especially challenging because modern large language models (LLMs) produce disinformation with human-like quality. Additionally, the diversity in prompting methods used to generate disinformation complicates accurate source attribution. These methods introduce domain-specific features that can mask the fundamental characteristics of the models. In this paper, we introduce the concept of model attribution as a domain generalization problem, where each prompting method represents a unique domain. We argue that an effective attribution model must be invariant to these domain-specific features. It should also be proficient in identifying the originating models across all scenarios, reflecting real-world detection challenges. To address this, we introduce a novel approach based on Supervised Contrastive Learning. This method is designed to enhance the model's robustness to variations in prompts and focuses on distinguishing between different source LLMs. We evaluate our model through rigorous experiments involving three common prompting methods: ``open-ended'', ``rewriting'', and ``paraphrasing'', and three advanced LLMs: ``llama 2'', ``chatgpt'', and ``vicuna''. Our results demonstrate the effectiveness of our approach in model attribution tasks, achieving state-of-the-art performance across diverse and unseen datasets.","sentences":["Model attribution for machine-generated disinformation poses a significant challenge in understanding its origins and mitigating its spread.","This task is especially challenging because modern large language models (LLMs) produce disinformation with human-like quality.","Additionally, the diversity in prompting methods used to generate disinformation complicates accurate source attribution.","These methods introduce domain-specific features that can mask the fundamental characteristics of the models.","In this paper, we introduce the concept of model attribution as a domain generalization problem, where each prompting method represents a unique domain.","We argue that an effective attribution model must be invariant to these domain-specific features.","It should also be proficient in identifying the originating models across all scenarios, reflecting real-world detection challenges.","To address this, we introduce a novel approach based on Supervised Contrastive Learning.","This method is designed to enhance the model's robustness to variations in prompts and focuses on distinguishing between different source LLMs.","We evaluate our model through rigorous experiments involving three common prompting methods: ``open-ended'', ``rewriting'', and ``paraphrasing'', and three advanced LLMs: ``llama 2'', ``chatgpt'', and ``vicuna''.","Our results demonstrate the effectiveness of our approach in model attribution tasks, achieving state-of-the-art performance across diverse and unseen datasets."],"url":"http://arxiv.org/abs/2407.21264v1"}
{"created":"2024-07-31 00:34:33","title":"Responsive ML inference in multi-tenanted environments using AQUA","abstract":"Here is the text without linebreaks: Modern model serving engines infer prompts on large language models in batches. While batch processing prompts leads to high inference throughput, it delays responding to requests that do not fit in a batch, potentially starving them. We propose that fair scheduling prompts for inference by time-sharing GPUs cycles, instead of batch processing them, is key to preventing prompt starvation and achieving responsive inference. However, time-shared prompt scheduling incurs the overhead of frequently paging dynamic context needed to infer a prompt back into GPU memory. Today, serving engines support paging inference context between GPU memory and the host DRAM. The overhead of transferring context from DRAM to GPU memory is high since it is lower-bounded by the limited PCIe bandwidth. We overcome this challenge by offloading inference context from a GPU to the memory of another GPU on the same server, connected via inter-GPU interconnects that support magnitudes higher bandwidth than PCIe. We achieve this by developing AQUA, a transparent and elastic GPU memory management framework for responsive LLM inference. We evaluate AQUA by hosting eight state-of-the-art large generative ML models of different modalities (e.g., text, audio, vision) on a server with 8 cutting-edge Nvidia A100 80G GPUs. Using representative inference workloads, we show that AQUA improves the responsiveness of LLM inference by 4X compared to the state-of-the-art and it improves LLM inference throughput over a single long prompt by 6X.","sentences":["Here is the text without linebreaks: Modern model serving engines infer prompts on large language models in batches.","While batch processing prompts leads to high inference throughput, it delays responding to requests that do not fit in a batch, potentially starving them.","We propose that fair scheduling prompts for inference by time-sharing GPUs cycles, instead of batch processing them, is key to preventing prompt starvation and achieving responsive inference.","However, time-shared prompt scheduling incurs the overhead of frequently paging dynamic context needed to infer a prompt back into GPU memory.","Today, serving engines support paging inference context between GPU memory and the host DRAM.","The overhead of transferring context from DRAM to GPU memory is high since it is lower-bounded by the limited PCIe bandwidth.","We overcome this challenge by offloading inference context from a GPU to the memory of another GPU on the same server, connected via inter-GPU interconnects that support magnitudes higher bandwidth than PCIe.","We achieve this by developing AQUA, a transparent and elastic GPU memory management framework for responsive LLM inference.","We evaluate AQUA by hosting eight state-of-the-art large generative ML models of different modalities (e.g., text, audio, vision) on a server with 8 cutting-edge Nvidia A100 80G GPUs.","Using representative inference workloads, we show that AQUA improves the responsiveness of LLM inference by 4X compared to the state-of-the-art and it improves LLM inference throughput over a single long prompt by 6X."],"url":"http://arxiv.org/abs/2407.21255v1"}
{"created":"2024-07-30 23:43:59","title":"Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens","abstract":"While large language models (LLMs) are extensively used, there are raising concerns regarding privacy, security, and copyright due to their opaque training data, which brings the problem of detecting pre-training data on the table. Current solutions to this problem leverage techniques explored in machine learning privacy such as Membership Inference Attacks (MIAs), which heavily depend on LLMs' capability of verbatim memorization. However, this reliance presents challenges, especially given the vast amount of training data and the restricted number of effective training epochs. In this paper, we propose an adaptive pre-training data detection method which alleviates this reliance and effectively amplify the identification. Our method adaptively locates \\textit{surprising tokens} of the input. A token is surprising to a LLM if the prediction on the token is \"certain but wrong\", which refers to low Shannon entropy of the probability distribution and low probability of the ground truth token at the same time. By using the prediction probability of surprising tokens to measure \\textit{surprising}, the detection method is achieved based on the simple hypothesis that seeing seen data is less surprising for the model compared with seeing unseen data. The method can be applied without any access to the the pre-training data corpus or additional training like reference models. Our approach exhibits a consistent enhancement compared to existing methods in diverse experiments conducted on various benchmarks and models, achieving a maximum improvement of 29.5\\%. We also introduce a new benchmark Dolma-Book developed upon a novel framework, which employs book data collected both before and after model training to provide further evaluation.","sentences":["While large language models (LLMs) are extensively used, there are raising concerns regarding privacy, security, and copyright due to their opaque training data, which brings the problem of detecting pre-training data on the table.","Current solutions to this problem leverage techniques explored in machine learning privacy such as Membership Inference Attacks (MIAs), which heavily depend on LLMs' capability of verbatim memorization.","However, this reliance presents challenges, especially given the vast amount of training data and the restricted number of effective training epochs.","In this paper, we propose an adaptive pre-training data detection method which alleviates this reliance and effectively amplify the identification.","Our method adaptively locates \\textit{surprising tokens} of the input.","A token is surprising to a LLM if the prediction on the token is \"certain but wrong\", which refers to low Shannon entropy of the probability distribution and low probability of the ground truth token at the same time.","By using the prediction probability of surprising tokens to measure \\textit{surprising}, the detection method is achieved based on the simple hypothesis that seeing seen data is less surprising for the model compared with seeing unseen data.","The method can be applied without any access to the the pre-training data corpus or additional training like reference models.","Our approach exhibits a consistent enhancement compared to existing methods in diverse experiments conducted on various benchmarks and models, achieving a maximum improvement of 29.5\\%.","We also introduce a new benchmark Dolma-Book developed upon a novel framework, which employs book data collected both before and after model training to provide further evaluation."],"url":"http://arxiv.org/abs/2407.21248v1"}
{"created":"2024-07-30 22:31:19","title":"Assessing Programming Task Difficulty for Efficient Evaluation of Large Language Models","abstract":"Large Language Models (LLMs) show promising potential in Software Engineering, especially for code-related tasks like code completion and code generation. LLMs' evaluation is generally centred around general metrics computed over benchmarks. While painting a macroscopic view of the benchmarks and of the LLMs' capacity, it is unclear how each programming task in these benchmarks assesses the capabilities of the LLMs. In particular, the difficulty level of the tasks in the benchmarks is not reflected in the score used to report the performance of the model. Yet, a model achieving a 90% score on a benchmark of predominantly easy tasks is likely less capable than a model achieving a 90% score on a benchmark containing predominantly difficult tasks. This paper devises a framework, HardEval, for assessing task difficulty for LLMs and crafting new tasks based on identified hard tasks. The framework uses a diverse array of prompts for a single task across multiple LLMs to obtain a difficulty score for each task of a benchmark. Using two code generation benchmarks, HumanEval+ and ClassEval, we show that HardEval can reliably identify the hard tasks within those benchmarks, highlighting that only 21% of HumanEval+ and 27% of ClassEval tasks are hard for LLMs. Through our analysis of task difficulty, we also characterize 6 practical hard task topics which we used to generate new hard tasks. Orthogonal to current benchmarking evaluation efforts, HardEval can assist researchers and practitioners in fostering better assessments of LLMs. The difficulty score can be used to identify hard tasks within existing benchmarks. This, in turn, can be leveraged to generate more hard tasks centred around specific topics either for evaluation or improvement of LLMs. HardEval generalistic approach can be applied to other domains such as code completion or Q/A.","sentences":["Large Language Models (LLMs) show promising potential in Software Engineering, especially for code-related tasks like code completion and code generation.","LLMs' evaluation is generally centred around general metrics computed over benchmarks.","While painting a macroscopic view of the benchmarks and of the LLMs' capacity, it is unclear how each programming task in these benchmarks assesses the capabilities of the LLMs.","In particular, the difficulty level of the tasks in the benchmarks is not reflected in the score used to report the performance of the model.","Yet, a model achieving a 90% score on a benchmark of predominantly easy tasks is likely less capable than a model achieving a 90% score on a benchmark containing predominantly difficult tasks.","This paper devises a framework, HardEval, for assessing task difficulty for LLMs and crafting new tasks based on identified hard tasks.","The framework uses a diverse array of prompts for a single task across multiple LLMs to obtain a difficulty score for each task of a benchmark.","Using two code generation benchmarks, HumanEval+ and ClassEval, we show that HardEval can reliably identify the hard tasks within those benchmarks, highlighting that only 21% of HumanEval+ and 27% of ClassEval tasks are hard for LLMs.","Through our analysis of task difficulty, we also characterize 6 practical hard task topics which we used to generate new hard tasks.","Orthogonal to current benchmarking evaluation efforts, HardEval can assist researchers and practitioners in fostering better assessments of LLMs.","The difficulty score can be used to identify hard tasks within existing benchmarks.","This, in turn, can be leveraged to generate more hard tasks centred around specific topics either for evaluation or improvement of LLMs.","HardEval generalistic approach can be applied to other domains such as code completion or Q/A."],"url":"http://arxiv.org/abs/2407.21227v1"}
{"created":"2024-07-30 20:24:44","title":"Decomposed Prompting to Answer Questions on a Course Discussion Board","abstract":"We propose and evaluate a question-answering system that uses decomposed prompting to classify and answer student questions on a course discussion board. Our system uses a large language model (LLM) to classify questions into one of four types: conceptual, homework, logistics, and not answerable. This enables us to employ a different strategy for answering questions that fall under different types. Using a variant of GPT-3, we achieve $81\\%$ classification accuracy. We discuss our system's performance on answering conceptual questions from a machine learning course and various failure modes.","sentences":["We propose and evaluate a question-answering system that uses decomposed prompting to classify and answer student questions on a course discussion board.","Our system uses a large language model (LLM) to classify questions into one of four types: conceptual, homework, logistics, and not answerable.","This enables us to employ a different strategy for answering questions that fall under different types.","Using a variant of GPT-3, we achieve $81\\%$ classification accuracy.","We discuss our system's performance on answering conceptual questions from a machine learning course and various failure modes."],"url":"http://arxiv.org/abs/2407.21170v1"}
{"created":"2024-07-30 18:19:38","title":"Palu: Compressing KV-Cache with Low-Rank Projection","abstract":"KV-Cache compression methods generally sample a KV-Cache of effectual tokens or quantize it into lower bits. However, these methods cannot exploit the redundancy of the hidden dimension of KV tensors. This paper investigates a unique hidden dimension approach called Palu, a novel KV-Cache compression framework that utilizes low-rank projection. Palu decomposes the linear layers into low-rank matrices, caches the smaller intermediate states, and reconstructs the full keys and values on the fly. To improve accuracy, compression rate, and efficiency, Palu further encompasses (1) a medium-grained low-rank decomposition scheme, (2) an efficient rank search algorithm, (3) a low-rank-aware quantization algorithm, and (4) matrix fusion with optimized GPU kernels. Our extensive experiments with popular LLMs show that Palu can compress KV-Cache by more than 91.25% while maintaining a significantly better accuracy (up to 1.19 lower perplexity) than state-of-the-art KV-Cache quantization methods at a similar or even higher memory usage. When compressing KV-Cache for 50%, Palu delivers up to 1.61x end-to-end speedup for the attention module. Our code is publicly available at https://github.com/shadowpa0327/Palu.","sentences":["KV-Cache compression methods generally sample a KV-Cache of effectual tokens or quantize it into lower bits.","However, these methods cannot exploit the redundancy of the hidden dimension of KV tensors.","This paper investigates a unique hidden dimension approach called Palu, a novel KV-Cache compression framework that utilizes low-rank projection.","Palu decomposes the linear layers into low-rank matrices, caches the smaller intermediate states, and reconstructs the full keys and values on the fly.","To improve accuracy, compression rate, and efficiency, Palu further encompasses (1) a medium-grained low-rank decomposition scheme, (2) an efficient rank search algorithm, (3) a low-rank-aware quantization algorithm, and (4) matrix fusion with optimized GPU kernels.","Our extensive experiments with popular LLMs show that Palu can compress KV-Cache by more than 91.25% while maintaining a significantly better accuracy (up to 1.19 lower perplexity) than state-of-the-art KV-Cache quantization methods at a similar or even higher memory usage.","When compressing KV-Cache for 50%, Palu delivers up to 1.61x end-to-end speedup for the attention module.","Our code is publicly available at https://github.com/shadowpa0327/Palu."],"url":"http://arxiv.org/abs/2407.21118v1"}
{"created":"2024-07-30 17:11:15","title":"Entropy, Thermodynamics and the Geometrization of the Language Model","abstract":"In this paper, we discuss how pure mathematics and theoretical physics can be applied to the study of language models. Using set theory and analysis, we formulate mathematically rigorous definitions of language models, and introduce the concept of the moduli space of distributions for a language model. We formulate a generalized distributional hypothesis using functional analysis and topology. We define the entropy function associated with a language model and show how it allows us to understand many interesting phenomena in languages. We argue that the zero points of the entropy function and the points where the entropy is close to 0 are the key obstacles for an LLM to approximate an intelligent language model, which explains why good LLMs need billions of parameters. Using the entropy function, we formulate a conjecture about AGI.   Then, we show how thermodynamics gives us an immediate interpretation to language models. In particular we will define the concepts of partition function, internal energy and free energy for a language model, which offer insights into how language models work. Based on these results, we introduce a general concept of the geometrization of language models and define what is called the Boltzmann manifold. While the current LLMs are the special cases of the Boltzmann manifold.","sentences":["In this paper, we discuss how pure mathematics and theoretical physics can be applied to the study of language models.","Using set theory and analysis, we formulate mathematically rigorous definitions of language models, and introduce the concept of the moduli space of distributions for a language model.","We formulate a generalized distributional hypothesis using functional analysis and topology.","We define the entropy function associated with a language model and show how it allows us to understand many interesting phenomena in languages.","We argue that the zero points of the entropy function and the points where the entropy is close to 0 are the key obstacles for an LLM to approximate an intelligent language model, which explains why good LLMs need billions of parameters.","Using the entropy function, we formulate a conjecture about AGI.   ","Then, we show how thermodynamics gives us an immediate interpretation to language models.","In particular we will define the concepts of partition function, internal energy and free energy for a language model, which offer insights into how language models work.","Based on these results, we introduce a general concept of the geometrization of language models and define what is called the Boltzmann manifold.","While the current LLMs are the special cases of the Boltzmann manifold."],"url":"http://arxiv.org/abs/2407.21092v1"}
{"created":"2024-07-30 07:58:28","title":"Accelerating Large Language Model Inference with Self-Supervised Early Exits","abstract":"This paper presents a novel technique for accelerating inference in large, pre-trained language models (LLMs) by introducing early exits during inference. The computational demands of these models, used across a wide range of applications, can be substantial. By capitalizing on the inherent variability in token complexity, our approach enables selective acceleration of the inference process. Specifically, we propose the integration of early exit ''heads'' atop existing transformer layers, which facilitate conditional terminations based on a confidence metric. These heads are trained in a self-supervised manner using the model's own predictions as training data, thereby eliminating the need for additional annotated data. The confidence metric, established using a calibration set, ensures a desired level of accuracy while enabling early termination when confidence exceeds a predetermined threshold. Notably, our method preserves the original accuracy and reduces computational time on certain tasks, leveraging the existing knowledge of pre-trained LLMs without requiring extensive retraining. This lightweight, modular modification has the potential to greatly enhance the practical usability of LLMs, particularly in applications like real-time language processing in resource-constrained environments.","sentences":["This paper presents a novel technique for accelerating inference in large, pre-trained language models (LLMs) by introducing early exits during inference.","The computational demands of these models, used across a wide range of applications, can be substantial.","By capitalizing on the inherent variability in token complexity, our approach enables selective acceleration of the inference process.","Specifically, we propose the integration of early exit ''heads'' atop existing transformer layers, which facilitate conditional terminations based on a confidence metric.","These heads are trained in a self-supervised manner using the model's own predictions as training data, thereby eliminating the need for additional annotated data.","The confidence metric, established using a calibration set, ensures a desired level of accuracy while enabling early termination when confidence exceeds a predetermined threshold.","Notably, our method preserves the original accuracy and reduces computational time on certain tasks, leveraging the existing knowledge of pre-trained LLMs without requiring extensive retraining.","This lightweight, modular modification has the potential to greatly enhance the practical usability of LLMs, particularly in applications like real-time language processing in resource-constrained environments."],"url":"http://arxiv.org/abs/2407.21082v1"}
{"created":"2024-07-29 20:42:59","title":"Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models","abstract":"Large Language Models (LLMs) rely on instruction samples for alignment, but creating these datasets poses challenges, particularly in expert-dependent tasks like coding, which can be cost-prohibitive. One approach to mitigate these challenges is synthesizing data using another LLM. In this paper, we introduce a scalable method for generating synthetic instructions to enhance the code generation capability of LLMs. The proposed algorithm, Genetic-Instruct, mimics evolutionary processes, utilizing self-instruction to create numerous synthetic samples from a limited number of seeds. Genetic-Instruct is designed for efficient scaling of the generation process. Fine-tuning multiple coding LLMs with the synthetic samples demonstrates a significant improvement in their code generation accuracy compared to the baselines.","sentences":["Large Language Models (LLMs) rely on instruction samples for alignment, but creating these datasets poses challenges, particularly in expert-dependent tasks like coding, which can be cost-prohibitive.","One approach to mitigate these challenges is synthesizing data using another LLM.","In this paper, we introduce a scalable method for generating synthetic instructions to enhance the code generation capability of LLMs.","The proposed algorithm, Genetic-Instruct, mimics evolutionary processes, utilizing self-instruction to create numerous synthetic samples from a limited number of seeds.","Genetic-Instruct is designed for efficient scaling of the generation process.","Fine-tuning multiple coding LLMs with the synthetic samples demonstrates a significant improvement in their code generation accuracy compared to the baselines."],"url":"http://arxiv.org/abs/2407.21077v1"}
