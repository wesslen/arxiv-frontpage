{"created":"2024-04-17 17:48:18","title":"A Deep Dive into Large Language Models for Automated Bug Localization and Repair","abstract":"Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks, including automated program repair (APR). In this study, we take a deep dive into automated bug fixing utilizing LLMs. In contrast to many deep learning-based APR methods that assume known bug locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug fixing. This methodological separation of bug localization and fixing using different LLMs enables effective integration of diverse contextual information and improved incorporation of inductive biases. We introduce Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework that integrates a bug localization model, an adjustment unit, and a bug-fixing model. Toggle takes a buggy function as input and generates a complete corrected function. We investigate various styles of prompting to the bug fixing model to identify the most effective prompts that better utilize the inductive bias and significantly outperform others. Toggle achieves the new state-of-the-art (SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable performance on several other widely-used APR datasets, including Defects4J.","sentences":["Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks, including automated program repair (APR).","In this study, we take a deep dive into automated bug fixing utilizing LLMs.","In contrast to many deep learning-based APR methods that assume known bug locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug fixing.","This methodological separation of bug localization and fixing using different LLMs enables effective integration of diverse contextual information and improved incorporation of inductive biases.","We introduce Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework that integrates a bug localization model, an adjustment unit, and a bug-fixing model.","Toggle takes a buggy function as input and generates a complete corrected function.","We investigate various styles of prompting to the bug fixing model to identify the most effective prompts that better utilize the inductive bias and significantly outperform others.","Toggle achieves the new state-of-the-art (SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable performance on several other widely-used APR datasets, including Defects4J."],"url":"http://arxiv.org/abs/2404.11595v1"}
{"created":"2024-04-17 17:08:05","title":"MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation","abstract":"We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Project page: https://snap-research.github.io/mixture-of-attention","sentences":["We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA).","Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch.","MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch.","A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation.","Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model.","Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable.","Project page: https://snap-research.github.io/mixture-of-attention"],"url":"http://arxiv.org/abs/2404.11565v1"}
{"created":"2024-04-17 16:53:16","title":"Quantifying Multilingual Performance of Large Language Models Across Languages","abstract":"The training process of Large Language Models (LLMs) requires extensive text corpus. However, these data are often unevenly distributed in different languages. As a result, LLMs perform well on common languages, such as English, German, and French, but perform poorly on low-resource languages. However, currently there is no work to quantitatively measure the performance of LLMs in low-resource languages. To fill this gap, we proposed the Language Ranker that aims to benchmark and rank different languages according to the performance of LLMs on those languages. We employ the LLM's performance on the English corpus as a baseline to compare the performances of different languages and English. We have the following three findings: 1. The performance rankings of different LLMs in all languages are roughly the same. 2. LLMs with different sizes have the same partial order of performance. 3. There is a strong correlation between LlaMa2's performance in different languages and the proportion of the pre-training corpus. These findings illustrate that the Language Ranker can be used as an indicator to measure the language performance of LLMs.","sentences":["The training process of Large Language Models (LLMs) requires extensive text corpus.","However, these data are often unevenly distributed in different languages.","As a result, LLMs perform well on common languages, such as English, German, and French, but perform poorly on low-resource languages.","However, currently there is no work to quantitatively measure the performance of LLMs in low-resource languages.","To fill this gap, we proposed the Language Ranker that aims to benchmark and rank different languages according to the performance of LLMs on those languages.","We employ the LLM's performance on the English corpus as a baseline to compare the performances of different languages and English.","We have the following three findings: 1.","The performance rankings of different LLMs in all languages are roughly the same.","2. LLMs with different sizes have the same partial order of performance.","3.","There is a strong correlation between LlaMa2's performance in different languages and the proportion of the pre-training corpus.","These findings illustrate that the Language Ranker can be used as an indicator to measure the language performance of LLMs."],"url":"http://arxiv.org/abs/2404.11553v1"}
{"created":"2024-04-17 16:24:07","title":"Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization","abstract":"Fusing knowledge from multiple Large Language Models (LLMs) can combine their diverse strengths to achieve improved performance on a given task. However, current fusion approaches either rely on learning-based fusers that do not generalize to new LLMs, or do not take into account how well each LLM understands the input. In this work, we study LLM fusion at test-time, which enables leveraging knowledge from arbitrary user-specified LLMs during inference. We introduce Pack of LLMs (PackLLM), an effective method for test-time fusion that leverages each LLM's expertise, given an input prompt. PackLLM performs model fusion by solving an optimization problem for determining each LLM's importance, so that perplexity over the input prompt is minimized. First, our simple PackLLM-sim variant validates that perplexity is a good indicator for measuring each LLM's expertise. Second, our PackLLM-opt variant approximately solves the perplexity minimization problem via a greedy algorithm. The derived importance weights are used to combine the LLMs during inference. We conduct experiments with over 100 total LLMs on a diverse set of tasks. Experimental results show that (i) perplexity is a reliable measure for LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89% accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance over learning-based fusion approaches by 3.92-11.94% accuracy points.","sentences":["Fusing knowledge from multiple Large Language Models (LLMs) can combine their diverse strengths to achieve improved performance on a given task.","However, current fusion approaches either rely on learning-based fusers that do not generalize to new LLMs, or do not take into account how well each LLM understands the input.","In this work, we study LLM fusion at test-time, which enables leveraging knowledge from arbitrary user-specified LLMs during inference.","We introduce Pack of LLMs (PackLLM), an effective method for test-time fusion that leverages each LLM's expertise, given an input prompt.","PackLLM performs model fusion by solving an optimization problem for determining each LLM's importance, so that perplexity over the input prompt is minimized.","First, our simple PackLLM-sim variant validates that perplexity is a good indicator for measuring each LLM's expertise.","Second, our PackLLM-opt variant approximately solves the perplexity minimization problem via a greedy algorithm.","The derived importance weights are used to combine the LLMs during inference.","We conduct experiments with over 100 total LLMs on a diverse set of tasks.","Experimental results show that (i) perplexity is a reliable measure for LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89% accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance over learning-based fusion approaches by 3.92-11.94% accuracy points."],"url":"http://arxiv.org/abs/2404.11531v1"}
{"created":"2024-04-17 16:07:53","title":"Embedding Privacy in Computational Social Science and Artificial Intelligence Research","abstract":"Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.","sentences":["Privacy is a human right.","It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them.","Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights.","The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society.","We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start.","This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face.","It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results."],"url":"http://arxiv.org/abs/2404.11515v1"}
{"created":"2024-04-17 15:57:50","title":"Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models","abstract":"In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications. For the wide application of LLMs, the inference efficiency is an essential concern, which has been widely studied in existing work, and numerous optimization algorithms and code libraries have been proposed to improve it. Nonetheless, users still find it challenging to compare the effectiveness of all the above methods and understand the underlying mechanisms. In this work, we perform a detailed coarse-to-fine analysis of the inference performance of various code libraries. To evaluate the overall effectiveness, we examine four usage scenarios within two practical applications. We further provide both theoretical and empirical fine-grained analyses of each module in the Transformer architecture. Our experiments yield comprehensive results that are invaluable for researchers to evaluate code libraries and improve inference strategies.","sentences":["In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications.","For the wide application of LLMs, the inference efficiency is an essential concern, which has been widely studied in existing work, and numerous optimization algorithms and code libraries have been proposed to improve it.","Nonetheless, users still find it challenging to compare the effectiveness of all the above methods and understand the underlying mechanisms.","In this work, we perform a detailed coarse-to-fine analysis of the inference performance of various code libraries.","To evaluate the overall effectiveness, we examine four usage scenarios within two practical applications.","We further provide both theoretical and empirical fine-grained analyses of each module in the Transformer architecture.","Our experiments yield comprehensive results that are invaluable for researchers to evaluate code libraries and improve inference strategies."],"url":"http://arxiv.org/abs/2404.11502v1"}
{"created":"2024-04-17 15:40:45","title":"AgentKit: Flow Engineering with Graphs, not Coding","abstract":"We propose an intuitive LLM prompting framework (AgentKit) for multifunctional agents. AgentKit offers a unified framework for explicitly constructing a complex \"thought process\" from simple natural language prompts. The basic building block in AgentKit is a node, containing a natural language prompt for a specific subtask. The user then puts together chains of nodes, like stacking LEGO pieces. The chains of nodes can be designed to explicitly enforce a naturally structured \"thought process\". For example, for the task of writing a paper, one may start with the thought process of 1) identify a core message, 2) identify prior research gaps, etc. The nodes in AgentKit can be designed and combined in different ways to implement multiple advanced capabilities including on-the-fly hierarchical planning, reflection, and learning from interactions. In addition, due to the modular nature and the intuitive design to simulate explicit human thought process, a basic agent could be implemented as simple as a list of prompts for the subtasks and therefore could be designed and tuned by someone without any programming experience. Quantitatively, we show that agents designed through AgentKit achieve SOTA performance on WebShop and Crafter. These advances underscore AgentKit's potential in making LLM agents effective and accessible for a wider range of applications. https://github.com/holmeswww/AgentKit","sentences":["We propose an intuitive LLM prompting framework (AgentKit) for multifunctional agents.","AgentKit offers a unified framework for explicitly constructing a complex \"thought process\" from simple natural language prompts.","The basic building block in AgentKit is a node, containing a natural language prompt for a specific subtask.","The user then puts together chains of nodes, like stacking LEGO pieces.","The chains of nodes can be designed to explicitly enforce a naturally structured \"thought process\".","For example, for the task of writing a paper, one may start with the thought process of 1) identify a core message, 2) identify prior research gaps, etc.","The nodes in AgentKit can be designed and combined in different ways to implement multiple advanced capabilities including on-the-fly hierarchical planning, reflection, and learning from interactions.","In addition, due to the modular nature and the intuitive design to simulate explicit human thought process, a basic agent could be implemented as simple as a list of prompts for the subtasks and therefore could be designed and tuned by someone without any programming experience.","Quantitatively, we show that agents designed through AgentKit achieve SOTA performance on WebShop and Crafter.","These advances underscore AgentKit's potential in making LLM agents effective and accessible for a wider range of applications.","https://github.com/holmeswww/AgentKit"],"url":"http://arxiv.org/abs/2404.11483v1"}
{"created":"2024-04-17 15:05:03","title":"Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models","abstract":"With the rapid advancement of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift. This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem. In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs. We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment. Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation. In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues. Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era. We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.","sentences":["With the rapid advancement of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift.","This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem.","In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs.","We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment.","Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation.","In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues.","Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era.","We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey."],"url":"http://arxiv.org/abs/2404.11457v1"}
{"created":"2024-04-17 14:55:27","title":"AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts","abstract":"Cognitive Behavioral Therapy (CBT) is an effective technique for addressing the irrational thoughts stemming from mental illnesses, but it necessitates precise identification of cognitive pathways to be successfully implemented in patient care. In current society, individuals frequently express negative emotions on social media on specific topics, often exhibiting cognitive distortions, including suicidal behaviors in extreme cases. Yet, there is a notable absence of methodologies for analyzing cognitive pathways that could aid psychotherapists in conducting effective interventions online. In this study, we gathered data from social media and established the task of extracting cognitive pathways, annotating the data based on a cognitive theoretical framework. We initially categorized the task of extracting cognitive pathways as a hierarchical text classification with four main categories and nineteen subcategories. Following this, we structured a text summarization task to help psychotherapists quickly grasp the essential information. Our experiments evaluate the performance of deep learning and large language models (LLMs) on these tasks. The results demonstrate that our deep learning method achieved a micro-F1 score of 62.34% in the hierarchical text classification task. Meanwhile, in the text summarization task, GPT-4 attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the experimental deep learning model's performance. However, it may suffer from an issue of hallucination. We have made all models and codes publicly available to support further research in this field.","sentences":["Cognitive Behavioral Therapy (CBT) is an effective technique for addressing the irrational thoughts stemming from mental illnesses, but it necessitates precise identification of cognitive pathways to be successfully implemented in patient care.","In current society, individuals frequently express negative emotions on social media on specific topics, often exhibiting cognitive distortions, including suicidal behaviors in extreme cases.","Yet, there is a notable absence of methodologies for analyzing cognitive pathways that could aid psychotherapists in conducting effective interventions online.","In this study, we gathered data from social media and established the task of extracting cognitive pathways, annotating the data based on a cognitive theoretical framework.","We initially categorized the task of extracting cognitive pathways as a hierarchical text classification with four main categories and nineteen subcategories.","Following this, we structured a text summarization task to help psychotherapists quickly grasp the essential information.","Our experiments evaluate the performance of deep learning and large language models (LLMs) on these tasks.","The results demonstrate that our deep learning method achieved a micro-F1 score of 62.34% in the hierarchical text classification task.","Meanwhile, in the text summarization task, GPT-4 attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the experimental deep learning model's performance.","However, it may suffer from an issue of hallucination.","We have made all models and codes publicly available to support further research in this field."],"url":"http://arxiv.org/abs/2404.11449v1"}
{"created":"2024-04-17 14:54:58","title":"Open-Ended Wargames with Large Language Models","abstract":"Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames. We introduce \"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.","sentences":["Wargames are a powerful tool for understanding and rehearsing real-world decision making.","Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes.","There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses.","Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames.","We introduce \"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative wargames.","With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof.","We describe its software architecture conceptually and release an open-source implementation alongside this publication.","As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis.","We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem."],"url":"http://arxiv.org/abs/2404.11446v1"}
{"created":"2024-04-17 14:10:27","title":"DUPE: Detection Undermining via Prompt Engineering for Deepfake Text","abstract":"As large language models (LLMs) become increasingly commonplace, concern about distinguishing between human and AI text increases as well. The growing power of these models is of particular concern to teachers, who may worry that students will use LLMs to write school assignments. Facing a technology with which they are unfamiliar, teachers may turn to publicly-available AI text detectors. Yet the accuracy of many of these detectors has not been thoroughly verified, posing potential harm to students who are falsely accused of academic dishonesty. In this paper, we evaluate three different AI text detectors-Kirchenbauer et al. watermarks, ZeroGPT, and GPTZero-against human and AI-generated essays. We find that watermarking results in a high false positive rate, and that ZeroGPT has both high false positive and false negative rates. Further, we are able to significantly increase the false negative rate of all detectors by using ChatGPT 3.5 to paraphrase the original AI-generated texts, thereby effectively bypassing the detectors.","sentences":["As large language models (LLMs) become increasingly commonplace, concern about distinguishing between human and AI text increases as well.","The growing power of these models is of particular concern to teachers, who may worry that students will use LLMs to write school assignments.","Facing a technology with which they are unfamiliar, teachers may turn to publicly-available AI text detectors.","Yet the accuracy of many of these detectors has not been thoroughly verified, posing potential harm to students who are falsely accused of academic dishonesty.","In this paper, we evaluate three different AI text detectors-Kirchenbauer et al. watermarks, ZeroGPT, and GPTZero-against human and AI-generated essays.","We find that watermarking results in a high false positive rate, and that ZeroGPT has both high false positive and false negative rates.","Further, we are able to significantly increase the false negative rate of all detectors by using ChatGPT 3.5 to paraphrase the original AI-generated texts, thereby effectively bypassing the detectors."],"url":"http://arxiv.org/abs/2404.11408v1"}
{"created":"2024-04-17 13:33:11","title":"From Image to UML: First Results of Image Based UML Diagram Generation Using LLMs","abstract":"In software engineering processes, systems are first specified using a modeling language such as UML. These initial designs are often collaboratively created, many times in meetings where different domain experts use whiteboards, paper or other types of quick supports to create drawings and blueprints that then will need to be formalized. These proper, machine-readable, models are key to ensure models can be part of automated processes (e.g. input of a low-code generation pipeline, a model-based testing system, ...). But going form hand-drawn diagrams to actual models is a time-consuming process that sometimes ends up with such drawings just added as informal images to the software documentation, reducing their value a lot. To avoid this tedious task, we explore the usage of Large Language Models (LLM) to generate the formal representation of (UML) models from a given drawing. More specifically, we have evaluated the capabilities of different LLMs to convert images of UML class diagrams into the actual models represented in the images. While the results are good enough to use such an approach as part of a model-driven engineering pipeline we also highlight some of their current limitations and the need to keep the human in the loop to overcome those limitations.","sentences":["In software engineering processes, systems are first specified using a modeling language such as UML.","These initial designs are often collaboratively created, many times in meetings where different domain experts use whiteboards, paper or other types of quick supports to create drawings and blueprints that then will need to be formalized.","These proper, machine-readable, models are key to ensure models can be part of automated processes (e.g. input of a low-code generation pipeline, a model-based testing system, ...).","But going form hand-drawn diagrams to actual models is a time-consuming process that sometimes ends up with such drawings just added as informal images to the software documentation, reducing their value a lot.","To avoid this tedious task, we explore the usage of Large Language Models (LLM) to generate the formal representation of (UML) models from a given drawing.","More specifically, we have evaluated the capabilities of different LLMs to convert images of UML class diagrams into the actual models represented in the images.","While the results are good enough to use such an approach as part of a model-driven engineering pipeline we also highlight some of their current limitations and the need to keep the human in the loop to overcome those limitations."],"url":"http://arxiv.org/abs/2404.11376v1"}
{"created":"2024-04-17 13:03:07","title":"Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System","abstract":"Collaborative filtering recommender systems (CF-RecSys) have shown successive results in enhancing the user experience on social media and e-commerce platforms. However, as CF-RecSys struggles under cold scenarios with sparse user-item interactions, recent strategies have focused on leveraging modality information of user/items (e.g., text or images) based on pre-trained modality encoders and Large Language Models (LLMs). Despite their effectiveness under cold scenarios, we observe that they underperform simple traditional collaborative filtering models under warm scenarios due to the lack of collaborative knowledge. In this work, we propose an efficient All-round LLM-based Recommender system, called A-LLMRec, that excels not only in the cold scenario but also in the warm scenario. Our main idea is to enable an LLM to directly leverage the collaborative knowledge contained in a pre-trained state-of-the-art CF-RecSys so that the emergent ability of the LLM as well as the high-quality user/item embeddings that are already trained by the state-of-the-art CF-RecSys can be jointly exploited. This approach yields two advantages: (1) model-agnostic, allowing for integration with various existing CF-RecSys, and (2) efficiency, eliminating the extensive fine-tuning typically required for LLM-based recommenders. Our extensive experiments on various real-world datasets demonstrate the superiority of A-LLMRec in various scenarios, including cold/warm, few-shot, cold user, and cross-domain scenarios. Beyond the recommendation task, we also show the potential of A-LLMRec in generating natural language outputs based on the understanding of the collaborative knowledge by performing a favorite genre prediction task. Our code is available at https://github.com/ghdtjr/A-LLMRec .","sentences":["Collaborative filtering recommender systems (CF-RecSys) have shown successive results in enhancing the user experience on social media and e-commerce platforms.","However, as CF-RecSys struggles under cold scenarios with sparse user-item interactions, recent strategies have focused on leveraging modality information of user/items (e.g., text or images) based on pre-trained modality encoders and Large Language Models (LLMs).","Despite their effectiveness under cold scenarios, we observe that they underperform simple traditional collaborative filtering models under warm scenarios due to the lack of collaborative knowledge.","In this work, we propose an efficient All-round LLM-based Recommender system, called A-LLMRec, that excels not only in the cold scenario but also in the warm scenario.","Our main idea is to enable an LLM to directly leverage the collaborative knowledge contained in a pre-trained state-of-the-art CF-RecSys so that the emergent ability of the LLM as well as the high-quality user/item embeddings that are already trained by the state-of-the-art CF-RecSys can be jointly exploited.","This approach yields two advantages: (1) model-agnostic, allowing for integration with various existing CF-RecSys, and (2) efficiency, eliminating the extensive fine-tuning typically required for LLM-based recommenders.","Our extensive experiments on various real-world datasets demonstrate the superiority of A-LLMRec in various scenarios, including cold/warm, few-shot, cold user, and cross-domain scenarios.","Beyond the recommendation task, we also show the potential of A-LLMRec in generating natural language outputs based on the understanding of the collaborative knowledge by performing a favorite genre prediction task.","Our code is available at https://github.com/ghdtjr/A-LLMRec ."],"url":"http://arxiv.org/abs/2404.11343v1"}
{"created":"2024-04-17 12:58:51","title":"LLMs for Cyber Security: New Opportunities","abstract":"Large language models (LLMs) are a class of powerful and versatile models that are beneficial to many industries. With the emergence of LLMs, we take a fresh look at cyber security, specifically exploring and summarizing the potential of LLMs in addressing challenging problems in the security and safety domains.","sentences":["Large language models (LLMs) are a class of powerful and versatile models that are beneficial to many industries.","With the emergence of LLMs, we take a fresh look at cyber security, specifically exploring and summarizing the potential of LLMs in addressing challenging problems in the security and safety domains."],"url":"http://arxiv.org/abs/2404.11338v1"}
{"created":"2024-04-17 11:52:47","title":"A Preference-driven Paradigm for Enhanced Translation with Large Language Models","abstract":"Recent research has shown that large language models (LLMs) can achieve remarkable translation performance through supervised fine-tuning (SFT) using only a small amount of parallel data. However, SFT simply instructs the model to imitate the reference translations at the token level, making it vulnerable to the noise present in the references. Hence, the assistance from SFT often reaches a plateau once the LLMs have achieved a certain level of translation capability, and further increasing the size of parallel data does not provide additional benefits. To overcome this plateau associated with imitation-based SFT, we propose a preference-based approach built upon the Plackett-Luce model. The objective is to steer LLMs towards a more nuanced understanding of translation preferences from a holistic view, while also being more resilient in the absence of gold translations. We further build a dataset named MAPLE to verify the effectiveness of our approach, which includes multiple translations of varying quality for each source sentence. Extensive experiments demonstrate the superiority of our approach in \"breaking the plateau\" across diverse LLMs and test settings. Our in-depth analysis underscores the pivotal role of diverse translations and accurate preference scores in the success of our approach.","sentences":["Recent research has shown that large language models (LLMs) can achieve remarkable translation performance through supervised fine-tuning (SFT) using only a small amount of parallel data.","However, SFT simply instructs the model to imitate the reference translations at the token level, making it vulnerable to the noise present in the references.","Hence, the assistance from SFT often reaches a plateau once the LLMs have achieved a certain level of translation capability, and further increasing the size of parallel data does not provide additional benefits.","To overcome this plateau associated with imitation-based SFT, we propose a preference-based approach built upon the Plackett-Luce model.","The objective is to steer LLMs towards a more nuanced understanding of translation preferences from a holistic view, while also being more resilient in the absence of gold translations.","We further build a dataset named MAPLE to verify the effectiveness of our approach, which includes multiple translations of varying quality for each source sentence.","Extensive experiments demonstrate the superiority of our approach in \"breaking the plateau\" across diverse LLMs and test settings.","Our in-depth analysis underscores the pivotal role of diverse translations and accurate preference scores in the success of our approach."],"url":"http://arxiv.org/abs/2404.11288v1"}
{"created":"2024-04-17 11:33:21","title":"RD2Bench: Toward Data-Centric Automatic R&D","abstract":"The progress of humanity is driven by those successful discoveries accompanied by countless failed experiments. Researchers often seek the potential research directions by reading and then verifying them through experiments. The process imposes a significant burden on researchers. In the past decade, the data-driven black-box deep learning method demonstrates its effectiveness in a wide range of real-world scenarios, which exacerbates the experimental burden of researchers and thus renders the potential successful discoveries veiled. Therefore, automating such a research and development (R&D) process is an urgent need. In this paper, we serve as the first effort to formalize the goal by proposing a Real-world Data-centric automatic R&D Benchmark, namely RD2Bench. RD2Bench benchmarks all the operations in data-centric automatic R&D (D-CARD) as a whole to navigate future work toward our goal directly. We focuses on evaluating the interaction and synergistic effects of various model capabilities and aiding to select the well-performed trustworthy models. Although RD2Bench is very challenging to the state-of-the-art (SOTA) large language model (LLM) named GPT-4, indicating ample research opportunities and more research efforts, LLMs possess promising potential to bring more significant development to D-CARD: They are able to implement some simple methods without adopting any additional techniques. We appeal to future work to take developing techniques for tackling automatic R&D into consideration, thus bringing the opportunities of the potential revolutionary upgrade to human productivity.","sentences":["The progress of humanity is driven by those successful discoveries accompanied by countless failed experiments.","Researchers often seek the potential research directions by reading and then verifying them through experiments.","The process imposes a significant burden on researchers.","In the past decade, the data-driven black-box deep learning method demonstrates its effectiveness in a wide range of real-world scenarios, which exacerbates the experimental burden of researchers and thus renders the potential successful discoveries veiled.","Therefore, automating such a research and development (R&D) process is an urgent need.","In this paper, we serve as the first effort to formalize the goal by proposing a Real-world Data-centric automatic R&D Benchmark, namely RD2Bench.","RD2Bench benchmarks all the operations in data-centric automatic R&D (D-CARD) as a whole to navigate future work toward our goal directly.","We focuses on evaluating the interaction and synergistic effects of various model capabilities and aiding to select the well-performed trustworthy models.","Although RD2Bench is very challenging to the state-of-the-art (SOTA) large language model (LLM) named GPT-4, indicating ample research opportunities and more research efforts, LLMs possess promising potential to bring more significant development to D-CARD: They are able to implement some simple methods without adopting any additional techniques.","We appeal to future work to take developing techniques for tackling automatic R&D into consideration, thus bringing the opportunities of the potential revolutionary upgrade to human productivity."],"url":"http://arxiv.org/abs/2404.11276v1"}
{"created":"2024-04-17 11:19:04","title":"Towards Human Awareness in Robot Task Planning with Large Language Models","abstract":"The recent breakthroughs in the research on Large Language Models (LLMs) have triggered a transformation across several research domains. Notably, the integration of LLMs has greatly enhanced performance in robot Task And Motion Planning (TAMP). However, previous approaches often neglect the consideration of dynamic environments, i.e., the presence of dynamic objects such as humans. In this paper, we propose a novel approach to address this gap by incorporating human awareness into LLM-based robot task planning. To obtain an effective representation of the dynamic environment, our approach integrates humans' information into a hierarchical scene graph. To ensure the plan's executability, we leverage LLMs to ground the environmental topology and actionable knowledge into formal planning language. Most importantly, we use LLMs to predict future human activities and plan tasks for the robot considering the predictions. Our contribution facilitates the development of integrating human awareness into LLM-driven robot task planning, and paves the way for proactive robot decision-making in dynamic environments.","sentences":["The recent breakthroughs in the research on Large Language Models (LLMs) have triggered a transformation across several research domains.","Notably, the integration of LLMs has greatly enhanced performance in robot Task And Motion Planning (TAMP).","However, previous approaches often neglect the consideration of dynamic environments, i.e., the presence of dynamic objects such as humans.","In this paper, we propose a novel approach to address this gap by incorporating human awareness into LLM-based robot task planning.","To obtain an effective representation of the dynamic environment, our approach integrates humans' information into a hierarchical scene graph.","To ensure the plan's executability, we leverage LLMs to ground the environmental topology and actionable knowledge into formal planning language.","Most importantly, we use LLMs to predict future human activities and plan tasks for the robot considering the predictions.","Our contribution facilitates the development of integrating human awareness into LLM-driven robot task planning, and paves the way for proactive robot decision-making in dynamic environments."],"url":"http://arxiv.org/abs/2404.11267v1"}
{"created":"2024-04-17 11:12:59","title":"Sampling-based Pseudo-Likelihood for Membership Inference Attacks","abstract":"Large Language Models (LLMs) are trained on large-scale web data, which makes it difficult to grasp the contribution of each text. This poses the risk of leaking inappropriate data such as benchmarks, personal information, and copyrighted texts in the training data. Membership Inference Attacks (MIA), which determine whether a given text is included in the model's training data, have been attracting attention. Previous studies of MIAs revealed that likelihood-based classification is effective for detecting leaks in LLMs. However, the existing methods cannot be applied to some proprietary models like ChatGPT or Claude 3 because the likelihood is unavailable to the user. In this study, we propose a Sampling-based Pseudo-Likelihood (\\textbf{SPL}) method for MIA (\\textbf{SaMIA}) that calculates SPL using only the text generated by an LLM to detect leaks. The SaMIA treats the target text as the reference text and multiple outputs from the LLM as text samples, calculates the degree of $n$-gram match as SPL, and determines the membership of the text in the training data. Even without likelihoods, SaMIA performed on par with existing likelihood-based methods.","sentences":["Large Language Models (LLMs) are trained on large-scale web data, which makes it difficult to grasp the contribution of each text.","This poses the risk of leaking inappropriate data such as benchmarks, personal information, and copyrighted texts in the training data.","Membership Inference Attacks (MIA), which determine whether a given text is included in the model's training data, have been attracting attention.","Previous studies of MIAs revealed that likelihood-based classification is effective for detecting leaks in LLMs.","However, the existing methods cannot be applied to some proprietary models like ChatGPT or Claude 3 because the likelihood is unavailable to the user.","In this study, we propose a Sampling-based Pseudo-Likelihood (\\textbf{SPL}) method for MIA (\\textbf{SaMIA}) that calculates SPL using only the text generated by an LLM to detect leaks.","The SaMIA treats the target text as the reference text and multiple outputs from the LLM as text samples, calculates the degree of $n$-gram match as SPL, and determines the membership of the text in the training data.","Even without likelihoods, SaMIA performed on par with existing likelihood-based methods."],"url":"http://arxiv.org/abs/2404.11262v1"}
{"created":"2024-04-17 10:20:42","title":"Unlocking Memories with AI: Exploring the Role of AI-Generated Cues in Personal Reminiscing","abstract":"While technology-mediated reminiscing has been studied for decades, generating relevant cues to trigger personal reminiscing remains challenging. The potential of AI in generating relevant content across various domains has been recently recognized, yet its use in facilitating reminiscing is still less explored. This work aims to explore the use of AI in supporting the recall of personal memories associated with significant objects at home. We designed Treasurefinder, a device powered by a large language model (LLM) that generates open-ended questions based on stories stored in NFC-tagged physical objects or cards. We conducted an exploratory study with 12 participants, grouped in pairs, to observe reminiscing behaviors when using Treasurefinder. The results showed the AI-generated questions 1) supported individuals to recall the past, 2) provided new insights about the other person, and 3) encouraged reflection. Notably, the device facilitated active memory retrieval related to cherished objects that are often overlooked.","sentences":["While technology-mediated reminiscing has been studied for decades, generating relevant cues to trigger personal reminiscing remains challenging.","The potential of AI in generating relevant content across various domains has been recently recognized, yet its use in facilitating reminiscing is still less explored.","This work aims to explore the use of AI in supporting the recall of personal memories associated with significant objects at home.","We designed Treasurefinder, a device powered by a large language model (LLM) that generates open-ended questions based on stories stored in NFC-tagged physical objects or cards.","We conducted an exploratory study with 12 participants, grouped in pairs, to observe reminiscing behaviors when using Treasurefinder.","The results showed the AI-generated questions 1) supported individuals to recall the past, 2) provided new insights about the other person, and 3) encouraged reflection.","Notably, the device facilitated active memory retrieval related to cherished objects that are often overlooked."],"url":"http://arxiv.org/abs/2404.11227v1"}
{"created":"2024-04-17 10:19:15","title":"In-Context Learning State Vector with Inner and Momentum Optimization","abstract":"Large Language Models (LLMs) have exhibited an impressive ability to perform In-Context Learning (ICL) from only a few examples. Recent works have indicated that the functions learned by ICL can be represented through compressed vectors derived from the transformer. However, the working mechanisms and optimization of these vectors are yet to be thoroughly explored. In this paper, we address this gap by presenting a comprehensive analysis of these compressed vectors, drawing parallels to the parameters trained with gradient descent, and introduce the concept of state vector. Inspired by the works on model soup and momentum-based gradient descent, we propose inner and momentum optimization methods that are applied to refine the state vector progressively as test-time adaptation. Moreover, we simulate state vector aggregation in the multiple example setting, where demonstrations comprising numerous examples are usually too lengthy for regular ICL, and further propose a divide-and-conquer aggregation method to address this challenge. We conduct extensive experiments using Llama-2 and GPT-J in both zero-shot setting and few-shot setting. The experimental results show that our optimization method effectively enhances the state vector and achieves the state-of-the-art performance on diverse tasks. Code is available at https://github.com/HITsz-TMG/ICL-State-Vector","sentences":["Large Language Models (LLMs) have exhibited an impressive ability to perform In-Context Learning (ICL) from only a few examples.","Recent works have indicated that the functions learned by ICL can be represented through compressed vectors derived from the transformer.","However, the working mechanisms and optimization of these vectors are yet to be thoroughly explored.","In this paper, we address this gap by presenting a comprehensive analysis of these compressed vectors, drawing parallels to the parameters trained with gradient descent, and introduce the concept of state vector.","Inspired by the works on model soup and momentum-based gradient descent, we propose inner and momentum optimization methods that are applied to refine the state vector progressively as test-time adaptation.","Moreover, we simulate state vector aggregation in the multiple example setting, where demonstrations comprising numerous examples are usually too lengthy for regular ICL, and further propose a divide-and-conquer aggregation method to address this challenge.","We conduct extensive experiments using Llama-2 and GPT-J in both zero-shot setting and few-shot setting.","The experimental results show that our optimization method effectively enhances the state vector and achieves the state-of-the-art performance on diverse tasks.","Code is available at https://github.com/HITsz-TMG/ICL-State-Vector"],"url":"http://arxiv.org/abs/2404.11225v1"}
{"created":"2024-04-17 10:00:56","title":"Position Engineering: Boosting Large Language Models through Positional Information Manipulation","abstract":"The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel technique termed position engineering, which offers a more efficient way to guide large language models. Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself. We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL). Our findings show that position engineering substantially improves upon the baseline in both cases. Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models.","sentences":["The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided.","In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance.","In this paper, we introduce a novel technique termed position engineering, which offers a more efficient way to guide large language models.","Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself.","We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL).","Our findings show that position engineering substantially improves upon the baseline in both cases.","Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models."],"url":"http://arxiv.org/abs/2404.11216v1"}
{"created":"2024-04-17 09:45:43","title":"Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM","abstract":"Medical report generation automates radiology descriptions from images, easing the burden on physicians and minimizing errors. However, current methods lack structured outputs and physician interactivity for clear, clinically relevant reports. Our method introduces a prompt-guided approach to generate structured chest X-ray reports using a pre-trained large language model (LLM). First, we identify anatomical regions in chest X-rays to generate focused sentences that center on key visual elements, thereby establishing a structured report foundation with anatomy-based sentences. We also convert the detected anatomy into textual prompts conveying anatomical comprehension to the LLM. Additionally, the clinical context prompts guide the LLM to emphasize interactivity and clinical requirements. By integrating anatomy-focused sentences and anatomy/clinical prompts, the pre-trained LLM can generate structured chest X-ray reports tailored to prompted anatomical regions and clinical contexts. We evaluate using language generation and clinical effectiveness metrics, demonstrating strong performance.","sentences":["Medical report generation automates radiology descriptions from images, easing the burden on physicians and minimizing errors.","However, current methods lack structured outputs and physician interactivity for clear, clinically relevant reports.","Our method introduces a prompt-guided approach to generate structured chest X-ray reports using a pre-trained large language model (LLM).","First, we identify anatomical regions in chest X-rays to generate focused sentences that center on key visual elements, thereby establishing a structured report foundation with anatomy-based sentences.","We also convert the detected anatomy into textual prompts conveying anatomical comprehension to the LLM.","Additionally, the clinical context prompts guide the LLM to emphasize interactivity and clinical requirements.","By integrating anatomy-focused sentences and anatomy/clinical prompts, the pre-trained LLM can generate structured chest X-ray reports tailored to prompted anatomical regions and clinical contexts.","We evaluate using language generation and clinical effectiveness metrics, demonstrating strong performance."],"url":"http://arxiv.org/abs/2404.11209v1"}
{"created":"2024-04-17 08:16:48","title":"Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation","abstract":"Large Language Models (LLMs) have become the go-to solution for many Natural Language Processing (NLP) tasks due to their ability to tackle various problems and produce high-quality results. Specifically, they are increasingly used to automatically generate code, easing the burden on developers by handling repetitive tasks. However, this improvement in quality has led to high computational and memory demands, making LLMs inaccessible to users with limited resources. In this paper, we focus on Central Processing Unit (CPU)-compatible models and conduct a thorough semi-manual evaluation of their strengths and weaknesses in generating Python code. We enhance their performance by introducing a Chain-of-Thought prompt that guides the model in problem-solving. Additionally, we propose a dataset of 60 programming problems with varying difficulty levels for evaluation purposes. Our assessment also includes testing these models on two state-of-the-art datasets: HumanEval and EvalPlus. We commit to sharing our dataset and experimental results publicly to ensure transparency.","sentences":["Large Language Models (LLMs) have become the go-to solution for many Natural Language Processing (NLP) tasks due to their ability to tackle various problems and produce high-quality results.","Specifically, they are increasingly used to automatically generate code, easing the burden on developers by handling repetitive tasks.","However, this improvement in quality has led to high computational and memory demands, making LLMs inaccessible to users with limited resources.","In this paper, we focus on Central Processing Unit (CPU)-compatible models and conduct a thorough semi-manual evaluation of their strengths and weaknesses in generating Python code.","We enhance their performance by introducing a Chain-of-Thought prompt that guides the model in problem-solving.","Additionally, we propose a dataset of 60 programming problems with varying difficulty levels for evaluation purposes.","Our assessment also includes testing these models on two state-of-the-art datasets: HumanEval and EvalPlus.","We commit to sharing our dataset and experimental results publicly to ensure transparency."],"url":"http://arxiv.org/abs/2404.11160v1"}
{"created":"2024-04-17 07:08:45","title":"TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment","abstract":"Proprietary large language models (LLMs) have been widely applied in various scenarios. Additionally, deploying LLMs on edge devices is trending for efficiency and privacy reasons. However, edge deployment of proprietary LLMs introduces new security challenges: edge-deployed models are exposed as white-box accessible to users, enabling adversaries to conduct effective model stealing (MS) attacks. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify four critical protection properties that existing methods fail to simultaneously satisfy: (1) maintaining protection after a model is physically copied; (2) authorizing model access at request level; (3) safeguarding runtime reverse engineering; (4) achieving high security with negligible runtime overhead. To address the above issues, we propose TransLinkGuard, a plug-and-play model protection approach against model stealing on edge devices. The core part of TransLinkGuard is a lightweight authorization module residing in a secure environment, e.g., TEE. The authorization module can freshly authorize each request based on its input. Extensive experiments show that TransLinkGuard achieves the same security protection as the black-box security guarantees with negligible overhead.","sentences":["Proprietary large language models (LLMs) have been widely applied in various scenarios.","Additionally, deploying LLMs on edge devices is trending for efficiency and privacy reasons.","However, edge deployment of proprietary LLMs introduces new security challenges: edge-deployed models are exposed as white-box accessible to users, enabling adversaries to conduct effective model stealing (MS) attacks.","Unfortunately, existing defense mechanisms fail to provide effective protection.","Specifically, we identify four critical protection properties that existing methods fail to simultaneously satisfy: (1) maintaining protection after a model is physically copied; (2) authorizing model access at request level; (3) safeguarding runtime reverse engineering; (4) achieving high security with negligible runtime overhead.","To address the above issues, we propose TransLinkGuard, a plug-and-play model protection approach against model stealing on edge devices.","The core part of TransLinkGuard is a lightweight authorization module residing in a secure environment, e.g., TEE.","The authorization module can freshly authorize each request based on its input.","Extensive experiments show that TransLinkGuard achieves the same security protection as the black-box security guarantees with negligible overhead."],"url":"http://arxiv.org/abs/2404.11121v1"}
{"created":"2024-04-17 06:26:32","title":"Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues","abstract":"Aligning large language models (LLMs) with human expectations requires high-quality instructional dialogues, which can be achieved by raising diverse, in-depth, and insightful instructions that deepen interactions. Existing methods target instructions from real instruction dialogues as a learning goal and fine-tune a user simulator for posing instructions. However, the user simulator struggles to implicitly model complex dialogue flows and pose high-quality instructions. In this paper, we take inspiration from the cognitive abilities inherent in human learning and propose the explicit modeling of complex dialogue flows through instructional strategy reuse. Specifically, we first induce high-level strategies from various real instruction dialogues. These strategies are applied to new dialogue scenarios deductively, where the instructional strategies facilitate high-quality instructions. Experimental results show that our method can generate diverse, in-depth, and insightful instructions for a given dialogue history. The constructed multi-turn instructional dialogues can outperform competitive baselines on the downstream chat model.","sentences":["Aligning large language models (LLMs) with human expectations requires high-quality instructional dialogues, which can be achieved by raising diverse, in-depth, and insightful instructions that deepen interactions.","Existing methods target instructions from real instruction dialogues as a learning goal and fine-tune a user simulator for posing instructions.","However, the user simulator struggles to implicitly model complex dialogue flows and pose high-quality instructions.","In this paper, we take inspiration from the cognitive abilities inherent in human learning and propose the explicit modeling of complex dialogue flows through instructional strategy reuse.","Specifically, we first induce high-level strategies from various real instruction dialogues.","These strategies are applied to new dialogue scenarios deductively, where the instructional strategies facilitate high-quality instructions.","Experimental results show that our method can generate diverse, in-depth, and insightful instructions for a given dialogue history.","The constructed multi-turn instructional dialogues can outperform competitive baselines on the downstream chat model."],"url":"http://arxiv.org/abs/2404.11095v1"}
{"created":"2024-04-17 05:57:17","title":"ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large Language Models","abstract":"The rapid advancement of large language models (LLMs) necessitates the development of new benchmarks to accurately assess their capabilities. To address this need for Vietnamese, this work aims to introduce ViLLM-Eval, the comprehensive evaluation suite designed to measure the advanced knowledge and reasoning abilities of foundation models within a Vietnamese context. ViLLM-Eval consists of multiple-choice questions and predict next word tasks spanning various difficulty levels and diverse disciplines, ranging from humanities to science and engineering. A thorough evaluation of the most advanced LLMs on ViLLM-Eval revealed that even the best performing models have significant room for improvement in understanding and responding to Vietnamese language tasks. ViLLM-Eval is believed to be instrumental in identifying key strengths and weaknesses of foundation models, ultimately promoting their development and enhancing their performance for Vietnamese users. This paper provides a thorough overview of ViLLM-Eval as part of the Vietnamese Large Language Model shared task, held within the 10th International Workshop on Vietnamese Language and Speech Processing (VLSP 2023).","sentences":["The rapid advancement of large language models (LLMs) necessitates the development of new benchmarks to accurately assess their capabilities.","To address this need for Vietnamese, this work aims to introduce ViLLM-Eval, the comprehensive evaluation suite designed to measure the advanced knowledge and reasoning abilities of foundation models within a Vietnamese context.","ViLLM-Eval consists of multiple-choice questions and predict next word tasks spanning various difficulty levels and diverse disciplines, ranging from humanities to science and engineering.","A thorough evaluation of the most advanced LLMs on ViLLM-Eval revealed that even the best performing models have significant room for improvement in understanding and responding to Vietnamese language tasks.","ViLLM-Eval is believed to be instrumental in identifying key strengths and weaknesses of foundation models, ultimately promoting their development and enhancing their performance for Vietnamese users.","This paper provides a thorough overview of ViLLM-Eval as part of the Vietnamese Large Language Model shared task, held within the 10th International Workshop on Vietnamese Language and Speech Processing (VLSP 2023)."],"url":"http://arxiv.org/abs/2404.11086v2"}
{"created":"2024-04-17 05:05:05","title":"Large Language Models Meet User Interfaces: The Case of Provisioning Feedback","abstract":"Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in education can enhance teaching efficiency and enrich student learning. Current LLM usage involves conversational user interfaces (CUIs) for tasks like generating materials or providing feedback. However, this presents challenges including the need for educator expertise in AI and CUIs, ethical concerns with high-stakes decisions, and privacy risks. CUIs also struggle with complex tasks. To address these, we propose transitioning from CUIs to user-friendly applications leveraging LLMs via API calls. We present a framework for ethically incorporating GenAI into educational tools and demonstrate its application in our tool, Feedback Copilot, which provides personalized feedback on student assignments. Our evaluation shows the effectiveness of this approach, with implications for GenAI researchers, educators, and technologists. This work charts a course for the future of GenAI in education.","sentences":["Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in education can enhance teaching efficiency and enrich student learning.","Current LLM usage involves conversational user interfaces (CUIs) for tasks like generating materials or providing feedback.","However, this presents challenges including the need for educator expertise in AI and CUIs, ethical concerns with high-stakes decisions, and privacy risks.","CUIs also struggle with complex tasks.","To address these, we propose transitioning from CUIs to user-friendly applications leveraging LLMs via API calls.","We present a framework for ethically incorporating GenAI into educational tools and demonstrate its application in our tool, Feedback Copilot, which provides personalized feedback on student assignments.","Our evaluation shows the effectiveness of this approach, with implications for GenAI researchers, educators, and technologists.","This work charts a course for the future of GenAI in education."],"url":"http://arxiv.org/abs/2404.11072v1"}
