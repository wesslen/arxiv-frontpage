{"created":"2023-12-19 18:59:53","title":"Weakly Supervised Open-Vocabulary Object Detection","abstract":"Despite weakly supervised object detection (WSOD) being a promising step toward evading strong instance-level annotations, its capability is confined to closed-set categories within a single training dataset. In this paper, we propose a novel weakly supervised open-vocabulary object detection framework, namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize diverse datasets with only image-level annotations. To achieve this, we explore three vital strategies, including dataset-level feature adaptation, image-level salient object localization, and region-level vision-language alignment. First, we perform data-aware feature extraction to produce an input-conditional coefficient, which is leveraged into dataset attribute prototypes to identify dataset bias and help achieve cross-dataset generalization. Second, a customized location-oriented weakly supervised region proposal network is proposed to utilize high-level semantic layouts from the category-agnostic segment anything model to distinguish object boundaries. Lastly, we introduce a proposal-concept synchronized multiple-instance network, i.e., object mining and refinement with visual-semantic alignment, to discover objects matched to the text embeddings of concepts. Extensive experiments on Pascal VOC and MS COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art compared with previous WSOD methods in both close-set object localization and detection tasks. Meanwhile, WSOVOD enables cross-dataset and open-vocabulary learning to achieve on-par or even better performance than well-established fully-supervised open-vocabulary object detection (FSOVOD).","sentences":["Despite weakly supervised object detection (WSOD) being a promising step toward evading strong instance-level annotations, its capability is confined to closed-set categories within a single training dataset.","In this paper, we propose a novel weakly supervised open-vocabulary object detection framework, namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize diverse datasets with only image-level annotations.","To achieve this, we explore three vital strategies, including dataset-level feature adaptation, image-level salient object localization, and region-level vision-language alignment.","First, we perform data-aware feature extraction to produce an input-conditional coefficient, which is leveraged into dataset attribute prototypes to identify dataset bias and help achieve cross-dataset generalization.","Second, a customized location-oriented weakly supervised region proposal network is proposed to utilize high-level semantic layouts from the category-agnostic segment anything model to distinguish object boundaries.","Lastly, we introduce a proposal-concept synchronized multiple-instance network, i.e., object mining and refinement with visual-semantic alignment, to discover objects matched to the text embeddings of concepts.","Extensive experiments on Pascal VOC and MS COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art compared with previous WSOD methods in both close-set object localization and detection tasks.","Meanwhile, WSOVOD enables cross-dataset and open-vocabulary learning to achieve on-par or even better performance than well-established fully-supervised open-vocabulary object detection (FSOVOD)."],"url":"http://arxiv.org/abs/2312.12437v1"}
{"created":"2023-12-19 18:59:22","title":"A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise","abstract":"The surge of interest towards Multi-modal Large Language Models (MLLMs), e.g., GPT-4V(ision) from OpenAI, has marked a significant trend in both academia and industry. They endow Large Language Models (LLMs) with powerful capabilities in visual understanding, enabling them to tackle diverse multi-modal tasks. Very recently, Google released Gemini, its newest and most capable MLLM built from the ground up for multi-modality. In light of the superior reasoning capabilities, can Gemini challenge GPT-4V's leading position in multi-modal learning? In this paper, we present a preliminary exploration of Gemini Pro's visual understanding proficiency, which comprehensively covers four domains: fundamental perception, advanced cognition, challenging vision tasks, and various expert capacities. We compare Gemini Pro with the state-of-the-art GPT-4V to evaluate its upper limits, along with the latest open-sourced MLLM, Sphinx, which reveals the gap between manual efforts and black-box systems. The qualitative samples indicate that, while GPT-4V and Gemini showcase different answering styles and preferences, they can exhibit comparable visual reasoning capabilities, and Sphinx still trails behind them concerning domain generalizability. Specifically, GPT-4V tends to elaborate detailed explanations and intermediate steps, and Gemini prefers to output a direct and concise answer. The quantitative evaluation on the popular MME benchmark also demonstrates the potential of Gemini to be a strong challenger to GPT-4V. Our early investigation of Gemini also observes some common issues of MLLMs, indicating that there still remains a considerable distance towards artificial general intelligence. Our project for tracking the progress of MLLM is released at https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.","sentences":["The surge of interest towards Multi-modal Large Language Models (MLLMs), e.g., GPT-4V(ision) from OpenAI, has marked a significant trend in both academia and industry.","They endow Large Language Models (LLMs) with powerful capabilities in visual understanding, enabling them to tackle diverse multi-modal tasks.","Very recently, Google released Gemini, its newest and most capable MLLM built from the ground up for multi-modality.","In light of the superior reasoning capabilities, can Gemini challenge GPT-4V's leading position in multi-modal learning?","In this paper, we present a preliminary exploration of Gemini Pro's visual understanding proficiency, which comprehensively covers four domains: fundamental perception, advanced cognition, challenging vision tasks, and various expert capacities.","We compare Gemini Pro with the state-of-the-art GPT-4V to evaluate its upper limits, along with the latest open-sourced MLLM, Sphinx, which reveals the gap between manual efforts and black-box systems.","The qualitative samples indicate that, while GPT-4V and Gemini showcase different answering styles and preferences, they can exhibit comparable visual reasoning capabilities, and Sphinx still trails behind them concerning domain generalizability.","Specifically, GPT-4V tends to elaborate detailed explanations and intermediate steps, and Gemini prefers to output a direct and concise answer.","The quantitative evaluation on the popular MME benchmark also demonstrates the potential of Gemini to be a strong challenger to GPT-4V. Our early investigation of Gemini also observes some common issues of MLLMs, indicating that there still remains a considerable distance towards artificial general intelligence.","Our project for tracking the progress of MLLM is released at https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models."],"url":"http://arxiv.org/abs/2312.12436v1"}
{"created":"2023-12-19 18:58:40","title":"Tracking Any Object Amodally","abstract":"Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants. Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential. However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets. To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences. Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame. To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation. We achieve a 3.3\\% and 1.6\\% improvement on the detection and tracking of occluded objects on TAO-Amodal. When evaluated on people, our method produces dramatic improvements of 2x compared to state-of-the-art modal baselines.","sentences":["Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants.","Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential.","However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets.","To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences.","Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame.","To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation.","We achieve a 3.3\\% and 1.6\\% improvement on the detection and tracking of occluded objects on TAO-Amodal.","When evaluated on people, our method produces dramatic improvements of 2x compared to state-of-the-art modal baselines."],"url":"http://arxiv.org/abs/2312.12433v1"}
{"created":"2023-12-19 18:57:34","title":"On Inference Stability for Diffusion Models","abstract":"Denoising Probabilistic Models (DPMs) represent an emerging domain of generative models that excel in generating diverse and high-quality images. However, most current training methods for DPMs often neglect the correlation between timesteps, limiting the model's performance in generating images effectively. Notably, we theoretically point out that this issue can be caused by the cumulative estimation gap between the predicted and the actual trajectory. To minimize that gap, we propose a novel \\textit{sequence-aware} loss that aims to reduce the estimation gap to enhance the sampling quality. Furthermore, we theoretically show that our proposed loss function is a tighter upper bound of the estimation loss in comparison with the conventional loss in DPMs. Experimental results on several benchmark datasets including CIFAR10, CelebA, and CelebA-HQ consistently show a remarkable improvement of our proposed method regarding the image generalization quality measured by FID and Inception Score compared to several DPM baselines. Our code and pre-trained checkpoints are available at \\url{https://github.com/viettmab/SA-DPM}.","sentences":["Denoising Probabilistic Models (DPMs) represent an emerging domain of generative models that excel in generating diverse and high-quality images.","However, most current training methods for DPMs often neglect the correlation between timesteps, limiting the model's performance in generating images effectively.","Notably, we theoretically point out that this issue can be caused by the cumulative estimation gap between the predicted and the actual trajectory.","To minimize that gap, we propose a novel \\textit{sequence-aware} loss that aims to reduce the estimation gap to enhance the sampling quality.","Furthermore, we theoretically show that our proposed loss function is a tighter upper bound of the estimation loss in comparison with the conventional loss in DPMs.","Experimental results on several benchmark datasets including CIFAR10, CelebA, and CelebA-HQ consistently show a remarkable improvement of our proposed method regarding the image generalization quality measured by FID and Inception Score compared to several DPM baselines.","Our code and pre-trained checkpoints are available at \\url{https://github.com/viettmab/SA-DPM}."],"url":"http://arxiv.org/abs/2312.12431v1"}
{"created":"2023-12-19 18:56:52","title":"Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP","abstract":"We introduce Efficient Title Reranker via Broadcasting Query Encoder, a novel title reranking technique to achieve efficient title reranking 20x-40x faster than vanilla passage reranker. However, one of the challenges with the training of Efficient Title Reranker is the instability. Analyzing the issue, we found some very difficult ground truths might act as noisy labels causing accuracy to drop as well as some extreme values in model probability output causing nan. To address these issues, we introduce the Sigmoid Trick, a novel technique that reduces the gradient update of both cases resulting in better retrieval efficacy. Experiments showed the effectiveness of ETR and sigmoid trick as we achieved four state-of-the-art positions on the kilt knowledge benchmark.","sentences":["We introduce Efficient Title Reranker via Broadcasting Query Encoder, a novel title reranking technique to achieve efficient title reranking 20x-40x faster than vanilla passage reranker.","However, one of the challenges with the training of Efficient Title Reranker is the instability.","Analyzing the issue, we found some very difficult ground truths might act as noisy labels causing accuracy to drop as well as some extreme values in model probability output causing nan.","To address these issues, we introduce the Sigmoid Trick, a novel technique that reduces the gradient update of both cases resulting in better retrieval efficacy.","Experiments showed the effectiveness of ETR and sigmoid trick as we achieved four state-of-the-art positions on the kilt knowledge benchmark."],"url":"http://arxiv.org/abs/2312.12430v1"}
{"created":"2023-12-19 18:56:44","title":"The Endoscapes Dataset for Surgical Scene Segmentation, Object Detection, and Critical View of Safety Assessment: Official Splits and Benchmark","abstract":"This technical report provides a detailed overview of Endoscapes, a dataset of laparoscopic cholecystectomy (LC) videos with highly intricate annotations targeted at automated assessment of the Critical View of Safety (CVS). Endoscapes comprises 201 LC videos with frames annotated sparsely but regularly with segmentation masks, bounding boxes, and CVS assessment by three different clinical experts. Altogether, there are 11090 frames annotated with CVS and 1933 frames annotated with tool and anatomy bounding boxes from the 201 videos, as well as an additional 422 frames from 50 of the 201 videos annotated with tool and anatomy segmentation masks. In this report, we provide detailed dataset statistics (size, class distribution, dataset splits, etc.) and a comprehensive performance benchmark for instance segmentation, object detection, and CVS prediction. The dataset and model checkpoints are publically available at https://github.com/CAMMA-public/Endoscapes.","sentences":["This technical report provides a detailed overview of Endoscapes, a dataset of laparoscopic cholecystectomy (LC) videos with highly intricate annotations targeted at automated assessment of the Critical View of Safety (CVS).","Endoscapes comprises 201 LC videos with frames annotated sparsely but regularly with segmentation masks, bounding boxes, and CVS assessment by three different clinical experts.","Altogether, there are 11090 frames annotated with CVS and 1933 frames annotated with tool and anatomy bounding boxes from the 201 videos, as well as an additional 422 frames from 50 of the 201 videos annotated with tool and anatomy segmentation masks.","In this report, we provide detailed dataset statistics (size, class distribution, dataset splits, etc.) and a comprehensive performance benchmark for instance segmentation, object detection, and CVS prediction.","The dataset and model checkpoints are publically available at https://github.com/CAMMA-public/Endoscapes."],"url":"http://arxiv.org/abs/2312.12429v1"}
{"created":"2023-12-19 18:53:47","title":"SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process","abstract":"In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models. We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process. As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps. Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process. By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner. To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation. The results demonstrate the superiority of our SegRefiner from multiple aspects. Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks. Secondly, it outperforms previous model-agnostic refinement methods by a significant margin. Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images. The source code and trained models are available at https://github.com/MengyuWang826/SegRefiner.","sentences":["In this paper, we explore a principal way to enhance the quality of object masks produced by different segmentation models.","We propose a model-agnostic solution called SegRefiner, which offers a novel perspective on this problem by interpreting segmentation refinement as a data generation process.","As a result, the refinement process can be smoothly implemented through a series of denoising diffusion steps.","Specifically, SegRefiner takes coarse masks as inputs and refines them using a discrete diffusion process.","By predicting the label and corresponding states-transition probabilities for each pixel, SegRefiner progressively refines the noisy masks in a conditional denoising manner.","To assess the effectiveness of SegRefiner, we conduct comprehensive experiments on various segmentation tasks, including semantic segmentation, instance segmentation, and dichotomous image segmentation.","The results demonstrate the superiority of our SegRefiner from multiple aspects.","Firstly, it consistently improves both the segmentation metrics and boundary metrics across different types of coarse masks.","Secondly, it outperforms previous model-agnostic refinement methods by a significant margin.","Lastly, it exhibits a strong capability to capture extremely fine details when refining high-resolution images.","The source code and trained models are available at https://github.com/MengyuWang826/SegRefiner."],"url":"http://arxiv.org/abs/2312.12425v1"}
{"created":"2023-12-19 18:53:01","title":"Jack of All Tasks, Master of Many: Designing General-purpose Coarse-to-Fine Vision-Language Model","abstract":"The ability of large language models (LLMs) to process visual inputs has given rise to general-purpose vision systems, unifying various vision-language (VL) tasks by instruction tuning. However, due to the enormous diversity in input-output formats in the vision domain, existing general-purpose models fail to successfully integrate segmentation and multi-image inputs with coarse-level tasks into a single framework. In this work, we introduce VistaLLM, a powerful visual system that addresses coarse- and fine-grained VL tasks over single and multiple input images using a unified framework. VistaLLM utilizes an instruction-guided image tokenizer that filters global embeddings using task descriptions to extract compressed and refined features from numerous images. Moreover, VistaLLM employs a gradient-aware adaptive sampling technique to represent binary segmentation masks as sequences, significantly improving over previously used uniform sampling. To bolster the desired capability of VistaLLM, we curate CoinIt, a comprehensive coarse-to-fine instruction tuning dataset with 6.8M samples. We also address the lack of multi-image grounding datasets by introducing a novel task, AttCoSeg (Attribute-level Co-Segmentation), which boosts the model's reasoning and grounding capability over multiple input images. Extensive experiments on a wide range of V- and VL tasks demonstrate the effectiveness of VistaLLM by achieving consistent state-of-the-art performance over strong baselines across all downstream tasks. Our project page can be found at https://shramanpramanick.github.io/VistaLLM/.","sentences":["The ability of large language models (LLMs) to process visual inputs has given rise to general-purpose vision systems, unifying various vision-language (VL) tasks by instruction tuning.","However, due to the enormous diversity in input-output formats in the vision domain, existing general-purpose models fail to successfully integrate segmentation and multi-image inputs with coarse-level tasks into a single framework.","In this work, we introduce VistaLLM, a powerful visual system that addresses coarse- and fine-grained VL tasks over single and multiple input images using a unified framework.","VistaLLM utilizes an instruction-guided image tokenizer that filters global embeddings using task descriptions to extract compressed and refined features from numerous images.","Moreover, VistaLLM employs a gradient-aware adaptive sampling technique to represent binary segmentation masks as sequences, significantly improving over previously used uniform sampling.","To bolster the desired capability of VistaLLM, we curate CoinIt, a comprehensive coarse-to-fine instruction tuning dataset with 6.8M samples.","We also address the lack of multi-image grounding datasets by introducing a novel task, AttCoSeg (Attribute-level Co-Segmentation), which boosts the model's reasoning and grounding capability over multiple input images.","Extensive experiments on a wide range of V- and VL tasks demonstrate the effectiveness of VistaLLM by achieving consistent state-of-the-art performance over strong baselines across all downstream tasks.","Our project page can be found at https://shramanpramanick.github.io/VistaLLM/."],"url":"http://arxiv.org/abs/2312.12423v1"}
{"created":"2023-12-19 18:51:12","title":"Terrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation","abstract":"The SSH protocol provides secure access to network services, particularly remote terminal login and file transfer within organizational networks and to over 15 million servers on the open internet. SSH uses an authenticated key exchange to establish a secure channel between a client and a server, which protects the confidentiality and integrity of messages sent in either direction. The secure channel prevents message manipulation, replay, insertion, deletion, and reordering. In this paper, we show that as new encryption algorithms and mitigations were added to SSH, the SSH Binary Packet Protocol is no longer a secure channel: SSH channel integrity (INT-PST) is broken for three widely used encryption modes. This allows prefix truncation attacks where some encrypted packets at the beginning of the SSH channel can be deleted without the client or server noticing it. We demonstrate several real-world applications of this attack. We show that we can fully break SSH extension negotiation (RFC 8308), such that an attacker can downgrade the public key algorithms for user authentication or turn off a new countermeasure against keystroke timing attacks introduced in OpenSSH 9.5. We also identified an implementation flaw in AsyncSSH that, together with prefix truncation, allows an attacker to redirect the victim's login into a shell controlled by the attacker. In an internet-wide scan for vulnerable encryption modes and support for extension negotiation, we find that 77% of SSH servers support an exploitable encryption mode, while 57% even list it as their preferred choice. We identify two root causes that enable these attacks: First, the SSH handshake supports optional messages that are not authenticated. Second, SSH does not reset message sequence numbers when encryption is enabled. Based on this analysis, we propose effective and backward-compatible changes to SSH that mitigate our attacks.","sentences":["The SSH protocol provides secure access to network services, particularly remote terminal login and file transfer within organizational networks and to over 15 million servers on the open internet.","SSH uses an authenticated key exchange to establish a secure channel between a client and a server, which protects the confidentiality and integrity of messages sent in either direction.","The secure channel prevents message manipulation, replay, insertion, deletion, and reordering.","In this paper, we show that as new encryption algorithms and mitigations were added to SSH, the SSH Binary Packet Protocol is no longer a secure channel: SSH channel integrity (INT-PST) is broken for three widely used encryption modes.","This allows prefix truncation attacks where some encrypted packets at the beginning of the SSH channel can be deleted without the client or server noticing it.","We demonstrate several real-world applications of this attack.","We show that we can fully break SSH extension negotiation (RFC 8308), such that an attacker can downgrade the public key algorithms for user authentication or turn off a new countermeasure against keystroke timing attacks introduced in OpenSSH 9.5.","We also identified an implementation flaw in AsyncSSH that, together with prefix truncation, allows an attacker to redirect the victim's login into a shell controlled by the attacker.","In an internet-wide scan for vulnerable encryption modes and support for extension negotiation, we find that 77% of SSH servers support an exploitable encryption mode, while 57% even list it as their preferred choice.","We identify two root causes that enable these attacks:","First, the SSH handshake supports optional messages that are not authenticated.","Second, SSH does not reset message sequence numbers when encryption is enabled.","Based on this analysis, we propose effective and backward-compatible changes to SSH that mitigate our attacks."],"url":"http://arxiv.org/abs/2312.12422v1"}
{"created":"2023-12-19 18:50:33","title":"Scene-Conditional 3D Object Stylization and Composition","abstract":"Recently, 3D generative models have made impressive progress, enabling the generation of almost arbitrary 3D assets from text or image inputs. However, these approaches generate objects in isolation without any consideration for the scene where they will eventually be placed. In this paper, we propose a framework that allows for the stylization of an existing 3D asset to fit into a given 2D scene, and additionally produce a photorealistic composition as if the asset was placed within the environment. This not only opens up a new level of control for object stylization, for example, the same assets can be stylized to reflect changes in the environment, such as summer to winter or fantasy versus futuristic settings-but also makes the object-scene composition more controllable. We achieve this by combining modeling and optimizing the object's texture and environmental lighting through differentiable ray tracing with image priors from pre-trained text-to-image diffusion models. We demonstrate that our method is applicable to a wide variety of indoor and outdoor scenes and arbitrary objects.","sentences":["Recently, 3D generative models have made impressive progress, enabling the generation of almost arbitrary 3D assets from text or image inputs.","However, these approaches generate objects in isolation without any consideration for the scene where they will eventually be placed.","In this paper, we propose a framework that allows for the stylization of an existing 3D asset to fit into a given 2D scene, and additionally produce a photorealistic composition as if the asset was placed within the environment.","This not only opens up a new level of control for object stylization, for example, the same assets can be stylized to reflect changes in the environment, such as summer to winter or fantasy versus futuristic settings-but also makes the object-scene composition more controllable.","We achieve this by combining modeling and optimizing the object's texture and environmental lighting through differentiable ray tracing with image priors from pre-trained text-to-image diffusion models.","We demonstrate that our method is applicable to a wide variety of indoor and outdoor scenes and arbitrary objects."],"url":"http://arxiv.org/abs/2312.12419v1"}
{"created":"2023-12-19 18:50:10","title":"LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset","abstract":"Instance shape reconstruction from a 3D scene involves recovering the full geometries of multiple objects at the semantic instance level. Many methods leverage data-driven learning due to the intricacies of scene complexity and significant indoor occlusions. Training these methods often requires a large-scale, high-quality dataset with aligned and paired shape annotations with real-world scans. Existing datasets are either synthetic or misaligned, restricting the performance of data-driven methods on real data. To this end, we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising 10,412 high-quality CAD annotations aligned with 920 real-world scene scans from ArkitScenes, created manually by professional artists. On this top, we propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo) method. It is empowered by a hybrid feature aggregation design to fuse multi-modal inputs and recover high-fidelity object geometries. Besides, we present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate that our shape annotations provide scene occupancy clues that can further improve 3D object detection. Supported by LASA, extensive experiments show that our methods achieve state-of-the-art performance in both instance-level scene reconstruction and 3D object detection tasks.","sentences":["Instance shape reconstruction from a 3D scene involves recovering the full geometries of multiple objects at the semantic instance level.","Many methods leverage data-driven learning due to the intricacies of scene complexity and significant indoor occlusions.","Training these methods often requires a large-scale, high-quality dataset with aligned and paired shape annotations with real-world scans.","Existing datasets are either synthetic or misaligned, restricting the performance of data-driven methods on real data.","To this end, we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising 10,412 high-quality CAD annotations aligned with 920 real-world scene scans from ArkitScenes, created manually by professional artists.","On this top, we propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo) method.","It is empowered by a hybrid feature aggregation design to fuse multi-modal inputs and recover high-fidelity object geometries.","Besides, we present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate that our shape annotations provide scene occupancy clues that can further improve 3D object detection.","Supported by LASA, extensive experiments show that our methods achieve state-of-the-art performance in both instance-level scene reconstruction and 3D object detection tasks."],"url":"http://arxiv.org/abs/2312.12418v1"}
{"created":"2023-12-19 18:47:30","title":"Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models","abstract":"The quality of the prompts provided to text-to-image diffusion models determines how faithful the generated content is to the user's intent, often requiring `prompt engineering'. To harness visual concepts from target images without prompt engineering, current approaches largely rely on embedding inversion by optimizing and then mapping them to pseudo-tokens. However, working with such high-dimensional vector representations is challenging because they lack semantics and interpretability, and only allow simple vector operations when using them. Instead, this work focuses on inverting the diffusion model to obtain interpretable language prompts directly. The challenge of doing this lies in the fact that the resulting optimization problem is fundamentally discrete and the space of prompts is exponentially large; this makes using standard optimization techniques, such as stochastic gradient descent, difficult. To this end, we utilize a delayed projection scheme to optimize for prompts representative of the vocabulary space in the model. Further, we leverage the findings that different timesteps of the diffusion process cater to different levels of detail in an image. The later, noisy, timesteps of the forward diffusion process correspond to the semantic information, and therefore, prompt inversion in this range provides tokens representative of the image semantics. We show that our approach can identify semantically interpretable and meaningful prompts for a target image which can be used to synthesize diverse images with similar content. We further illustrate the application of the optimized prompts in evolutionary image generation and concept removal.","sentences":["The quality of the prompts provided to text-to-image diffusion models determines how faithful the generated content is to the user's intent, often requiring `prompt engineering'.","To harness visual concepts from target images without prompt engineering, current approaches largely rely on embedding inversion by optimizing and then mapping them to pseudo-tokens.","However, working with such high-dimensional vector representations is challenging because they lack semantics and interpretability, and only allow simple vector operations when using them.","Instead, this work focuses on inverting the diffusion model to obtain interpretable language prompts directly.","The challenge of doing this lies in the fact that the resulting optimization problem is fundamentally discrete and the space of prompts is exponentially large; this makes using standard optimization techniques, such as stochastic gradient descent, difficult.","To this end, we utilize a delayed projection scheme to optimize for prompts representative of the vocabulary space in the model.","Further, we leverage the findings that different timesteps of the diffusion process cater to different levels of detail in an image.","The later, noisy, timesteps of the forward diffusion process correspond to the semantic information, and therefore, prompt inversion in this range provides tokens representative of the image semantics.","We show that our approach can identify semantically interpretable and meaningful prompts for a target image which can be used to synthesize diverse images with similar content.","We further illustrate the application of the optimized prompts in evolutionary image generation and concept removal."],"url":"http://arxiv.org/abs/2312.12416v1"}
{"created":"2023-12-19 18:38:01","title":"Towards Automatic Support of Software Model Evolution with Large Language~Models","abstract":"Modeling structure and behavior of software systems plays a crucial role, in various areas of software engineering. As with other software engineering artifacts, software models are subject to evolution. Supporting modelers in evolving models by model completion facilities and providing high-level edit operations such as frequently occurring editing patterns is still an open problem. Recently, large language models (i.e., generative neural networks) have garnered significant attention in various research areas, including software engineering. In this paper, we explore the potential of large language models in supporting the evolution of software models in software engineering. We propose an approach that utilizes large language models for model completion and discovering editing patterns in model histories of software systems. Through controlled experiments using simulated model repositories, we conduct an evaluation of the potential of large language models for these two tasks. We have found that large language models are indeed a promising technology for supporting software model evolution, and that it is worth investigating further in the area of software model evolution.","sentences":["Modeling structure and behavior of software systems plays a crucial role, in various areas of software engineering.","As with other software engineering artifacts, software models are subject to evolution.","Supporting modelers in evolving models by model completion facilities and providing high-level edit operations such as frequently occurring editing patterns is still an open problem.","Recently, large language models (i.e., generative neural networks) have garnered significant attention in various research areas, including software engineering.","In this paper, we explore the potential of large language models in supporting the evolution of software models in software engineering.","We propose an approach that utilizes large language models for model completion and discovering editing patterns in model histories of software systems.","Through controlled experiments using simulated model repositories, we conduct an evaluation of the potential of large language models for these two tasks.","We have found that large language models are indeed a promising technology for supporting software model evolution, and that it is worth investigating further in the area of software model evolution."],"url":"http://arxiv.org/abs/2312.12404v1"}
{"created":"2023-12-19 18:37:39","title":"On Alternating-time Temporal Logic, Hyperproperties, and Strategy Sharing","abstract":"Alternating-time temporal logic (ATL$^*$) is a well-established framework for formal reasoning about multi-agent systems. However, while ATL$^*$ can reason about the strategic ability of agents (e.g., some coalition $A$ can ensure that a goal is reached eventually), we cannot compare multiple strategic interactions, nor can we require multiple agents to follow the same strategy. For example, we cannot state that coalition $A$ can reach a goal sooner (or more often) than some other coalition $A'$. In this paper, we propose HyperATLS$^*_S$, an extension of ATL$^*$ in which we can (1) compare the outcome of multiple strategic interactions w.r.t. a hyperproperty, i.e., a property that refers to multiple paths at the same time, and (2) enforce that some agents share the same strategy. We show that HyperATL$^*_S$ is a rich specification language that captures important AI-related properties that were out of reach of existing logics. We prove that model checking of HyperATL$^*_S$ on concurrent game structures is decidable. We implement our model-checking algorithm in a tool we call HyMASMC and evaluate it on a range of benchmarks.","sentences":["Alternating-time temporal logic (ATL$^*$) is a well-established framework for formal reasoning about multi-agent systems.","However, while ATL$^*$ can reason about the strategic ability of agents (e.g., some coalition $A$ can ensure that a goal is reached eventually), we cannot compare multiple strategic interactions, nor can we require multiple agents to follow the same strategy.","For example, we cannot state that coalition $A$ can reach a goal sooner (or more often) than some other coalition $A'$.","In this paper, we propose HyperATLS$^*_S$, an extension of ATL$^*$ in which we can (1) compare the outcome of multiple strategic interactions w.r.t.","a hyperproperty, i.e., a property that refers to multiple paths at the same time, and (2) enforce that some agents share the same strategy.","We show that HyperATL$^*_S$ is a rich specification language that captures important AI-related properties that were out of reach of existing logics.","We prove that model checking of HyperATL$^*_S$ on concurrent game structures is decidable.","We implement our model-checking algorithm in a tool we call HyMASMC and evaluate it on a range of benchmarks."],"url":"http://arxiv.org/abs/2312.12403v1"}
{"created":"2023-12-19 18:35:33","title":"New classes of the greedy-applicable arm feature distributions in the sparse linear bandit problem","abstract":"We consider the sparse contextual bandit problem where arm feature affects reward through the inner product of sparse parameters. Recent studies have developed sparsity-agnostic algorithms based on the greedy arm selection policy. However, the analysis of these algorithms requires strong assumptions on the arm feature distribution to ensure that the greedily selected samples are sufficiently diverse; One of the most common assumptions, relaxed symmetry, imposes approximate origin-symmetry on the distribution, which cannot allow distributions that has origin-asymmetric support. In this paper, we show that the greedy algorithm is applicable to a wider range of the arm feature distributions from two aspects. Firstly, we show that a mixture distribution that has a greedy-applicable component is also greedy-applicable. Second, we propose new distribution classes, related to Gaussian mixture, discrete, and radial distribution, for which the sample diversity is guaranteed. The proposed classes can describe distributions with origin-asymmetric support and, in conjunction with the first claim, provide theoretical guarantees of the greedy policy for a very wide range of the arm feature distributions.","sentences":["We consider the sparse contextual bandit problem where arm feature affects reward through the inner product of sparse parameters.","Recent studies have developed sparsity-agnostic algorithms based on the greedy arm selection policy.","However, the analysis of these algorithms requires strong assumptions on the arm feature distribution to ensure that the greedily selected samples are sufficiently diverse; One of the most common assumptions, relaxed symmetry, imposes approximate origin-symmetry on the distribution, which cannot allow distributions that has origin-asymmetric support.","In this paper, we show that the greedy algorithm is applicable to a wider range of the arm feature distributions from two aspects.","Firstly, we show that a mixture distribution that has a greedy-applicable component is also greedy-applicable.","Second, we propose new distribution classes, related to Gaussian mixture, discrete, and radial distribution, for which the sample diversity is guaranteed.","The proposed classes can describe distributions with origin-asymmetric support and, in conjunction with the first claim, provide theoretical guarantees of the greedy policy for a very wide range of the arm feature distributions."],"url":"http://arxiv.org/abs/2312.12400v1"}
{"created":"2023-12-19 18:35:01","title":"Virtual Reality-Assisted Physiotherapy for Visuospatial Neglect Rehabilitation: A Proof-of-Concept Study","abstract":"This study explores a VR-based intervention for Visuospatial neglect (VSN), a post-stroke condition. It aims to develop a VR task utilizing interactive visual-audio cues to improve sensory-motor training and assess its impact on VSN patients' engagement and performance. Collaboratively designed with physiotherapists, the VR task uses directional and auditory stimuli to alert and direct patients, tested over 12 sessions with two individuals. Results show a consistent decrease in task completion variability and positive patient feedback, highlighting the VR task's potential for enhancing engagement and suggesting its feasibility in rehabilitation. The study underlines the significance of collaborative design in healthcare technology and advocates for further research with a larger sample size to confirm the benefits of VR in VSN treatment, as well as its applicability to other multimodal disorders.","sentences":["This study explores a VR-based intervention for Visuospatial neglect (VSN), a post-stroke condition.","It aims to develop a VR task utilizing interactive visual-audio cues to improve sensory-motor training and assess its impact on VSN patients' engagement and performance.","Collaboratively designed with physiotherapists, the VR task uses directional and auditory stimuli to alert and direct patients, tested over 12 sessions with two individuals.","Results show a consistent decrease in task completion variability and positive patient feedback, highlighting the VR task's potential for enhancing engagement and suggesting its feasibility in rehabilitation.","The study underlines the significance of collaborative design in healthcare technology and advocates for further research with a larger sample size to confirm the benefits of VR in VSN treatment, as well as its applicability to other multimodal disorders."],"url":"http://arxiv.org/abs/2312.12399v1"}
{"created":"2023-12-19 18:11:19","title":"Mixture of Cluster-conditional LoRA Experts for Vision-language Instruction Tuning","abstract":"Instruction tuning of the Large Vision-language Models (LVLMs) has revolutionized the development of versatile models with zero-shot generalization across a wide range of downstream vision-language tasks. However, diversity of training tasks of different sources and formats would lead to inevitable task conflicts, where different tasks conflicts for the same set of model parameters, resulting in sub-optimal instruction-following abilities. To address that, we propose the Mixture of Cluster-conditional LoRA Experts (MoCLE), a novel Mixture of Experts (MoE) architecture designed to activate the task-customized model parameters based on the instruction clusters. A separate universal expert is further incorporated to improve the generalization capabilities of MoCLE for novel instructions. Extensive experiments on 10 zero-shot tasks demonstrate the effectiveness of MoCLE.","sentences":["Instruction tuning of the Large Vision-language Models (LVLMs) has revolutionized the development of versatile models with zero-shot generalization across a wide range of downstream vision-language tasks.","However, diversity of training tasks of different sources and formats would lead to inevitable task conflicts, where different tasks conflicts for the same set of model parameters, resulting in sub-optimal instruction-following abilities.","To address that, we propose the Mixture of Cluster-conditional LoRA Experts (MoCLE), a novel Mixture of Experts (MoE) architecture designed to activate the task-customized model parameters based on the instruction clusters.","A separate universal expert is further incorporated to improve the generalization capabilities of MoCLE for novel instructions.","Extensive experiments on 10 zero-shot tasks demonstrate the effectiveness of MoCLE."],"url":"http://arxiv.org/abs/2312.12379v1"}
{"created":"2023-12-19 18:00:15","title":"Chasing Fairness in Graphs: A GNN Architecture Perspective","abstract":"There has been significant progress in improving the performance of graph neural networks (GNNs) through enhancements in graph data, model architecture design, and training strategies. For fairness in graphs, recent studies achieve fair representations and predictions through either graph data pre-processing (e.g., node feature masking, and topology rewiring) or fair training strategies (e.g., regularization, adversarial debiasing, and fair contrastive learning). How to achieve fairness in graphs from the model architecture perspective is less explored. More importantly, GNNs exhibit worse fairness performance compared to multilayer perception since their model architecture (i.e., neighbor aggregation) amplifies biases. To this end, we aim to achieve fairness via a new GNN architecture. We propose \\textsf{F}air \\textsf{M}essage \\textsf{P}assing (FMP) designed within a unified optimization framework for GNNs. Notably, FMP \\textit{explicitly} renders sensitive attribute usage in \\textit{forward propagation} for node classification task using cross-entropy loss without data pre-processing. In FMP, the aggregation is first adopted to utilize neighbors' information and then the bias mitigation step explicitly pushes demographic group node presentation centers together. In this way, FMP scheme can aggregate useful information from neighbors and mitigate bias to achieve better fairness and prediction tradeoff performance. Experiments on node classification tasks demonstrate that the proposed FMP outperforms several baselines in terms of fairness and accuracy on three real-world datasets. The code is available in {\\url{https://github.com/zhimengj0326/FMP}}.","sentences":["There has been significant progress in improving the performance of graph neural networks (GNNs) through enhancements in graph data, model architecture design, and training strategies.","For fairness in graphs, recent studies achieve fair representations and predictions through either graph data pre-processing (e.g., node feature masking, and topology rewiring) or fair training strategies (e.g., regularization, adversarial debiasing, and fair contrastive learning).","How to achieve fairness in graphs from the model architecture perspective is less explored.","More importantly, GNNs exhibit worse fairness performance compared to multilayer perception since their model architecture (i.e., neighbor aggregation) amplifies biases.","To this end, we aim to achieve fairness via a new GNN architecture.","We propose \\textsf{F}air \\textsf{M}essage \\textsf{P}assing (FMP) designed within a unified optimization framework for GNNs.","Notably, FMP \\textit{explicitly} renders sensitive attribute usage in \\textit{forward propagation} for node classification task using cross-entropy loss without data pre-processing.","In FMP, the aggregation is first adopted to utilize neighbors' information and then the bias mitigation step explicitly pushes demographic group node presentation centers together.","In this way, FMP scheme can aggregate useful information from neighbors and mitigate bias to achieve better fairness and prediction tradeoff performance.","Experiments on node classification tasks demonstrate that the proposed FMP outperforms several baselines in terms of fairness and accuracy on three real-world datasets.","The code is available in {\\url{https://github.com/zhimengj0326/FMP}}."],"url":"http://arxiv.org/abs/2312.12369v1"}
{"created":"2023-12-19 17:48:26","title":"SpokesBiz -- an Open Corpus of Conversational Polish","abstract":"This paper announces the early release of SpokesBiz, a freely available corpus of conversational Polish developed within the CLARIN-BIZ project and comprising over 650 hours of recordings. The transcribed recordings have been diarized and manually annotated for punctuation and casing. We outline the general structure and content of the corpus, showcasing selected applications in linguistic research, evaluation and improvement of automatic speech recognition (ASR) systems","sentences":["This paper announces the early release of SpokesBiz, a freely available corpus of conversational Polish developed within the CLARIN-BIZ project and comprising over 650 hours of recordings.","The transcribed recordings have been diarized and manually annotated for punctuation and casing.","We outline the general structure and content of the corpus, showcasing selected applications in linguistic research, evaluation and improvement of automatic speech recognition (ASR) systems"],"url":"http://arxiv.org/abs/2312.12364v1"}
{"created":"2023-12-19 17:40:27","title":"CLIP-DINOiser: Teaching CLIP a few DINO tricks","abstract":"The popular CLIP model displays impressive zero-shot capabilities thanks to its seamless interaction with arbitrary text prompts. However, its lack of spatial awareness makes it unsuitable for dense computer vision tasks, e.g., semantic segmentation, without an additional fine-tuning step that often uses annotations and can potentially suppress its original open-vocabulary properties. Meanwhile, self-supervised representation methods have demonstrated good localization properties without human-made annotations nor explicit supervision. In this work, we take the best of both worlds and propose a zero-shot open-vocabulary semantic segmentation method, which does not require any annotations. We propose to locally improve dense MaskCLIP features, computed with a simple modification of CLIP's last pooling layer, by integrating localization priors extracted from self-supervised features. By doing so, we greatly improve the performance of MaskCLIP and produce smooth outputs. Moreover, we show that the used self-supervised feature properties can directly be learnt from CLIP features therefore allowing us to obtain the best results with a single pass through CLIP model. Our method CLIP-DINOiser needs only a single forward pass of CLIP and two light convolutional layers at inference, no extra supervision nor extra memory and reaches state-of-the-art results on challenging and fine-grained benchmarks such as COCO, Pascal Context, Cityscapes and ADE20k. The code to reproduce our results is available at https://github.com/wysoczanska/clip_dinoiser.","sentences":["The popular CLIP model displays impressive zero-shot capabilities thanks to its seamless interaction with arbitrary text prompts.","However, its lack of spatial awareness makes it unsuitable for dense computer vision tasks, e.g., semantic segmentation, without an additional fine-tuning step that often uses annotations and can potentially suppress its original open-vocabulary properties.","Meanwhile, self-supervised representation methods have demonstrated good localization properties without human-made annotations nor explicit supervision.","In this work, we take the best of both worlds and propose a zero-shot open-vocabulary semantic segmentation method, which does not require any annotations.","We propose to locally improve dense MaskCLIP features, computed with a simple modification of CLIP's last pooling layer, by integrating localization priors extracted from self-supervised features.","By doing so, we greatly improve the performance of MaskCLIP and produce smooth outputs.","Moreover, we show that the used self-supervised feature properties can directly be learnt from CLIP features therefore allowing us to obtain the best results with a single pass through CLIP model.","Our method CLIP-DINOiser needs only a single forward pass of CLIP and two light convolutional layers at inference, no extra supervision nor extra memory and reaches state-of-the-art results on challenging and fine-grained benchmarks such as COCO, Pascal Context, Cityscapes and ADE20k.","The code to reproduce our results is available at https://github.com/wysoczanska/clip_dinoiser."],"url":"http://arxiv.org/abs/2312.12359v1"}
{"created":"2023-12-19 17:39:48","title":"Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface","abstract":"In millimeter-wave (mmWave) cellular systems, reconfigurable intelligent surfaces (RISs) are foreseeably deployed with a large number of reflecting elements to achieve high beamforming gains. The large-sized RIS will make radio links fall in the near-field localization regime with spatial non-stationarity issues. Moreover, the discrete phase restriction on the RIS reflection coefficient incurs exponential complexity for discrete beamforming. It remains an open problem to find the optimal RIS reflection coefficient design in polynomial time. To address these issues, we propose a scalable partitioned-far-field protocol that considers both the near-filed non-stationarity and discrete beamforming. The protocol approximates near-field signal propagation using a partitioned-far-field representation to inherit the sparsity from the sophisticated far-field and facilitate the near-field localization scheme. To improve the theoretical localization performance, we propose a fast passive beamforming (FPB) algorithm that optimally solves the discrete RIS beamforming problem, reducing the search complexity from exponential order to linear order. Furthermore, by exploiting the partitioned structure of RIS, we introduce a two-stage coarse-to-fine localization algorithm that leverages both the time delay and angle information. Numerical results demonstrate that centimeter-level localization precision is achieved under medium and high signal-to-noise ratios (SNR), revealing that RISs can provide support for low-cost and high-precision localization in future cellular systems.","sentences":["In millimeter-wave (mmWave) cellular systems, reconfigurable intelligent surfaces (RISs) are foreseeably deployed with a large number of reflecting elements to achieve high beamforming gains.","The large-sized RIS will make radio links fall in the near-field localization regime with spatial non-stationarity issues.","Moreover, the discrete phase restriction on the RIS reflection coefficient incurs exponential complexity for discrete beamforming.","It remains an open problem to find the optimal RIS reflection coefficient design in polynomial time.","To address these issues, we propose a scalable partitioned-far-field protocol that considers both the near-filed non-stationarity and discrete beamforming.","The protocol approximates near-field signal propagation using a partitioned-far-field representation to inherit the sparsity from the sophisticated far-field and facilitate the near-field localization scheme.","To improve the theoretical localization performance, we propose a fast passive beamforming (FPB) algorithm that optimally solves the discrete RIS beamforming problem, reducing the search complexity from exponential order to linear order.","Furthermore, by exploiting the partitioned structure of RIS, we introduce a two-stage coarse-to-fine localization algorithm that leverages both the time delay and angle information.","Numerical results demonstrate that centimeter-level localization precision is achieved under medium and high signal-to-noise ratios (SNR), revealing that RISs can provide support for low-cost and high-precision localization in future cellular systems."],"url":"http://arxiv.org/abs/2312.12358v1"}
{"created":"2023-12-19 17:37:23","title":"How to apply tree decomposition ideas in large networks?","abstract":"Graph decompositions are the natural generalisation of tree decompositions where the decomposition tree is replaced by a genuine graph. Recently they found theoretical applications in the theory of sparsity, topological graph theory, structural graph theory and geometric group theory.   We demonstrate applicability of graph decompositions on large networks by implementing an efficient algorithm and testing it on road networks.","sentences":["Graph decompositions are the natural generalisation of tree decompositions where the decomposition tree is replaced by a genuine graph.","Recently they found theoretical applications in the theory of sparsity, topological graph theory, structural graph theory and geometric group theory.   ","We demonstrate applicability of graph decompositions on large networks by implementing an efficient algorithm and testing it on road networks."],"url":"http://arxiv.org/abs/2312.12354v1"}
{"created":"2023-12-19 17:26:44","title":"SMC-NCA: Semantic-guided Multi-level Contrast for Semi-supervised Action Segmentation","abstract":"Semi-supervised action segmentation aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels. Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data. However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem. In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for semi-supervised action segmentation. Specifically, for representation learning, SMC is firstly used to explore intra- and inter-information variations in a unified and contrastive way, based on dynamic clustering process of the original input, encoded semantic and temporal features. Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning. Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8% and 12.6% in terms of edit distance and accuracy, respectively. Additionally, the NCA unit results in significant better segmentation performance against the others in the presence of only 5% labelled videos. We also demonstrate the effectiveness of the proposed method on our Parkinson's Disease Mouse Behaviour (PDMB) dataset. The code and datasets will be made publicly available.","sentences":["Semi-supervised action segmentation aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels.","Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data.","However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem.","In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for semi-supervised action segmentation.","Specifically, for representation learning, SMC is firstly used to explore intra- and inter-information variations in a unified and contrastive way, based on dynamic clustering process of the original input, encoded semantic and temporal features.","Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning.","Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8% and 12.6% in terms of edit distance and accuracy, respectively.","Additionally, the NCA unit results in significant better segmentation performance against the others in the presence of only 5% labelled videos.","We also demonstrate the effectiveness of the proposed method on our Parkinson's Disease Mouse Behaviour (PDMB) dataset.","The code and datasets will be made publicly available."],"url":"http://arxiv.org/abs/2312.12347v1"}
{"created":"2023-12-19 17:17:52","title":"On the Effectiveness of Retrieval, Alignment, and Replay in Manipulation","abstract":"Imitation learning with visual observations is notoriously inefficient when addressed with end-to-end behavioural cloning methods. In this paper, we explore an alternative paradigm which decomposes reasoning into three phases. First, a retrieval phase, which informs the robot what it can do with an object. Second, an alignment phase, which informs the robot where to interact with the object. And third, a replay phase, which informs the robot how to interact with the object. Through a series of real-world experiments on everyday tasks, such as grasping, pouring, and inserting objects, we show that this decomposition brings unprecedented learning efficiency, and effective inter- and intra-class generalisation. Videos are available at https://www.robot-learning.uk/retrieval-alignment-replay.","sentences":["Imitation learning with visual observations is notoriously inefficient when addressed with end-to-end behavioural cloning methods.","In this paper, we explore an alternative paradigm which decomposes reasoning into three phases.","First, a retrieval phase, which informs the robot what it can do with an object.","Second, an alignment phase, which informs the robot where to interact with the object.","And third, a replay phase, which informs the robot how to interact with the object.","Through a series of real-world experiments on everyday tasks, such as grasping, pouring, and inserting objects, we show that this decomposition brings unprecedented learning efficiency, and effective inter- and intra-class generalisation.","Videos are available at https://www.robot-learning.uk/retrieval-alignment-replay."],"url":"http://arxiv.org/abs/2312.12345v1"}
{"created":"2023-12-19 17:16:43","title":"Avoiding Data Contamination in Language Model Evaluation: Dynamic Test Construction with Latest Materials","abstract":"Data contamination in evaluation is getting increasingly prevalent with the emerge of language models pre-trained on super large, automatically-crawled corpora. This problem leads to significant challenges in accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop LatestEval automated pipeline to 1) gather latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our experiments demonstrate that language models exhibit negligible memorisation behaviours on LatestEval as opposed to previous benchmarks, suggesting a significantly reduced risk of data contamination and leading to a more robust evaluation. Data and code are publicly available at: https://github.com/liyucheng09/LatestEval.","sentences":["Data contamination in evaluation is getting increasingly prevalent with the emerge of language models pre-trained on super large, automatically-crawled corpora.","This problem leads to significant challenges in accurate assessment of model capabilities and generalisations.","In this paper, we propose LatestEval, an automatic method leverages the most recent texts to create uncontaminated reading comprehension evaluations.","LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models.","We develop LatestEval automated pipeline to 1) gather latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context.","This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste.","Our experiments demonstrate that language models exhibit negligible memorisation behaviours on LatestEval as opposed to previous benchmarks, suggesting a significantly reduced risk of data contamination and leading to a more robust evaluation.","Data and code are publicly available at: https://github.com/liyucheng09/LatestEval."],"url":"http://arxiv.org/abs/2312.12343v1"}
{"created":"2023-12-19 17:14:06","title":"Engineering an Exact Pseudo-Boolean Model Counter","abstract":"Model counting, a fundamental task in computer science, involves determining the number of satisfying assignments to a Boolean formula, typically represented in conjunctive normal form (CNF). While model counting for CNF formulas has received extensive attention with a broad range of applications, the study of model counting for Pseudo-Boolean (PB) formulas has been relatively overlooked. Pseudo-Boolean formulas, being more succinct than propositional Boolean formulas, offer greater flexibility in representing real-world problems. Consequently, there is a crucial need to investigate efficient techniques for model counting for PB formulas.   In this work, we propose the first exact Pseudo-Boolean model counter, PBCount, that relies on knowledge compilation approach via algebraic decision diagrams. Our extensive empirical evaluation shows that PBCount can compute counts for 1513 instances while the current state-of-the-art approach could only handle 1013 instances. Our work opens up several avenues for future work in the context of model counting for PB formulas, such as the development of preprocessing techniques and exploration of approaches other than knowledge compilation.","sentences":["Model counting, a fundamental task in computer science, involves determining the number of satisfying assignments to a Boolean formula, typically represented in conjunctive normal form (CNF).","While model counting for CNF formulas has received extensive attention with a broad range of applications, the study of model counting for Pseudo-Boolean (PB) formulas has been relatively overlooked.","Pseudo-Boolean formulas, being more succinct than propositional Boolean formulas, offer greater flexibility in representing real-world problems.","Consequently, there is a crucial need to investigate efficient techniques for model counting for PB formulas.   ","In this work, we propose the first exact Pseudo-Boolean model counter, PBCount, that relies on knowledge compilation approach via algebraic decision diagrams.","Our extensive empirical evaluation shows that PBCount can compute counts for 1513 instances while the current state-of-the-art approach could only handle 1013 instances.","Our work opens up several avenues for future work in the context of model counting for PB formulas, such as the development of preprocessing techniques and exploration of approaches other than knowledge compilation."],"url":"http://arxiv.org/abs/2312.12341v1"}
{"created":"2023-12-19 17:13:51","title":"Scalable Geometric Fracture Assembly via Co-creation Space among Assemblers","abstract":"Geometric fracture assembly presents a challenging practical task in archaeology and 3D computer vision. Previous methods have focused solely on assembling fragments based on semantic information, which has limited the quantity of objects that can be effectively assembled. Therefore, there is a need to develop a scalable framework for geometric fracture assembly without relying on semantic information. To improve the effectiveness of assembling geometric fractures without semantic information, we propose a co-creation space comprising several assemblers capable of gradually and unambiguously assembling fractures. Additionally, we introduce a novel loss function, i.e., the geometric-based collision loss, to address collision issues during the fracture assembly process and enhance the results. Our framework exhibits better performance on both PartNet and Breaking Bad datasets compared to existing state-of-the-art frameworks. Extensive experiments and quantitative comparisons demonstrate the effectiveness of our proposed framework, which features linear computational complexity, enhanced abstraction, and improved generalization. Our code is publicly available at https://github.com/Ruiyuan-Zhang/CCS.","sentences":["Geometric fracture assembly presents a challenging practical task in archaeology and 3D computer vision.","Previous methods have focused solely on assembling fragments based on semantic information, which has limited the quantity of objects that can be effectively assembled.","Therefore, there is a need to develop a scalable framework for geometric fracture assembly without relying on semantic information.","To improve the effectiveness of assembling geometric fractures without semantic information, we propose a co-creation space comprising several assemblers capable of gradually and unambiguously assembling fractures.","Additionally, we introduce a novel loss function, i.e., the geometric-based collision loss, to address collision issues during the fracture assembly process and enhance the results.","Our framework exhibits better performance on both PartNet and Breaking Bad datasets compared to existing state-of-the-art frameworks.","Extensive experiments and quantitative comparisons demonstrate the effectiveness of our proposed framework, which features linear computational complexity, enhanced abstraction, and improved generalization.","Our code is publicly available at https://github.com/Ruiyuan-Zhang/CCS."],"url":"http://arxiv.org/abs/2312.12340v1"}
{"created":"2023-12-19 17:12:35","title":"Value Explicit Pretraining for Goal-Based Transfer Learning","abstract":"We propose a method that allows for learning task-agnostic representations based on value function estimates from a sequence of observations where the last frame corresponds to a goal. These representations would learn to relate states across different tasks, based on the temporal distance to the goal state, irrespective of the appearance changes and dynamics. This method could be used to transfer learnt policies/skills to unseen related tasks.","sentences":["We propose a method that allows for learning task-agnostic representations based on value function estimates from a sequence of observations where the last frame corresponds to a goal.","These representations would learn to relate states across different tasks, based on the temporal distance to the goal state, irrespective of the appearance changes and dynamics.","This method could be used to transfer learnt policies/skills to unseen related tasks."],"url":"http://arxiv.org/abs/2312.12339v1"}
{"created":"2023-12-19 17:08:43","title":"Smart Connected Farms and Networked Farmers to Tackle Climate Challenges Impacting Agricultural Production","abstract":"To meet the grand challenges of agricultural production including climate change impacts on crop production, a tight integration of social science, technology and agriculture experts including farmers are needed. There are rapid advances in information and communication technology, precision agriculture and data analytics, which are creating a fertile field for the creation of smart connected farms (SCF) and networked farmers. A network and coordinated farmer network provides unique advantages to farmers to enhance farm production and profitability, while tackling adverse climate events. The aim of this article is to provide a comprehensive overview of the state of the art in SCF including the advances in engineering, computer sciences, data sciences, social sciences and economics including data privacy, sharing and technology adoption.","sentences":["To meet the grand challenges of agricultural production including climate change impacts on crop production, a tight integration of social science, technology and agriculture experts including farmers are needed.","There are rapid advances in information and communication technology, precision agriculture and data analytics, which are creating a fertile field for the creation of smart connected farms (SCF) and networked farmers.","A network and coordinated farmer network provides unique advantages to farmers to enhance farm production and profitability, while tackling adverse climate events.","The aim of this article is to provide a comprehensive overview of the state of the art in SCF including the advances in engineering, computer sciences, data sciences, social sciences and economics including data privacy, sharing and technology adoption."],"url":"http://arxiv.org/abs/2312.12338v1"}
{"created":"2023-12-19 17:03:50","title":"pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction","abstract":"We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images. Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time. To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution. We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation. We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance field.","sentences":["We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images.","Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time.","To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution.","We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation.","We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance field."],"url":"http://arxiv.org/abs/2312.12337v1"}
{"created":"2023-12-19 17:01:58","title":"PowMix: A Versatile Regularizer for Multimodal Sentiment Analysis","abstract":"Multimodal sentiment analysis (MSA) leverages heterogeneous data sources to interpret the complex nature of human sentiments. Despite significant progress in multimodal architecture design, the field lacks comprehensive regularization methods. This paper introduces PowMix, a versatile embedding space regularizer that builds upon the strengths of unimodal mixing-based regularization approaches and introduces novel algorithmic components that are specifically tailored to multimodal tasks. PowMix is integrated before the fusion stage of multimodal architectures and facilitates intra-modal mixing, such as mixing text with text, to act as a regularizer. PowMix consists of five components: 1) a varying number of generated mixed examples, 2) mixing factor reweighting, 3) anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing. Extensive experimentation across benchmark MSA datasets and a broad spectrum of diverse architectural designs demonstrate the efficacy of PowMix, as evidenced by consistent performance improvements over baselines and existing mixing methods. An in-depth ablation study highlights the critical contribution of each PowMix component and how they synergistically enhance performance. Furthermore, algorithmic analysis demonstrates how PowMix behaves in different scenarios, particularly comparing early versus late fusion architectures. Notably, PowMix enhances overall performance without sacrificing model robustness or magnifying text dominance. It also retains its strong performance in situations of limited data. Our findings position PowMix as a promising versatile regularization strategy for MSA. Code will be made available.","sentences":["Multimodal sentiment analysis (MSA) leverages heterogeneous data sources to interpret the complex nature of human sentiments.","Despite significant progress in multimodal architecture design, the field lacks comprehensive regularization methods.","This paper introduces PowMix, a versatile embedding space regularizer that builds upon the strengths of unimodal mixing-based regularization approaches and introduces novel algorithmic components that are specifically tailored to multimodal tasks.","PowMix is integrated before the fusion stage of multimodal architectures and facilitates intra-modal mixing, such as mixing text with text, to act as a regularizer.","PowMix consists of five components: 1) a varying number of generated mixed examples, 2) mixing factor reweighting, 3) anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing.","Extensive experimentation across benchmark MSA datasets and a broad spectrum of diverse architectural designs demonstrate the efficacy of PowMix, as evidenced by consistent performance improvements over baselines and existing mixing methods.","An in-depth ablation study highlights the critical contribution of each PowMix component and how they synergistically enhance performance.","Furthermore, algorithmic analysis demonstrates how PowMix behaves in different scenarios, particularly comparing early versus late fusion architectures.","Notably, PowMix enhances overall performance without sacrificing model robustness or magnifying text dominance.","It also retains its strong performance in situations of limited data.","Our findings position PowMix as a promising versatile regularization strategy for MSA. Code will be made available."],"url":"http://arxiv.org/abs/2312.12334v1"}
{"created":"2023-12-19 17:01:29","title":"Path Planning for Continuum Rods Using Bernstein Surfaces","abstract":"This paper presents a method for optimal motion planning of continuum robots by employing Bernstein surfaces to approximate the system's dynamics and impose complex constraints, including collision avoidance. The main contribution is the approximation of infinite-dimensional continuous problems into their discrete counterparts, facilitating their solution using standard optimization solvers. This discretization leverages the unique properties of Bernstein surface, providing a framework that extends previous works which focused on ODEs approximated by Bernstein polynomials. Numerical validations are conducted through several numerical scenarios. The presented methodology offers a promising direction for solving complex optimal control problems in the realm of soft robotics.","sentences":["This paper presents a method for optimal motion planning of continuum robots by employing Bernstein surfaces to approximate the system's dynamics and impose complex constraints, including collision avoidance.","The main contribution is the approximation of infinite-dimensional continuous problems into their discrete counterparts, facilitating their solution using standard optimization solvers.","This discretization leverages the unique properties of Bernstein surface, providing a framework that extends previous works which focused on ODEs approximated by Bernstein polynomials.","Numerical validations are conducted through several numerical scenarios.","The presented methodology offers a promising direction for solving complex optimal control problems in the realm of soft robotics."],"url":"http://arxiv.org/abs/2312.12333v1"}
{"created":"2023-12-19 16:52:29","title":"Optimizing Local Satisfaction of Long-Run Average Objectives in Markov Decision Processes","abstract":"Long-run average optimization problems for Markov decision processes (MDPs) require constructing policies with optimal steady-state behavior, i.e., optimal limit frequency of visits to the states. However, such policies may suffer from local instability, i.e., the frequency of states visited in a bounded time horizon along a run differs significantly from the limit frequency. In this work, we propose an efficient algorithmic solution to this problem.","sentences":["Long-run average optimization problems for Markov decision processes (MDPs) require constructing policies with optimal steady-state behavior, i.e., optimal limit frequency of visits to the states.","However, such policies may suffer from local instability, i.e., the frequency of states visited in a bounded time horizon along a run differs significantly from the limit frequency.","In this work, we propose an efficient algorithmic solution to this problem."],"url":"http://arxiv.org/abs/2312.12325v1"}
{"created":"2023-12-19 16:47:12","title":"Bypassing the Safety Training of Open-Source LLMs with Priming Attacks","abstract":"With the recent surge in popularity of LLMs has come an ever-increasing need for LLM safety training. In this paper, we show that SOTA open-source LLMs are vulnerable to simple, optimization-free attacks we refer to as $\\textit{priming attacks}$, which are easy to execute and effectively bypass alignment from safety training. Our proposed attack improves the Attack Success Rate on Harmful Behaviors, as measured by Llama Guard, by up to $3.3\\times$ compared to baselines. Source code and data are available at https://github.com/uiuc-focal-lab/llm-priming-attacks .","sentences":["With the recent surge in popularity of LLMs has come an ever-increasing need for LLM safety training.","In this paper, we show that SOTA open-source LLMs are vulnerable to simple, optimization-free attacks we refer to as $\\textit{priming attacks}$, which are easy to execute and effectively bypass alignment from safety training.","Our proposed attack improves the Attack Success Rate on Harmful Behaviors, as measured by Llama Guard, by up to $3.3\\times$ compared to baselines.","Source code and data are available at https://github.com/uiuc-focal-lab/llm-priming-attacks ."],"url":"http://arxiv.org/abs/2312.12321v1"}
{"created":"2023-12-19 16:43:17","title":"An Alternate View on Optimal Filtering in an RKHS","abstract":"Kernel Adaptive Filtering (KAF) are mathematically principled methods which search for a function in a Reproducing Kernel Hilbert Space. While they work well for tasks such as time series prediction and system identification they are plagued by a linear relationship between number of training samples and model size, hampering their use on the very large data sets common in today's data saturated world. Previous methods try to solve this issue by sparsification. We describe a novel view of optimal filtering which may provide a route towards solutions in a RKHS which do not necessarily have this linear growth in model size. We do this by defining a RKHS in which the time structure of a stochastic process is still present. Using correntropy [11], an extension of the idea of a covariance function, we create a time based functional which describes some potentially nonlinear desired mapping function. This form of a solution may provide a fruitful line of research for creating more efficient representations of functionals in a RKHS, while theoretically providing computational complexity in the test set similar to Wiener solution.","sentences":["Kernel Adaptive Filtering (KAF) are mathematically principled methods which search for a function in a Reproducing Kernel Hilbert Space.","While they work well for tasks such as time series prediction and system identification they are plagued by a linear relationship between number of training samples and model size, hampering their use on the very large data sets common in today's data saturated world.","Previous methods try to solve this issue by sparsification.","We describe a novel view of optimal filtering which may provide a route towards solutions in a RKHS which do not necessarily have this linear growth in model size.","We do this by defining a RKHS in which the time structure of a stochastic process is still present.","Using correntropy","[11], an extension of the idea of a covariance function, we create a time based functional which describes some potentially nonlinear desired mapping function.","This form of a solution may provide a fruitful line of research for creating more efficient representations of functionals in a RKHS, while theoretically providing computational complexity in the test set similar to Wiener solution."],"url":"http://arxiv.org/abs/2312.12318v1"}
{"created":"2023-12-19 16:39:02","title":"First qualitative observations on deep learning vision model YOLO and DETR for automated driving in Austria","abstract":"This study investigates the application of single and two-stage 2D-object detection algorithms like You Only Look Once (YOLO), Real-Time DEtection TRansformer (RT-DETR) algorithm for automated object detection to enhance road safety for autonomous driving on Austrian roads. The YOLO algorithm is a state-of-the-art real-time object detection system known for its efficiency and accuracy. In the context of driving, its potential to rapidly identify and track objects is crucial for advanced driver assistance systems (ADAS) and autonomous vehicles. The research focuses on the unique challenges posed by the road conditions and traffic scenarios in Austria. The country's diverse landscape, varying weather conditions, and specific traffic regulations necessitate a tailored approach for reliable object detection. The study utilizes a selective dataset comprising images and videos captured on Austrian roads, encompassing urban, rural, and alpine environments.","sentences":["This study investigates the application of single and two-stage 2D-object detection algorithms like You Only Look Once (YOLO), Real-Time DEtection TRansformer (RT-DETR) algorithm for automated object detection to enhance road safety for autonomous driving on Austrian roads.","The YOLO algorithm is a state-of-the-art real-time object detection system known for its efficiency and accuracy.","In the context of driving, its potential to rapidly identify and track objects is crucial for advanced driver assistance systems (ADAS) and autonomous vehicles.","The research focuses on the unique challenges posed by the road conditions and traffic scenarios in Austria.","The country's diverse landscape, varying weather conditions, and specific traffic regulations necessitate a tailored approach for reliable object detection.","The study utilizes a selective dataset comprising images and videos captured on Austrian roads, encompassing urban, rural, and alpine environments."],"url":"http://arxiv.org/abs/2312.12314v1"}
{"created":"2023-12-19 16:34:53","title":"Bioinspired Soft Robotics: state of the art, challenges, and future directions","abstract":"Purpose of Review: This review provides an overview of the state of the art in bioinspired soft robotics with by examining advancements in actuation, functionality, modeling, and control. Recent Findings: Recent research into actuation methods, such as artificial muscles, have expanded the functionality and potential use of bioinspired soft robots. Additionally, the application of finite dimensional models has improved computational efficiency for modeling soft continuum systems, and garnered interest as a basis for controller formulation. Summary: Bioinspiration in the field of soft robotics has led to diverse approaches to problems in a range of task spaces. In particular, new capabilities in system simplification, miniaturization, and untethering have each contributed to the field's growth. There is still significant room for improvement in the streamlining of design and manufacturing for these systems, as well as in their control.","sentences":["Purpose of Review: This review provides an overview of the state of the art in bioinspired soft robotics with by examining advancements in actuation, functionality, modeling, and control.","Recent Findings:","Recent research into actuation methods, such as artificial muscles, have expanded the functionality and potential use of bioinspired soft robots.","Additionally, the application of finite dimensional models has improved computational efficiency for modeling soft continuum systems, and garnered interest as a basis for controller formulation.","Summary: Bioinspiration in the field of soft robotics has led to diverse approaches to problems in a range of task spaces.","In particular, new capabilities in system simplification, miniaturization, and untethering have each contributed to the field's growth.","There is still significant room for improvement in the streamlining of design and manufacturing for these systems, as well as in their control."],"url":"http://arxiv.org/abs/2312.12312v1"}
{"created":"2023-12-19 16:29:07","title":"TeamCAD -- A Multimodal Interface for Remote Computer Aided Design","abstract":"Remote collaboration is a common reality of spatial design processes, but tools for computer aided design were made for single users. Via TeamCAD, we introduce a user experience where online remote collaboration experience is more like working on a table. Using speech and gesture recognition based on state of the art machine learning through webcam and microphone input, TeamCAD plugs into existing software through API's, keybindings, and mouse input. We share results from user studies conducted on graduate students from <removed for double blind review>. Our user tests were run on Blender animation software, making simultaneous use of both modalities for given tasks. We mitigated challenges in terms of robustness and latency in readily available voice recognition models. Our prototype has proven to be an intuitive interface, providing a suitable denominator for collaborators with or without previous experience in three-dimensional modeling applications.","sentences":["Remote collaboration is a common reality of spatial design processes, but tools for computer aided design were made for single users.","Via TeamCAD, we introduce a user experience where online remote collaboration experience is more like working on a table.","Using speech and gesture recognition based on state of the art machine learning through webcam and microphone input, TeamCAD plugs into existing software through API's, keybindings, and mouse input.","We share results from user studies conducted on graduate students from <removed for double blind review>.","Our user tests were run on Blender animation software, making simultaneous use of both modalities for given tasks.","We mitigated challenges in terms of robustness and latency in readily available voice recognition models.","Our prototype has proven to be an intuitive interface, providing a suitable denominator for collaborators with or without previous experience in three-dimensional modeling applications."],"url":"http://arxiv.org/abs/2312.12309v1"}
{"created":"2023-12-19 16:21:51","title":"Peer Neighborhood Mechanisms: A Framework for Mechanism Generalization","abstract":"Peer prediction incentive mechanisms for crowdsourcing are generally limited to eliciting samples from categorical distributions. Prior work on extending peer prediction to arbitrary distributions has largely relied on assumptions on the structures of the distributions or known properties of the data providers. We introduce a novel class of incentive mechanisms that extend peer prediction mechanisms to arbitrary distributions by replacing the notion of an exact match with a concept of neighborhood matching. We present conditions on the belief updates of the data providers that guarantee incentive-compatibility for rational data providers, and admit a broad class of possible reasonable updates.","sentences":["Peer prediction incentive mechanisms for crowdsourcing are generally limited to eliciting samples from categorical distributions.","Prior work on extending peer prediction to arbitrary distributions has largely relied on assumptions on the structures of the distributions or known properties of the data providers.","We introduce a novel class of incentive mechanisms that extend peer prediction mechanisms to arbitrary distributions by replacing the notion of an exact match with a concept of neighborhood matching.","We present conditions on the belief updates of the data providers that guarantee incentive-compatibility for rational data providers, and admit a broad class of possible reasonable updates."],"url":"http://arxiv.org/abs/2312.12303v1"}
{"created":"2023-12-19 16:20:49","title":"Instruct-SCTG: Guiding Sequential Controlled Text Generation through Instructions","abstract":"Instruction-tuned large language models have shown remarkable performance in aligning generated text with user intentions across various tasks. However, maintaining human-like discourse structure in the generated text remains a challenging research question. In this paper, we propose Instruct-SCTG, a flexible and effective sequential framework that harnesses instruction-tuned language models to generate structurally coherent text in both fine-tuned and zero-shot setups. Our framework generates articles in a section-by-section manner, aligned with the desired human structure using natural language instructions. Furthermore, we introduce a new automatic metric that measures discourse divergence in a fuzzy manner. Extensive experiments on three datasets from representative domains of news and recipes demonstrate the state-of-the-art performance of our framework in imposing discourse structure during text generation, as verified by both automatic and human evaluation. Our code will be available on Github.","sentences":["Instruction-tuned large language models have shown remarkable performance in aligning generated text with user intentions across various tasks.","However, maintaining human-like discourse structure in the generated text remains a challenging research question.","In this paper, we propose Instruct-SCTG, a flexible and effective sequential framework that harnesses instruction-tuned language models to generate structurally coherent text in both fine-tuned and zero-shot setups.","Our framework generates articles in a section-by-section manner, aligned with the desired human structure using natural language instructions.","Furthermore, we introduce a new automatic metric that measures discourse divergence in a fuzzy manner.","Extensive experiments on three datasets from representative domains of news and recipes demonstrate the state-of-the-art performance of our framework in imposing discourse structure during text generation, as verified by both automatic and human evaluation.","Our code will be available on Github."],"url":"http://arxiv.org/abs/2312.12299v1"}
{"created":"2023-12-19 16:17:35","title":"Describing Robots from Design to Learning: Towards an Interactive Lifecycle Representation of Robots","abstract":"The robot development process is divided into several stages, which create barriers to the exchange of information between these different stages. We advocate for an interactive lifecycle representation, extending from robot morphology design to learning, and introduce the role of robot description formats in facilitating information transfer throughout this pipeline. We analyzed the relationship between design and simulation, enabling us to employ robot process automation methods for transferring information from the design phase to the learning phase in simulation. As part of this effort, we have developed an open-source plugin called ACDC4Robot for Fusion 360, which automates this process and transforms Fusion 360 into a user-friendly graphical interface for creating and editing robot description formats. Additionally, we offer an out-of-the-box robot model library to streamline and reduce repetitive tasks. All codes are hosted open-source. (\\url{https://github.com/bionicdl-sustech/ACDC4Robot})","sentences":["The robot development process is divided into several stages, which create barriers to the exchange of information between these different stages.","We advocate for an interactive lifecycle representation, extending from robot morphology design to learning, and introduce the role of robot description formats in facilitating information transfer throughout this pipeline.","We analyzed the relationship between design and simulation, enabling us to employ robot process automation methods for transferring information from the design phase to the learning phase in simulation.","As part of this effort, we have developed an open-source plugin called ACDC4Robot for Fusion 360, which automates this process and transforms Fusion 360 into a user-friendly graphical interface for creating and editing robot description formats.","Additionally, we offer an out-of-the-box robot model library to streamline and reduce repetitive tasks.","All codes are hosted open-source.","(\\url{https://github.com/bionicdl-sustech/ACDC4Robot})"],"url":"http://arxiv.org/abs/2312.12295v1"}
{"created":"2023-12-19 16:13:47","title":"Toward enriched Cognitive Learning with XAI","abstract":"As computational systems supported by artificial intelligence (AI) techniques continue to play an increasingly pivotal role in making high-stakes recommendations and decisions across various domains, the demand for explainable AI (XAI) has grown significantly, extending its impact into cognitive learning research. Providing explanations for novel concepts is recognised as a fundamental aid in the learning process, particularly when addressing challenges stemming from knowledge deficiencies and skill application. Addressing these difficulties involves timely explanations and guidance throughout the learning process, prompting the interest of AI experts in developing explainer models. In this paper, we introduce an intelligent system (CL-XAI) for Cognitive Learning which is supported by XAI, focusing on two key research objectives: exploring how human learners comprehend the internal mechanisms of AI models using XAI tools and evaluating the effectiveness of such tools through human feedback. The use of CL-XAI is illustrated with a game-inspired virtual use case where learners tackle combinatorial problems to enhance problem-solving skills and deepen their understanding of complex concepts, highlighting the potential for transformative advances in cognitive learning and co-learning.","sentences":["As computational systems supported by artificial intelligence (AI) techniques continue to play an increasingly pivotal role in making high-stakes recommendations and decisions across various domains, the demand for explainable AI (XAI) has grown significantly, extending its impact into cognitive learning research.","Providing explanations for novel concepts is recognised as a fundamental aid in the learning process, particularly when addressing challenges stemming from knowledge deficiencies and skill application.","Addressing these difficulties involves timely explanations and guidance throughout the learning process, prompting the interest of AI experts in developing explainer models.","In this paper, we introduce an intelligent system (CL-XAI) for Cognitive Learning which is supported by XAI, focusing on two key research objectives: exploring how human learners comprehend the internal mechanisms of AI models using XAI tools and evaluating the effectiveness of such tools through human feedback.","The use of CL-XAI is illustrated with a game-inspired virtual use case where learners tackle combinatorial problems to enhance problem-solving skills and deepen their understanding of complex concepts, highlighting the potential for transformative advances in cognitive learning and co-learning."],"url":"http://arxiv.org/abs/2312.12290v1"}
{"created":"2023-12-19 16:12:40","title":"New Qutrit Codes from Pure and Bordered Multidimensional Circulant Construction","abstract":"We use multidimensional circulant approach to construct new qutrit stabilizer $\\dsb{\\ell, 0, d}$ codes with parameters $(\\ell, d) \\in \\{(51, 16), (52, 16), (54, 17), (55, 17), (57, 17)\\}$ through symplectic self-dual additive codes over $\\F_9$. In addition to these five new codes, we use bordered construction to derive two more qutrit codes with parameters $(\\ell, d) \\in \\{(53, 16), (56, 17)\\}$ that improve upon previously best known parameters.","sentences":["We use multidimensional circulant approach to construct new qutrit stabilizer $\\dsb{\\ell, 0, d}$ codes with parameters $(\\ell, d) \\in \\{(51, 16), (52, 16), (54, 17), (55, 17), (57, 17)\\}$ through symplectic self-dual additive codes over $\\F_9$. In addition to these five new codes, we use bordered construction to derive two more qutrit codes with parameters $(\\ell, d) \\in \\{(53, 16), (56, 17)\\}$ that improve upon previously best known parameters."],"url":"http://arxiv.org/abs/2312.12288v1"}
{"created":"2023-12-19 16:00:13","title":"The Hardness of Local Certification of Finite-State Dynamics","abstract":"Finite-State Dynamics (FSD) is one of the simplest and constrained distributed systems. An FSD is defined by an $n$-node network, with each node maintaining an internal state selected from a finite set. At each time-step, these nodes synchronously update their internal states based solely on the states of their neighboring nodes.   Rather than focusing on specific types of local functions, in this article, our primary focus is on the problem of determining the maximum time required for an FSD to reach a stable global state. This global state can be seen as the acceptance state or as the output of a distributed computation. For fixed $k$ and $q$, we define the problem $\\text{convergence}(k,q)$, which consists of deciding if a $q$-state FSD converges in at most $k$ time-steps.   Our main focus is to study the problem $\\text{convergence}$ from the perspective of distributed certification, with a focus on the model of proof-labeling schemes (PLS). First, we study the problem $\\text{convergence}$ on arbitrary graphs and show that every PLS has certificates of size $\\Theta(n^2)$ (up to logarithmic factors). Then, we turn to the restriction of the problem on graphs of maximum degree $\\Delta$. Roughly, we show that the problem admits a PLS with certificates of size $\\Delta^{k+1}$, while every PLS requires certificates of size at least $2^{k/6} \\cdot 6/k$ on graphs of maximum degree 3.","sentences":["Finite-State Dynamics (FSD) is one of the simplest and constrained distributed systems.","An FSD is defined by an $n$-node network, with each node maintaining an internal state selected from a finite set.","At each time-step, these nodes synchronously update their internal states based solely on the states of their neighboring nodes.   ","Rather than focusing on specific types of local functions, in this article, our primary focus is on the problem of determining the maximum time required for an FSD to reach a stable global state.","This global state can be seen as the acceptance state or as the output of a distributed computation.","For fixed $k$ and $q$, we define the problem $\\text{convergence}(k,q)$, which consists of deciding if a $q$-state FSD converges in at most $k$ time-steps.   ","Our main focus is to study the problem $\\text{convergence}$ from the perspective of distributed certification, with a focus on the model of proof-labeling schemes (PLS).","First, we study the problem $\\text{convergence}$ on arbitrary graphs and show that every PLS has certificates of size $\\Theta(n^2)$ (up to logarithmic factors).","Then, we turn to the restriction of the problem on graphs of maximum degree $\\Delta$. Roughly, we show that the problem admits a PLS with certificates of size $\\Delta^{k+1}$, while every PLS requires certificates of size at least $2^{k/6} \\cdot 6/k$ on graphs of maximum degree 3."],"url":"http://arxiv.org/abs/2312.12278v1"}
{"created":"2023-12-19 15:57:37","title":"Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation","abstract":"Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis. Despite the numerous domain adaptation techniques proposed to tackle this complex problem, their primary focus has been on the common representations of time series data. This concentration might inadvertently lead to the oversight of valuable domain-specific information originating from different source domains. To bridge this gap, we introduce POND, a novel prompt-based deep learning model designed explicitly for multi-source time series domain adaptation. POND is tailored to address significant challenges, notably: 1) The unavailability of a quantitative relationship between meta-data information and time series distributions, and 2) The dearth of exploration into extracting domain-specific meta-data information. In this paper, we present an instance-level prompt generator and a fidelity loss mechanism to facilitate the faithful learning of meta-data information. Additionally, we propose a domain discrimination technique to discern domain-specific meta-data information from multiple source domains. Our approach involves a simple yet effective meta-learning algorithm to optimize the objective efficiently. Furthermore, we augment the model's performance by incorporating the Mixture of Expert (MoE) technique. The efficacy and robustness of our proposed POND model are extensively validated through experiments across 50 scenarios encompassing five datasets, which demonstrates that our proposed POND model outperforms the state-of-the-art methods by up to $66\\%$ on the F1-score.","sentences":["Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis.","Despite the numerous domain adaptation techniques proposed to tackle this complex problem, their primary focus has been on the common representations of time series data.","This concentration might inadvertently lead to the oversight of valuable domain-specific information originating from different source domains.","To bridge this gap, we introduce POND, a novel prompt-based deep learning model designed explicitly for multi-source time series domain adaptation.","POND is tailored to address significant challenges, notably: 1) The unavailability of a quantitative relationship between meta-data information and time series distributions, and 2)","The dearth of exploration into extracting domain-specific meta-data information.","In this paper, we present an instance-level prompt generator and a fidelity loss mechanism to facilitate the faithful learning of meta-data information.","Additionally, we propose a domain discrimination technique to discern domain-specific meta-data information from multiple source domains.","Our approach involves a simple yet effective meta-learning algorithm to optimize the objective efficiently.","Furthermore, we augment the model's performance by incorporating the Mixture of Expert (MoE) technique.","The efficacy and robustness of our proposed POND model are extensively validated through experiments across 50 scenarios encompassing five datasets, which demonstrates that our proposed POND model outperforms the state-of-the-art methods by up to $66\\%$ on the F1-score."],"url":"http://arxiv.org/abs/2312.12276v1"}
{"created":"2023-12-19 15:56:30","title":"Emergence of In-Context Reinforcement Learning from Noise Distillation","abstract":"In-Context Reinforcement Learning is an emerging field with great potential for advancing Artificial Intelligence. Its core capability lies in generalizing to unseen tasks through interaction with the environment. To master these capabilities, an agent must be trained on specifically curated data that includes a policy improvement that an algorithm seeks to extract and then apply in context in the environment. However, for numerous tasks, training RL agents may be unfeasible, while obtaining human demonstrations can be relatively easy. Additionally, it is rare to be given the optimal policy, typically, only suboptimal demonstrations are available. We propose $AD^{\\epsilon}$, a method that leverages demonstrations without policy improvement and enables multi-task in-context learning in the presence of a suboptimal demonstrator. This is achieved by artificially creating a history of incremental improvement, wherein noise is systematically introduced into the demonstrator's policy. Consequently, each successive transition illustrates a marginally better trajectory than the previous one. Our approach was tested on the Dark Room and Dark Key-to-Door environments, resulting in over a $\\textbf{2}$x improvement compared to the best available policy in the data.","sentences":["In-Context Reinforcement Learning is an emerging field with great potential for advancing Artificial Intelligence.","Its core capability lies in generalizing to unseen tasks through interaction with the environment.","To master these capabilities, an agent must be trained on specifically curated data that includes a policy improvement that an algorithm seeks to extract and then apply in context in the environment.","However, for numerous tasks, training RL agents may be unfeasible, while obtaining human demonstrations can be relatively easy.","Additionally, it is rare to be given the optimal policy, typically, only suboptimal demonstrations are available.","We propose $AD^{\\epsilon}$, a method that leverages demonstrations without policy improvement and enables multi-task in-context learning in the presence of a suboptimal demonstrator.","This is achieved by artificially creating a history of incremental improvement, wherein noise is systematically introduced into the demonstrator's policy.","Consequently, each successive transition illustrates a marginally better trajectory than the previous one.","Our approach was tested on the Dark Room and Dark Key-to-Door environments, resulting in over a $\\textbf{2}$x improvement compared to the best available policy in the data."],"url":"http://arxiv.org/abs/2312.12275v1"}
{"created":"2023-12-19 15:56:19","title":"Intrinsic Image Diffusion for Single-view Material Estimation","abstract":"We present Intrinsic Image Diffusion, a generative model for appearance decomposition of indoor scenes. Given a single input view, we sample multiple possible material explanations represented as albedo, roughness, and metallic maps. Appearance decomposition poses a considerable challenge in computer vision due to the inherent ambiguity between lighting and material properties and the lack of real datasets. To address this issue, we advocate for a probabilistic formulation, where instead of attempting to directly predict the true material properties, we employ a conditional generative model to sample from the solution space. Furthermore, we show that utilizing the strong learned prior of recent diffusion models trained on large-scale real-world images can be adapted to material estimation and highly improves the generalization to real images. Our method produces significantly sharper, more consistent, and more detailed materials, outperforming state-of-the-art methods by $1.5dB$ on PSNR and by $45\\%$ better FID score on albedo prediction. We demonstrate the effectiveness of our approach through experiments on both synthetic and real-world datasets.","sentences":["We present Intrinsic Image Diffusion, a generative model for appearance decomposition of indoor scenes.","Given a single input view, we sample multiple possible material explanations represented as albedo, roughness, and metallic maps.","Appearance decomposition poses a considerable challenge in computer vision due to the inherent ambiguity between lighting and material properties and the lack of real datasets.","To address this issue, we advocate for a probabilistic formulation, where instead of attempting to directly predict the true material properties, we employ a conditional generative model to sample from the solution space.","Furthermore, we show that utilizing the strong learned prior of recent diffusion models trained on large-scale real-world images can be adapted to material estimation and highly improves the generalization to real images.","Our method produces significantly sharper, more consistent, and more detailed materials, outperforming state-of-the-art methods by $1.5dB$ on PSNR and by $45\\%$ better FID score on albedo prediction.","We demonstrate the effectiveness of our approach through experiments on both synthetic and real-world datasets."],"url":"http://arxiv.org/abs/2312.12274v1"}
{"created":"2023-12-19 15:56:08","title":"VQA4CIR: Boosting Composed Image Retrieval with Visual Question Answering","abstract":"Albeit progress has been made in Composed Image Retrieval (CIR), we empirically find that a certain percentage of failure retrieval results are not consistent with their relative captions. To address this issue, this work provides a Visual Question Answering (VQA) perspective to boost the performance of CIR. The resulting VQA4CIR is a post-processing approach and can be directly plugged into existing CIR methods. Given the top-C retrieved images by a CIR method, VQA4CIR aims to decrease the adverse effect of the failure retrieval results being inconsistent with the relative caption. To find the retrieved images inconsistent with the relative caption, we resort to the \"QA generation to VQA\" self-verification pipeline. For QA generation, we suggest fine-tuning LLM (e.g., LLaMA) to generate several pairs of questions and answers from each relative caption. We then fine-tune LVLM (e.g., LLaVA) to obtain the VQA model. By feeding the retrieved image and question to the VQA model, one can find the images inconsistent with relative caption when the answer by VQA is inconsistent with the answer in the QA pair. Consequently, the CIR performance can be boosted by modifying the ranks of inconsistently retrieved images. Experimental results show that our proposed method outperforms state-of-the-art CIR methods on the CIRR and Fashion-IQ datasets.","sentences":["Albeit progress has been made in Composed Image Retrieval (CIR), we empirically find that a certain percentage of failure retrieval results are not consistent with their relative captions.","To address this issue, this work provides a Visual Question Answering (VQA) perspective to boost the performance of CIR.","The resulting VQA4CIR is a post-processing approach and can be directly plugged into existing CIR methods.","Given the top-C retrieved images by a CIR method, VQA4CIR aims to decrease the adverse effect of the failure retrieval results being inconsistent with the relative caption.","To find the retrieved images inconsistent with the relative caption, we resort to the \"QA generation to VQA\" self-verification pipeline.","For QA generation, we suggest fine-tuning LLM (e.g., LLaMA) to generate several pairs of questions and answers from each relative caption.","We then fine-tune LVLM (e.g., LLaVA) to obtain the VQA model.","By feeding the retrieved image and question to the VQA model, one can find the images inconsistent with relative caption when the answer by VQA is inconsistent with the answer in the QA pair.","Consequently, the CIR performance can be boosted by modifying the ranks of inconsistently retrieved images.","Experimental results show that our proposed method outperforms state-of-the-art CIR methods on the CIRR and Fashion-IQ datasets."],"url":"http://arxiv.org/abs/2312.12273v1"}
{"created":"2023-12-19 15:52:28","title":"Sketch Vision: Artificial Intelligence with Sight for Imagination","abstract":"Visual design relies on seeing things in different ways, acting on them, and seeing results to act again. Parametric design tools are often not robust to design changes that result from sketching over the visualization of their output. We propose a sketch to 3d workflow as an experiment medium for evaluating neural networks and their latent spaces as a representation that is robust to overlay sketching.","sentences":["Visual design relies on seeing things in different ways, acting on them, and seeing results to act again.","Parametric design tools are often not robust to design changes that result from sketching over the visualization of their output.","We propose a sketch to 3d workflow as an experiment medium for evaluating neural networks and their latent spaces as a representation that is robust to overlay sketching."],"url":"http://arxiv.org/abs/2312.12270v1"}
{"created":"2023-12-19 15:51:49","title":"Automated speech audiometry: Can it work using open-source pre-trained Kaldi-NL automatic speech recognition?","abstract":"A practical speech audiometry tool is the digits-in-noise (DIN) test for hearing screening of populations of varying ages and hearing status. The test is usually conducted by a human supervisor (e.g., clinician), who scores the responses spoken by the listener, or online, where a software scores the responses entered by the listener. The test has 24 digit-triplets presented in an adaptive staircase procedure, resulting in a speech reception threshold (SRT). We propose an alternative automated DIN test setup that can evaluate spoken responses whilst conducted without a human supervisor, using the open-source automatic speech recognition toolkit, Kaldi-NL. Thirty self-reported normal-hearing Dutch adults (19-64 years) completed one DIN+Kaldi-NL test. Their spoken responses were recorded, and used for evaluating the transcript of decoded responses by Kaldi-NL. Study 1 evaluated the Kaldi-NL performance through its word error rate (WER), percentage of summed decoding errors regarding only digits found in the transcript compared to the total number of digits present in the spoken responses. Average WER across participants was 5.0% (range 0 - 48%, SD = 8.8%), with average decoding errors in three triplets per participant. Study 2 analysed the effect that triplets with decoding errors from Kaldi-NL had on the DIN test output (SRT), using bootstrapping simulations. Previous research indicated 0.70 dB as the typical within-subject SRT variability for normal-hearing adults. Study 2 showed that up to four triplets with decoding errors produce SRT variations within this range, suggesting that our proposed setup could be feasible for clinical applications.","sentences":["A practical speech audiometry tool is the digits-in-noise (DIN) test for hearing screening of populations of varying ages and hearing status.","The test is usually conducted by a human supervisor (e.g., clinician), who scores the responses spoken by the listener, or online, where a software scores the responses entered by the listener.","The test has 24 digit-triplets presented in an adaptive staircase procedure, resulting in a speech reception threshold (SRT).","We propose an alternative automated DIN test setup that can evaluate spoken responses whilst conducted without a human supervisor, using the open-source automatic speech recognition toolkit, Kaldi-NL.","Thirty self-reported normal-hearing Dutch adults (19-64 years) completed one DIN+Kaldi-NL test.","Their spoken responses were recorded, and used for evaluating the transcript of decoded responses by Kaldi-NL.","Study 1 evaluated the Kaldi-NL performance through its word error rate (WER), percentage of summed decoding errors regarding only digits found in the transcript compared to the total number of digits present in the spoken responses.","Average WER across participants was 5.0% (range 0 - 48%, SD = 8.8%), with average decoding errors in three triplets per participant.","Study 2 analysed the effect that triplets with decoding errors from Kaldi-NL had on the DIN test output (SRT), using bootstrapping simulations.","Previous research indicated 0.70 dB as the typical within-subject SRT variability for normal-hearing adults.","Study 2 showed that up to four triplets with decoding errors produce SRT variations within this range, suggesting that our proposed setup could be feasible for clinical applications."],"url":"http://arxiv.org/abs/2312.12269v1"}
{"created":"2023-12-19 15:51:26","title":"Web 3.0 and a Decentralized Approach to Education","abstract":"With the natural evolution of the web, the need for decentralization has rendered the current centralized education system out of date. The student does not \"own\" their credentials, as the only way their accomplishments are directly linked to their person and considered valuable is by verification through a stamp of an expensive, prestigious institution. However, going to a university is no longer the only way to acquire an education; open-source learning material is widely available and accessible through the internet. However, our society does not deem these methods of education as verifiable if they do not include a degree or certificate. Additionally, a valid certificate for the vast majority of open-source courses costs a few hundred dollars to obtain. The centralized nature of education inadvertently places students in underprivileged communities at a disadvantage in comparison to students in economically advantaged communities, thus a decentralized approach to education would eliminate the vast majority of such discrepancies. In the present paper, we integrate Decentralized Identity (DID) with Web 3.0 to upload credentials linked directly to the user. Each credential is appended to an Ethereum blockchain that, by design, cannot be altered once uploaded. We include DID document based access controls to display the candidate's upload and verification history. Finally, we utilize TLS protocols to provide a secure connection to the internet for ensuring non-fungibility of credentials and authentication of users.","sentences":["With the natural evolution of the web, the need for decentralization has rendered the current centralized education system out of date.","The student does not \"own\" their credentials, as the only way their accomplishments are directly linked to their person and considered valuable is by verification through a stamp of an expensive, prestigious institution.","However, going to a university is no longer the only way to acquire an education; open-source learning material is widely available and accessible through the internet.","However, our society does not deem these methods of education as verifiable if they do not include a degree or certificate.","Additionally, a valid certificate for the vast majority of open-source courses costs a few hundred dollars to obtain.","The centralized nature of education inadvertently places students in underprivileged communities at a disadvantage in comparison to students in economically advantaged communities, thus a decentralized approach to education would eliminate the vast majority of such discrepancies.","In the present paper, we integrate Decentralized Identity (DID) with Web 3.0 to upload credentials linked directly to the user.","Each credential is appended to an Ethereum blockchain that, by design, cannot be altered once uploaded.","We include DID document based access controls to display the candidate's upload and verification history.","Finally, we utilize TLS protocols to provide a secure connection to the internet for ensuring non-fungibility of credentials and authentication of users."],"url":"http://arxiv.org/abs/2312.12268v1"}
{"created":"2023-12-19 15:46:47","title":"FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels","abstract":"Federated learning with noisy labels (F-LNL) aims at seeking an optimal server model via collaborative distributed learning by aggregating multiple client models trained with local noisy or clean samples. On the basis of a federated learning framework, recent advances primarily adopt label noise filtering to separate clean samples from noisy ones on each client, thereby mitigating the negative impact of label noise. However, these prior methods do not learn noise filters by exploiting knowledge across all clients, leading to sub-optimal and inferior noise filtering performance and thus damaging training stability. In this paper, we present FedDiv to tackle the challenges of F-LNL. Specifically, we propose a global noise filter called Federated Noise Filter for effectively identifying samples with noisy labels on every client, thereby raising stability during local training sessions. Without sacrificing data privacy, this is achieved by modeling the global distribution of label noise across all clients. Then, in an effort to make the global model achieve higher performance, we introduce a Predictive Consistency based Sampler to identify more credible local data for local model training, thus preventing noise memorization and further boosting the training stability. Extensive experiments on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv} achieves superior performance over state-of-the-art F-LNL methods under different label noise settings for both IID and non-IID data partitions. Source code is publicly available at https://github.com/lijichang/FLNL-FedDiv.","sentences":["Federated learning with noisy labels (F-LNL) aims at seeking an optimal server model via collaborative distributed learning by aggregating multiple client models trained with local noisy or clean samples.","On the basis of a federated learning framework, recent advances primarily adopt label noise filtering to separate clean samples from noisy ones on each client, thereby mitigating the negative impact of label noise.","However, these prior methods do not learn noise filters by exploiting knowledge across all clients, leading to sub-optimal and inferior noise filtering performance and thus damaging training stability.","In this paper, we present FedDiv to tackle the challenges of F-LNL.","Specifically, we propose a global noise filter called Federated Noise Filter for effectively identifying samples with noisy labels on every client, thereby raising stability during local training sessions.","Without sacrificing data privacy, this is achieved by modeling the global distribution of label noise across all clients.","Then, in an effort to make the global model achieve higher performance, we introduce a Predictive Consistency based Sampler to identify more credible local data for local model training, thus preventing noise memorization and further boosting the training stability.","Extensive experiments on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \\texttt{FedDiv} achieves superior performance over state-of-the-art F-LNL methods under different label noise settings for both IID and non-IID data partitions.","Source code is publicly available at https://github.com/lijichang/FLNL-FedDiv."],"url":"http://arxiv.org/abs/2312.12263v1"}
{"created":"2023-12-19 15:43:50","title":"Inferring the relationship between soil temperature and the normalized difference vegetation index with machine learning","abstract":"Changes in climate can greatly affect the phenology of plants, which can have important feedback effects, such as altering the carbon cycle. These phenological feedback effects are often induced by a shift in the start or end dates of the growing season of plants. The normalized difference vegetation index (NDVI) serves as a straightforward indicator for assessing the presence of green vegetation and can also provide an estimation of the plants' growing season. In this study, we investigated the effect of soil temperature on the timing of the start of the season (SOS), timing of the peak of the season (POS), and the maximum annual NDVI value (PEAK) in subarctic grassland ecosystems between 2014 and 2019. We also explored the impact of other meteorological variables, including air temperature, precipitation, and irradiance, on the inter-annual variation in vegetation phenology. Using machine learning (ML) techniques and SHapley Additive exPlanations (SHAP) values, we analyzed the relative importance and contribution of each variable to the phenological predictions. Our results reveal a significant relationship between soil temperature and SOS and POS, indicating that higher soil temperatures lead to an earlier start and peak of the growing season. However, the Peak NDVI values showed just a slight increase with higher soil temperatures. The analysis of other meteorological variables demonstrated their impacts on the inter-annual variation of the vegetation phenology. Ultimately, this study contributes to our knowledge of the relationships between soil temperature, meteorological variables, and vegetation phenology, providing valuable insights for predicting vegetation phenology characteristics and managing subarctic grasslands in the face of climate change. Additionally, this work provides a solid foundation for future ML-based vegetation phenology studies.","sentences":["Changes in climate can greatly affect the phenology of plants, which can have important feedback effects, such as altering the carbon cycle.","These phenological feedback effects are often induced by a shift in the start or end dates of the growing season of plants.","The normalized difference vegetation index (NDVI) serves as a straightforward indicator for assessing the presence of green vegetation and can also provide an estimation of the plants' growing season.","In this study, we investigated the effect of soil temperature on the timing of the start of the season (SOS), timing of the peak of the season (POS), and the maximum annual NDVI value (PEAK) in subarctic grassland ecosystems between 2014 and 2019.","We also explored the impact of other meteorological variables, including air temperature, precipitation, and irradiance, on the inter-annual variation in vegetation phenology.","Using machine learning (ML) techniques and SHapley Additive exPlanations (SHAP) values, we analyzed the relative importance and contribution of each variable to the phenological predictions.","Our results reveal a significant relationship between soil temperature and SOS and POS, indicating that higher soil temperatures lead to an earlier start and peak of the growing season.","However, the Peak NDVI values showed just a slight increase with higher soil temperatures.","The analysis of other meteorological variables demonstrated their impacts on the inter-annual variation of the vegetation phenology.","Ultimately, this study contributes to our knowledge of the relationships between soil temperature, meteorological variables, and vegetation phenology, providing valuable insights for predicting vegetation phenology characteristics and managing subarctic grasslands in the face of climate change.","Additionally, this work provides a solid foundation for future ML-based vegetation phenology studies."],"url":"http://arxiv.org/abs/2312.12258v1"}
{"created":"2023-12-19 15:39:09","title":"TaskFlex Solver for Multi-Agent Pursuit via Automatic Curriculum Learning","abstract":"This paper addresses the problem of multi-agent pursuit, where slow pursuers cooperate to capture fast evaders in a confined environment with obstacles. Existing heuristic algorithms often lack expressive coordination strategies and are highly sensitive to task conditions, requiring extensive hyperparameter tuning. In contrast, reinforcement learning (RL) has been applied to this problem and is capable of obtaining cooperative pursuit strategies. However, RL-based methods face challenges in training for complex scenarios due to the vast amount of training data and limited adaptability to varying task conditions, such as different scene sizes, varying numbers and speeds of obstacles, and flexible speed ratios of the evader to the pursuer. In this work, we combine RL and curriculum learning to introduce a flexible solver for multiagent pursuit problems, named TaskFlex Solver (TFS), which is capable of solving multi-agent pursuit problems with diverse and dynamically changing task conditions in both 2-dimensional and 3-dimensional scenarios. TFS utilizes a curriculum learning method that constructs task distributions based on training progress, enhancing training efficiency and final performance. Our algorithm consists of two main components: the Task Evaluator, which evaluates task success rates and selects tasks of moderate difficulty to maintain a curriculum archive, and the Task Sampler, which constructs training distributions by sampling tasks from the curriculum archive to maximize policy improvement. Experiments show that TFS produces much stronger performance than baselines and achieves close to 100% capture rates in both 2-dimensional and 3-dimensional multi-agent pursuit problems with diverse and dynamically changing scenes. The project website is at https://sites.google.com/view/tfs-2023.","sentences":["This paper addresses the problem of multi-agent pursuit, where slow pursuers cooperate to capture fast evaders in a confined environment with obstacles.","Existing heuristic algorithms often lack expressive coordination strategies and are highly sensitive to task conditions, requiring extensive hyperparameter tuning.","In contrast, reinforcement learning (RL) has been applied to this problem and is capable of obtaining cooperative pursuit strategies.","However, RL-based methods face challenges in training for complex scenarios due to the vast amount of training data and limited adaptability to varying task conditions, such as different scene sizes, varying numbers and speeds of obstacles, and flexible speed ratios of the evader to the pursuer.","In this work, we combine RL and curriculum learning to introduce a flexible solver for multiagent pursuit problems, named TaskFlex Solver (TFS), which is capable of solving multi-agent pursuit problems with diverse and dynamically changing task conditions in both 2-dimensional and 3-dimensional scenarios.","TFS utilizes a curriculum learning method that constructs task distributions based on training progress, enhancing training efficiency and final performance.","Our algorithm consists of two main components: the Task Evaluator, which evaluates task success rates and selects tasks of moderate difficulty to maintain a curriculum archive, and the Task Sampler, which constructs training distributions by sampling tasks from the curriculum archive to maximize policy improvement.","Experiments show that TFS produces much stronger performance than baselines and achieves close to 100% capture rates in both 2-dimensional and 3-dimensional multi-agent pursuit problems with diverse and dynamically changing scenes.","The project website is at https://sites.google.com/view/tfs-2023."],"url":"http://arxiv.org/abs/2312.12255v1"}
{"created":"2023-12-19 15:37:27","title":"Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced Evaluation of Urban Environments","abstract":"Sentiment analysis methods are rapidly being adopted by the field of Urban Design and Planning, for the crowdsourced evaluation of urban environments. However, most models used within this domain are able to identify positive or negative sentiment associated with a textual appraisal as a whole, without inferring information about specific urban aspects contained within it, or the sentiment associated with them. While Aspect Based Sentiment Analysis (ABSA) is becoming increasingly popular, most existing ABSA models are trained on non-urban themes such as restaurants, electronics, consumer goods and the like. This body of research develops an ABSA model capable of extracting urban aspects contained within geo-located textual urban appraisals, along with corresponding aspect sentiment classification. We annotate a dataset of 2500 crowdsourced reviews of public parks, and train a Bidirectional Encoder Representations from Transformers (BERT) model with Local Context Focus (LCF) on this data. Our model achieves significant improvement in prediction accuracy on urban reviews, for both Aspect Term Extraction (ATE) and Aspect Sentiment Classification (ASC) tasks. For demonstrative analysis, positive and negative urban aspects across Boston are spatially visualized. We hope that this model is useful for designers and planners for fine-grained urban sentiment evaluation.","sentences":["Sentiment analysis methods are rapidly being adopted by the field of Urban Design and Planning, for the crowdsourced evaluation of urban environments.","However, most models used within this domain are able to identify positive or negative sentiment associated with a textual appraisal as a whole, without inferring information about specific urban aspects contained within it, or the sentiment associated with them.","While Aspect Based Sentiment Analysis (ABSA) is becoming increasingly popular, most existing ABSA models are trained on non-urban themes such as restaurants, electronics, consumer goods and the like.","This body of research develops an ABSA model capable of extracting urban aspects contained within geo-located textual urban appraisals, along with corresponding aspect sentiment classification.","We annotate a dataset of 2500 crowdsourced reviews of public parks, and train a Bidirectional Encoder Representations from Transformers (BERT) model with Local Context Focus (LCF) on this data.","Our model achieves significant improvement in prediction accuracy on urban reviews, for both Aspect Term Extraction (ATE) and Aspect Sentiment Classification (ASC) tasks.","For demonstrative analysis, positive and negative urban aspects across Boston are spatially visualized.","We hope that this model is useful for designers and planners for fine-grained urban sentiment evaluation."],"url":"http://arxiv.org/abs/2312.12253v1"}
{"created":"2023-12-19 15:36:35","title":"Fairness and Consensus in a Gossip Model of Social Networks","abstract":"We present a new formal model for opinion learning in social networks. Our model is based on DeGroot, but it allows for asynchronous interaction between agents. We show that our model might not reach consensus under standard weak fairness assumption for distributed systems. However, we show that it reaches consensus under strong-connectedness, absence of puppet agents and a new condition called bounded wait. We study several notions of fairness and their implications for consensus, introducing bounded fairness and $m$-consecutive bounded fairness. As an important corollary, we obtain consensus for random executions of the model. We also show that our model can be generalized to allow for dynamic influence between agents, where consensus with connectivity and bounded wait holds as long as the influence is bounded.","sentences":["We present a new formal model for opinion learning in social networks.","Our model is based on DeGroot, but it allows for asynchronous interaction between agents.","We show that our model might not reach consensus under standard weak fairness assumption for distributed systems.","However, we show that it reaches consensus under strong-connectedness, absence of puppet agents and a new condition called bounded wait.","We study several notions of fairness and their implications for consensus, introducing bounded fairness and $m$-consecutive bounded fairness.","As an important corollary, we obtain consensus for random executions of the model.","We also show that our model can be generalized to allow for dynamic influence between agents, where consensus with connectivity and bounded wait holds as long as the influence is bounded."],"url":"http://arxiv.org/abs/2312.12251v1"}
{"created":"2023-12-19 15:33:57","title":"ST(OR)2: Spatio-Temporal Object Level Reasoning for Activity Recognition in the Operating Room","abstract":"Surgical robotics holds much promise for improving patient safety and clinician experience in the Operating Room (OR). However, it also comes with new challenges, requiring strong team coordination and effective OR management. Automatic detection of surgical activities is a key requirement for developing AI-based intelligent tools to tackle these challenges. The current state-of-the-art surgical activity recognition methods however operate on image-based representations and depend on large-scale labeled datasets whose collection is time-consuming and resource-expensive. This work proposes a new sample-efficient and object-based approach for surgical activity recognition in the OR. Our method focuses on the geometric arrangements between clinicians and surgical devices, thus utilizing the significant object interaction dynamics in the OR. We conduct experiments in a low-data regime study for long video activity recognition. We also benchmark our method againstother object-centric approaches on clip-level action classification and show superior performance.","sentences":["Surgical robotics holds much promise for improving patient safety and clinician experience in the Operating Room (OR).","However, it also comes with new challenges, requiring strong team coordination and effective OR management.","Automatic detection of surgical activities is a key requirement for developing AI-based intelligent tools to tackle these challenges.","The current state-of-the-art surgical activity recognition methods however operate on image-based representations and depend on large-scale labeled datasets whose collection is time-consuming and resource-expensive.","This work proposes a new sample-efficient and object-based approach for surgical activity recognition in the OR.","Our method focuses on the geometric arrangements between clinicians and surgical devices, thus utilizing the significant object interaction dynamics in the OR.","We conduct experiments in a low-data regime study for long video activity recognition.","We also benchmark our method againstother object-centric approaches on clip-level action classification and show superior performance."],"url":"http://arxiv.org/abs/2312.12250v1"}
{"created":"2023-12-19 15:30:10","title":"MDD-UNet: Domain Adaptation for Medical Image Segmentation with Theoretical Guarantees, a Proof of Concept","abstract":"The current state-of-the art techniques for image segmentation are often based on U-Net architectures, a U-shaped encoder-decoder networks with skip connections. Despite the powerful performance, the architecture often does not perform well when used on data which has different characteristics than the data it was trained on. Many techniques for improving performance in the presence of domain shift have been developed, however typically only have loose connections to the theory of domain adaption. In this work, we propose an unsupervised domain adaptation framework for U-Nets with theoretical guarantees based on the Margin Disparity Discrepancy [1] called the MDD-UNet. We evaluate the proposed technique on the task of hippocampus segmentation, and find that the MDD-UNet is able to learn features which are domain-invariant with no knowledge about the labels in the target domain. The MDD-UNet improves performance over the standard U-Net on 11 out of 12 combinations of datasets. This work serves as a proof of concept by demonstrating an improvement on the U-Net in it's standard form without modern enhancements, which opens up a new avenue of studying domain adaptation for models with very large hypothesis spaces from both methodological and practical perspectives. Code is available at https://github.com/asbjrnmunk/mdd-unet.","sentences":["The current state-of-the art techniques for image segmentation are often based on U-Net architectures, a U-shaped encoder-decoder networks with skip connections.","Despite the powerful performance, the architecture often does not perform well when used on data which has different characteristics than the data it was trained on.","Many techniques for improving performance in the presence of domain shift have been developed, however typically only have loose connections to the theory of domain adaption.","In this work, we propose an unsupervised domain adaptation framework for U-Nets with theoretical guarantees based on the Margin Disparity Discrepancy","[1] called the MDD-UNet.","We evaluate the proposed technique on the task of hippocampus segmentation, and find that the MDD-UNet is able to learn features which are domain-invariant with no knowledge about the labels in the target domain.","The MDD-UNet improves performance over the standard U-Net on 11 out of 12 combinations of datasets.","This work serves as a proof of concept by demonstrating an improvement on the U-Net in it's standard form without modern enhancements, which opens up a new avenue of studying domain adaptation for models with very large hypothesis spaces from both methodological and practical perspectives.","Code is available at https://github.com/asbjrnmunk/mdd-unet."],"url":"http://arxiv.org/abs/2312.12246v1"}
{"created":"2023-12-19 15:28:00","title":"Protecting Massive MIMO-Radar Coexistence: Precoding Design and Power Control","abstract":"This paper studies the coexistence between a downlink multiuser massive multi-input-multi-output (MIMO) communication system and MIMO radar. The performance of the massive MIMO system with maximum ratio ($\\MR$), zero-forcing ($\\ZF$), and protective $\\ZF$ ($\\PZF$) precoding designs is characterized in terms of spectral efficiency (SE) and by taking the channel estimation errors and power control into account. The idea of $\\PZF$ precoding relies on the projection of the information-bearing signal onto the null space of the radar channel to protect the radar against communication signals. We further derive closed-form expressions for the detection probability of the radar system for the considered precoding designs. By leveraging the closed-form expressions for the SE and detection probability, we formulate a power control problem at the radar and base station (BS) to maximize the detection probability while satisfying the per-user SE requirements. This optimization problem can be efficiently tackled via the bisection method by solving a linear feasibility problem. Our analysis and simulations show that the $\\PZF$ design has the highest detection probability performance among all designs, with intermediate SE performance compared to the other two designs. Moreover, by optimally selecting the power control coefficients at the BS and radar, the detection probability improves significantly.","sentences":["This paper studies the coexistence between a downlink multiuser massive multi-input-multi-output (MIMO) communication system and MIMO radar.","The performance of the massive MIMO system with maximum ratio ($\\MR$), zero-forcing ($\\ZF$), and protective $\\ZF$ ($\\PZF$) precoding designs is characterized in terms of spectral efficiency (SE) and by taking the channel estimation errors and power control into account.","The idea of $\\PZF$ precoding relies on the projection of the information-bearing signal onto the null space of the radar channel to protect the radar against communication signals.","We further derive closed-form expressions for the detection probability of the radar system for the considered precoding designs.","By leveraging the closed-form expressions for the SE and detection probability, we formulate a power control problem at the radar and base station (BS) to maximize the detection probability while satisfying the per-user SE requirements.","This optimization problem can be efficiently tackled via the bisection method by solving a linear feasibility problem.","Our analysis and simulations show that the $\\PZF$ design has the highest detection probability performance among all designs, with intermediate SE performance compared to the other two designs.","Moreover, by optimally selecting the power control coefficients at the BS and radar, the detection probability improves significantly."],"url":"http://arxiv.org/abs/2312.12244v1"}
{"created":"2023-12-19 15:26:47","title":"Distributed Binary Labeling Problems in High-Degree Graphs","abstract":"Balliu et al. (DISC 2020) classified the hardness of solving binary labeling problems with distributed graph algorithms; in these problems the task is to select a subset of edges in a $2$-colored tree in which white nodes of degree $d$ and black nodes of degree $\\delta$ have constraints on the number of selected incident edges. They showed that the deterministic round complexity of any such problem is $O_{d,\\delta}(1)$, $\\Theta_{d,\\delta}(\\log n)$, or $\\Theta_{d,\\delta}(n)$, or the problem is unsolvable. However, their classification only addresses complexity as a function of $n$; here $O_{d,\\delta}$ hides constants that may depend on parameters $d$ and $\\delta$.   In this work we study the complexity of binary labeling problems as a function of all three parameters: $n$, $d$, and $\\delta$. To this end, we introduce the family of structurally simple problems, which includes, among others, all binary labeling problems in which cardinality constraints can be represented with a context-free grammar. We classify possible complexities of structurally simple problems. As our main result, we show that if the complexity of a problem falls in the broad class of $\\Theta_{d,\\delta}(\\log n)$, then the complexity for each $d$ and $\\delta$ is always either $\\Theta(\\log_d n)$, $\\Theta(\\log_\\delta n)$, or $\\Theta(\\log n)$.   To prove our upper bounds, we introduce a new, more aggressive version of the rake-and-compress technique that benefits from high-degree nodes.","sentences":["Balliu et al. (DISC 2020) classified the hardness of solving binary labeling problems with distributed graph algorithms; in these problems the task is to select a subset of edges in a $2$-colored tree in which white nodes of degree $d$ and black nodes of degree $\\delta$ have constraints on the number of selected incident edges.","They showed that the deterministic round complexity of any such problem is $O_{d,\\delta}(1)$, $\\Theta_{d,\\delta}(\\log n)$, or $\\Theta_{d,\\delta}(n)$, or the problem is unsolvable.","However, their classification only addresses complexity as a function of $n$; here $O_{d,\\delta}$ hides constants that may depend on parameters $d$ and $\\delta$.   ","In this work we study the complexity of binary labeling problems as a function of all three parameters: $n$, $d$, and $\\delta$.","To this end, we introduce the family of structurally simple problems, which includes, among others, all binary labeling problems in which cardinality constraints can be represented with a context-free grammar.","We classify possible complexities of structurally simple problems.","As our main result, we show that if the complexity of a problem falls in the broad class of $\\Theta_{d,\\delta}(\\log n)$, then the complexity for each $d$ and $\\delta$ is always either $\\Theta(\\log_d n)$, $\\Theta(\\log_\\delta n)$, or $\\Theta(\\log n)$.   To prove our upper bounds, we introduce a new, more aggressive version of the rake-and-compress technique that benefits from high-degree nodes."],"url":"http://arxiv.org/abs/2312.12243v1"}
{"created":"2023-12-19 15:25:39","title":"GeomVerse: A Systematic Evaluation of Large Models for Geometric Reasoning","abstract":"Large language models have shown impressive results for multi-hop mathematical reasoning when the input question is only textual. Many mathematical reasoning problems, however, contain both text and image. With the ever-increasing adoption of vision language models (VLMs), understanding their reasoning abilities for such problems is crucial. In this paper, we evaluate the reasoning capabilities of VLMs along various axes through the lens of geometry problems. We procedurally create a synthetic dataset of geometry questions with controllable difficulty levels along multiple axes, thus enabling a systematic evaluation. The empirical results obtained using our benchmark for state-of-the-art VLMs indicate that these models are not as capable in subjects like geometry (and, by generalization, other topics requiring similar reasoning) as suggested by previous benchmarks. This is made especially clear by the construction of our benchmark at various depth levels, since solving higher-depth problems requires long chains of reasoning rather than additional memorized knowledge. We release the dataset for further research in this area.","sentences":["Large language models have shown impressive results for multi-hop mathematical reasoning when the input question is only textual.","Many mathematical reasoning problems, however, contain both text and image.","With the ever-increasing adoption of vision language models (VLMs), understanding their reasoning abilities for such problems is crucial.","In this paper, we evaluate the reasoning capabilities of VLMs along various axes through the lens of geometry problems.","We procedurally create a synthetic dataset of geometry questions with controllable difficulty levels along multiple axes, thus enabling a systematic evaluation.","The empirical results obtained using our benchmark for state-of-the-art VLMs indicate that these models are not as capable in subjects like geometry (and, by generalization, other topics requiring similar reasoning) as suggested by previous benchmarks.","This is made especially clear by the construction of our benchmark at various depth levels, since solving higher-depth problems requires long chains of reasoning rather than additional memorized knowledge.","We release the dataset for further research in this area."],"url":"http://arxiv.org/abs/2312.12241v1"}
{"created":"2023-12-19 15:22:37","title":"Roll With the Punches: Expansion and Shrinkage of Soft Label Selection for Semi-supervised Fine-Grained Learning","abstract":"While semi-supervised learning (SSL) has yielded promising results, the more realistic SSL scenario remains to be explored, in which the unlabeled data exhibits extremely high recognition difficulty, e.g., fine-grained visual classification in the context of SSL (SS-FGVC). The increased recognition difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling accuracy, resulting in poor performance of the SSL model. To tackle this challenge, we propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC) by reconstructing the pseudo-label selection process by jointly optimizing Expansion Objective and Shrinkage Objective, which is based on a soft label manner. Respectively, the former objective encourages soft labels to absorb more candidate classes to ensure the attendance of ground-truth class, while the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization. In comparisons with various state-of-the-art methods, our approach demonstrates its superior performance in SS-FGVC. Checkpoints and source code are available at https://github.com/NJUyued/SoC4SS-FGVC.","sentences":["While semi-supervised learning (SSL) has yielded promising results, the more realistic SSL scenario remains to be explored, in which the unlabeled data exhibits extremely high recognition difficulty, e.g., fine-grained visual classification in the context of SSL (SS-FGVC).","The increased recognition difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling accuracy, resulting in poor performance of the SSL model.","To tackle this challenge, we propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC) by reconstructing the pseudo-label selection process by jointly optimizing Expansion Objective and Shrinkage Objective, which is based on a soft label manner.","Respectively, the former objective encourages soft labels to absorb more candidate classes to ensure the attendance of ground-truth class, while the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization.","In comparisons with various state-of-the-art methods, our approach demonstrates its superior performance in SS-FGVC.","Checkpoints and source code are available at https://github.com/NJUyued/SoC4SS-FGVC."],"url":"http://arxiv.org/abs/2312.12237v1"}
{"created":"2023-12-19 15:20:27","title":"Generalization Analysis of Machine Learning Algorithms via the Worst-Case Data-Generating Probability Measure","abstract":"In this paper, the worst-case probability measure over the data is introduced as a tool for characterizing the generalization capabilities of machine learning algorithms. More specifically, the worst-case probability measure is a Gibbs probability measure and the unique solution to the maximization of the expected loss under a relative entropy constraint with respect to a reference probability measure. Fundamental generalization metrics, such as the sensitivity of the expected loss, the sensitivity of the empirical risk, and the generalization gap are shown to have closed-form expressions involving the worst-case data-generating probability measure. Existing results for the Gibbs algorithm, such as characterizing the generalization gap as a sum of mutual information and lautum information, up to a constant factor, are recovered. A novel parallel is established between the worst-case data-generating probability measure and the Gibbs algorithm. Specifically, the Gibbs probability measure is identified as a fundamental commonality of the model space and the data space for machine learning algorithms.","sentences":["In this paper, the worst-case probability measure over the data is introduced as a tool for characterizing the generalization capabilities of machine learning algorithms.","More specifically, the worst-case probability measure is a Gibbs probability measure and the unique solution to the maximization of the expected loss under a relative entropy constraint with respect to a reference probability measure.","Fundamental generalization metrics, such as the sensitivity of the expected loss, the sensitivity of the empirical risk, and the generalization gap are shown to have closed-form expressions involving the worst-case data-generating probability measure.","Existing results for the Gibbs algorithm, such as characterizing the generalization gap as a sum of mutual information and lautum information, up to a constant factor, are recovered.","A novel parallel is established between the worst-case data-generating probability measure and the Gibbs algorithm.","Specifically, the Gibbs probability measure is identified as a fundamental commonality of the model space and the data space for machine learning algorithms."],"url":"http://arxiv.org/abs/2312.12236v1"}
{"created":"2023-12-19 15:18:40","title":"Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model","abstract":"Recently, diffusion-based image generation methods are credited for their remarkable text-to-image generation capabilities, while still facing challenges in accurately generating multilingual scene text images. To tackle this problem, we propose Diff-Text, which is a training-free scene text generation framework for any language. Our model outputs a photo-realistic image given a text of any language along with a textual description of a scene. The model leverages rendered sketch images as priors, thus arousing the potential multilingual-generation ability of the pre-trained Stable Diffusion. Based on the observation from the influence of the cross-attention map on object placement in generated images, we propose a localized attention constraint into the cross-attention layer to address the unreasonable positioning problem of scene text. Additionally, we introduce contrastive image-level prompts to further refine the position of the textual region and achieve more accurate scene text generation. Experiments demonstrate that our method outperforms the existing method in both the accuracy of text recognition and the naturalness of foreground-background blending.","sentences":["Recently, diffusion-based image generation methods are credited for their remarkable text-to-image generation capabilities, while still facing challenges in accurately generating multilingual scene text images.","To tackle this problem, we propose Diff-Text, which is a training-free scene text generation framework for any language.","Our model outputs a photo-realistic image given a text of any language along with a textual description of a scene.","The model leverages rendered sketch images as priors, thus arousing the potential multilingual-generation ability of the pre-trained Stable Diffusion.","Based on the observation from the influence of the cross-attention map on object placement in generated images, we propose a localized attention constraint into the cross-attention layer to address the unreasonable positioning problem of scene text.","Additionally, we introduce contrastive image-level prompts to further refine the position of the textual region and achieve more accurate scene text generation.","Experiments demonstrate that our method outperforms the existing method in both the accuracy of text recognition and the naturalness of foreground-background blending."],"url":"http://arxiv.org/abs/2312.12232v1"}
{"created":"2023-12-19 15:13:08","title":"HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models with Minimal Feedback","abstract":"We introduce HuTuMotion, an innovative approach for generating natural human motions that navigates latent motion diffusion models by leveraging few-shot human feedback. Unlike existing approaches that sample latent variables from a standard normal prior distribution, our method adapts the prior distribution to better suit the characteristics of the data, as indicated by human feedback, thus enhancing the quality of motion generation. Furthermore, our findings reveal that utilizing few-shot feedback can yield performance levels on par with those attained through extensive human feedback. This discovery emphasizes the potential and efficiency of incorporating few-shot human-guided optimization within latent diffusion models for personalized and style-aware human motion generation applications. The experimental results show the significantly superior performance of our method over existing state-of-the-art approaches.","sentences":["We introduce HuTuMotion, an innovative approach for generating natural human motions that navigates latent motion diffusion models by leveraging few-shot human feedback.","Unlike existing approaches that sample latent variables from a standard normal prior distribution, our method adapts the prior distribution to better suit the characteristics of the data, as indicated by human feedback, thus enhancing the quality of motion generation.","Furthermore, our findings reveal that utilizing few-shot feedback can yield performance levels on par with those attained through extensive human feedback.","This discovery emphasizes the potential and efficiency of incorporating few-shot human-guided optimization within latent diffusion models for personalized and style-aware human motion generation applications.","The experimental results show the significantly superior performance of our method over existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2312.12227v1"}
{"created":"2023-12-19 15:12:39","title":"On the Parameterization of Second-Order Optimization Effective Towards the Infinite Width","abstract":"Second-order optimization has been developed to accelerate the training of deep neural networks and it is being applied to increasingly larger-scale models. In this study, towards training on further larger scales, we identify a specific parameterization for second-order optimization that promotes feature learning in a stable manner even if the network width increases significantly. Inspired by a maximal update parameterization, we consider a one-step update of the gradient and reveal the appropriate scales of hyperparameters including random initialization, learning rates, and damping terms. Our approach covers two major second-order optimization algorithms, K-FAC and Shampoo, and we demonstrate that our parameterization achieves higher generalization performance in feature learning. In particular, it enables us to transfer the hyperparameters across models with different widths.","sentences":["Second-order optimization has been developed to accelerate the training of deep neural networks and it is being applied to increasingly larger-scale models.","In this study, towards training on further larger scales, we identify a specific parameterization for second-order optimization that promotes feature learning in a stable manner even if the network width increases significantly.","Inspired by a maximal update parameterization, we consider a one-step update of the gradient and reveal the appropriate scales of hyperparameters including random initialization, learning rates, and damping terms.","Our approach covers two major second-order optimization algorithms, K-FAC and Shampoo, and we demonstrate that our parameterization achieves higher generalization performance in feature learning.","In particular, it enables us to transfer the hyperparameters across models with different widths."],"url":"http://arxiv.org/abs/2312.12226v1"}
{"created":"2023-12-19 15:11:46","title":"Self-Supervised Detection of Perfect and Partial Input-Dependent Symmetries","abstract":"Group equivariance ensures consistent responses to group transformations of the input, leading to more robust models and enhanced generalization capabilities. However, this property can lead to overly constrained models if the symmetries considered in the group differ from those observed in data. While common methods address this by determining the appropriate level of symmetry at the dataset level, they are limited to supervised settings and ignore scenarios in which multiple levels of symmetry co-exist in the same dataset. For instance, pictures of cars and planes exhibit different levels of rotation, yet both are included in the CIFAR-10 dataset. In this paper, we propose a method able to detect the level of symmetry of each input without the need for labels. To this end, we derive a sufficient and necessary condition to learn the distribution of symmetries in the data. Using the learned distribution, we generate pseudo-labels that allow us to learn the levels of symmetry of each input in a self-supervised manner. We validate the effectiveness of our approach on synthetic datasets with different per-class levels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotated within a class-dependent interval. We demonstrate that our method can be used for practical applications such as the generation of standardized datasets in which the symmetries are not present, as well as the detection of out-of-distribution symmetries during inference. By doing so, both the generalization and robustness of non-equivariant models can be improved. Our code is publicly available at https://github.com/aurban0/ssl-sym.","sentences":["Group equivariance ensures consistent responses to group transformations of the input, leading to more robust models and enhanced generalization capabilities.","However, this property can lead to overly constrained models if the symmetries considered in the group differ from those observed in data.","While common methods address this by determining the appropriate level of symmetry at the dataset level, they are limited to supervised settings and ignore scenarios in which multiple levels of symmetry co-exist in the same dataset.","For instance, pictures of cars and planes exhibit different levels of rotation, yet both are included in the CIFAR-10 dataset.","In this paper, we propose a method able to detect the level of symmetry of each input without the need for labels.","To this end, we derive a sufficient and necessary condition to learn the distribution of symmetries in the data.","Using the learned distribution, we generate pseudo-labels that allow us to learn the levels of symmetry of each input in a self-supervised manner.","We validate the effectiveness of our approach on synthetic datasets with different per-class levels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotated within a class-dependent interval.","We demonstrate that our method can be used for practical applications such as the generation of standardized datasets in which the symmetries are not present, as well as the detection of out-of-distribution symmetries during inference.","By doing so, both the generalization and robustness of non-equivariant models can be improved.","Our code is publicly available at https://github.com/aurban0/ssl-sym."],"url":"http://arxiv.org/abs/2312.12223v1"}
