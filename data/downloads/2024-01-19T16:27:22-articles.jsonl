{"created":"2024-01-17 18:55:12","title":"Vlogger: Make Your Dream A Vlog","abstract":"In this work, we present Vlogger, a generic AI system for generating a minute-level video blog (i.e., vlog) of user descriptions. Different from short videos with a few seconds, vlog often contains a complex storyline with diversified scenes, which is challenging for most existing video generation approaches. To break through this bottleneck, our Vlogger smartly leverages Large Language Model (LLM) as Director and decomposes a long video generation task of vlog into four key stages, where we invoke various foundation models to play the critical roles of vlog professionals, including (1) Script, (2) Actor, (3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings, our Vlogger can generate vlogs through explainable cooperation of top-down planning and bottom-up shooting. Moreover, we introduce a novel video diffusion model, ShowMaker, which serves as a videographer in our Vlogger for generating the video snippet of each shooting scene. By incorporating Script and Actor attentively as textual and visual prompts, it can effectively enhance spatial-temporal coherence in the snippet. Besides, we design a concise mixed training paradigm for ShowMaker, boosting its capacity for both T2V generation and prediction. Finally, the extensive experiments show that our method achieves state-of-the-art performance on zero-shot T2V generation and prediction tasks. More importantly, Vlogger can generate over 5-minute vlogs from open-world descriptions, without loss of video coherence on script and actor. The code and model is all available at https://github.com/zhuangshaobin/Vlogger.","sentences":["In this work, we present Vlogger, a generic AI system for generating a minute-level video blog (i.e., vlog) of user descriptions.","Different from short videos with a few seconds, vlog often contains a complex storyline with diversified scenes, which is challenging for most existing video generation approaches.","To break through this bottleneck, our Vlogger smartly leverages Large Language Model (LLM) as Director and decomposes a long video generation task of vlog into four key stages, where we invoke various foundation models to play the critical roles of vlog professionals, including (1) Script, (2) Actor, (3) ShowMaker, and (4) Voicer.","With such a design of mimicking human beings, our Vlogger can generate vlogs through explainable cooperation of top-down planning and bottom-up shooting.","Moreover, we introduce a novel video diffusion model, ShowMaker, which serves as a videographer in our Vlogger for generating the video snippet of each shooting scene.","By incorporating Script and Actor attentively as textual and visual prompts, it can effectively enhance spatial-temporal coherence in the snippet.","Besides, we design a concise mixed training paradigm for ShowMaker, boosting its capacity for both T2V generation and prediction.","Finally, the extensive experiments show that our method achieves state-of-the-art performance on zero-shot T2V generation and prediction tasks.","More importantly, Vlogger can generate over 5-minute vlogs from open-world descriptions, without loss of video coherence on script and actor.","The code and model is all available at https://github.com/zhuangshaobin/Vlogger."],"url":"http://arxiv.org/abs/2401.09414v1"}
{"created":"2024-01-17 18:45:13","title":"Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text","abstract":"With the recent proliferation of Large Language Models (LLMs), there has been an increasing demand for tools to detect machine-generated text. The effective detection of machine-generated text face two pertinent problems: First, they are severely limited in generalizing against real-world scenarios, where machine-generated text is produced by a variety of generators, including but not limited to GPT-4 and Dolly, and spans diverse domains, ranging from academic manuscripts to social media posts. Second, existing detection methodologies treat texts produced by LLMs through a restrictive binary classification lens, neglecting the nuanced diversity of artifacts generated by different LLMs. In this work, we undertake a systematic study on the detection of machine-generated text in real-world scenarios. We first study the effectiveness of state-of-the-art approaches and find that they are severely limited against text produced by diverse generators and domains in the real world. Furthermore, t-SNE visualizations of the embeddings from a pretrained LLM's encoder show that they cannot reliably distinguish between human and machine-generated text. Based on our findings, we introduce a novel system, T5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder combined with LLM embedding sub-clustering to address the text produced by diverse generators and domains in the real world. We evaluate our approach across 9 machine-generated text systems and 9 domains and find that our approach provides state-of-the-art generalization ability, with an average increase in F1 score on machine-generated text of 19.6\\% on unseen generators and domains compared to the top performing existing approaches and correctly attributes the generator of text with an accuracy of 93.6\\%.","sentences":["With the recent proliferation of Large Language Models (LLMs), there has been an increasing demand for tools to detect machine-generated text.","The effective detection of machine-generated text face two pertinent problems:","First, they are severely limited in generalizing against real-world scenarios, where machine-generated text is produced by a variety of generators, including but not limited to GPT-4 and Dolly, and spans diverse domains, ranging from academic manuscripts to social media posts.","Second, existing detection methodologies treat texts produced by LLMs through a restrictive binary classification lens, neglecting the nuanced diversity of artifacts generated by different LLMs.","In this work, we undertake a systematic study on the detection of machine-generated text in real-world scenarios.","We first study the effectiveness of state-of-the-art approaches and find that they are severely limited against text produced by diverse generators and domains in the real world.","Furthermore, t-SNE visualizations of the embeddings from a pretrained LLM's encoder show that they cannot reliably distinguish between human and machine-generated text.","Based on our findings, we introduce a novel system, T5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder combined with LLM embedding sub-clustering to address the text produced by diverse generators and domains in the real world.","We evaluate our approach across 9 machine-generated text systems and 9 domains and find that our approach provides state-of-the-art generalization ability, with an average increase in F1 score on machine-generated text of 19.6\\% on unseen generators and domains compared to the top performing existing approaches and correctly attributes the generator of text with an accuracy of 93.6\\%."],"url":"http://arxiv.org/abs/2401.09407v1"}
{"created":"2024-01-17 18:13:07","title":"Stuck in the Quicksand of Numeracy, Far from AGI Summit: Evaluating LLMs' Mathematical Competency through Ontology-guided Perturbations","abstract":"Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness, in mathematical reasoning tasks, remains an open question. In response, we develop (i) an ontology of perturbations of maths questions, (ii) a semi-automatic method of perturbation, and (iii) a dataset of perturbed maths questions to probe the limits of LLM capabilities in mathematical reasoning tasks. These controlled perturbations span across multiple fine dimensions of the structural and representational aspects of maths questions. Using GPT-4, we generated the MORE dataset by perturbing randomly selected five seed questions from GSM8K. This process was guided by our ontology and involved a thorough automatic and manual filtering process, yielding a set of 216 maths problems. We conducted comprehensive evaluation of both closed-source and open-source LLMs on MORE. The results show a significant performance drop across all the models against the perturbed questions. This strongly suggests that current LLMs lack robust mathematical skills and deep reasoning abilities. This research not only identifies multiple gaps in the capabilities of current models, but also highlights multiple potential directions for future development. Our dataset will be made publicly available at https://huggingface.co/datasets/declare-lab/GSM8k_MORE.","sentences":["Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance.","However, the true depth of their competencies and robustness, in mathematical reasoning tasks, remains an open question.","In response, we develop (i) an ontology of perturbations of maths questions, (ii) a semi-automatic method of perturbation, and (iii) a dataset of perturbed maths questions to probe the limits of LLM capabilities in mathematical reasoning tasks.","These controlled perturbations span across multiple fine dimensions of the structural and representational aspects of maths questions.","Using GPT-4, we generated the MORE dataset by perturbing randomly selected five seed questions from GSM8K. This process was guided by our ontology and involved a thorough automatic and manual filtering process, yielding a set of 216 maths problems.","We conducted comprehensive evaluation of both closed-source and open-source LLMs on MORE.","The results show a significant performance drop across all the models against the perturbed questions.","This strongly suggests that current LLMs lack robust mathematical skills and deep reasoning abilities.","This research not only identifies multiple gaps in the capabilities of current models, but also highlights multiple potential directions for future development.","Our dataset will be made publicly available at https://huggingface.co/datasets/declare-lab/GSM8k_MORE."],"url":"http://arxiv.org/abs/2401.09395v1"}
{"created":"2024-01-17 16:57:19","title":"Large Language Models Are Neurosymbolic Reasoners","abstract":"A wide range of real-world applications is characterized by their symbolic nature, necessitating a strong capability for symbolic reasoning. This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners. We focus on text-based games, significant benchmarks for agents with natural language capabilities, particularly in symbolic tasks like math, map reading, sorting, and applying common sense in text-based worlds. To facilitate these agents, we propose an LLM agent designed to tackle symbolic challenges and achieve in-game objectives. We begin by initializing the LLM agent and informing it of its role. The agent then receives observations and a set of valid actions from the text-based games, along with a specific symbolic module. With these inputs, the LLM agent chooses an action and interacts with the game environments. Our experimental results demonstrate that our method significantly enhances the capability of LLMs as automated agents for symbolic reasoning, and our LLM agent is effective in text-based games involving symbolic tasks, achieving an average performance of 88% across all tasks.","sentences":["A wide range of real-world applications is characterized by their symbolic nature, necessitating a strong capability for symbolic reasoning.","This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners.","We focus on text-based games, significant benchmarks for agents with natural language capabilities, particularly in symbolic tasks like math, map reading, sorting, and applying common sense in text-based worlds.","To facilitate these agents, we propose an LLM agent designed to tackle symbolic challenges and achieve in-game objectives.","We begin by initializing the LLM agent and informing it of its role.","The agent then receives observations and a set of valid actions from the text-based games, along with a specific symbolic module.","With these inputs, the LLM agent chooses an action and interacts with the game environments.","Our experimental results demonstrate that our method significantly enhances the capability of LLMs as automated agents for symbolic reasoning, and our LLM agent is effective in text-based games involving symbolic tasks, achieving an average performance of 88% across all tasks."],"url":"http://arxiv.org/abs/2401.09334v1"}
{"created":"2024-01-17 16:05:19","title":"Material Informatics through Neural Networks on Ab-Initio Electron Charge Densities: the Role of Transfer Learning","abstract":"In this work, the dynamic realms of Materials Science and Computer Science advancements meet the critical challenge of identifying efficient descriptors capable of capturing the essential features of physical systems. Such task has remained formidable, with solutions often involving ad-hoc scalar and vectorial sets of materials properties, making optimization and transferability challenging. We extract representations directly from ab-initio differential electron charge density profiles using Neural Networks, highlighting the pivotal role of transfer learning in such task. Firstly, we demonstrate significant improvements in regression of a specific defected-materials property with respect to training a deep network from scratch, both in terms of predictions and their reproducibilities, by considering various pre-trained models and selecting the optimal one after fine-tuning. The remarkable performances obtained confirmed the transferability of the existent pre-trained Convolutional Neural Networks (CNNs) on physics domain data, very different from the original training data. Secondly, we demonstrate a saturation in the regression capabilities of computer vision models towards properties of an extensive variety of undefected systems, and how it can be overcome with the help of large language model (LLM) transformers, with as little text information as composition names. Finally, we prove the insufficiency of open-models, like GPT-4, in achieving the analogous tasks and performances as the proposed domain-specific ones. The work offers a promising avenue for enhancing the effectiveness of descriptor identification in complex physical systems, shedding light over the power of transfer learning to easily adapt and combine available models, with different modalities, to the physics domain, at the same time opening space to a benchmark for LLMs capabilities in such domain.","sentences":["In this work, the dynamic realms of Materials Science and Computer Science advancements meet the critical challenge of identifying efficient descriptors capable of capturing the essential features of physical systems.","Such task has remained formidable, with solutions often involving ad-hoc scalar and vectorial sets of materials properties, making optimization and transferability challenging.","We extract representations directly from ab-initio differential electron charge density profiles using Neural Networks, highlighting the pivotal role of transfer learning in such task.","Firstly, we demonstrate significant improvements in regression of a specific defected-materials property with respect to training a deep network from scratch, both in terms of predictions and their reproducibilities, by considering various pre-trained models and selecting the optimal one after fine-tuning.","The remarkable performances obtained confirmed the transferability of the existent pre-trained Convolutional Neural Networks (CNNs) on physics domain data, very different from the original training data.","Secondly, we demonstrate a saturation in the regression capabilities of computer vision models towards properties of an extensive variety of undefected systems, and how it can be overcome with the help of large language model (LLM) transformers, with as little text information as composition names.","Finally, we prove the insufficiency of open-models, like GPT-4, in achieving the analogous tasks and performances as the proposed domain-specific ones.","The work offers a promising avenue for enhancing the effectiveness of descriptor identification in complex physical systems, shedding light over the power of transfer learning to easily adapt and combine available models, with different modalities, to the physics domain, at the same time opening space to a benchmark for LLMs capabilities in such domain."],"url":"http://arxiv.org/abs/2401.09301v1"}
{"created":"2024-01-17 11:50:53","title":"Bridging Research and Readers: A Multi-Modal Automated Academic Papers Interpretation System","abstract":"In the contemporary information era, significantly accelerated by the advent of Large-scale Language Models, the proliferation of scientific literature is reaching unprecedented levels. Researchers urgently require efficient tools for reading and summarizing academic papers, uncovering significant scientific literature, and employing diverse interpretative methodologies. To address this burgeoning demand, the role of automated scientific literature interpretation systems has become paramount. However, prevailing models, both commercial and open-source, confront notable challenges: they often overlook multimodal data, grapple with summarizing over-length texts, and lack diverse user interfaces. In response, we introduce an open-source multi-modal automated academic paper interpretation system (MMAPIS) with three-step process stages, incorporating LLMs to augment its functionality. Our system first employs the hybrid modality preprocessing and alignment module to extract plain text, and tables or figures from documents separately. It then aligns this information based on the section names they belong to, ensuring that data with identical section names are categorized under the same section. Following this, we introduce a hierarchical discourse-aware summarization method. It utilizes the extracted section names to divide the article into shorter text segments, facilitating specific summarizations both within and between sections via LLMs with specific prompts. Finally, we have designed four types of diversified user interfaces, including paper recommendation, multimodal Q\\&A, audio broadcasting, and interpretation blog, which can be widely applied across various scenarios. Our qualitative and quantitative evaluations underscore the system's superiority, especially in scientific summarization, where it outperforms solutions relying solely on GPT-4.","sentences":["In the contemporary information era, significantly accelerated by the advent of Large-scale Language Models, the proliferation of scientific literature is reaching unprecedented levels.","Researchers urgently require efficient tools for reading and summarizing academic papers, uncovering significant scientific literature, and employing diverse interpretative methodologies.","To address this burgeoning demand, the role of automated scientific literature interpretation systems has become paramount.","However, prevailing models, both commercial and open-source, confront notable challenges: they often overlook multimodal data, grapple with summarizing over-length texts, and lack diverse user interfaces.","In response, we introduce an open-source multi-modal automated academic paper interpretation system (MMAPIS) with three-step process stages, incorporating LLMs to augment its functionality.","Our system first employs the hybrid modality preprocessing and alignment module to extract plain text, and tables or figures from documents separately.","It then aligns this information based on the section names they belong to, ensuring that data with identical section names are categorized under the same section.","Following this, we introduce a hierarchical discourse-aware summarization method.","It utilizes the extracted section names to divide the article into shorter text segments, facilitating specific summarizations both within and between sections via LLMs with specific prompts.","Finally, we have designed four types of diversified user interfaces, including paper recommendation, multimodal Q\\&A, audio broadcasting, and interpretation blog, which can be widely applied across various scenarios.","Our qualitative and quantitative evaluations underscore the system's superiority, especially in scientific summarization, where it outperforms solutions relying solely on GPT-4."],"url":"http://arxiv.org/abs/2401.09150v1"}
{"created":"2024-01-17 11:47:59","title":"InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding","abstract":"Large language models (LLMs) with long sequences begin to power more and more fundamentally new applications we use every day. Existing methods for long-sequence LLM training are neither efficient nor compatible with commonly-used training algorithms such as FlashAttention. We design Buff to address these issues. Buff decouples all of the sharding dimensions into a new hierarchical space, and systematically analyzes the memory and communication cost of LLM training. Then, it generates an effective hybrid parallelism strategy. We design a new selective overlap mechanism to mitigate the communication overhead introduced by the hybrid parallelism. We also implement memory management techniques to reduce GPU memory fragmentation. Evaluation results show that Buff generates parallelization strategies that match or outperform existing methods in model FLOPs utilization.","sentences":["Large language models (LLMs) with long sequences begin to power more and more fundamentally new applications we use every day.","Existing methods for long-sequence LLM training are neither efficient nor compatible with commonly-used training algorithms such as FlashAttention.","We design Buff to address these issues.","Buff decouples all of the sharding dimensions into a new hierarchical space, and systematically analyzes the memory and communication cost of LLM training.","Then, it generates an effective hybrid parallelism strategy.","We design a new selective overlap mechanism to mitigate the communication overhead introduced by the hybrid parallelism.","We also implement memory management techniques to reduce GPU memory fragmentation.","Evaluation results show that Buff generates parallelization strategies that match or outperform existing methods in model FLOPs utilization."],"url":"http://arxiv.org/abs/2401.09149v1"}
{"created":"2024-01-17 09:53:50","title":"BibSonomy Meets ChatLLMs for Publication Management: From Chat to Publication Management: Organizing your related work using BibSonomy & LLMs","abstract":"The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications. Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata. Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management. It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1) Explorative Search & Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing & Management - aiding in the organization of personal publication libraries, in this case BibSonomy, by automating the addition of metadata and tags, while facilitating manual edits and updates. We compare our system to different LLM models in three different settings, including a user study, and we can show its advantages in different metrics.","sentences":["The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications.","Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata.","Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management.","It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper.","It supports two main use-cases: (1) Explorative Search & Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing & Management - aiding in the organization of personal publication libraries, in this case BibSonomy, by automating the addition of metadata and tags, while facilitating manual edits and updates.","We compare our system to different LLM models in three different settings, including a user study, and we can show its advantages in different metrics."],"url":"http://arxiv.org/abs/2401.09092v1"}
{"created":"2024-01-17 09:51:32","title":"Understanding the concerns and choices of public when using large language models for healthcare","abstract":"Large language models (LLMs) have shown their potential in biomedical fields. However, how the public uses them for healthcare purposes such as medical Q\\&A, self-diagnosis, and daily healthcare information seeking is under-investigated. In this paper, we adopt a mixed-methods approach, including surveys (N=167) and interviews (N=17) to investigate how and why the public uses LLMs for healthcare. LLMs as a healthcare tool have gained popularity, and are often used in combination with other information channels such as search engines and online health communities to optimize information quality. LLMs provide more accurate information and a more convenient interaction/service model compared to traditional channels. LLMs also do a better job of reducing misinformation, especially in daily healthcare questions. Doctors using LLMs for diagnosis is less acceptable than for auxiliary work such as writing medical records. Based on the findings, we reflect on the ethical and effective use of LLMs for healthcare and propose future research directions.","sentences":["Large language models (LLMs) have shown their potential in biomedical fields.","However, how the public uses them for healthcare purposes such as medical Q\\&A, self-diagnosis, and daily healthcare information seeking is under-investigated.","In this paper, we adopt a mixed-methods approach, including surveys (N=167) and interviews (N=17) to investigate how and why the public uses LLMs for healthcare.","LLMs as a healthcare tool have gained popularity, and are often used in combination with other information channels such as search engines and online health communities to optimize information quality.","LLMs provide more accurate information and a more convenient interaction/service model compared to traditional channels.","LLMs also do a better job of reducing misinformation, especially in daily healthcare questions.","Doctors using LLMs for diagnosis is less acceptable than for auxiliary work such as writing medical records.","Based on the findings, we reflect on the ethical and effective use of LLMs for healthcare and propose future research directions."],"url":"http://arxiv.org/abs/2401.09090v1"}
{"created":"2024-01-17 09:44:07","title":"Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models","abstract":"Recently, the flourishing large language models(LLM), especially ChatGPT, have shown exceptional performance in language understanding, reasoning, and interaction, attracting users and researchers from multiple fields and domains. Although LLMs have shown great capacity to perform human-like task accomplishment in natural language and natural image, their potential in handling remote sensing interpretation tasks has not yet been fully explored. Moreover, the lack of automation in remote sensing task planning hinders the accessibility of remote sensing interpretation techniques, especially to non-remote sensing experts from multiple research fields. To this end, we present Remote Sensing ChatGPT, an LLM-powered agent that utilizes ChatGPT to connect various AI-based remote sensing models to solve complicated interpretation tasks. More specifically, given a user request and a remote sensing image, we utilized ChatGPT to understand user requests, perform task planning according to the tasks' functions, execute each subtask iteratively, and generate the final response according to the output of each subtask. Considering that LLM is trained with natural language and is not capable of directly perceiving visual concepts as contained in remote sensing images, we designed visual cues that inject visual information into ChatGPT. With Remote Sensing ChatGPT, users can simply send a remote sensing image with the corresponding request, and get the interpretation results as well as language feedback from Remote Sensing ChatGPT. Experiments and examples show that Remote Sensing ChatGPT can tackle a wide range of remote sensing tasks and can be extended to more tasks with more sophisticated models such as the remote sensing foundation model. The code and demo of Remote Sensing ChatGPT is publicly available at https://github.com/HaonanGuo/Remote-Sensing-ChatGPT .","sentences":["Recently, the flourishing large language models(LLM), especially ChatGPT, have shown exceptional performance in language understanding, reasoning, and interaction, attracting users and researchers from multiple fields and domains.","Although LLMs have shown great capacity to perform human-like task accomplishment in natural language and natural image, their potential in handling remote sensing interpretation tasks has not yet been fully explored.","Moreover, the lack of automation in remote sensing task planning hinders the accessibility of remote sensing interpretation techniques, especially to non-remote sensing experts from multiple research fields.","To this end, we present Remote Sensing ChatGPT, an LLM-powered agent that utilizes ChatGPT to connect various AI-based remote sensing models to solve complicated interpretation tasks.","More specifically, given a user request and a remote sensing image, we utilized ChatGPT to understand user requests, perform task planning according to the tasks' functions, execute each subtask iteratively, and generate the final response according to the output of each subtask.","Considering that LLM is trained with natural language and is not capable of directly perceiving visual concepts as contained in remote sensing images, we designed visual cues that inject visual information into ChatGPT.","With Remote Sensing ChatGPT, users can simply send a remote sensing image with the corresponding request, and get the interpretation results as well as language feedback from Remote Sensing ChatGPT.","Experiments and examples show that Remote Sensing ChatGPT can tackle a wide range of remote sensing tasks and can be extended to more tasks with more sophisticated models such as the remote sensing foundation model.","The code and demo of Remote Sensing ChatGPT is publicly available at https://github.com/HaonanGuo/Remote-Sensing-ChatGPT ."],"url":"http://arxiv.org/abs/2401.09083v1"}
{"created":"2024-01-17 09:44:03","title":"What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents","abstract":"With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good' social actors and treat people respectfully.","sentences":["With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate.","These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements.","Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations.","We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s).","Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good' social actors and treat people respectfully."],"url":"http://arxiv.org/abs/2401.09082v1"}
{"created":"2024-01-17 09:23:59","title":"Code Simulation Challenges for Large Language Models","abstract":"We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirically, our new Chain of Simulation (CoSm) method improves on the standard Chain of Thought prompting approach by avoiding the pitfalls of memorisation.","sentences":["We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms.","We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code.","We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions.","We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution.","We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures.","LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line.","Empirically, our new Chain of Simulation (CoSm) method improves on the standard Chain of Thought prompting approach by avoiding the pitfalls of memorisation."],"url":"http://arxiv.org/abs/2401.09074v1"}
{"created":"2024-01-17 08:32:17","title":"Canvil: Designerly Adaptation for LLM-Powered User Experiences","abstract":"Advancements in large language models (LLMs) are poised to spark a proliferation of LLM-powered user experiences. In product teams, designers are often tasked with crafting user experiences that align with user needs. To involve designers and leverage their user-centered perspectives to create effective and responsible LLM-powered products, we introduce the practice of designerly adaptation for engaging with LLMs as an adaptable design material. We first identify key characteristics of designerly adaptation through a formative study with designers experienced in designing for LLM-powered products (N=12). These characteristics are 1) have a low technical barrier to entry, 2) leverage designers' unique perspectives bridging users and technology, and 3) encourage model tinkering. Based on this characterization, we build Canvil, a Figma widget that operationalizes designerly adaptation. Canvil supports structured authoring of system prompts to adapt LLM behavior, testing of adapted models on diverse user inputs, and integration of model outputs into interface designs. We use Canvil as a technology probe in a group-based design study (6 groups, N=17) to investigate the implications of integrating designerly adaptation into design workflows. We find that designers are able to iteratively tinker with different adaptation approaches and reason about interface affordances to enhance end-user interaction with LLMs. Furthermore, designers identified promising collaborative workflows for designerly adaptation. Our work opens new avenues for collaborative processes and tools that foreground designers' user-centered expertise in the crafting and deployment of LLM-powered user experiences.","sentences":["Advancements in large language models (LLMs) are poised to spark a proliferation of LLM-powered user experiences.","In product teams, designers are often tasked with crafting user experiences that align with user needs.","To involve designers and leverage their user-centered perspectives to create effective and responsible LLM-powered products, we introduce the practice of designerly adaptation for engaging with LLMs as an adaptable design material.","We first identify key characteristics of designerly adaptation through a formative study with designers experienced in designing for LLM-powered products (N=12).","These characteristics are 1) have a low technical barrier to entry, 2) leverage designers' unique perspectives bridging users and technology, and 3) encourage model tinkering.","Based on this characterization, we build Canvil, a Figma widget that operationalizes designerly adaptation.","Canvil supports structured authoring of system prompts to adapt LLM behavior, testing of adapted models on diverse user inputs, and integration of model outputs into interface designs.","We use Canvil as a technology probe in a group-based design study (6 groups, N=17) to investigate the implications of integrating designerly adaptation into design workflows.","We find that designers are able to iteratively tinker with different adaptation approaches and reason about interface affordances to enhance end-user interaction with LLMs.","Furthermore, designers identified promising collaborative workflows for designerly adaptation.","Our work opens new avenues for collaborative processes and tools that foreground designers' user-centered expertise in the crafting and deployment of LLM-powered user experiences."],"url":"http://arxiv.org/abs/2401.09051v1"}
{"created":"2024-01-17 08:22:52","title":"LLMs for Relational Reasoning: How Far are We?","abstract":"Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting.","sentences":["Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.)","by achieving state-of-the-art performance on extensive downstream tasks.","Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs.","Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks.","Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks.","In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples.","Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting."],"url":"http://arxiv.org/abs/2401.09042v1"}
{"created":"2024-01-17 06:48:16","title":"Augmenting Math Word Problems via Iterative Question Composing","abstract":"Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\\% accuracy on MATH(arXiv:2103.03874), 5.8\\% higher than the previous (model size $\\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.","sentences":["Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs.","In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills.","Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\\% accuracy on MATH(arXiv:2103.03874), 5.8\\% higher than the previous (model size $\\sim$7B) SOTA.","Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM.","MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC."],"url":"http://arxiv.org/abs/2401.09003v1"}
{"created":"2024-01-17 06:42:44","title":"AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models","abstract":"In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations. Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation. Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding. Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks. This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field. Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation aligns with the baseline's trend while offering a more profound and detailed assessment. We believe that by accurately evaluating the effectiveness of attack prompts in the Jailbreak task, our work lays a solid foundation for assessing a wider array of similar or even more complex tasks in the realm of prompt injection, potentially revolutionizing this field.","sentences":["In our research, we pioneer a novel approach to evaluate the effectiveness of jailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2, diverging from traditional robustness-focused binary evaluations.","Our study introduces two distinct evaluation frameworks: a coarse-grained evaluation and a fine-grained evaluation.","Each framework, using a scoring range from 0 to 1, offers a unique perspective, enabling a more comprehensive and nuanced evaluation of attack effectiveness and empowering attackers to refine their attack prompts with greater understanding.","Furthermore, we have developed a comprehensive ground truth dataset specifically tailored for jailbreak tasks.","This dataset not only serves as a crucial benchmark for our current study but also establishes a foundational resource for future research, enabling consistent and comparative analyses in this evolving field.","Upon meticulous comparison with traditional evaluation methods, we discovered that our evaluation aligns with the baseline's trend while offering a more profound and detailed assessment.","We believe that by accurately evaluating the effectiveness of attack prompts in the Jailbreak task, our work lays a solid foundation for assessing a wider array of similar or even more complex tasks in the realm of prompt injection, potentially revolutionizing this field."],"url":"http://arxiv.org/abs/2401.09002v1"}
{"created":"2024-01-17 04:43:21","title":"ReFT: Reasoning with Reinforced Fine-Tuning","abstract":"One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data. In math problem-solving, for example, there is usually only one annotated reasoning path for each question in the training data. Intuitively, it would be better for the algorithm to learn from multiple annotated reasoning paths given a question. To address this issue, we propose a simple yet effective approach called Reinforced Fine-Tuning (ReFT) to enhance the generalizability of learning LLMs for reasoning, with math problem-solving as an example. ReFT first warmups the model with SFT, and then employs on-line reinforcement learning, specifically the PPO algorithm in this paper, to further fine-tune the model, where an abundance of reasoning paths are automatically sampled given the question and the rewards are naturally derived from the ground-truth answers. Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that ReFT significantly outperforms SFT, and the performance can be potentially further boosted by combining inference-time strategies such as majority voting and re-ranking. Note that ReFT obtains the improvement by learning from the same training questions as SFT, without relying on extra or augmented training questions. This indicates a superior generalization ability for ReFT.","sentences":["One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations.","This approach does not show sufficiently strong generalization ability, however, because the training only relies on the given CoT data.","In math problem-solving, for example, there is usually only one annotated reasoning path for each question in the training data.","Intuitively, it would be better for the algorithm to learn from multiple annotated reasoning paths given a question.","To address this issue, we propose a simple yet effective approach called Reinforced Fine-Tuning (ReFT) to enhance the generalizability of learning LLMs for reasoning, with math problem-solving as an example.","ReFT first warmups the model with SFT, and then employs on-line reinforcement learning, specifically the PPO algorithm in this paper, to further fine-tune the model, where an abundance of reasoning paths are automatically sampled given the question and the rewards are naturally derived from the ground-truth answers.","Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that ReFT significantly outperforms SFT, and the performance can be potentially further boosted by combining inference-time strategies such as majority voting and re-ranking.","Note that ReFT obtains the improvement by learning from the same training questions as SFT, without relying on extra or augmented training questions.","This indicates a superior generalization ability for ReFT."],"url":"http://arxiv.org/abs/2401.08967v1"}
