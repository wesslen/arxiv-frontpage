{"created":"2024-09-09 17:30:20","title":"Are Large Language Models a Threat to Programming Platforms? An Exploratory Study","abstract":"Competitive programming platforms like LeetCode, Codeforces, and HackerRank evaluate programming skills, often used by recruiters for screening. With the rise of advanced Large Language Models (LLMs) such as ChatGPT, Gemini, and Meta AI, their problem-solving ability on these platforms needs assessment. This study explores LLMs' ability to tackle diverse programming challenges across platforms with varying difficulty, offering insights into their real-time and offline performance and comparing them with human programmers.   We tested 98 problems from LeetCode, 126 from Codeforces, covering 15 categories. Nine online contests from Codeforces and LeetCode were conducted, along with two certification tests on HackerRank, to assess real-time performance. Prompts and feedback mechanisms were used to guide LLMs, and correlations were explored across different scenarios.   LLMs, like ChatGPT (71.43% success on LeetCode), excelled in LeetCode and HackerRank certifications but struggled in virtual contests, particularly on Codeforces. They performed better than users in LeetCode archives, excelling in time and memory efficiency but underperforming in harder Codeforces contests. While not immediately threatening, LLMs performance on these platforms is concerning, and future improvements will need addressing.","sentences":["Competitive programming platforms like LeetCode, Codeforces, and HackerRank evaluate programming skills, often used by recruiters for screening.","With the rise of advanced Large Language Models (LLMs) such as ChatGPT, Gemini, and Meta AI, their problem-solving ability on these platforms needs assessment.","This study explores LLMs' ability to tackle diverse programming challenges across platforms with varying difficulty, offering insights into their real-time and offline performance and comparing them with human programmers.   ","We tested 98 problems from LeetCode, 126 from Codeforces, covering 15 categories.","Nine online contests from Codeforces and LeetCode were conducted, along with two certification tests on HackerRank, to assess real-time performance.","Prompts and feedback mechanisms were used to guide LLMs, and correlations were explored across different scenarios.   ","LLMs, like ChatGPT (71.43% success on LeetCode), excelled in LeetCode and HackerRank certifications but struggled in virtual contests, particularly on Codeforces.","They performed better than users in LeetCode archives, excelling in time and memory efficiency but underperforming in harder Codeforces contests.","While not immediately threatening, LLMs performance on these platforms is concerning, and future improvements will need addressing."],"url":"http://arxiv.org/abs/2409.05824v1"}
{"created":"2024-09-09 17:23:29","title":"Improving Pretraining Data Using Perplexity Correlations","abstract":"Quality pretraining data is often seen as the key to high-performance language models. However, progress in understanding pretraining data has been slow due to the costly pretraining runs required for data selection experiments. We present a framework that avoids these costs and selects high-quality pretraining data without any LLM training of our own. Our work is based on a simple observation: LLM losses on many pretraining texts are correlated with downstream benchmark performance, and selecting high-correlation documents is an effective pretraining data selection method. We build a new statistical framework for data selection centered around estimates of perplexity-benchmark correlations and perform data selection using a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of thousands of web domains. In controlled pretraining experiments at the 160M parameter scale on 8 benchmarks, our approach outperforms DSIR on every benchmark, while matching the best data selector found in DataComp-LM, a hand-engineered bigram classifier.","sentences":["Quality pretraining data is often seen as the key to high-performance language models.","However, progress in understanding pretraining data has been slow due to the costly pretraining runs required for data selection experiments.","We present a framework that avoids these costs and selects high-quality pretraining data without any LLM training of our own.","Our work is based on a simple observation: LLM losses on many pretraining texts are correlated with downstream benchmark performance, and selecting high-correlation documents is an effective pretraining data selection method.","We build a new statistical framework for data selection centered around estimates of perplexity-benchmark correlations and perform data selection using a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of thousands of web domains.","In controlled pretraining experiments at the 160M parameter scale on 8 benchmarks, our approach outperforms DSIR on every benchmark, while matching the best data selector found in DataComp-LM, a hand-engineered bigram classifier."],"url":"http://arxiv.org/abs/2409.05816v1"}
{"created":"2024-09-09 17:11:51","title":"Benchmarking Chinese Knowledge Rectification in Large Language Models","abstract":"While Large Language Models (LLMs) exhibit remarkable generative capabilities, they are not without flaws, particularly in the form of hallucinations. This issue is even more pronounced when LLMs are applied to specific languages and domains. For example, LLMs may generate nonsense information when handling Chinese ancient poetry, proverbs, or idioms, owing to the lack of specific knowledge. To this end, this paper introduces a benchmark for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically, we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of knowledge from various sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony, antithesis, and logical constructs inherent in the Chinese language. Through the analysis of this dataset, we uncover the challenges faced by current LLMs in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques on this dataset unveil the substantial scope for advancement in the rectification of Chinese knowledge. Code and dataset are available at https://github.com/zjunlp/EasyEdit.","sentences":["While Large Language Models (LLMs) exhibit remarkable generative capabilities, they are not without flaws, particularly in the form of hallucinations.","This issue is even more pronounced when LLMs are applied to specific languages and domains.","For example, LLMs may generate nonsense information when handling Chinese ancient poetry, proverbs, or idioms, owing to the lack of specific knowledge.","To this end, this paper introduces a benchmark for rectifying Chinese knowledge in LLMs via knowledge editing.","Specifically, we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of knowledge from various sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony, antithesis, and logical constructs inherent in the Chinese language.","Through the analysis of this dataset, we uncover the challenges faced by current LLMs in mastering Chinese.","Furthermore, our evaluation of state-of-the-art knowledge editing techniques on this dataset unveil the substantial scope for advancement in the rectification of Chinese knowledge.","Code and dataset are available at https://github.com/zjunlp/EasyEdit."],"url":"http://arxiv.org/abs/2409.05806v1"}
{"created":"2024-09-09 16:33:16","title":"Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models","abstract":"Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.","sentences":["Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli.","Yet, very little is known about the representation properties that enable this high prediction performance.","Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task?","In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs.","We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues.","Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs.","We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."],"url":"http://arxiv.org/abs/2409.05771v1"}
{"created":"2024-09-09 16:32:14","title":"Model Input Verification of Large Scale Simulations","abstract":"Reliable simulations are critical for analyzing and understanding complex systems, but their accuracy depends on correct input data. Incorrect inputs such as invalid or out-of-range values, missing data, and format inconsistencies can cause simulation crashes or unnoticed result distortions, ultimately undermining the validity of the conclusions. This paper presents a methodology for verifying the validity of input data in simulations, a process we term model input verification (MIV). We implement this approach in FabGuard, a toolset that uses established data schema and validation tools for the specific needs of simulation modeling. We introduce a formalism for categorizing MIV patterns and offer a streamlined verification pipeline that integrates into existing simulation workflows. FabGuard's applicability is demonstrated across three diverse domains: conflict-driven migration, disaster evacuation, and disease spread models. We also explore the use of Large Language Models (LLMs) for automating constraint generation and inference. In a case study with a migration simulation, LLMs not only correctly inferred 22 out of 23 developer-defined constraints, but also identified errors in existing constraints and proposed new, valid constraints. Our evaluation demonstrates that MIV is feasible on large datasets, with FabGuard efficiently processing 12,000 input files in 140 seconds and maintaining consistent performance across varying file sizes.","sentences":["Reliable simulations are critical for analyzing and understanding complex systems, but their accuracy depends on correct input data.","Incorrect inputs such as invalid or out-of-range values, missing data, and format inconsistencies can cause simulation crashes or unnoticed result distortions, ultimately undermining the validity of the conclusions.","This paper presents a methodology for verifying the validity of input data in simulations, a process we term model input verification (MIV).","We implement this approach in FabGuard, a toolset that uses established data schema and validation tools for the specific needs of simulation modeling.","We introduce a formalism for categorizing MIV patterns and offer a streamlined verification pipeline that integrates into existing simulation workflows.","FabGuard's applicability is demonstrated across three diverse domains: conflict-driven migration, disaster evacuation, and disease spread models.","We also explore the use of Large Language Models (LLMs) for automating constraint generation and inference.","In a case study with a migration simulation, LLMs not only correctly inferred 22 out of 23 developer-defined constraints, but also identified errors in existing constraints and proposed new, valid constraints.","Our evaluation demonstrates that MIV is feasible on large datasets, with FabGuard efficiently processing 12,000 input files in 140 seconds and maintaining consistent performance across varying file sizes."],"url":"http://arxiv.org/abs/2409.05768v1"}
{"created":"2024-09-09 16:02:27","title":"A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System","abstract":"This paper presents a novel conversational AI-enabled active ideation interface as a creative idea-generation tool to assist novice designers in mitigating the initial latency and ideation bottlenecks that are commonly observed. It is a dynamic, interactive, and contextually responsive approach, actively involving a large language model (LLM) from the domain of natural language processing (NLP) in artificial intelligence (AI) to produce multiple statements of potential ideas for different design problems. Integrating such AI models with ideation creates what we refer to as an Active Ideation scenario, which helps foster continuous dialogue-based interaction, context-sensitive conversation, and prolific idea generation. A pilot study was conducted with thirty novice designers to generate ideas for given problems using traditional methods and the new CAI-based interface. The key parameters of fluency, novelty, and variety were used to compare the outcomes qualitatively by a panel of experts. The findings demonstrated the effectiveness of the proposed tool for generating prolific, diverse and novel ideas. The interface was enhanced by incorporating a prompt-engineered structured dialogue style for each ideation stage to make it uniform and more convenient for the designers. The resulting responses of such a structured CAI interface were found to be more succinct and aligned towards the subsequent design stage, namely conceptualization. The paper thus established the rich potential of using Generative AI (Gen-AI) for the early ill-structured phase of the creative product design process.","sentences":["This paper presents a novel conversational AI-enabled active ideation interface as a creative idea-generation tool to assist novice designers in mitigating the initial latency and ideation bottlenecks that are commonly observed.","It is a dynamic, interactive, and contextually responsive approach, actively involving a large language model (LLM) from the domain of natural language processing (NLP) in artificial intelligence (AI) to produce multiple statements of potential ideas for different design problems.","Integrating such AI models with ideation creates what we refer to as an Active Ideation scenario, which helps foster continuous dialogue-based interaction, context-sensitive conversation, and prolific idea generation.","A pilot study was conducted with thirty novice designers to generate ideas for given problems using traditional methods and the new CAI-based interface.","The key parameters of fluency, novelty, and variety were used to compare the outcomes qualitatively by a panel of experts.","The findings demonstrated the effectiveness of the proposed tool for generating prolific, diverse and novel ideas.","The interface was enhanced by incorporating a prompt-engineered structured dialogue style for each ideation stage to make it uniform and more convenient for the designers.","The resulting responses of such a structured CAI interface were found to be more succinct and aligned towards the subsequent design stage, namely conceptualization.","The paper thus established the rich potential of using Generative AI (Gen-AI) for the early ill-structured phase of the creative product design process."],"url":"http://arxiv.org/abs/2409.05747v1"}
{"created":"2024-09-09 16:01:58","title":"LLMs Will Always Hallucinate, and We Need to Live With This","abstract":"As Large Language Models become more ubiquitous across domains, it becomes important to examine their inherent limitations critically. This work argues that hallucinations in language models are not just occasional errors but an inevitable feature of these systems. We demonstrate that hallucinations stem from the fundamental mathematical and logical structure of LLMs. It is, therefore, impossible to eliminate them through architectural improvements, dataset enhancements, or fact-checking mechanisms. Our analysis draws on computational theory and Godel's First Incompleteness Theorem, which references the undecidability of problems like the Halting, Emptiness, and Acceptance Problems. We demonstrate that every stage of the LLM process-from training data compilation to fact retrieval, intent classification, and text generation-will have a non-zero probability of producing hallucinations. This work introduces the concept of Structural Hallucination as an intrinsic nature of these systems. By establishing the mathematical certainty of hallucinations, we challenge the prevailing notion that they can be fully mitigated.","sentences":["As Large Language Models become more ubiquitous across domains, it becomes important to examine their inherent limitations critically.","This work argues that hallucinations in language models are not just occasional errors but an inevitable feature of these systems.","We demonstrate that hallucinations stem from the fundamental mathematical and logical structure of LLMs.","It is, therefore, impossible to eliminate them through architectural improvements, dataset enhancements, or fact-checking mechanisms.","Our analysis draws on computational theory and Godel's First Incompleteness Theorem, which references the undecidability of problems like the Halting, Emptiness, and Acceptance Problems.","We demonstrate that every stage of the LLM process-from training data compilation to fact retrieval, intent classification, and text generation-will have a non-zero probability of producing hallucinations.","This work introduces the concept of Structural Hallucination as an intrinsic nature of these systems.","By establishing the mathematical certainty of hallucinations, we challenge the prevailing notion that they can be fully mitigated."],"url":"http://arxiv.org/abs/2409.05746v1"}
{"created":"2024-09-09 15:44:39","title":"A System and Benchmark for LLM-based Q\\&A on Heterogeneous Data","abstract":"In many industrial settings, users wish to ask questions whose answers may be found in structured data sources such as a spreadsheets, databases, APIs, or combinations thereof. Often, the user doesn't know how to identify or access the right data source. This problem is compounded even further if multiple (and potentially siloed) data sources must be assembled to derive the answer. Recently, various Text-to-SQL applications that leverage Large Language Models (LLMs) have addressed some of these problems by enabling users to ask questions in natural language. However, these applications remain impractical in realistic industrial settings because they fail to cope with the data source heterogeneity that typifies such environments. In this paper, we address heterogeneity by introducing the siwarex platform, which enables seamless natural language access to both databases and APIs. To demonstrate the effectiveness of siwarex, we extend the popular Spider dataset and benchmark by replacing some of its tables by data retrieval APIs. We find that siwarex does a good job of coping with data source heterogeneity. Our modified Spider benchmark will soon be available to the research community","sentences":["In many industrial settings, users wish to ask questions whose answers may be found in structured data sources such as a spreadsheets, databases, APIs, or combinations thereof.","Often, the user doesn't know how to identify or access the right data source.","This problem is compounded even further if multiple (and potentially siloed) data sources must be assembled to derive the answer.","Recently, various Text-to-SQL applications that leverage Large Language Models (LLMs) have addressed some of these problems by enabling users to ask questions in natural language.","However, these applications remain impractical in realistic industrial settings because they fail to cope with the data source heterogeneity that typifies such environments.","In this paper, we address heterogeneity by introducing the siwarex platform, which enables seamless natural language access to both databases and APIs.","To demonstrate the effectiveness of siwarex, we extend the popular Spider dataset and benchmark by replacing some of its tables by data retrieval APIs.","We find that siwarex does a good job of coping with data source heterogeneity.","Our modified Spider benchmark will soon be available to the research community"],"url":"http://arxiv.org/abs/2409.05735v1"}
{"created":"2024-09-09 15:42:19","title":"Towards Democratizing Multilingual Large Language Models For Medicine Through A Two-Stage Instruction Fine-tuning Approach","abstract":"Open-source, multilingual medical large language models (LLMs) have the potential to serve linguistically diverse populations across different regions. Adapting generic LLMs for healthcare often requires continual pretraining, but this approach is computationally expensive and sometimes impractical. Instruction fine-tuning on a specific task may not always guarantee optimal performance due to the lack of broader domain knowledge that the model needs to understand and reason effectively in diverse scenarios. To address these challenges, we introduce two multilingual instruction fine-tuning datasets, MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in six languages. We propose a two-stage training paradigm: the first stage injects general medical knowledge using MMed-IFT, while the second stage fine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our method achieves competitive results on both English and multilingual benchmarks, striking a balance between computational efficiency and performance. We plan to make our dataset and model weights public at \\url{https://github.com/SpassMed/Med-Llama3} in the future.","sentences":["Open-source, multilingual medical large language models (LLMs) have the potential to serve linguistically diverse populations across different regions.","Adapting generic LLMs for healthcare often requires continual pretraining, but this approach is computationally expensive and sometimes impractical.","Instruction fine-tuning on a specific task may not always guarantee optimal performance due to the lack of broader domain knowledge that the model needs to understand and reason effectively in diverse scenarios.","To address these challenges, we introduce two multilingual instruction fine-tuning datasets, MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in six languages.","We propose a two-stage training paradigm: the first stage injects general medical knowledge using MMed-IFT, while the second stage fine-tunes task-specific multiple-choice questions with MMed-IFT-MC.","Our method achieves competitive results on both English and multilingual benchmarks, striking a balance between computational efficiency and performance.","We plan to make our dataset and model weights public at \\url{https://github.com/SpassMed/Med-Llama3} in the future."],"url":"http://arxiv.org/abs/2409.05732v1"}
{"created":"2024-09-09 15:14:31","title":"The Influence of Task and Group Disparities over Users' Attitudes Toward Using Large Language Models for Psychotherapy","abstract":"The population suffering from mental health disorders has kept increasing in recent years. With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention. However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored. As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools. Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China. The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools. Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention. These findings can guide the design of future LLM-based psychotherapy services.","sentences":["The population suffering from mental health disorders has kept increasing in recent years.","With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention.","However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored.","As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools.","Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China.","The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools.","Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention.","These findings can guide the design of future LLM-based psychotherapy services."],"url":"http://arxiv.org/abs/2409.05703v1"}
{"created":"2024-09-09 13:20:31","title":"MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery","abstract":"Retrieval-Augmented Generation (RAG) leverages retrieval tools to access external databases, thereby enhancing the generation quality of large language models (LLMs) through optimized context. However, the existing retrieval methods are constrained inherently, as they can only perform relevance matching between explicitly stated queries and well-formed knowledge, but unable to handle tasks involving ambiguous information needs or unstructured knowledge. Consequently, existing RAG systems are primarily effective for straightforward question-answering tasks. In this work, we propose MemoRAG, a novel retrieval-augmented generation paradigm empowered by long-term memory. MemoRAG adopts a dual-system architecture. On the one hand, it employs a light but long-range LLM to form the global memory of database. Once a task is presented, it generates draft answers, cluing the retrieval tools to locate useful information within the database. On the other hand, it leverages an expensive but expressive LLM, which generates the ultimate answer based on the retrieved information. Building on this general framework, we further optimize MemoRAG's performance by enhancing its cluing mechanism and memorization capacity. In our experiment, MemoRAG achieves superior performance across a variety of evaluation tasks, including both complex ones where conventional RAG fails and straightforward ones where RAG is commonly applied.","sentences":["Retrieval-Augmented Generation (RAG) leverages retrieval tools to access external databases, thereby enhancing the generation quality of large language models (LLMs) through optimized context.","However, the existing retrieval methods are constrained inherently, as they can only perform relevance matching between explicitly stated queries and well-formed knowledge, but unable to handle tasks involving ambiguous information needs or unstructured knowledge.","Consequently, existing RAG systems are primarily effective for straightforward question-answering tasks.","In this work, we propose MemoRAG, a novel retrieval-augmented generation paradigm empowered by long-term memory.","MemoRAG adopts a dual-system architecture.","On the one hand, it employs a light but long-range LLM to form the global memory of database.","Once a task is presented, it generates draft answers, cluing the retrieval tools to locate useful information within the database.","On the other hand, it leverages an expensive but expressive LLM, which generates the ultimate answer based on the retrieved information.","Building on this general framework, we further optimize MemoRAG's performance by enhancing its cluing mechanism and memorization capacity.","In our experiment, MemoRAG achieves superior performance across a variety of evaluation tasks, including both complex ones where conventional RAG fails and straightforward ones where RAG is commonly applied."],"url":"http://arxiv.org/abs/2409.05591v2"}
{"created":"2024-09-09 12:30:43","title":"CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning","abstract":"Large language models (LLMs) have been utilized in solving diverse reasoning tasks, encompassing common sense, arithmetic and deduction tasks. However, with difficulties of reversing thinking patterns and irrelevant premises, how to determine the authenticity of the cause in abductive logical reasoning remains underexplored. Inspired by hypothesis and verification method and identification of irrelevant information in human thinking process, we propose a new framework for LLMs abductive logical reasoning called CauseJudger (CJ), which identifies the authenticity of possible cause by transforming thinking from reverse to forward and removing irrelevant information. In addition, we construct an abductive logical reasoning dataset for decision task called CauseLogics, which contains 200,000 tasks of varying reasoning lengths. Our experiments show the efficiency of CJ with overall experiments and ablation experiments as well as case studies on our dataset and reconstructed public dataset. Notably, CJ's implementation is efficient, requiring only two calls to LLM. Its impact is profound: when using gpt-3.5, CJ achieves a maximum correctness improvement of 41% compared to Zero-Shot-CoT. Moreover, with gpt-4, CJ attains an accuracy exceeding 90% across all datasets.","sentences":["Large language models (LLMs) have been utilized in solving diverse reasoning tasks, encompassing common sense, arithmetic and deduction tasks.","However, with difficulties of reversing thinking patterns and irrelevant premises, how to determine the authenticity of the cause in abductive logical reasoning remains underexplored.","Inspired by hypothesis and verification method and identification of irrelevant information in human thinking process, we propose a new framework for LLMs abductive logical reasoning called CauseJudger (CJ), which identifies the authenticity of possible cause by transforming thinking from reverse to forward and removing irrelevant information.","In addition, we construct an abductive logical reasoning dataset for decision task called CauseLogics, which contains 200,000 tasks of varying reasoning lengths.","Our experiments show the efficiency of CJ with overall experiments and ablation experiments as well as case studies on our dataset and reconstructed public dataset.","Notably, CJ's implementation is efficient, requiring only two calls to LLM.","Its impact is profound: when using gpt-3.5, CJ achieves a maximum correctness improvement of 41% compared to Zero-Shot-CoT.","Moreover, with gpt-4, CJ attains an accuracy exceeding 90% across all datasets."],"url":"http://arxiv.org/abs/2409.05559v1"}
{"created":"2024-09-09 12:25:10","title":"SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning","abstract":"A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations. Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a `swarm of intelligence' similar to biological systems. This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature's design principles.","sentences":["A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data.","In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities.","Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods.","The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties.","By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations.","Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a `swarm of intelligence' similar to biological systems.","This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature's design principles."],"url":"http://arxiv.org/abs/2409.05556v1"}
{"created":"2024-09-09 11:28:02","title":"Harmonic Reasoning in Large Language Models","abstract":"Large Language Models (LLMs) are becoming very popular and are used for many different purposes, including creative tasks in the arts. However, these models sometimes have trouble with specific reasoning tasks, especially those that involve logical thinking and counting. This paper looks at how well LLMs understand and reason when dealing with musical tasks like figuring out notes from intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o to see how they handle these tasks. Our results show that while LLMs do well with note intervals, they struggle with more complicated tasks like recognizing chords and scales. This points out clear limits in current LLM abilities and shows where we need to make them better, which could help improve how they think and work in both artistic and other complex areas. We also provide an automatically generated benchmark data set for the described tasks.","sentences":["Large Language Models (LLMs) are becoming very popular and are used for many different purposes, including creative tasks in the arts.","However, these models sometimes have trouble with specific reasoning tasks, especially those that involve logical thinking and counting.","This paper looks at how well LLMs understand and reason when dealing with musical tasks like figuring out notes from intervals and identifying chords and scales.","We tested GPT-3.5 and GPT-4o to see how they handle these tasks.","Our results show that while LLMs do well with note intervals, they struggle with more complicated tasks like recognizing chords and scales.","This points out clear limits in current LLM abilities and shows where we need to make them better, which could help improve how they think and work in both artistic and other complex areas.","We also provide an automatically generated benchmark data set for the described tasks."],"url":"http://arxiv.org/abs/2409.05521v1"}
{"created":"2024-09-09 11:09:28","title":"Enhancing Critical Thinking in Education by means of a Socratic Chatbot","abstract":"While large language models (LLMs) are increasingly playing a pivotal role in education by providing instantaneous, adaptive responses, their potential to promote critical thinking remains understudied. In this paper, we fill such a gap and present an innovative educational chatbot designed to foster critical thinking through Socratic questioning. Unlike traditional intelligent tutoring systems, including educational chatbots, that tend to offer direct answers, the proposed Socratic tutor encourages students to explore various perspectives and engage in self-reflection by posing structured, thought-provoking questions. Our Socratic questioning is implemented by fine and prompt-tuning the open-source pretrained LLM with a specialized dataset that stimulates critical thinking and offers multiple viewpoints. In an effort to democratize access and to protect the students' privacy, the proposed tutor is based on small LLMs (Llama2 7B and 13B-parameter models) that are able to run locally on off-the-shelf hardware. We validate our approach in a battery of experiments consisting of interactions between a simulated student and the chatbot to evaluate its effectiveness in enhancing critical thinking skills. Results indicate that the Socratic tutor supports the development of reflection and critical thinking significantly better than standard chatbots. Our approach opens the door for improving educational outcomes by cultivating active learning and encouraging intellectual autonomy.","sentences":["While large language models (LLMs) are increasingly playing a pivotal role in education by providing instantaneous, adaptive responses, their potential to promote critical thinking remains understudied.","In this paper, we fill such a gap and present an innovative educational chatbot designed to foster critical thinking through Socratic questioning.","Unlike traditional intelligent tutoring systems, including educational chatbots, that tend to offer direct answers, the proposed Socratic tutor encourages students to explore various perspectives and engage in self-reflection by posing structured, thought-provoking questions.","Our Socratic questioning is implemented by fine and prompt-tuning the open-source pretrained LLM with a specialized dataset that stimulates critical thinking and offers multiple viewpoints.","In an effort to democratize access and to protect the students' privacy, the proposed tutor is based on small LLMs (Llama2 7B and 13B-parameter models) that are able to run locally on off-the-shelf hardware.","We validate our approach in a battery of experiments consisting of interactions between a simulated student and the chatbot to evaluate its effectiveness in enhancing critical thinking skills.","Results indicate that the Socratic tutor supports the development of reflection and critical thinking significantly better than standard chatbots.","Our approach opens the door for improving educational outcomes by cultivating active learning and encouraging intellectual autonomy."],"url":"http://arxiv.org/abs/2409.05511v1"}
{"created":"2024-09-09 08:05:43","title":"DFabric: Scaling Out Data Parallel Applications with CXL-Ethernet Hybrid Interconnects","abstract":"Emerging interconnects, such as CXL and NVLink, have been integrated into the intra-host topology to scale more accelerators and facilitate efficient communication between them, such as GPUs. To keep pace with the accelerator's growing computing throughput, the interconnect has seen substantial enhancement in link bandwidth, e.g., 256GBps for CXL 3.0 links, which surpasses Ethernet and InfiniBand network links by an order of magnitude or more. Consequently, when data-intensive jobs, such as LLM training, scale across multiple hosts beyond the reach limit of the interconnect, the performance is significantly hindered by the limiting bandwidth of the network infrastructure. We address the problem by proposing DFabric, a two-tier interconnect architecture. We address the problem by proposing DFabric, a two-tier interconnect architecture. First, DFabric disaggregates rack's computing units with an interconnect fabric, i.e., CXL fabric, which scales at rack-level, so that they can enjoy intra-rack efficient interconnecting. Second, DFabric disaggregates NICs from hosts, and consolidates them to form a NIC pool with CXL fabric. By providing sufficient aggregated capacity comparable to interconnect bandwidth, the NIC pool bridges efficient communication across racks or beyond the reach limit of interconnect fabric. However, the local memory accessing becomes the bottleneck when enabling each host to utilize the NIC pool efficiently. To the end, DFabric builds a memory pool with sufficient bandwidth by disaggregating host local memory and adding more memory devices. We have implemented a prototype of DFabric that can run applications transparently. We validated its performance gain by running various microbenchmarks and compute-intensive applications such as DNN and graph.","sentences":["Emerging interconnects, such as CXL and NVLink, have been integrated into the intra-host topology to scale more accelerators and facilitate efficient communication between them, such as GPUs.","To keep pace with the accelerator's growing computing throughput, the interconnect has seen substantial enhancement in link bandwidth, e.g., 256GBps for CXL 3.0 links, which surpasses Ethernet and InfiniBand network links by an order of magnitude or more.","Consequently, when data-intensive jobs, such as LLM training, scale across multiple hosts beyond the reach limit of the interconnect, the performance is significantly hindered by the limiting bandwidth of the network infrastructure.","We address the problem by proposing DFabric, a two-tier interconnect architecture.","We address the problem by proposing DFabric, a two-tier interconnect architecture.","First, DFabric disaggregates rack's computing units with an interconnect fabric, i.e., CXL fabric, which scales at rack-level, so that they can enjoy intra-rack efficient interconnecting.","Second, DFabric disaggregates NICs from hosts, and consolidates them to form a NIC pool with CXL fabric.","By providing sufficient aggregated capacity comparable to interconnect bandwidth, the NIC pool bridges efficient communication across racks or beyond the reach limit of interconnect fabric.","However, the local memory accessing becomes the bottleneck when enabling each host to utilize the NIC pool efficiently.","To the end, DFabric builds a memory pool with sufficient bandwidth by disaggregating host local memory and adding more memory devices.","We have implemented a prototype of DFabric that can run applications transparently.","We validated its performance gain by running various microbenchmarks and compute-intensive applications such as DNN and graph."],"url":"http://arxiv.org/abs/2409.05404v1"}
{"created":"2024-09-09 07:32:30","title":"Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models","abstract":"The development of LLMs has greatly enhanced the intelligence and fluency of question answering, while the emergence of retrieval enhancement has enabled models to better utilize external information. However, the presence of noise and errors in retrieved information poses challenges to the robustness of LLMs. In this work, to evaluate the model's performance under multiple interferences, we first construct a dataset based on machine reading comprehension datasets simulating various scenarios, including critical information absence, noise, and conflicts. To address the issue of model accuracy decline caused by noisy external information, we propose a data augmentation-based fine-tuning method to enhance LLM's robustness against noise. Additionally, contrastive learning approach is utilized to preserve the model's discrimination capability of external information. We have conducted experiments on both existing LLMs and our approach, the results are evaluated by GPT-4, which indicates that our proposed methods improve model robustness while strengthening the model's discrimination capability.","sentences":["The development of LLMs has greatly enhanced the intelligence and fluency of question answering, while the emergence of retrieval enhancement has enabled models to better utilize external information.","However, the presence of noise and errors in retrieved information poses challenges to the robustness of LLMs.","In this work, to evaluate the model's performance under multiple interferences, we first construct a dataset based on machine reading comprehension datasets simulating various scenarios, including critical information absence, noise, and conflicts.","To address the issue of model accuracy decline caused by noisy external information, we propose a data augmentation-based fine-tuning method to enhance LLM's robustness against noise.","Additionally, contrastive learning approach is utilized to preserve the model's discrimination capability of external information.","We have conducted experiments on both existing LLMs and our approach, the results are evaluated by GPT-4, which indicates that our proposed methods improve model robustness while strengthening the model's discrimination capability."],"url":"http://arxiv.org/abs/2409.05385v2"}
{"created":"2024-09-09 06:57:22","title":"KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models","abstract":"Harnessing the robust capabilities of Large Language Models (LLMs) for narrative generation, logical reasoning, and common-sense knowledge integration, this study delves into utilizing LLMs to enhance automated radiology report generation (R2Gen). Despite the wealth of knowledge within LLMs, efficiently triggering relevant knowledge within these large models for specific tasks like R2Gen poses a critical research challenge. This paper presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration framework based on LLMs. Utilizing a frozen LLM to generate reports, the framework integrates a knowledge graph to unlock chest disease-related knowledge within the LLM to enhance the clinical utility of generated reports. This is achieved by leveraging the knowledge graph to distill disease-related features in a designed way. Since a radiology report encompasses both normal and disease-related findings, the extracted graph-enhanced disease-related features are integrated with regional image features, attending to both aspects. We explore two fusion methods to automatically prioritize and select the most relevant features. The fused features are employed by LLM to generate reports that are more sensitive to diseases and of improved quality. Our approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.","sentences":["Harnessing the robust capabilities of Large Language Models (LLMs) for narrative generation, logical reasoning, and common-sense knowledge integration, this study delves into utilizing LLMs to enhance automated radiology report generation (R2Gen).","Despite the wealth of knowledge within LLMs, efficiently triggering relevant knowledge within these large models for specific tasks like R2Gen poses a critical research challenge.","This paper presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration framework based on LLMs.","Utilizing a frozen LLM to generate reports, the framework integrates a knowledge graph to unlock chest disease-related knowledge within the LLM to enhance the clinical utility of generated reports.","This is achieved by leveraging the knowledge graph to distill disease-related features in a designed way.","Since a radiology report encompasses both normal and disease-related findings, the extracted graph-enhanced disease-related features are integrated with regional image features, attending to both aspects.","We explore two fusion methods to automatically prioritize and select the most relevant features.","The fused features are employed by LLM to generate reports that are more sensitive to diseases and of improved quality.","Our approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets."],"url":"http://arxiv.org/abs/2409.05370v1"}
{"created":"2024-09-09 06:55:37","title":"Diagnostic Reasoning in Natural Language: Computational Model and Application","abstract":"Diagnostic reasoning is a key component of expert work in many domains. It is a hard, time-consuming activity that requires expertise, and AI research has investigated the ways automated systems can support this process. Yet, due to the complexity of natural language, the applications of AI for diagnostic reasoning to language-related tasks are lacking. To close this gap, we investigate diagnostic abductive reasoning (DAR) in the context of language-grounded tasks (NL-DAR). We propose a novel modeling framework for NL-DAR based on Pearl's structural causal models and instantiate it in a comprehensive study of scientific paper assessment in the biomedical domain. We use the resulting dataset to investigate the human decision-making process in NL-DAR and determine the potential of LLMs to support structured decision-making over text. Our framework, open resources and tools lay the groundwork for the empirical study of collaborative diagnostic reasoning in the age of LLMs, in the scholarly domain and beyond.","sentences":["Diagnostic reasoning is a key component of expert work in many domains.","It is a hard, time-consuming activity that requires expertise, and AI research has investigated the ways automated systems can support this process.","Yet, due to the complexity of natural language, the applications of AI for diagnostic reasoning to language-related tasks are lacking.","To close this gap, we investigate diagnostic abductive reasoning (DAR) in the context of language-grounded tasks (NL-DAR).","We propose a novel modeling framework for NL-DAR based on Pearl's structural causal models and instantiate it in a comprehensive study of scientific paper assessment in the biomedical domain.","We use the resulting dataset to investigate the human decision-making process in NL-DAR and determine the potential of LLMs to support structured decision-making over text.","Our framework, open resources and tools lay the groundwork for the empirical study of collaborative diagnostic reasoning in the age of LLMs, in the scholarly domain and beyond."],"url":"http://arxiv.org/abs/2409.05367v1"}
