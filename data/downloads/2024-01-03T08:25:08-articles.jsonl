{"created":"2024-01-02 18:59:55","title":"Street Gaussians for Modeling Dynamic Urban Scenes","abstract":"This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos. Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes. However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses. We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations. Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background. To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance. The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066$\\times$1600 resolution) within half an hour of training. The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets. Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets. Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker. The code is available at https://zju3dv.github.io/street_gaussians/.","sentences":["This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos.","Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes.","However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses.","We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations.","Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background.","To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance.","The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066$\\times$1600 resolution) within half an hour of training.","The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets.","Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets.","Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker.","The code is available at https://zju3dv.github.io/street_gaussians/."],"url":"http://arxiv.org/abs/2401.01339v1"}
{"created":"2024-01-02 18:53:13","title":"Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models","abstract":"Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.","sentences":["Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs).","In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data.","We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.","At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself.","More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data.","Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT.","Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution.","Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench.","Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data.","This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents."],"url":"http://arxiv.org/abs/2401.01335v1"}
{"created":"2024-01-02 18:40:03","title":"TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview","abstract":"Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions about the information space include: finding options, comparing options, identifying the pros and cons of options, etc. Given the different personas and their information need (expressed through the sequence of questions), diverse conversation trajectories will arise -- because the answers to these similar queries will be very different. In this paper, we report on the first year of TREC iKAT, describing the task, topics, data collection, and evaluation framework. We further review the submissions and summarize the findings.","sentences":["Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works.","The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT).","However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context.","The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them.","iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action.","These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions about the information space include: finding options, comparing options, identifying the pros and cons of options, etc.","Given the different personas and their information need (expressed through the sequence of questions), diverse conversation trajectories will arise -- because the answers to these similar queries will be very different.","In this paper, we report on the first year of TREC iKAT, describing the task, topics, data collection, and evaluation framework.","We further review the submissions and summarize the findings."],"url":"http://arxiv.org/abs/2401.01330v1"}
{"created":"2024-01-02 18:32:14","title":"An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction","abstract":"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.","sentences":["In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem.","In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}.","It generates a linearized graph where nodes represent text spans and edges represent relation triplets.","Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types.","Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism.","Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results.","Code is available at https://github.com/urchade/ATG."],"url":"http://arxiv.org/abs/2401.01326v1"}
{"created":"2024-01-02 18:30:51","title":"LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning","abstract":"This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length.","sentences":["This work elicits LLMs' inherent ability to handle long contexts without fine-tuning.","The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference.","In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts.","Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.","We propose Self-Extend to stimulate LLMs' long context handling potential.","The basic idea is to construct bi-level attention information: the group level and the neighbor level.","The two levels are computed by the original model's self-attention, which means the proposed does not require any training.","With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning.","We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length."],"url":"http://arxiv.org/abs/2401.01325v1"}
{"created":"2024-01-02 18:28:37","title":"Lower Bounds on Cardinality of Reducts for Decision Tables from Closed Classes","abstract":"In this paper, we consider classes of decision tables closed under removal of attributes (columns) and changing of decisions attached to rows. For decision tables from closed classes, we study lower bounds on the minimum cardinality of reducts, which are minimal sets of attributes that allow us to recognize, for a given row, the decision attached to it. We assume that the number of rows in decision tables from the closed class is not bounded from above by a constant. We divide the set of such closed classes into two families. In one family, only standard lower bounds $\\Omega (\\log $ ${\\rm cl}(T))$ on the minimum cardinality of reducts for decision tables hold, where ${\\rm cl}(T)$ is the number of decision classes in the table $T$. In another family, these bounds can be essentially tightened up to $\\Omega ({\\rm cl}(T)^{1/q})$ for some natural $q$.","sentences":["In this paper, we consider classes of decision tables closed under removal of attributes (columns) and changing of decisions attached to rows.","For decision tables from closed classes, we study lower bounds on the minimum cardinality of reducts, which are minimal sets of attributes that allow us to recognize, for a given row, the decision attached to it.","We assume that the number of rows in decision tables from the closed class is not bounded from above by a constant.","We divide the set of such closed classes into two families.","In one family, only standard lower bounds $\\Omega (\\log $ ${\\rm cl}(T))$ on the minimum cardinality of reducts for decision tables hold, where ${\\rm cl}(T)$ is the number of decision classes in the table $T$. In another family, these bounds can be essentially tightened up to $\\Omega ({\\rm cl}(T)^{1/q})$ for some natural $q$."],"url":"http://arxiv.org/abs/2401.01324v1"}
{"created":"2024-01-02 17:58:43","title":"Classifying Words with 3-sort Automata","abstract":"Grammatical inference consists in learning a language or a grammar from data. In this paper, we consider a number of models for inferring a non-deterministic finite automaton (NFA) with 3 sorts of states, that must accept some words, and reject some other words from a given sample. We then propose a transformation from this 3-sort NFA into weighted-frequency and probabilistic NFA, and we apply the latter to a classification task. The experimental evaluation of our approach shows that the probabilistic NFAs can be successfully applied for classification tasks on both real-life and superficial benchmark data sets.","sentences":["Grammatical inference consists in learning a language or a grammar from data.","In this paper, we consider a number of models for inferring a non-deterministic finite automaton (NFA) with 3 sorts of states, that must accept some words, and reject some other words from a given sample.","We then propose a transformation from this 3-sort NFA into weighted-frequency and probabilistic NFA, and we apply the latter to a classification task.","The experimental evaluation of our approach shows that the probabilistic NFAs can be successfully applied for classification tasks on both real-life and superficial benchmark data sets."],"url":"http://arxiv.org/abs/2401.01314v1"}
{"created":"2024-01-02 17:56:30","title":"A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models","abstract":"As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc. This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.","sentences":["As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded.","This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives.","The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations.","Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training.","While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input.","This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc.","This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs.","Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023).","Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types.","This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs.","Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs."],"url":"http://arxiv.org/abs/2401.01313v1"}
{"created":"2024-01-02 17:54:02","title":"LLM Harmony: Multi-Agent Communication for Problem Solving","abstract":"Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.","sentences":["Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving.","Traditional techniques like chain-of-thought prompting necessitate explicit human guidance.","This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities.","The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios.","Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models."],"url":"http://arxiv.org/abs/2401.01312v1"}
{"created":"2024-01-02 17:31:45","title":"Application of the Cartier Operator in Coding Theory","abstract":"The $a$-number is an invariant of the isomorphism class of the $p$-torsion group scheme. We use the Cartier operator on $H^0(\\mathcal{A}_2,\\Omega^1)$ to find a closed formula for the $a$-number of the form $\\mathcal{A}_2 = v(Y^{\\sqrt{q}}+Y-x^{\\frac{\\sqrt{q}+1}{2}})$ where $q=p^s$ over the finite field $\\mathbb{F}_{q^2}$. The application of the computed $a$-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it.","sentences":["The $a$-number is an invariant of the isomorphism class of the $p$-torsion group scheme.","We use the Cartier operator on $H^0(\\mathcal{A}_2,\\Omega^1)$ to find a closed formula for the $a$-number of the form $\\mathcal{A}_2 = v(Y^{\\sqrt{q}}+Y-x^{\\frac{\\sqrt{q}+1}{2}})$ where $q=p^s$ over the finite field $\\mathbb{F}_{q^2}$. The application of the computed $a$-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it."],"url":"http://arxiv.org/abs/2401.01305v1"}
{"created":"2024-01-02 17:30:46","title":"Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles","abstract":"In this paper, we validate the performance of the a sensor fusion-based Global Navigation Satellite System (GNSS) spoofing attack detection framework for Autonomous Vehicles (AVs). To collect data, a vehicle equipped with a GNSS receiver, along with Inertial Measurement Unit (IMU) is used. The detection framework incorporates two strategies: The first strategy involves comparing the predicted location shift, which is the distance traveled between two consecutive timestamps, with the inertial sensor-based location shift. For this purpose, data from low-cost in-vehicle inertial sensors such as the accelerometer and gyroscope sensor are fused and fed into a long short-term memory (LSTM) neural network. The second strategy employs a Random-Forest supervised machine learning model to detect and classify turns, distinguishing between left and right turns using the output from the steering angle sensor. In experiments, two types of spoofing attack models: turn-by-turn and wrong turn are simulated. These spoofing attacks are modeled as SQL injection attacks, where, upon successful implementation, the navigation system perceives injected spoofed location information as legitimate while being unable to detect legitimate GNSS signals. Importantly, the IMU data remains uncompromised throughout the spoofing attack. To test the effectiveness of the detection framework, experiments are conducted in Tuscaloosa, AL, mimicking urban road structures. The results demonstrate the framework's ability to detect various sophisticated GNSS spoofing attacks, even including slow position drifting attacks. Overall, the experimental results showcase the robustness and efficacy of the sensor fusion-based spoofing attack detection approach in safeguarding AVs against GNSS spoofing threats.","sentences":["In this paper, we validate the performance of the a sensor fusion-based Global Navigation Satellite System (GNSS) spoofing attack detection framework for Autonomous Vehicles (AVs).","To collect data, a vehicle equipped with a GNSS receiver, along with Inertial Measurement Unit (IMU) is used.","The detection framework incorporates two strategies: The first strategy involves comparing the predicted location shift, which is the distance traveled between two consecutive timestamps, with the inertial sensor-based location shift.","For this purpose, data from low-cost in-vehicle inertial sensors such as the accelerometer and gyroscope sensor are fused and fed into a long short-term memory (LSTM) neural network.","The second strategy employs a Random-Forest supervised machine learning model to detect and classify turns, distinguishing between left and right turns using the output from the steering angle sensor.","In experiments, two types of spoofing attack models: turn-by-turn and wrong turn are simulated.","These spoofing attacks are modeled as SQL injection attacks, where, upon successful implementation, the navigation system perceives injected spoofed location information as legitimate while being unable to detect legitimate GNSS signals.","Importantly, the IMU data remains uncompromised throughout the spoofing attack.","To test the effectiveness of the detection framework, experiments are conducted in Tuscaloosa, AL, mimicking urban road structures.","The results demonstrate the framework's ability to detect various sophisticated GNSS spoofing attacks, even including slow position drifting attacks.","Overall, the experimental results showcase the robustness and efficacy of the sensor fusion-based spoofing attack detection approach in safeguarding AVs against GNSS spoofing threats."],"url":"http://arxiv.org/abs/2401.01304v1"}
{"created":"2024-01-02 17:30:18","title":"On the uniqueness and computation of commuting extensions","abstract":"A tuple (Z_1,...,Z_p) of matrices of size r is said to be a commuting extension of a tuple (A_1,...,A_p) of matrices of size n <r if the Z_i pairwise commute and each A_i sits in the upper left corner of a block decomposition of Z_i. This notion was discovered and rediscovered in several contexts including algebraic complexity theory (in Strassen's work on tensor rank), in numerical analysis for the construction of cubature formulas and in quantum mechanics for the study of computational methods and the study of the so-called \"quantum Zeno dynamics.\" Commuting extensions have also attracted the attention of the linear algebra community. In this paper we present 3 types of results:   (i) Theorems on the uniqueness of commuting extensions for three matrices or more.   (ii) Algorithms for the computation of commuting extensions of minimal size. These algorithms work under the same assumptions as our uniqueness theorems. They are applicable up to r=4n/3, and are apparently the first provably efficient algorithms for this problem applicable beyond r=n+1.   (iii) A genericity theorem showing that our algorithms and uniqueness theorems can be applied to a wide range of input matrices.","sentences":["A tuple (Z_1,...,Z_p) of matrices of size r is said to be a commuting extension of a tuple (A_1,...,A_p) of matrices of size n <r if the Z_i pairwise commute and each A_i sits in the upper left corner of a block decomposition of Z_i.","This notion was discovered and rediscovered in several contexts including algebraic complexity theory (in Strassen's work on tensor rank), in numerical analysis for the construction of cubature formulas and in quantum mechanics for the study of computational methods and the study of the so-called \"quantum Zeno dynamics.\"","Commuting extensions have also attracted the attention of the linear algebra community.","In this paper we present 3 types of results:   (i) Theorems on the uniqueness of commuting extensions for three matrices or more.   ","(ii) Algorithms for the computation of commuting extensions of minimal size.","These algorithms work under the same assumptions as our uniqueness theorems.","They are applicable up to r=4n/3, and are apparently the first provably efficient algorithms for this problem applicable beyond r=n+1.   ","(iii) A genericity theorem showing that our algorithms and uniqueness theorems can be applied to a wide range of input matrices."],"url":"http://arxiv.org/abs/2401.01302v1"}
{"created":"2024-01-02 17:28:06","title":"Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models","abstract":"Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations. Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources.","sentences":["Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts.","We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency.","Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area.","(2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases.","(3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup.","(4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations.","Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks.","Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources."],"url":"http://arxiv.org/abs/2401.01301v1"}
{"created":"2024-01-02 16:58:49","title":"Generative AI is already widespread in the public sector","abstract":"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology.","sentences":["Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy.","Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work.","But to what extent is generative AI already in use in the public sector?","Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question.","We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system.","Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future.","For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact).","Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%).","While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces.","In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines.","The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology."],"url":"http://arxiv.org/abs/2401.01291v1"}
{"created":"2024-01-02 16:56:40","title":"Competitive Searching over Terrains","abstract":"We study a variant of the searching problem where the environment consists of a known terrain and the goal is to obtain visibility of an unknown target point on the surface of the terrain. The searcher starts on the surface of the terrain and is allowed to fly above the terrain. The goal is to devise a searching strategy that minimizes the competitive ratio, that is, the worst-case ratio between the distance traveled by the searching strategy and the minimum travel distance needed to detect the target. For $1.5$D terrains we show that any searching strategy has a competitive ratio of at least $\\sqrt{82}$ and we present a nearly-optimal searching strategy that achieves a competitive ratio of $3\\sqrt{19/2} \\approx \\sqrt{82} + 0.19$. This strategy extends directly to the case where the searcher has no knowledge of the terrain beforehand. For $2.5$D terrains we show that the optimal competitive ratio depends on the maximum slope $\\lambda$ of the terrain, and is hence unbounded in general. Specifically, we provide a lower bound on the competitive ratio of $\\Omega(\\sqrt{\\lambda})$. Finally, we complement the lower bound with a searching strategy based on the maximum slope of the known terrain, which achieves a competitive ratio of $O(\\sqrt{\\lambda})$.","sentences":["We study a variant of the searching problem where the environment consists of a known terrain and the goal is to obtain visibility of an unknown target point on the surface of the terrain.","The searcher starts on the surface of the terrain and is allowed to fly above the terrain.","The goal is to devise a searching strategy that minimizes the competitive ratio, that is, the worst-case ratio between the distance traveled by the searching strategy and the minimum travel distance needed to detect the target.","For $1.5$D terrains we show that any searching strategy has a competitive ratio of at least $\\sqrt{82}$ and we present a nearly-optimal searching strategy that achieves a competitive ratio of $3\\sqrt{19/2} \\approx \\sqrt{82}","+ 0.19$.","This strategy extends directly to the case where the searcher has no knowledge of the terrain beforehand.","For $2.5$D terrains we show that the optimal competitive ratio depends on the maximum slope $\\lambda$ of the terrain, and is hence unbounded in general.","Specifically, we provide a lower bound on the competitive ratio of $\\Omega(\\sqrt{\\lambda})$. Finally, we complement the lower bound with a searching strategy based on the maximum slope of the known terrain, which achieves a competitive ratio of $O(\\sqrt{\\lambda})$."],"url":"http://arxiv.org/abs/2401.01289v1"}
{"created":"2024-01-02 16:56:13","title":"Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges","abstract":"Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area. Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development. A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented. The study concludes by addressing the challenges faced and suggesting potential research directions in this field.","sentences":["Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus.","Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions.","In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations.","Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area.","Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness.","We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development.","A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented.","The study concludes by addressing the challenges faced and suggesting potential research directions in this field."],"url":"http://arxiv.org/abs/2401.01288v1"}
{"created":"2024-01-02 16:54:58","title":"A Comprehensive Study of Knowledge Editing for Large Language Models","abstract":"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. Drawing inspiration from educational and cognitive research theories, we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches. Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures inherent within LLMs. Finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications.","sentences":["Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication.","However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization.","This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance.","Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors.","There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications.","To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs.","In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches.","Drawing inspiration from educational and cognitive research theories, we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge.","Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches.","Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures inherent within LLMs.","Finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications."],"url":"http://arxiv.org/abs/2401.01286v1"}
{"created":"2024-01-02 16:52:50","title":"Socially Responsible Computing in an Introductory Course","abstract":"Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum. Our students need to be able to examine the social complexities in which technology development and use are situated. Also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging. Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing. Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules. Rather than adding social on top of the technical content, our curricular approach seeks to weave them together. The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change. We share our approach to designing this new introductory socially responsible computing course and the students' reflections. We also highlight seven considerations for educators seeking to incorporate socially responsible computing.","sentences":["Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum.","Our students need to be able to examine the social complexities in which technology development and use are situated.","Also, aligning students' personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging.","Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing.","Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules.","Rather than adding social on top of the technical content, our curricular approach seeks to weave them together.","The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change.","We share our approach to designing this new introductory socially responsible computing course and the students' reflections.","We also highlight seven considerations for educators seeking to incorporate socially responsible computing."],"url":"http://arxiv.org/abs/2401.01285v1"}
{"created":"2024-01-02 16:51:17","title":"Quality and Quantity of Machine Translation References for Automated Metrics","abstract":"Automatic machine translation metrics often use human translations to determine the quality system translations. Common wisdom in the field dictates that the human references should be of very high quality. However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. We find that higher-quality references lead to better metric correlations with humans at the segment-level. Having up to 7 references per segment and taking their average helps all metrics. Interestingly, the references from vendors of different qualities can be mixed together and improve metric success. Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.","sentences":["Automatic machine translation metrics often use human translations to determine the quality system translations.","Common wisdom in the field dictates that the human references should be of very high quality.","However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation.","We find that higher-quality references lead to better metric correlations with humans at the segment-level.","Having up to 7 references per segment and taking their average helps all metrics.","Interestingly, the references from vendors of different qualities can be mixed together and improve metric success.","Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success.","These findings can be used by evaluators of shared tasks when references need to be created under a certain budget."],"url":"http://arxiv.org/abs/2401.01283v1"}
{"created":"2024-01-02 16:37:42","title":"GEqO: ML-Accelerated Semantic Equivalence Detection","abstract":"Large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions. These engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs. Reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time. Detecting common computation is the first and key step for reducing this computational redundancy. However, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated. In addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries). Unfortunately, existing solutions fall short of satisfying these requirements.   In this paper, we take a major step towards filling this gap by proposing GEqO, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale. GEqO introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism. Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another. Our extensive empirical evaluation shows that, on TPC-DS-like queries, GEqO yields significant performance gains-up to 200x faster than automated verifiers-and finds up to 2x more equivalences than optimizer and signature-based equivalence detection approaches.","sentences":["Large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions.","These engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs.","Reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time.","Detecting common computation is the first and key step for reducing this computational redundancy.","However, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated.","In addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries).","Unfortunately, existing solutions fall short of satisfying these requirements.   ","In this paper, we take a major step towards filling this gap by proposing GEqO, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale.","GEqO introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism.","Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another.","Our extensive empirical evaluation shows that, on TPC-DS-like queries, GEqO yields significant performance gains-up to 200x faster than automated verifiers-and finds up to 2x more equivalences than optimizer and signature-based equivalence detection approaches."],"url":"http://arxiv.org/abs/2401.01280v1"}
{"created":"2024-01-02 16:20:40","title":"CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation","abstract":"Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset. The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts. It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike. CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions. Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation. Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval.","sentences":["Recently, the advent of large language models (LLMs) has revolutionized generative agents.","Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users.","However, the absence of a comprehensive benchmark impedes progress in this field.","To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset.","The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts.","It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike.","CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions.","Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation.","Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval."],"url":"http://arxiv.org/abs/2401.01275v1"}
{"created":"2024-01-02 16:18:53","title":"Learning-based agricultural management in partially observable environments subject to climate variability","abstract":"Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management. Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models. Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. Additionally, we explore the impact of climate variability, particularly during extreme weather events, on agricultural outcomes and management. Our findings demonstrate the adaptability of fertilization policies to varying climate conditions. Notably, a fixed policy exhibits resilience in the face of minor climate fluctuations, leading to commendable corn yields, cost-effectiveness, and environmental conservation. However, our study illuminates the need for agent retraining to acquire new optimal policies under extreme weather events. This research charts a promising course toward adaptable fertilization strategies that can seamlessly align with dynamic climate scenarios, ultimately contributing to the optimization of crop management practices.","sentences":["Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability.","While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts.","In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs).","Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management.","Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models.","Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies.","Additionally, we explore the impact of climate variability, particularly during extreme weather events, on agricultural outcomes and management.","Our findings demonstrate the adaptability of fertilization policies to varying climate conditions.","Notably, a fixed policy exhibits resilience in the face of minor climate fluctuations, leading to commendable corn yields, cost-effectiveness, and environmental conservation.","However, our study illuminates the need for agent retraining to acquire new optimal policies under extreme weather events.","This research charts a promising course toward adaptable fertilization strategies that can seamlessly align with dynamic climate scenarios, ultimately contributing to the optimization of crop management practices."],"url":"http://arxiv.org/abs/2401.01273v1"}
{"created":"2024-01-02 16:17:43","title":"MOC-RVQ: Multilevel Codebook-assisted Digital Generative Semantic Communication","abstract":"Vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation. Traditional codebooks need a wide index range, while modulation favors few discrete states. To address this, we propose a multilevel generative semantic communication system with a two-stage training framework. In the first stage, we train a high-quality codebook, using a multi-head octonary codebook (MOC) to compress the index range. We also integrate a residual vector quantization (RVQ) mechanism for effective multilevel communication. In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration. Experimental results highlight MOC-RVQ's superior performance over methods like BPG or JPEG, even without channel error correction coding.","sentences":["Vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation.","Traditional codebooks need a wide index range, while modulation favors few discrete states.","To address this, we propose a multilevel generative semantic communication system with a two-stage training framework.","In the first stage, we train a high-quality codebook, using a multi-head octonary codebook (MOC) to compress the index range.","We also integrate a residual vector quantization (RVQ) mechanism for effective multilevel communication.","In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration.","Experimental results highlight MOC-RVQ's superior performance over methods like BPG or JPEG, even without channel error correction coding."],"url":"http://arxiv.org/abs/2401.01272v1"}
{"created":"2024-01-02 16:14:35","title":"Optimal Rates of Kernel Ridge Regression under Source Condition in Large Dimensions","abstract":"Motivated by the studies of neural networks (e.g.,the neural tangent kernel theory), we perform a study on the large-dimensional behavior of kernel ridge regression (KRR) where the sample size $n \\asymp d^{\\gamma}$ for some $\\gamma > 0$. Given an RKHS $\\mathcal{H}$ associated with an inner product kernel defined on the sphere $\\mathbb{S}^{d}$, we suppose that the true function $f_{\\rho}^{*} \\in [\\mathcal{H}]^{s}$, the interpolation space of $\\mathcal{H}$ with source condition $s>0$. We first determined the exact order (both upper and lower bound) of the generalization error of kernel ridge regression for the optimally chosen regularization parameter $\\lambda$. We then further showed that when $0<s\\le1$, KRR is minimax optimal; and when $s>1$, KRR is not minimax optimal (a.k.a. he saturation effect). Our results illustrate that the curves of rate varying along $\\gamma$ exhibit the periodic plateau behavior and the multiple descent behavior and show how the curves evolve with $s>0$. Interestingly, our work provides a unified viewpoint of several recent works on kernel regression in the large-dimensional setting, which correspond to $s=0$ and $s=1$ respectively.","sentences":["Motivated by the studies of neural networks (e.g.,the neural tangent kernel theory), we perform a study on the large-dimensional behavior of kernel ridge regression (KRR) where the sample size $n \\asymp d^{\\gamma}$ for some $\\gamma > 0$.","Given an RKHS $\\mathcal{H}$ associated with an inner product kernel defined on the sphere $\\mathbb{S}^{d}$, we suppose that the true function $f_{\\rho}^{*} \\in [\\mathcal{H}]^{s}$, the interpolation space of $\\mathcal{H}$ with source condition $s>0$. We first determined the exact order (both upper and lower bound) of the generalization error of kernel ridge regression for the optimally chosen regularization parameter $\\lambda$.","We then further showed that when $0<s\\le1$, KRR is minimax optimal; and when $s>1$, KRR is not minimax optimal (a.k.a.","he saturation effect).","Our results illustrate that the curves of rate varying along $\\gamma$ exhibit the periodic plateau behavior and the multiple descent behavior and show how the curves evolve with $s>0$. Interestingly, our work provides a unified viewpoint of several recent works on kernel regression in the large-dimensional setting, which correspond to $s=0$ and $s=1$ respectively."],"url":"http://arxiv.org/abs/2401.01270v1"}
{"created":"2024-01-02 16:14:30","title":"LLbezpeky: Leveraging Large Language Models for Vulnerability Detection","abstract":"Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs outperform our expectations in finding issues within applications correctly flagging insecure apps in 91.67% of cases in the Ghera benchmark. We use inferences from our experiments towards building a robust and actionable vulnerability detection system and demonstrate its effectiveness. Our experiments also shed light on how different various simple configurations can affect the True Positive (TP) and False Positive (FP) rates.","sentences":["Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods.","Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt.","Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges.","Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages.","We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security.","We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities.","Our experiments show that LLMs outperform our expectations in finding issues within applications correctly flagging insecure apps in 91.67% of cases in the Ghera benchmark.","We use inferences from our experiments towards building a robust and actionable vulnerability detection system and demonstrate its effectiveness.","Our experiments also shed light on how different various simple configurations can affect the True Positive (TP) and False Positive (FP) rates."],"url":"http://arxiv.org/abs/2401.01269v1"}
{"created":"2024-01-02 16:14:02","title":"$f$-Divergence Based Classification: Beyond the Use of Cross-Entropy","abstract":"In deep learning, classification tasks are formalized as optimization problems solved via the minimization of the cross-entropy. However, recent advancements in the design of objective functions allow the $f$-divergence measure to generalize the formulation of the optimization problem for classification. With this goal in mind, we adopt a Bayesian perspective and formulate the classification task as a maximum a posteriori probability problem. We propose a class of objective functions based on the variational representation of the $f$-divergence, from which we extract a list of five posterior probability estimators leveraging well-known $f$-divergences. In addition, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of a new objective function (and posterior probability estimator) corresponding to a novel $f$-divergence referred to as shifted log (SL). First, we theoretically prove the convergence property of the posterior probability estimators. Then, we numerically test the set of proposed objective functions in three application scenarios: toy examples, image data sets, and signal detection/decoding problems. The analyzed tasks demonstrate the effectiveness of the proposed estimators and that the SL divergence achieves the highest classification accuracy in almost all the scenarios.","sentences":["In deep learning, classification tasks are formalized as optimization problems solved via the minimization of the cross-entropy.","However, recent advancements in the design of objective functions allow the $f$-divergence measure to generalize the formulation of the optimization problem for classification.","With this goal in mind, we adopt a Bayesian perspective and formulate the classification task as a maximum a posteriori probability problem.","We propose a class of objective functions based on the variational representation of the $f$-divergence, from which we extract a list of five posterior probability estimators leveraging well-known $f$-divergences.","In addition, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of a new objective function (and posterior probability estimator) corresponding to a novel $f$-divergence referred to as shifted log (SL).","First, we theoretically prove the convergence property of the posterior probability estimators.","Then, we numerically test the set of proposed objective functions in three application scenarios: toy examples, image data sets, and signal detection/decoding problems.","The analyzed tasks demonstrate the effectiveness of the proposed estimators and that the SL divergence achieves the highest classification accuracy in almost all the scenarios."],"url":"http://arxiv.org/abs/2401.01268v1"}
{"created":"2024-01-02 16:11:31","title":"Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm","abstract":"This work presents an optimization method for the synthesis of finite state machines. The focus is on the reduction in the on-chip area and the cost of the circuit. A list of finite state machines from MCNC91 benchmark circuits have been evolved using Cartesian Genetic Programming. On the average, almost 30% of reduction in the total number of gates has been achieved. The effects of some parameters on the evolutionary process have also been discussed in the paper.","sentences":["This work presents an optimization method for the synthesis of finite state machines.","The focus is on the reduction in the on-chip area and the cost of the circuit.","A list of finite state machines from MCNC91 benchmark circuits have been evolved using Cartesian Genetic Programming.","On the average, almost 30% of reduction in the total number of gates has been achieved.","The effects of some parameters on the evolutionary process have also been discussed in the paper."],"url":"http://arxiv.org/abs/2401.01265v1"}
{"created":"2024-01-02 16:09:36","title":"Fairness Certification for Natural Language Processing and Large Language Models","abstract":"Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.","sentences":["Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM).","However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education.","Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues.","Hence, it is important to develop a fairness certification for NLP approaches.","We follow a qualitative research approach towards a fairness certification for NLP.","In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area.","We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories.","Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization."],"url":"http://arxiv.org/abs/2401.01262v1"}
{"created":"2024-01-02 16:05:23","title":"Do Concept Bottleneck Models Obey Locality?","abstract":"Concept-based learning improves a deep learning model's interpretability by explaining its predictions via human-understandable concepts. Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts. Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures. In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts. To understand locality, we analyse how changes to features outside of a concept's spatial or semantic locality impact concept predictions. Our results suggest that even in well-defined scenarios where the presence of a concept is localised to a fixed feature subspace, or whose semantics are correlated to a small subset of other concepts, CBMs fail to learn this locality. These results cast doubt upon the quality of concept representations learnt by CBMs and strongly suggest that concept-based explanations may be fragile to changes outside their localities.","sentences":["Concept-based learning improves a deep learning model's interpretability by explaining its predictions via human-understandable concepts.","Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts.","Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures.","In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts.","To understand locality, we analyse how changes to features outside of a concept's spatial or semantic locality impact concept predictions.","Our results suggest that even in well-defined scenarios where the presence of a concept is localised to a fixed feature subspace, or whose semantics are correlated to a small subset of other concepts, CBMs fail to learn this locality.","These results cast doubt upon the quality of concept representations learnt by CBMs and strongly suggest that concept-based explanations may be fragile to changes outside their localities."],"url":"http://arxiv.org/abs/2401.01259v1"}
{"created":"2024-01-02 15:58:17","title":"Profiling Programming Language Learning","abstract":"This paper documents a year-long experiment to \"profile\" the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process. We added interactive quizzes to The Rust Programming Language, the official textbook for learning Rust. Over 13 months, 62,526 readers answered questions 1,140,202 times. First, we analyze the trajectories of readers. We find that many readers drop-out of the book early when faced with difficult language concepts like Rust's ownership types. Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions. We find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles. Third, we performed 12 interventions into the book to help readers with difficult questions. We find that on average, interventions improved quiz scores on the targeted questions by +20%. Fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small N. These results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales.","sentences":["This paper documents a year-long experiment to \"profile\" the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process.","We added interactive quizzes to The Rust Programming Language, the official textbook for learning Rust.","Over 13 months, 62,526 readers answered questions 1,140,202 times.","First, we analyze the trajectories of readers.","We find that many readers drop-out of the book early when faced with difficult language concepts like Rust's ownership types.","Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions.","We find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles.","Third, we performed 12 interventions into the book to help readers with difficult questions.","We find that on average, interventions improved quiz scores on the targeted questions by +20%.","Fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small N.","These results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales."],"url":"http://arxiv.org/abs/2401.01257v1"}
{"created":"2024-01-02 15:56:48","title":"VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM","abstract":"The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM to detail each entity. The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity. Finally, VideoDrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account. The diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos. Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference.","sentences":["The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts.","Most existing works tackle the single-scene scenario with only one video event occurring in a single background.","Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes.","In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation.","Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM.","The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement.","VideoDrafter identifies the common entities throughout the script and asks LLM to detail each entity.","The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity.","Finally, VideoDrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account.","The diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos.","Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference."],"url":"http://arxiv.org/abs/2401.01256v1"}
{"created":"2024-01-02 15:40:35","title":"Deplatforming Norm-Violating Influencers on Social Media Reduces Overall Online Attention Toward Them","abstract":"From politicians to podcast hosts, online platforms have systematically banned (``deplatformed'') influential users for breaking platform guidelines. Previous inquiries on the effectiveness of this intervention are inconclusive because 1) they consider only few deplatforming events; 2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views); 3) they do not consider all the potential places users impacted by the deplatforming event might migrate to. We address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers. We collect deplatforming events from Reddit posts and then manually curate the data, ensuring the correctness of a large dataset of deplatforming events. Then, we link these events to Google Trends and Wikipedia page views, platform-agnostic measures of online attention that capture the general public's interest in specific influencers. Through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers. After 12 months, we estimate that online attention toward deplatformed influencers is reduced by -63% (95% CI [-75%,-46%]) on Google and by -43% (95% CI [-57%,-24%]) on Wikipedia. Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention. Notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers; Overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation.","sentences":["From politicians to podcast hosts, online platforms have systematically banned (``deplatformed'') influential users for breaking platform guidelines.","Previous inquiries on the effectiveness of this intervention are inconclusive because 1) they consider only few deplatforming events; 2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views); 3) they do not consider all the potential places users impacted by the deplatforming event might migrate to.","We address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers.","We collect deplatforming events from Reddit posts and then manually curate the data, ensuring the correctness of a large dataset of deplatforming events.","Then, we link these events to Google Trends and Wikipedia page views, platform-agnostic measures of online attention that capture the general public's interest in specific influencers.","Through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers.","After 12 months, we estimate that online attention toward deplatformed influencers is reduced by -63% (95%","CI","[-75%,-46%]) on Google and by -43% (95% CI","[-57%,-24%]) on Wikipedia.","Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention.","Notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers; Overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation."],"url":"http://arxiv.org/abs/2401.01253v1"}
{"created":"2024-01-02 15:23:09","title":"Deep Learning-Based Computational Model for Disease Identification in Cocoa Pods (Theobroma cacao L.)","abstract":"The early identification of diseases in cocoa pods is an important task to guarantee the production of high-quality cocoa. The use of artificial intelligence techniques such as machine learning, computer vision and deep learning are promising solutions to help identify and classify diseases in cocoa pods. In this paper we introduce the development and evaluation of a deep learning computational model applied to the identification of diseases in cocoa pods, focusing on \"monilia\" and \"black pod\" diseases. An exhaustive review of state-of-the-art of computational models was carried out, based on scientific articles related to the identification of plant diseases using computer vision and deep learning techniques. As a result of the search, EfficientDet-Lite4, an efficient and lightweight model for object detection, was selected. A dataset, including images of both healthy and diseased cocoa pods, has been utilized to train the model to detect and pinpoint disease manifestations with considerable accuracy. Significant enhancements in the model training and evaluation demonstrate the capability of recognizing and classifying diseases through image analysis. Furthermore, the functionalities of the model were integrated into an Android native mobile with an user-friendly interface, allowing to younger or inexperienced farmers a fast and accuracy identification of health status of cocoa pods","sentences":["The early identification of diseases in cocoa pods is an important task to guarantee the production of high-quality cocoa.","The use of artificial intelligence techniques such as machine learning, computer vision and deep learning are promising solutions to help identify and classify diseases in cocoa pods.","In this paper we introduce the development and evaluation of a deep learning computational model applied to the identification of diseases in cocoa pods, focusing on \"monilia\" and \"black pod\" diseases.","An exhaustive review of state-of-the-art of computational models was carried out, based on scientific articles related to the identification of plant diseases using computer vision and deep learning techniques.","As a result of the search, EfficientDet-Lite4, an efficient and lightweight model for object detection, was selected.","A dataset, including images of both healthy and diseased cocoa pods, has been utilized to train the model to detect and pinpoint disease manifestations with considerable accuracy.","Significant enhancements in the model training and evaluation demonstrate the capability of recognizing and classifying diseases through image analysis.","Furthermore, the functionalities of the model were integrated into an Android native mobile with an user-friendly interface, allowing to younger or inexperienced farmers a fast and accuracy identification of health status of cocoa pods"],"url":"http://arxiv.org/abs/2401.01247v1"}
{"created":"2024-01-02 15:20:50","title":"Temporal Adaptive RGBT Tracking with Modality Prompt","abstract":"RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving. Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results. However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training. The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information. To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack. TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively. TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization. In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales. Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.","sentences":["RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving.","Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results.","However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training.","The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information.","To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack.","TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively.","TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization.","In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales.","Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed."],"url":"http://arxiv.org/abs/2401.01244v1"}
{"created":"2024-01-02 15:19:01","title":"Contrastive Sequential Interaction Network Learning on Co-Evolving Riemannian Spaces","abstract":"The sequential interaction network usually find itself in a variety of applications, e.g., recommender system. Herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature Euclidean space. Despite the promising results achieved by previous methods, a range of significant issues still largely remains open: On the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference? On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously? On the learning paradigm, can we get rid of the label information costly to acquire? To address the aforementioned issues, we propose a novel Contrastive model for Sequential Interaction Network learning on Co-Evolving RiEmannian spaces, CSINCERE. To the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network. In CSINCERE, we formulate a Cross-Space Aggregation for message-passing across representation spaces of different Riemannian geometries, and design a Neural Curvature Estimator based on Ricci curvatures for modeling the space evolvement over time. Thereafter, we present a Reweighed Co-Contrast between the temporal views of the sequential network, so that the couple of Riemannian spaces interact with each other for the interaction prediction without labels. Empirical results on 5 public datasets show the superiority of CSINCERE over the state-of-the-art methods.","sentences":["The sequential interaction network usually find itself in a variety of applications, e.g., recommender system.","Herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature Euclidean space.","Despite the promising results achieved by previous methods, a range of significant issues still largely remains open: On the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference?","On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously?","On the learning paradigm, can we get rid of the label information costly to acquire?","To address the aforementioned issues, we propose a novel Contrastive model for Sequential Interaction Network learning on Co-Evolving RiEmannian spaces, CSINCERE.","To the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network.","In CSINCERE, we formulate a Cross-Space Aggregation for message-passing across representation spaces of different Riemannian geometries, and design a Neural Curvature Estimator based on Ricci curvatures for modeling the space evolvement over time.","Thereafter, we present a Reweighed Co-Contrast between the temporal views of the sequential network, so that the couple of Riemannian spaces interact with each other for the interaction prediction without labels.","Empirical results on 5 public datasets show the superiority of CSINCERE over the state-of-the-art methods."],"url":"http://arxiv.org/abs/2401.01243v1"}
{"created":"2024-01-02 15:18:23","title":"Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning","abstract":"Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees. A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers). In this study we propose a contrastive approach for learning a binary event encoder from continuous time series data. As a preliminary result, we show that our approach has some potential in learning a valuable encoder.","sentences":["Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees.","A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers).","In this study we propose a contrastive approach for learning a binary event encoder from continuous time series data.","As a preliminary result, we show that our approach has some potential in learning a valuable encoder."],"url":"http://arxiv.org/abs/2401.01242v1"}
{"created":"2024-01-02 14:58:59","title":"Graph Elimination Networks","abstract":"Graph Neural Networks (GNNs) are widely applied across various domains, yet they perform poorly in deep layers. Existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation. In this paper, we delve into the neighborhood propagation mechanism of GNNs and discover that the real root cause of GNNs' performance degradation in deep layers lies in ineffective neighborhood feature propagation. This propagation leads to an exponential growth of a node's current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes. To address this issue, we introduce Graph Elimination Networks (GENs), which employ a specific algorithm to eliminate redundancies during neighborhood propagation. We demonstrate that GENs can enhance nodes' perception of distant neighborhoods and extend the depth of network propagation. Extensive experiments show that GENs outperform the state-of-the-art methods on various graph-level and node-level datasets.","sentences":["Graph Neural Networks (GNNs) are widely applied across various domains, yet they perform poorly in deep layers.","Existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation.","In this paper, we delve into the neighborhood propagation mechanism of GNNs and discover that the real root cause of GNNs' performance degradation in deep layers lies in ineffective neighborhood feature propagation.","This propagation leads to an exponential growth of a node's current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes.","To address this issue, we introduce Graph Elimination Networks (GENs), which employ a specific algorithm to eliminate redundancies during neighborhood propagation.","We demonstrate that GENs can enhance nodes' perception of distant neighborhoods and extend the depth of network propagation.","Extensive experiments show that GENs outperform the state-of-the-art methods on various graph-level and node-level datasets."],"url":"http://arxiv.org/abs/2401.01233v1"}
{"created":"2024-01-02 14:58:26","title":"Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning","abstract":"Graphs are typical non-Euclidean data of complex structures. In recent years, Riemannian graph representation learning has emerged as an exciting alternative to Euclidean ones. However, Riemannian methods are still in an early stage: most of them present a single curvature (radius) regardless of structural complexity, suffer from numerical instability due to the exponential/logarithmic map, and lack the ability to capture motif regularity. In light of the issues above, we propose the problem of \\emph{Motif-aware Riemannian Graph Representation Learning}, seeking a numerically stable encoder to capture motif regularity in a diverse-curvature manifold without labels. To this end, we present a novel Motif-aware Riemannian model with Generative-Contrastive learning (MotifRGC), which conducts a minmax game in Riemannian manifold in a self-supervised manner. First, we propose a new type of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold by a product layer with the diversified factor, and replace the exponential/logarithmic map by a stable kernel layer. Second, we introduce a motif-aware Riemannian generative-contrastive learning to capture motif regularity in the constructed manifold and learn motif-aware node representation without external labels. Empirical results show the superiority of MofitRGC.","sentences":["Graphs are typical non-Euclidean data of complex structures.","In recent years, Riemannian graph representation learning has emerged as an exciting alternative to Euclidean ones.","However, Riemannian methods are still in an early stage: most of them present a single curvature (radius) regardless of structural complexity, suffer from numerical instability due to the exponential/logarithmic map, and lack the ability to capture motif regularity.","In light of the issues above, we propose the problem of \\emph{Motif-aware Riemannian Graph Representation Learning}, seeking a numerically stable encoder to capture motif regularity in a diverse-curvature manifold without labels.","To this end, we present a novel Motif-aware Riemannian model with Generative-Contrastive learning (MotifRGC), which conducts a minmax game in Riemannian manifold in a self-supervised manner.","First, we propose a new type of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold by a product layer with the diversified factor, and replace the exponential/logarithmic map by a stable kernel layer.","Second, we introduce a motif-aware Riemannian generative-contrastive learning to capture motif regularity in the constructed manifold and learn motif-aware node representation without external labels.","Empirical results show the superiority of MofitRGC."],"url":"http://arxiv.org/abs/2401.01232v1"}
{"created":"2024-01-02 14:36:28","title":"IdentiFace : A VGG Based Multimodal Facial Biometric System","abstract":"The development of facial biometric systems has contributed greatly to the development of the computer vision field. Nowadays, there's always a need to develop a multimodal system that combines multiple biometric traits in an efficient, meaningful way. In this paper, we introduce \"IdentiFace\" which is a multimodal facial biometric system that combines the core of facial recognition with some of the most important soft biometric traits such as gender, face shape, and emotion. We also focused on developing the system using only VGG-16 inspired architecture with minor changes across different subsystems. This unification allows for simpler integration across modalities. It makes it easier to interpret the learned features between the tasks which gives a good indication about the decision-making process across the facial modalities and potential connection. For the recognition problem, we acquired a 99.2% test accuracy for five classes with high intra-class variations using data collected from the FERET database[1]. We achieved 99.4% on our dataset and 95.15% on the public dataset[2] in the gender recognition problem. We were also able to achieve a testing accuracy of 88.03% in the face-shape problem using the celebrity face-shape dataset[3]. Finally, we achieved a decent testing accuracy of 66.13% in the emotion task which is considered a very acceptable accuracy compared to related work on the FER2013 dataset[4].","sentences":["The development of facial biometric systems has contributed greatly to the development of the computer vision field.","Nowadays, there's always a need to develop a multimodal system that combines multiple biometric traits in an efficient, meaningful way.","In this paper, we introduce \"IdentiFace\" which is a multimodal facial biometric system that combines the core of facial recognition with some of the most important soft biometric traits such as gender, face shape, and emotion.","We also focused on developing the system using only VGG-16 inspired architecture with minor changes across different subsystems.","This unification allows for simpler integration across modalities.","It makes it easier to interpret the learned features between the tasks which gives a good indication about the decision-making process across the facial modalities and potential connection.","For the recognition problem, we acquired a 99.2% test accuracy for five classes with high intra-class variations using data collected from the FERET database[1].","We achieved 99.4% on our dataset and 95.15% on the public dataset[2] in the gender recognition problem.","We were also able to achieve a testing accuracy of 88.03% in the face-shape problem using the celebrity face-shape dataset[3].","Finally, we achieved a decent testing accuracy of 66.13% in the emotion task which is considered a very acceptable accuracy compared to related work on the FER2013 dataset[4]."],"url":"http://arxiv.org/abs/2401.01227v1"}
{"created":"2024-01-02 14:30:13","title":"Beam-Based Multiple Access for IRS-Aided Millimeter-Wave and Terahertz Communications","abstract":"Recently, intelligent reflecting surface (IRS)-aided millimeter-wave (mmWave) and terahertz (THz) communications are considered in the wireless community. This paper aims to design a beam-based multiple-access strategy for this new paradigm. Its key idea is to make use of multiple sub-arrays over a hybrid digital-analog array to form independent beams, each of which is steered towards the desired direction to mitigate inter-user interference and suppress unwanted signal reflection. The proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use). Consequently, it can substantially boost the system capacity, as verified by Monte-Carlo simulations.","sentences":["Recently, intelligent reflecting surface (IRS)-aided millimeter-wave (mmWave) and terahertz (THz) communications are considered in the wireless community.","This paper aims to design a beam-based multiple-access strategy for this new paradigm.","Its key idea is to make use of multiple sub-arrays over a hybrid digital-analog array to form independent beams, each of which is steered towards the desired direction to mitigate inter-user interference and suppress unwanted signal reflection.","The proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use).","Consequently, it can substantially boost the system capacity, as verified by Monte-Carlo simulations."],"url":"http://arxiv.org/abs/2401.01224v1"}
{"created":"2024-01-02 14:18:11","title":"Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond","abstract":"Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer. To provide sufficient learning support, modern MTL uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks. However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks. In this work, we challenge this setup and show that MTL can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task. We explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching. To demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets. Our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases. In all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when MT model's performance is worse than that of at least one single-task model).","sentences":["Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer.","To provide sufficient learning support, modern MTL uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks.","However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks.","In this work, we challenge this setup and show that MTL can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task.","We explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching.","To demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets.","Our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases.","In all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when MT model's performance is worse than that of at least one single-task model)."],"url":"http://arxiv.org/abs/2401.01219v1"}
{"created":"2024-01-02 14:12:41","title":"Zero-Shot Position Debiasing for Large Language Models","abstract":"Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperforms existing methods in mitigating four types of position biases. Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective.","sentences":["Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs).","However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance.","Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input.","Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality.","In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs.","ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets.","To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses.","Experiments on eight datasets and five tasks show that ZOE consistently outperforms existing methods in mitigating four types of position biases.","Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective."],"url":"http://arxiv.org/abs/2401.01218v1"}
{"created":"2024-01-02 14:11:24","title":"KCES: A Workflow Containerization Scheduling Scheme Under Cloud-Edge Collaboration Framework","abstract":"As more IoT applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge. However, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management. To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework. The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading. Considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay. A cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration. Based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration. Through a customized IoT application workflow instance, experimental results show that KCES is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks.","sentences":["As more IoT applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge.","However, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management.","To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework.","The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading.","Considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay.","A cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration.","Based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration.","Through a customized IoT application workflow instance, experimental results show that KCES is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks."],"url":"http://arxiv.org/abs/2401.01217v1"}
{"created":"2024-01-02 14:10:21","title":"Noise-NeRF: Hide Information in Neural Radiance Fields using Trainable Noise","abstract":"Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method. While attracting lots of attention, NeRF faces critical issues such as information confidentiality and security. Steganography is a technique used to embed information in another object as a means of protecting information security. Currently, there are few related studies on NeRF steganography, facing challenges in low steganography quality, model weight damage, and a limited amount of steganographic information. This paper proposes a novel NeRF steganography method based on trainable noise: Noise-NeRF. Furthermore, we propose the Adaptive Pixel Selection strategy and Pixel Perturbation strategy to improve the steganography quality and efficiency. The extensive experiments on open-source datasets show that Noise-NeRF provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography.","sentences":["Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method.","While attracting lots of attention, NeRF faces critical issues such as information confidentiality and security.","Steganography is a technique used to embed information in another object as a means of protecting information security.","Currently, there are few related studies on NeRF steganography, facing challenges in low steganography quality, model weight damage, and a limited amount of steganographic information.","This paper proposes a novel NeRF steganography method based on trainable noise: Noise-NeRF.","Furthermore, we propose the Adaptive Pixel Selection strategy and Pixel Perturbation strategy to improve the steganography quality and efficiency.","The extensive experiments on open-source datasets show that Noise-NeRF provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography."],"url":"http://arxiv.org/abs/2401.01216v1"}
{"created":"2024-01-02 14:04:42","title":"YOLO algorithm with hybrid attention feature pyramid network for solder joint defect detection","abstract":"Traditional manual detection for solder joint defect is no longer applied during industrial production due to low efficiency, inconsistent evaluation, high cost and lack of real-time data. A new approach has been proposed to address the issues of low accuracy, high false detection rates and computational cost of solder joint defect detection in surface mount technology of industrial scenarios. The proposed solution is a hybrid attention mechanism designed specifically for the solder joint defect detection algorithm to improve quality control in the manufacturing process by increasing the accuracy while reducing the computational cost. The hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features. The coordinate attention mechanism enhances the connection between different channels and reduces location information loss. The hybrid attention mechanism enhances the capability of the network to perceive long-distance position information and learn local features. The improved algorithm model has good detection ability for solder joint defect detection, with mAP reaching 91.5%, 4.3% higher than the You Only Look Once version 5 algorithm and better than other comparative algorithms. Compared to other versions, mean Average Precision, Precision, Recall, and Frame per Seconds indicators have also improved. The improvement of detection accuracy can be achieved while meeting real-time detection requirements.","sentences":["Traditional manual detection for solder joint defect is no longer applied during industrial production due to low efficiency, inconsistent evaluation, high cost and lack of real-time data.","A new approach has been proposed to address the issues of low accuracy, high false detection rates and computational cost of solder joint defect detection in surface mount technology of industrial scenarios.","The proposed solution is a hybrid attention mechanism designed specifically for the solder joint defect detection algorithm to improve quality control in the manufacturing process by increasing the accuracy while reducing the computational cost.","The hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features.","The coordinate attention mechanism enhances the connection between different channels and reduces location information loss.","The hybrid attention mechanism enhances the capability of the network to perceive long-distance position information and learn local features.","The improved algorithm model has good detection ability for solder joint defect detection, with mAP reaching 91.5%, 4.3% higher than the You Only Look Once version 5 algorithm and better than other comparative algorithms.","Compared to other versions, mean Average Precision, Precision, Recall, and Frame per Seconds indicators have also improved.","The improvement of detection accuracy can be achieved while meeting real-time detection requirements."],"url":"http://arxiv.org/abs/2401.01214v1"}
{"created":"2024-01-02 13:31:51","title":"FGENet: Fine-Grained Extraction Network for Congested Crowd Counting","abstract":"Crowd counting has gained significant popularity due to its practical applications. However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps. Additionally, they also struggle with high-density images.To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet). Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals.This study designs a fusion module, named Fine-Grained Feature Pyramid(FGFP), that is used to fuse feature maps extracted by the backbone of FGENet. The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual. At the end, FGENet establishes correspondences between prediction points and ground truth points by employing the Hungarian algorithm. For training FGENet, we design a robust loss function, named Three-Task Combination (TTC), to mitigate the impact of annotation noise. Extensive experiments are conducted on four widely used crowd counting datasets. Experimental results demonstrate the effectiveness of FGENet. Notably, our method achieves a remarkable improvement of 3.14 points in Mean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing its superiority over the existing state-of-the-art methods. Even more impressively, FGENet surpasses previous benchmarks on the UCF\\_CC\\_50 dataset with an astounding enhancement of 30.16 points in MAE.","sentences":["Crowd counting has gained significant popularity due to its practical applications.","However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps.","Additionally, they also struggle with high-density images.","To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet).","Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals.","This study designs a fusion module, named Fine-Grained Feature Pyramid(FGFP), that is used to fuse feature maps extracted by the backbone of FGENet.","The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual.","At the end, FGENet establishes correspondences between prediction points and ground truth points by employing the Hungarian algorithm.","For training FGENet, we design a robust loss function, named Three-Task Combination (TTC), to mitigate the impact of annotation noise.","Extensive experiments are conducted on four widely used crowd counting datasets.","Experimental results demonstrate the effectiveness of FGENet.","Notably, our method achieves a remarkable improvement of 3.14 points in Mean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing its superiority over the existing state-of-the-art methods.","Even more impressively, FGENet surpasses previous benchmarks on the UCF\\_CC\\_50 dataset with an astounding enhancement of 30.16 points in MAE."],"url":"http://arxiv.org/abs/2401.01208v1"}
{"created":"2024-01-02 13:28:39","title":"Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation","abstract":"In human-centric content generation, the pre-trained text-to-image models struggle to produce user-wanted portrait images, which retain the identity of individuals while exhibiting diverse expressions. This paper introduces our efforts towards personalized face generation. To this end, we propose a novel multi-modal face generation framework, capable of simultaneous identity-expression control and more fine-grained expression synthesis. Our expression control is so sophisticated that it can be specialized by the fine-grained emotional vocabulary. We devise a novel diffusion model that can undertake the task of simultaneously face swapping and reenactment. Due to the entanglement of identity and expression, it's nontrivial to separately and precisely control them in one framework, thus has not been explored yet. To overcome this, we propose several innovative designs in the conditional diffusion model, including balancing identity and expression encoder, improved midpoint sampling, and explicitly background conditioning. Extensive experiments have demonstrated the controllability and scalability of the proposed framework, in comparison with state-of-the-art text-to-image, face swapping, and face reenactment methods.","sentences":["In human-centric content generation, the pre-trained text-to-image models struggle to produce user-wanted portrait images, which retain the identity of individuals while exhibiting diverse expressions.","This paper introduces our efforts towards personalized face generation.","To this end, we propose a novel multi-modal face generation framework, capable of simultaneous identity-expression control and more fine-grained expression synthesis.","Our expression control is so sophisticated that it can be specialized by the fine-grained emotional vocabulary.","We devise a novel diffusion model that can undertake the task of simultaneously face swapping and reenactment.","Due to the entanglement of identity and expression, it's nontrivial to separately and precisely control them in one framework, thus has not been explored yet.","To overcome this, we propose several innovative designs in the conditional diffusion model, including balancing identity and expression encoder, improved midpoint sampling, and explicitly background conditioning.","Extensive experiments have demonstrated the controllability and scalability of the proposed framework, in comparison with state-of-the-art text-to-image, face swapping, and face reenactment methods."],"url":"http://arxiv.org/abs/2401.01207v1"}
{"created":"2024-01-02 13:13:28","title":"PPBFL: A Privacy Protected Blockchain-based Federated Learning Model","abstract":"With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus. However, challenges such as attacks on model parameters and the lack of incentive mechanisms hinder the effectiveness of federated learning. Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training. Blockchain ensures that model parameters stored in the InterPlanetary File System (IPFS) remain unaltered. A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning. Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training clients. Security analysis and experimental results demonstrate that PPBFL outperforms baseline methods in both model performance and security.","sentences":["With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus.","However, challenges such as attacks on model parameters and the lack of incentive mechanisms hinder the effectiveness of federated learning.","Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training.","Blockchain ensures that model parameters stored in the InterPlanetary File System (IPFS) remain unaltered.","A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning.","Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training clients.","Security analysis and experimental results demonstrate that PPBFL outperforms baseline methods in both model performance and security."],"url":"http://arxiv.org/abs/2401.01204v1"}
{"created":"2024-01-02 13:04:41","title":"Whole-examination AI estimation of fetal biometrics from 20-week ultrasound scans","abstract":"The current approach to fetal anomaly screening is based on biometric measurements derived from individually selected ultrasound images. In this paper, we introduce a paradigm shift that attains human-level performance in biometric measurement by aggregating automatically extracted biometrics from every frame across an entire scan, with no need for operator intervention. We use a convolutional neural network to classify each frame of an ultrasound video recording. We then measure fetal biometrics in every frame where appropriate anatomy is visible. We use a Bayesian method to estimate the true value of each biometric from a large number of measurements and probabilistically reject outliers. We performed a retrospective experiment on 1457 recordings (comprising 48 million frames) of 20-week ultrasound scans, estimated fetal biometrics in those scans and compared our estimates to the measurements sonographers took during the scan. Our method achieves human-level performance in estimating fetal biometrics and estimates well-calibrated credible intervals in which the true biometric value is expected to lie.","sentences":["The current approach to fetal anomaly screening is based on biometric measurements derived from individually selected ultrasound images.","In this paper, we introduce a paradigm shift that attains human-level performance in biometric measurement by aggregating automatically extracted biometrics from every frame across an entire scan, with no need for operator intervention.","We use a convolutional neural network to classify each frame of an ultrasound video recording.","We then measure fetal biometrics in every frame where appropriate anatomy is visible.","We use a Bayesian method to estimate the true value of each biometric from a large number of measurements and probabilistically reject outliers.","We performed a retrospective experiment on 1457 recordings (comprising 48 million frames) of 20-week ultrasound scans, estimated fetal biometrics in those scans and compared our estimates to the measurements sonographers took during the scan.","Our method achieves human-level performance in estimating fetal biometrics and estimates well-calibrated credible intervals in which the true biometric value is expected to lie."],"url":"http://arxiv.org/abs/2401.01201v1"}
{"created":"2024-01-02 13:03:39","title":"Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms","abstract":"Skin lesions are classified in benign or malignant. Among the malignant, melanoma is a very aggressive cancer and the major cause of deaths. So, early diagnosis of skin cancer is very desired. In the last few years, there is a growing interest in computer aided diagnostic (CAD) using most image and clinical data of the lesion. These sources of information present limitations due to their inability to provide information of the molecular structure of the lesion. NIR spectroscopy may provide an alternative source of information to automated CAD of skin lesions. The most commonly used techniques and classification algorithms used in spectroscopy are Principal Component Analysis (PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support Vector Machines (SVM). Nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (MDL) to spectroscopy. One of the main limitations to apply MDL to spectroscopy is the lack of public datasets. Since there is no public dataset of NIR spectral data to skin lesions, as far as we know, an effort has been made and a new dataset named NIR-SC-UFES, has been collected, annotated and analyzed generating the gold-standard for classification of NIR spectral data to skin cancer. Next, the machine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional neural network (1D-CNN) were investigated to classify cancer and non-cancer skin lesions. Experimental results indicate the best performance obtained by LightGBM with pre-processing using standard normal variate (SNV), feature extraction providing values of 0.839 for balanced accuracy, 0.851 for recall, 0.852 for precision, and 0.850 for F-score. The obtained results indicate the first steps in CAD of skin lesions aiming the automated triage of patients with skin lesions in vivo using NIR spectral data.","sentences":["Skin lesions are classified in benign or malignant.","Among the malignant, melanoma is a very aggressive cancer and the major cause of deaths.","So, early diagnosis of skin cancer is very desired.","In the last few years, there is a growing interest in computer aided diagnostic (CAD) using most image and clinical data of the lesion.","These sources of information present limitations due to their inability to provide information of the molecular structure of the lesion.","NIR spectroscopy may provide an alternative source of information to automated CAD of skin lesions.","The most commonly used techniques and classification algorithms used in spectroscopy are Principal Component Analysis (PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support Vector Machines (SVM).","Nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (MDL) to spectroscopy.","One of the main limitations to apply MDL to spectroscopy is the lack of public datasets.","Since there is no public dataset of NIR spectral data to skin lesions, as far as we know, an effort has been made and a new dataset named NIR-SC-UFES, has been collected, annotated and analyzed generating the gold-standard for classification of NIR spectral data to skin cancer.","Next, the machine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional neural network (1D-CNN) were investigated to classify cancer and non-cancer skin lesions.","Experimental results indicate the best performance obtained by LightGBM with pre-processing using standard normal variate (SNV), feature extraction providing values of 0.839 for balanced accuracy, 0.851 for recall, 0.852 for precision, and 0.850 for F-score.","The obtained results indicate the first steps in CAD of skin lesions aiming the automated triage of patients with skin lesions in vivo using NIR spectral data."],"url":"http://arxiv.org/abs/2401.01200v1"}
{"created":"2024-01-02 13:03:29","title":"JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example","abstract":"Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. \\cite{szegedy2013intriguing}. The experiments we carried out confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes. Noticeably, the JMA attack is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in a complex multilabel classification scenario with 20 labels, a capability that is out of reach of all the attacks proposed so far. As a further advantage, the JMA attack usually requires very few iterations, thus resulting more efficient than existing methods.","sentences":["Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings.","In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction.","The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem.","The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. \\cite{szegedy2013intriguing}.","The experiments we carried out confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes.","Noticeably, the JMA attack is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in a complex multilabel classification scenario with 20 labels, a capability that is out of reach of all the attacks proposed so far.","As a further advantage, the JMA attack usually requires very few iterations, thus resulting more efficient than existing methods."],"url":"http://arxiv.org/abs/2401.01199v1"}
{"created":"2024-01-02 13:01:50","title":"Uncertainty Resolution in Misinformation Detection","abstract":"Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pipelines.","sentences":["Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse.","Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided.","However, they struggle to assess ambiguous or context-deficient statements accurately.","This work introduces a new method to resolve uncertainty in such statements.","We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information.","We then leverage this framework to generate effective user queries for missing context.","Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1.","Thus, this approach may provide a valuable component for future misinformation mitigation pipelines."],"url":"http://arxiv.org/abs/2401.01197v1"}
{"created":"2024-01-02 12:50:06","title":"Deep Learning Driven Buffer-Aided Cooperative Networks for B5G/6G: Challenges, Solutions, and Future Opportunities","abstract":"Buffer-aided cooperative networks (BACNs) have garnered significant attention due to their potential applications in beyond fifth generation (B5G) or sixth generation (6G) critical scenarios. This article explores various typical application scenarios of buffer-aided relaying in B5G/6G networks to emphasize the importance of incorporating BACN. Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture. To address the challenges, we propose leveraging deep learning-based methods for the design and operation of B5G/6G networks with BACN, deviating from conventional buffer-aided relay selection approaches. In particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (DRL) and decentralized DRL in buffer-aided non-terrestrial networks. Finally, we outline future research directions in B5G/6G that pertain to the utilization of BACN.","sentences":["Buffer-aided cooperative networks (BACNs) have garnered significant attention due to their potential applications in beyond fifth generation (B5G) or sixth generation (6G) critical scenarios.","This article explores various typical application scenarios of buffer-aided relaying in B5G/6G networks to emphasize the importance of incorporating BACN.","Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture.","To address the challenges, we propose leveraging deep learning-based methods for the design and operation of B5G/6G networks with BACN, deviating from conventional buffer-aided relay selection approaches.","In particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (DRL) and decentralized DRL in buffer-aided non-terrestrial networks.","Finally, we outline future research directions in B5G/6G that pertain to the utilization of BACN."],"url":"http://arxiv.org/abs/2401.01195v1"}
{"created":"2024-01-02 12:44:36","title":"Further Explanations on \"SAT Requires Exhaustive Search\"","abstract":"Recently, Xu and Zhou [2023] introduced a constructive approach for exploring computational hardness, proving that SAT requires exhaustive search. In light of certain misinterpretations concerning the contributions and proofs in that paper, we focus on providing detailed explanations in this work. We begin by delineating the core innovation of the constructive approach, shedding light on the pivotal concept of algorithm designability. We address the overlooked white-box diagonalization method and highlight the concept of an almost independent solution space. In response to specific misunderstandings, such as the concerns surrounding the assumptions of Lemma 3.1, we offer comprehensive clarifications aimed at improving the comprehension of the proof. We are grateful for the feedback received on our prior paper and hope this work can foster a more well-informed discussion.","sentences":["Recently, Xu and Zhou","[2023] introduced a constructive approach for exploring computational hardness, proving that SAT requires exhaustive search.","In light of certain misinterpretations concerning the contributions and proofs in that paper, we focus on providing detailed explanations in this work.","We begin by delineating the core innovation of the constructive approach, shedding light on the pivotal concept of algorithm designability.","We address the overlooked white-box diagonalization method and highlight the concept of an almost independent solution space.","In response to specific misunderstandings, such as the concerns surrounding the assumptions of Lemma 3.1, we offer comprehensive clarifications aimed at improving the comprehension of the proof.","We are grateful for the feedback received on our prior paper and hope this work can foster a more well-informed discussion."],"url":"http://arxiv.org/abs/2401.01193v1"}
{"created":"2024-01-02 12:41:17","title":"Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems","abstract":"In many recent works, the potential of Exploratory Landscape Analysis (ELA) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated. These numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from High-level Property Prediction to Automated Algorithm Selection and Automated Algorithm Configuration. Without ELA features, analyzing and understanding the characteristics of single-objective continuous optimization problems would be impossible.   Yet, despite their undisputed usefulness, ELA features suffer from several drawbacks. These include, in particular, (1.) a strong correlation between multiple features, as well as (2.) its very limited applicability to multi-objective continuous optimization problems. As a remedy, recent works proposed deep learning-based approaches as alternatives to ELA. In these works, e.g., point-cloud transformers were used to characterize an optimization problem's fitness landscape. However, these approaches require a large amount of labeled training data.   Within this work, we propose a hybrid approach, Deep-ELA, which combines (the benefits of) deep learning and ELA features. Specifically, we pre-trained four transformers on millions of randomly generated optimization problems to learn deep representations of the landscapes of continuous single- and multi-objective optimization problems. Our proposed framework can either be used out-of-the-box for analyzing single- and multi-objective continuous optimization problems, or subsequently fine-tuned to various tasks focussing on algorithm behavior and problem understanding.","sentences":["In many recent works, the potential of Exploratory Landscape Analysis (ELA) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated.","These numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from High-level Property Prediction to Automated Algorithm Selection and Automated Algorithm Configuration.","Without ELA features, analyzing and understanding the characteristics of single-objective continuous optimization problems would be impossible.   ","Yet, despite their undisputed usefulness, ELA features suffer from several drawbacks.","These include, in particular, (1.)","a strong correlation between multiple features, as well as (2.)","its very limited applicability to multi-objective continuous optimization problems.","As a remedy, recent works proposed deep learning-based approaches as alternatives to ELA.","In these works, e.g., point-cloud transformers were used to characterize an optimization problem's fitness landscape.","However, these approaches require a large amount of labeled training data.   ","Within this work, we propose a hybrid approach, Deep-ELA, which combines (the benefits of) deep learning and ELA features.","Specifically, we pre-trained four transformers on millions of randomly generated optimization problems to learn deep representations of the landscapes of continuous single- and multi-objective optimization problems.","Our proposed framework can either be used out-of-the-box for analyzing single- and multi-objective continuous optimization problems, or subsequently fine-tuned to various tasks focussing on algorithm behavior and problem understanding."],"url":"http://arxiv.org/abs/2401.01192v1"}
{"created":"2024-01-02 12:35:03","title":"NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments","abstract":"Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map. Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments. We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynamic environments.","sentences":["Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map.","Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects.","In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments.","We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas.","Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift.","Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping.","Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynamic environments."],"url":"http://arxiv.org/abs/2401.01189v1"}
{"created":"2024-01-02 12:27:13","title":"On the Uniqueness of Bayesian Coarse Correlated Equilibria in Standard First-Price and All-Pay Auctions","abstract":"In first-price and all-pay auctions under the standard symmetric independent private-values model, we show that the unique Bayesian Coarse Correlated Equilibrium with symmetric, differentiable and strictly increasing bidding strategies is the unique strict Bayesian Nash Equilibrium. Interestingly, this result does not require assumptions on the prior distribution. The proof is based on a dual bound of the infinite-dimensional linear program. Numerical experiments without restrictions on bidding strategies show that for first-price auctions and discretisations up to 21 of the type and bid space, increasing discretisation sizes actually increase the concentration of Bayesian Coarse Correlated Equilibrium over the Bayesian Nash Equilibrium, so long as the prior c.d.f. is concave. Such a concentration is also observed for all-pay auctions, independent of the prior distribution. Overall, our results imply that the equilibria of these important class of auctions are indeed learnable.","sentences":["In first-price and all-pay auctions under the standard symmetric independent private-values model, we show that the unique Bayesian Coarse Correlated Equilibrium with symmetric, differentiable and strictly increasing bidding strategies is the unique strict Bayesian Nash Equilibrium.","Interestingly, this result does not require assumptions on the prior distribution.","The proof is based on a dual bound of the infinite-dimensional linear program.","Numerical experiments without restrictions on bidding strategies show that for first-price auctions and discretisations up to 21 of the type and bid space, increasing discretisation sizes actually increase the concentration of Bayesian Coarse Correlated Equilibrium over the Bayesian Nash Equilibrium, so long as the prior c.d.f. is concave.","Such a concentration is also observed for all-pay auctions, independent of the prior distribution.","Overall, our results imply that the equilibria of these important class of auctions are indeed learnable."],"url":"http://arxiv.org/abs/2401.01185v1"}
{"created":"2024-01-02 12:23:49","title":"Unifying Structured Data as Graph for Data-to-Text Pre-Training","abstract":"Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account. Extensive experiments on six benchmark datasets show the effectiveness of our model. Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.","sentences":["Data-to-text (D2T) generation aims to transform structured data into natural language text.","Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances.","However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph).","In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation.","To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer.","Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph.","In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account.","Extensive experiments on six benchmark datasets show the effectiveness of our model.","Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t."],"url":"http://arxiv.org/abs/2401.01183v1"}
{"created":"2024-01-02 12:18:40","title":"Query-Based Knowledge Sharing for Open-Vocabulary Multi-Label Classification","abstract":"Identifying labels that did not appear during training, known as multi-label zero-shot learning, is a non-trivial task in computer vision. To this end, recent studies have attempted to explore the multi-modal knowledge of vision-language pre-training (VLP) models by knowledge distillation, allowing to recognize unseen labels in an open-vocabulary manner. However, experimental evidence shows that knowledge distillation is suboptimal and provides limited performance gain in unseen label prediction. In this paper, a novel query-based knowledge sharing paradigm is proposed to explore the multi-modal knowledge from the pretrained VLP model for open-vocabulary multi-label classification. Specifically, a set of learnable label-agnostic query tokens is trained to extract critical vision knowledge from the input image, and further shared across all labels, allowing them to select tokens of interest as visual clues for recognition. Besides, we propose an effective prompt pool for robust label embedding, and reformulate the standard ranking learning into a form of classification to allow the magnitude of feature vectors for matching, which both significantly benefit label recognition. Experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively.","sentences":["Identifying labels that did not appear during training, known as multi-label zero-shot learning, is a non-trivial task in computer vision.","To this end, recent studies have attempted to explore the multi-modal knowledge of vision-language pre-training (VLP) models by knowledge distillation, allowing to recognize unseen labels in an open-vocabulary manner.","However, experimental evidence shows that knowledge distillation is suboptimal and provides limited performance gain in unseen label prediction.","In this paper, a novel query-based knowledge sharing paradigm is proposed to explore the multi-modal knowledge from the pretrained VLP model for open-vocabulary multi-label classification.","Specifically, a set of learnable label-agnostic query tokens is trained to extract critical vision knowledge from the input image, and further shared across all labels, allowing them to select tokens of interest as visual clues for recognition.","Besides, we propose an effective prompt pool for robust label embedding, and reformulate the standard ranking learning into a form of classification to allow the magnitude of feature vectors for matching, which both significantly benefit label recognition.","Experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively."],"url":"http://arxiv.org/abs/2401.01181v1"}
{"created":"2024-01-02 12:16:01","title":"Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery","abstract":"Deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides. Conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment. To overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory. Our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (DBH). Compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas. We evaluated our method on a comprehensive dataset of 400 trees and achieved a DBH estimation accuracy with an error rate of less than 2.5%. Our method holds significant potential for substantially improving forest management practices. By enhancing the accuracy and efficiency of tree inventory, our model empowers urban management to mitigate the adverse effects of deforestation and climate change.","sentences":["Deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides.","Conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment.","To overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory.","Our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (DBH).","Compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas.","We evaluated our method on a comprehensive dataset of 400 trees and achieved a DBH estimation accuracy with an error rate of less than 2.5%.","Our method holds significant potential for substantially improving forest management practices.","By enhancing the accuracy and efficiency of tree inventory, our model empowers urban management to mitigate the adverse effects of deforestation and climate change."],"url":"http://arxiv.org/abs/2401.01180v1"}
{"created":"2024-01-02 12:14:41","title":"Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training","abstract":"Modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of Vision-Language Self-Supervised Learning (VL-SSL) with large pre-trained models to learn versatile medical vision representations. However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders. To address both issues, we introduce the backbone-agnostic Adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight Adaptor module for cross-modal learning. Experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90% compared to current pre-training approaches. Notably, when fine-tuned with just 1% of data, Adaptor outperforms several Transformer-based methods trained on full datasets in medical image segmentation.","sentences":["Modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of Vision-Language Self-Supervised Learning (VL-SSL) with large pre-trained models to learn versatile medical vision representations.","However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders.","To address both issues, we introduce the backbone-agnostic Adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight Adaptor module for cross-modal learning.","Experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90% compared to current pre-training approaches.","Notably, when fine-tuned with just 1% of data, Adaptor outperforms several Transformer-based methods trained on full datasets in medical image segmentation."],"url":"http://arxiv.org/abs/2401.01179v1"}
{"created":"2024-01-02 12:13:35","title":"GBSS:a global building semantic segmentation dataset for large-scale remote sensing building extraction","abstract":"Semantic segmentation techniques for extracting building footprints from high-resolution remote sensing images have been widely used in many fields such as urban planning. However, large-scale building extraction demands higher diversity in training samples. In this paper, we construct a Global Building Semantic Segmentation (GBSS) dataset (The dataset will be released), which comprises 116.9k pairs of samples (about 742k buildings) from six continents. There are significant variations of building samples in terms of size and style, so the dataset can be a more challenging benchmark for evaluating the generalization and robustness of building semantic segmentation models. We validated through quantitative and qualitative comparisons between different datasets, and further confirmed the potential application in the field of transfer learning by conducting experiments on subsets.","sentences":["Semantic segmentation techniques for extracting building footprints from high-resolution remote sensing images have been widely used in many fields such as urban planning.","However, large-scale building extraction demands higher diversity in training samples.","In this paper, we construct a Global Building Semantic Segmentation (GBSS) dataset (The dataset will be released), which comprises 116.9k pairs of samples (about 742k buildings) from six continents.","There are significant variations of building samples in terms of size and style, so the dataset can be a more challenging benchmark for evaluating the generalization and robustness of building semantic segmentation models.","We validated through quantitative and qualitative comparisons between different datasets, and further confirmed the potential application in the field of transfer learning by conducting experiments on subsets."],"url":"http://arxiv.org/abs/2401.01178v1"}
{"created":"2024-01-02 12:10:16","title":"Fundamental Limitation of Semantic Communications: Neural Estimation for Rate-Distortion","abstract":"This paper studies the fundamental limit of semantic communications over the discrete memoryless channel. We consider the scenario to send a semantic source consisting of an observation state and its corresponding semantic state, both of which are recovered at the receiver. To derive the performance limitation, we adopt the semantic rate-distortion function (SRDF) to study the relationship among the minimum compression rate, observation distortion, semantic distortion, and channel capacity. For the case with unknown semantic source distribution, while only a set of the source samples is available, we propose a neural-network-based method by leveraging the generative networks to learn the semantic source distribution. Furthermore, for a special case where the semantic state is a deterministic function of the observation, we design a cascade neural network to estimate the SRDF. For the case with perfectly known semantic source distribution, we propose a general Blahut-Arimoto algorithm to effectively compute the SRDF. Finally, experimental results validate our proposed algorithms for the scenarios with ideal Gaussian semantic source and some practical datasets.","sentences":["This paper studies the fundamental limit of semantic communications over the discrete memoryless channel.","We consider the scenario to send a semantic source consisting of an observation state and its corresponding semantic state, both of which are recovered at the receiver.","To derive the performance limitation, we adopt the semantic rate-distortion function (SRDF) to study the relationship among the minimum compression rate, observation distortion, semantic distortion, and channel capacity.","For the case with unknown semantic source distribution, while only a set of the source samples is available, we propose a neural-network-based method by leveraging the generative networks to learn the semantic source distribution.","Furthermore, for a special case where the semantic state is a deterministic function of the observation, we design a cascade neural network to estimate the SRDF.","For the case with perfectly known semantic source distribution, we propose a general Blahut-Arimoto algorithm to effectively compute the SRDF.","Finally, experimental results validate our proposed algorithms for the scenarios with ideal Gaussian semantic source and some practical datasets."],"url":"http://arxiv.org/abs/2401.01176v1"}
{"created":"2024-01-02 12:09:06","title":"Learning Surface Scattering Parameters From SAR Images Using Differentiable Ray Tracing","abstract":"Simulating high-resolution Synthetic Aperture Radar (SAR) images in complex scenes has consistently presented a significant research challenge. The development of a microwave-domain surface scattering model and its reversibility are poised to play a pivotal role in enhancing the authenticity of SAR image simulations and facilitating the reconstruction of target parameters. Drawing inspiration from the field of computer graphics, this paper proposes a surface microwave rendering model that comprehensively considers both Specular and Diffuse contributions. The model is analytically represented by the coherent spatially varying bidirectional scattering distribution function (CSVBSDF) based on the Kirchhoff approximation (KA) and the perturbation method (SPM). And SAR imaging is achieved through the synergistic combination of ray tracing and fast mapping projection techniques. Furthermore, a differentiable ray tracing (DRT) engine based on SAR images was constructed for CSVBSDF surface scattering parameter learning. Within this SAR image simulation engine, the use of differentiable reverse ray tracing enables the rapid estimation of parameter gradients from SAR images. The effectiveness of this approach has been validated through simulations and comparisons with real SAR images. By learning the surface scattering parameters, substantial enhancements in SAR image simulation performance under various observation conditions have been demonstrated.","sentences":["Simulating high-resolution Synthetic Aperture Radar (SAR) images in complex scenes has consistently presented a significant research challenge.","The development of a microwave-domain surface scattering model and its reversibility are poised to play a pivotal role in enhancing the authenticity of SAR image simulations and facilitating the reconstruction of target parameters.","Drawing inspiration from the field of computer graphics, this paper proposes a surface microwave rendering model that comprehensively considers both Specular and Diffuse contributions.","The model is analytically represented by the coherent spatially varying bidirectional scattering distribution function (CSVBSDF) based on the Kirchhoff approximation (KA) and the perturbation method (SPM).","And SAR imaging is achieved through the synergistic combination of ray tracing and fast mapping projection techniques.","Furthermore, a differentiable ray tracing (DRT) engine based on SAR images was constructed for CSVBSDF surface scattering parameter learning.","Within this SAR image simulation engine, the use of differentiable reverse ray tracing enables the rapid estimation of parameter gradients from SAR images.","The effectiveness of this approach has been validated through simulations and comparisons with real SAR images.","By learning the surface scattering parameters, substantial enhancements in SAR image simulation performance under various observation conditions have been demonstrated."],"url":"http://arxiv.org/abs/2401.01175v1"}
{"created":"2024-01-02 12:06:31","title":"En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data","abstract":"We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars. Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3D generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3D humans without relying on pre-existing 3D or 2D assets. To address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3D generative model from synthetic 2D data. During inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3D shapes. Specifically, En3D comprises three modules: a 3D generator that accurately models generalizable 3D humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical UV partitioning and a differentiable rasterizer. Experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity. We also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation.","sentences":["We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars.","Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3D generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3D humans without relying on pre-existing 3D or 2D assets.","To address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3D generative model from synthetic 2D data.","During inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3D shapes.","Specifically, En3D comprises three modules: a 3D generator that accurately models generalizable 3D humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical UV partitioning and a differentiable rasterizer.","Experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity.","We also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation."],"url":"http://arxiv.org/abs/2401.01173v1"}
{"created":"2024-01-02 12:02:50","title":"Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults","abstract":"Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration's non-stationary nature. This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing's inherent and operational parameters. We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. Based on this, we design a time-frequency convolutional neural network (TF-CNN) to diagnose various faults in rolling-element bearings. Our experimental findings undeniably demonstrate the superior performance of TF-CNN in comparison to recently developed techniques. They also assert its versatility in capturing fault-relevant non-stationary features that couple with speed changes and show its exceptional resilience to noise, consistently surpassing competing methods across various signal-to-noise ratios and performance metrics. Altogether, the TF-CNN achieves substantial accuracy improvements up to 15%, in severe noise conditions.","sentences":["Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns.","Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status.","Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration's non-stationary nature.","This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels.","First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing's inherent and operational parameters.","We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults.","Based on this, we design a time-frequency convolutional neural network (TF-CNN) to diagnose various faults in rolling-element bearings.","Our experimental findings undeniably demonstrate the superior performance of TF-CNN in comparison to recently developed techniques.","They also assert its versatility in capturing fault-relevant non-stationary features that couple with speed changes and show its exceptional resilience to noise, consistently surpassing competing methods across various signal-to-noise ratios and performance metrics.","Altogether, the TF-CNN achieves substantial accuracy improvements up to 15%, in severe noise conditions."],"url":"http://arxiv.org/abs/2401.01172v1"}
{"created":"2024-01-02 11:53:06","title":"FedQV: Leveraging Quadratic Voting in Federated Learning","abstract":"Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels. A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular. In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules. In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one's true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FedQV against poisoning attacks. It also shows that combining FedQV with unequal voting ``budgets'' according to a reputation score increases its performance benefits even further. Finally, we show that FedQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.","sentences":["Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels.","A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular.","In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules.","In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections.","Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one's true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods.","Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FedQV against poisoning attacks.","It also shows that combining FedQV with unequal voting ``budgets'' according to a reputation score increases its performance benefits even further.","Finally, we show that FedQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks."],"url":"http://arxiv.org/abs/2401.01168v1"}
{"created":"2024-01-02 11:47:58","title":"Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer","abstract":"The electromagnetic inverse problem has long been a research hotspot. This study aims to reverse radar view angles in synthetic aperture radar (SAR) images given a target model. Nonetheless, the scarcity of SAR data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches. To address these challenges, we propose an interactive deep reinforcement learning (DRL) framework, where an electromagnetic simulator named differentiable SAR render (DSR) is embedded to facilitate the interaction between the agent and the environment, simulating a human-like process of angle prediction. Specifically, DSR generates SAR images at arbitrary view angles in real-time. And the differences in sequential and semantic aspects between the view angle-corresponding images are leveraged to construct the state space in DRL, which effectively suppress the complex background interference, enhance the sensitivity to temporal variations, and improve the capability to capture fine-grained information. Additionally, in order to maintain the stability and convergence of our method, a series of reward mechanisms, such as memory difference, smoothing and boundary penalty, are utilized to form the final reward function. Extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method. When utilized in the cross-domain area, the proposed method greatly mitigates inconsistency between simulated and real domains, outperforming reference methods significantly.","sentences":["The electromagnetic inverse problem has long been a research hotspot.","This study aims to reverse radar view angles in synthetic aperture radar (SAR) images given a target model.","Nonetheless, the scarcity of SAR data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches.","To address these challenges, we propose an interactive deep reinforcement learning (DRL) framework, where an electromagnetic simulator named differentiable SAR render (DSR) is embedded to facilitate the interaction between the agent and the environment, simulating a human-like process of angle prediction.","Specifically, DSR generates SAR images at arbitrary view angles in real-time.","And the differences in sequential and semantic aspects between the view angle-corresponding images are leveraged to construct the state space in DRL, which effectively suppress the complex background interference, enhance the sensitivity to temporal variations, and improve the capability to capture fine-grained information.","Additionally, in order to maintain the stability and convergence of our method, a series of reward mechanisms, such as memory difference, smoothing and boundary penalty, are utilized to form the final reward function.","Extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method.","When utilized in the cross-domain area, the proposed method greatly mitigates inconsistency between simulated and real domains, outperforming reference methods significantly."],"url":"http://arxiv.org/abs/2401.01165v1"}
{"created":"2024-01-02 11:46:44","title":"Distilling Local Texture Features for Colorectal Tissue Classification in Low Data Regimes","abstract":"Multi-class colorectal tissue classification is a challenging problem that is typically addressed in a setting, where it is assumed that ample amounts of training data is available. However, manual annotation of fine-grained colorectal tissue samples of multiple classes, especially the rare ones like stromal tumor and anal cancer is laborious and expensive. To address this, we propose a knowledge distillation-based approach, named KD-CTCNet, that effectively captures local texture information from few tissue samples, through a distillation loss, to improve the standard CNN features. The resulting enriched feature representation achieves improved classification performance specifically in low data regimes. Extensive experiments on two public datasets of colorectal tissues reveal the merits of the proposed contributions, with a consistent gain achieved over different approaches across low data settings. The code and models are publicly available on GitHub.","sentences":["Multi-class colorectal tissue classification is a challenging problem that is typically addressed in a setting, where it is assumed that ample amounts of training data is available.","However, manual annotation of fine-grained colorectal tissue samples of multiple classes, especially the rare ones like stromal tumor and anal cancer is laborious and expensive.","To address this, we propose a knowledge distillation-based approach, named KD-CTCNet, that effectively captures local texture information from few tissue samples, through a distillation loss, to improve the standard CNN features.","The resulting enriched feature representation achieves improved classification performance specifically in low data regimes.","Extensive experiments on two public datasets of colorectal tissues reveal the merits of the proposed contributions, with a consistent gain achieved over different approaches across low data settings.","The code and models are publicly available on GitHub."],"url":"http://arxiv.org/abs/2401.01164v1"}
{"created":"2024-01-02 11:46:42","title":"NU-Class Net: A Novel Deep Learning-based Approach for Video Quality Enhancement","abstract":"Video content has experienced a surge in popularity, asserting its dominance over internet traffic and Internet of Things (IoT) networks. Video compression has long been regarded as the primary means of efficiently managing the substantial multimedia traffic generated by video-capturing devices. Nevertheless, video compression algorithms entail significant computational demands in order to achieve substantial compression ratios. This complexity presents a formidable challenge when implementing efficient video coding standards in resource-constrained embedded systems, such as IoT edge node cameras. To tackle this challenge, this paper introduces NU-Class Net, an innovative deep-learning model designed to mitigate compression artifacts stemming from lossy compression codecs. This enhancement significantly elevates the perceptible quality of low-bit-rate videos. By employing the NU-Class Net, the video encoder within the video-capturing node can reduce output quality, thereby generating low-bit-rate videos and effectively curtailing both computation and bandwidth requirements at the edge. On the decoder side, which is typically less encumbered by resource limitations, NU-Class Net is applied after the video decoder to compensate for artifacts and approximate the quality of the original video. Experimental results affirm the efficacy of the proposed model in enhancing the perceptible quality of videos, especially those streamed at low bit rates.","sentences":["Video content has experienced a surge in popularity, asserting its dominance over internet traffic and Internet of Things (IoT) networks.","Video compression has long been regarded as the primary means of efficiently managing the substantial multimedia traffic generated by video-capturing devices.","Nevertheless, video compression algorithms entail significant computational demands in order to achieve substantial compression ratios.","This complexity presents a formidable challenge when implementing efficient video coding standards in resource-constrained embedded systems, such as IoT edge node cameras.","To tackle this challenge, this paper introduces NU-Class Net, an innovative deep-learning model designed to mitigate compression artifacts stemming from lossy compression codecs.","This enhancement significantly elevates the perceptible quality of low-bit-rate videos.","By employing the NU-Class Net, the video encoder within the video-capturing node can reduce output quality, thereby generating low-bit-rate videos and effectively curtailing both computation and bandwidth requirements at the edge.","On the decoder side, which is typically less encumbered by resource limitations, NU-Class Net is applied after the video decoder to compensate for artifacts and approximate the quality of the original video.","Experimental results affirm the efficacy of the proposed model in enhancing the perceptible quality of videos, especially those streamed at low bit rates."],"url":"http://arxiv.org/abs/2401.01163v1"}
{"created":"2024-01-02 11:13:01","title":"Deep Learning-Based Detection for Marker Codes over Insertion and Deletion Channels","abstract":"Marker code is an effective coding scheme to protect data from insertions and deletions. It has potential applications in future storage systems, such as DNA storage and racetrack memory. When decoding marker codes, perfect channel state information (CSI), i.e., insertion and deletion probabilities, are required to detect insertion and deletion errors. Sometimes, the perfect CSI is not easy to obtain or the accurate channel model is unknown. Therefore, it is deserved to develop detecting algorithms for marker code without the knowledge of perfect CSI. In this paper, we propose two CSI-agnostic detecting algorithms for marker code based on deep learning. The first one is a model-driven deep learning method, which deep unfolds the original iterative detecting algorithm of marker code. In this method, CSI become weights in neural networks and these weights can be learned from training data. The second one is a data-driven method which is an end-to-end system based on the deep bidirectional gated recurrent unit network. Simulation results show that error performances of the proposed methods are significantly better than that of the original detection algorithm with CSI uncertainty. Furthermore, the proposed data-driven method exhibits better error performances than other methods for unknown channel models.","sentences":["Marker code is an effective coding scheme to protect data from insertions and deletions.","It has potential applications in future storage systems, such as DNA storage and racetrack memory.","When decoding marker codes, perfect channel state information (CSI), i.e., insertion and deletion probabilities, are required to detect insertion and deletion errors.","Sometimes, the perfect CSI is not easy to obtain or the accurate channel model is unknown.","Therefore, it is deserved to develop detecting algorithms for marker code without the knowledge of perfect CSI.","In this paper, we propose two CSI-agnostic detecting algorithms for marker code based on deep learning.","The first one is a model-driven deep learning method, which deep unfolds the original iterative detecting algorithm of marker code.","In this method, CSI become weights in neural networks and these weights can be learned from training data.","The second one is a data-driven method which is an end-to-end system based on the deep bidirectional gated recurrent unit network.","Simulation results show that error performances of the proposed methods are significantly better than that of the original detection algorithm with CSI uncertainty.","Furthermore, the proposed data-driven method exhibits better error performances than other methods for unknown channel models."],"url":"http://arxiv.org/abs/2401.01155v1"}
{"created":"2024-01-02 11:08:39","title":"Applying Bayesian Data Analysis for Causal Inference about Requirements Quality: A Replicated Experiment","abstract":"Context: It is commonly accepted that the quality of requirements specifications impacts subsequent software engineering activities. However, we still lack empirical evidence to support organizations in deciding whether their requirements are good enough or impede subsequent activities. Objective: We aim to contribute empirical evidence to the effect that requirements quality defects have on a software engineering activity that depends on this requirement. Method: We replicate a controlled experiment in which 25 participants from industry and university generate domain models from four natural language requirements containing different quality defects. We evaluate the resulting models using both frequentist and Bayesian data analysis. Results: Contrary to our expectations, our results show that the use of passive voice only has a minor impact on the resulting domain models. The use of ambiguous pronouns, however, shows a strong effect on various properties of the resulting domain models. Most notably, ambiguous pronouns lead to incorrect associations in domain models. Conclusion: Despite being equally advised against by literature and frequentist methods, the Bayesian data analysis shows that the two investigated quality defects have vastly different impacts on software engineering activities and, hence, deserve different levels of attention. Our employed method can be further utilized by researchers to improve reliable, detailed empirical evidence on requirements quality.","sentences":["Context: It is commonly accepted that the quality of requirements specifications impacts subsequent software engineering activities.","However, we still lack empirical evidence to support organizations in deciding whether their requirements are good enough or impede subsequent activities.","Objective: We aim to contribute empirical evidence to the effect that requirements quality defects have on a software engineering activity that depends on this requirement.","Method: We replicate a controlled experiment in which 25 participants from industry and university generate domain models from four natural language requirements containing different quality defects.","We evaluate the resulting models using both frequentist and Bayesian data analysis.","Results: Contrary to our expectations, our results show that the use of passive voice only has a minor impact on the resulting domain models.","The use of ambiguous pronouns, however, shows a strong effect on various properties of the resulting domain models.","Most notably, ambiguous pronouns lead to incorrect associations in domain models.","Conclusion: Despite being equally advised against by literature and frequentist methods, the Bayesian data analysis shows that the two investigated quality defects have vastly different impacts on software engineering activities and, hence, deserve different levels of attention.","Our employed method can be further utilized by researchers to improve reliable, detailed empirical evidence on requirements quality."],"url":"http://arxiv.org/abs/2401.01154v1"}
{"created":"2024-01-02 11:04:51","title":"The social graph based on real data","abstract":"In this paper, we propose a model enabling the creation of a social graph corresponding to real society. The procedure uses data describing the real social relations in the community, like marital status or number of kids. Results show the power-law behavior of the distribution of links and, typical for small worlds, the independence of the clustering coefficient on the size of the graph.","sentences":["In this paper, we propose a model enabling the creation of a social graph corresponding to real society.","The procedure uses data describing the real social relations in the community, like marital status or number of kids.","Results show the power-law behavior of the distribution of links and, typical for small worlds, the independence of the clustering coefficient on the size of the graph."],"url":"http://arxiv.org/abs/2401.01152v1"}
{"created":"2024-01-02 11:01:25","title":"CXL and the Return of Scale-Up Database Engines","abstract":"The growing trend towards specialization has led to a proliferation of accelerators and alternative processing devices. When embedded in conventional computer architectures, the PCIe link connecting the CPU to these devices becomes a bottleneck. Several proposals for alternative designs have been put forward, with these efforts having now converged into the Compute Express Link (CXL) specification. CXL is an interconnect protocol on top of PCIe with a more modern and powerful interface. While still on version 1.0 in terms of commercial availability, the potential of CXL to radically change the underlying architecture has already attracted considerable attention. This attention has been focused mainly on the possibility of using CXL to build a shared memory system among the machines in a rack. We argue, however, that such benefits are just the beginning of more significant changes that will have a major impact on database engines and data processing systems. In a nutshell, while the cloud favored scale-out approaches, CXL brings back scale-up architectures. In the paper we describe how CXL enables such architectures, and the research challenges associated with the emerging scale-up, heterogeneous hardware platforms.","sentences":["The growing trend towards specialization has led to a proliferation of accelerators and alternative processing devices.","When embedded in conventional computer architectures, the PCIe link connecting the CPU to these devices becomes a bottleneck.","Several proposals for alternative designs have been put forward, with these efforts having now converged into the Compute Express Link (CXL) specification.","CXL is an interconnect protocol on top of PCIe with a more modern and powerful interface.","While still on version 1.0 in terms of commercial availability, the potential of CXL to radically change the underlying architecture has already attracted considerable attention.","This attention has been focused mainly on the possibility of using CXL to build a shared memory system among the machines in a rack.","We argue, however, that such benefits are just the beginning of more significant changes that will have a major impact on database engines and data processing systems.","In a nutshell, while the cloud favored scale-out approaches, CXL brings back scale-up architectures.","In the paper we describe how CXL enables such architectures, and the research challenges associated with the emerging scale-up, heterogeneous hardware platforms."],"url":"http://arxiv.org/abs/2401.01150v1"}
{"created":"2024-01-02 10:59:29","title":"Search Games with Predictions","abstract":"We study search games between a mobile Searcher and an immobile Hider in which the Searcher aims to minimize some payoff, which is either the time to find the Hider (the search time), or a normalized search time. We consider a new setting in which the Searcher has some potentially erroneous information, or prediction on the Hider's position. Specifically, we study tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and the robustness (i.e., the worst case expected payoff assuming that the prediction is adversarially generated). We show how to apply this framework in search games over both discrete and continuous, as well as bounded and unbounded spaces. Specifically, we prove optimal consistency/robustness tradeoffs for three fundamental search games, namely searching in a number of discrete locations, expanding search in a tree network, and searching in the infinite line. Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations.","sentences":["We study search games between a mobile Searcher and an immobile Hider in which the Searcher aims to minimize some payoff, which is either the time to find the Hider (the search time), or a normalized search time.","We consider a new setting in which the Searcher has some potentially erroneous information, or prediction on the Hider's position.","Specifically, we study tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and the robustness (i.e., the worst case expected payoff assuming that the prediction is adversarially generated).","We show how to apply this framework in search games over both discrete and continuous, as well as bounded and unbounded spaces.","Specifically, we prove optimal consistency/robustness tradeoffs for three fundamental search games, namely searching in a number of discrete locations, expanding search in a tree network, and searching in the infinite line.","Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations."],"url":"http://arxiv.org/abs/2401.01149v1"}
{"created":"2024-01-02 10:56:24","title":"Privacy Preserving Personal Assistant with On-Device Diarization and Spoken Dialogue System for Home and Beyond","abstract":"In the age of personal voice assistants, the question of privacy arises. These digital companions often lack memory of past interactions, while relying heavily on the internet for speech processing, raising privacy concerns. Modern smartphones now enable on-device speech processing, making cloud-based solutions unnecessary. Personal assistants for the elderly should excel at memory recall, especially in medical examinations. The e-ViTA project developed a versatile conversational application with local processing and speaker recognition. This paper highlights the importance of speaker diarization enriched with sensor data fusion for contextualized conversation preservation. The use cases applied to the e-VITA project have shown that truly personalized dialogue is pivotal for individual voice assistants. Secure local processing and sensor data fusion ensure virtual companions meet individual user needs without compromising privacy or data security.","sentences":["In the age of personal voice assistants, the question of privacy arises.","These digital companions often lack memory of past interactions, while relying heavily on the internet for speech processing, raising privacy concerns.","Modern smartphones now enable on-device speech processing, making cloud-based solutions unnecessary.","Personal assistants for the elderly should excel at memory recall, especially in medical examinations.","The e-ViTA project developed a versatile conversational application with local processing and speaker recognition.","This paper highlights the importance of speaker diarization enriched with sensor data fusion for contextualized conversation preservation.","The use cases applied to the e-VITA project have shown that truly personalized dialogue is pivotal for individual voice assistants.","Secure local processing and sensor data fusion ensure virtual companions meet individual user needs without compromising privacy or data security."],"url":"http://arxiv.org/abs/2401.01146v1"}
{"created":"2024-01-02 10:51:25","title":"Enhancing Communication Efficiency of Semantic Transmission via Joint Processing Technique","abstract":"This work presents a novel semantic transmission framework in wireless networks, leveraging the joint processing technique. Our framework enables multiple cooperating base stations to efficiently transmit semantic information to multiple users simultaneously. To enhance the semantic communication efficiency of the transmission framework, we formulate an optimization problem with the objective of maximizing the semantic spectral efficiency of the framework and propose a lowcomplexity dynamic semantic mapping and resource allocation algorithm. This algorithm, based on deep reinforcement learning and alternative optimization, achieves near-optimal performance while reducing computational complexity. Simulation results validate the effectiveness of the proposed algorithm, bridging the research gap and facilitating the practical implementation of semantic communication systems.","sentences":["This work presents a novel semantic transmission framework in wireless networks, leveraging the joint processing technique.","Our framework enables multiple cooperating base stations to efficiently transmit semantic information to multiple users simultaneously.","To enhance the semantic communication efficiency of the transmission framework, we formulate an optimization problem with the objective of maximizing the semantic spectral efficiency of the framework and propose a lowcomplexity dynamic semantic mapping and resource allocation algorithm.","This algorithm, based on deep reinforcement learning and alternative optimization, achieves near-optimal performance while reducing computational complexity.","Simulation results validate the effectiveness of the proposed algorithm, bridging the research gap and facilitating the practical implementation of semantic communication systems."],"url":"http://arxiv.org/abs/2401.01143v1"}
{"created":"2024-01-02 10:42:42","title":"Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge","abstract":"Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery. This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption, draining only 180mW for a complete inference on an input image. The latency is comparable to the ones observed in the state-of-the-art, with 780us/img. To the authors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD. In this case, the accelerator requires 18,268 logic cells and 51 BRAM, with an overall power consumption of 430mW and a latency of 54 us for a complete inference on input data. This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications.","sentences":["Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery.","This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge.","Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code.","Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD).","On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators.","It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption, draining only 180mW for a complete inference on an input image.","The latency is comparable to the ones observed in the state-of-the-art, with 780us/img.","To the authors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD.","In this case, the accelerator requires 18,268 logic cells and 51 BRAM, with an overall power consumption of 430mW and a latency of 54 us for a complete inference on input data.","This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications."],"url":"http://arxiv.org/abs/2401.01141v1"}
{"created":"2024-01-02 10:39:23","title":"Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach","abstract":"In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms. This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs. The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs). The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs). With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN. A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL. Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.","sentences":["In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms.","This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs.","The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs).","The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs).","With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN.","A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL.","Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications."],"url":"http://arxiv.org/abs/2401.01140v1"}
{"created":"2024-01-02 10:22:21","title":"Optimally or almost optimally extendable self-orthogonal codes and locally recoverable codes from some functions over finite fields","abstract":"Linear codes are widely studied in coding theory as they have nice applications in distributed storage, combinatorics, lattices, cryptography and so on. Constructing linear codes with desirable properties is an interesting research topic. In this paper, based on the augmentation technique, we present two families of linear codes from some functions over finite fields. The first family of linear codes is constructed from monomial functions over finite fields. The locality of them is determined and the weight distributions of two subfamilies of the codes are also given. An infinite family of almost optimal recoverable codes and some optimal recoverable codes are obtained from the linear codes. In particular, the two subfamilies of the codes are proved to be both optimally or almost optimally extendable and self-orthogonal. The second family of linear codes is constructed from weakly regular bent functions over finite fields and their weight distribution is determined. This family of codes is proved to have locality 3 for some cases and is conjectured to have locality 2 for other cases. Particularly, two families of optimal locally recoverable codes are derived from the linear codes. Besides, this family of codes is also proved to be both optimally or almost optimally extendable and self-orthogonal.","sentences":["Linear codes are widely studied in coding theory as they have nice applications in distributed storage, combinatorics, lattices, cryptography and so on.","Constructing linear codes with desirable properties is an interesting research topic.","In this paper, based on the augmentation technique, we present two families of linear codes from some functions over finite fields.","The first family of linear codes is constructed from monomial functions over finite fields.","The locality of them is determined and the weight distributions of two subfamilies of the codes are also given.","An infinite family of almost optimal recoverable codes and some optimal recoverable codes are obtained from the linear codes.","In particular, the two subfamilies of the codes are proved to be both optimally or almost optimally extendable and self-orthogonal.","The second family of linear codes is constructed from weakly regular bent functions over finite fields and their weight distribution is determined.","This family of codes is proved to have locality 3 for some cases and is conjectured to have locality 2 for other cases.","Particularly, two families of optimal locally recoverable codes are derived from the linear codes.","Besides, this family of codes is also proved to be both optimally or almost optimally extendable and self-orthogonal."],"url":"http://arxiv.org/abs/2401.01135v1"}
{"created":"2024-01-02 10:22:06","title":"Hybrid Pooling and Convolutional Network for Improving Accuracy and Training Convergence Speed in Object Detection","abstract":"This paper introduces HPC-Net, a high-precision and rapidly convergent object detection network.","sentences":["This paper introduces HPC-Net, a high-precision and rapidly convergent object detection network."],"url":"http://arxiv.org/abs/2401.01134v1"}
