{"text":"The code is available at https://zju3dv.github.io/street_gaussians/.","meta":{"url":"http://arxiv.org/abs/2401.01339v1","data_type":"evaluation"},"label":"architectures","_input_hash":-614888652,"_task_hash":-223505867,"_view_id":"classification","answer":"reject","_timestamp":1704741847,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"Automatic machine translation metrics often use human translations to determine the quality system translations.","meta":{"url":"http://arxiv.org/abs/2401.01283v1","data_type":"evaluation"},"label":"architectures","_input_hash":1888668523,"_task_hash":-1070988881,"_view_id":"classification","answer":"reject","_timestamp":1704741851,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"We find that higher-quality references lead to better metric correlations with humans at the segment-level.","meta":{"url":"http://arxiv.org/abs/2401.01283v1","data_type":"evaluation"},"label":"architectures","_input_hash":-938412547,"_task_hash":-270591969,"_view_id":"classification","answer":"reject","_timestamp":1704741853,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders.","meta":{"url":"http://arxiv.org/abs/2401.01179v1","data_type":"evaluation"},"label":"architectures","_input_hash":-198507618,"_task_hash":-93842255,"_view_id":"classification","answer":"accept","_timestamp":1704741866,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections.","meta":{"url":"http://arxiv.org/abs/2401.01168v1","data_type":"evaluation"},"label":"architectures","_input_hash":1005280930,"_task_hash":-1917051508,"_view_id":"classification","answer":"reject","_timestamp":1704741876,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"Nonetheless, the scarcity of SAR data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches.","meta":{"url":"http://arxiv.org/abs/2401.01165v1","data_type":"evaluation"},"label":"architectures","_input_hash":1796634020,"_task_hash":-803025324,"_view_id":"classification","answer":"reject","_timestamp":1704741881,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"Our simulations use seeded random replacement of reviewers to allow us to compare the reviewer recommenders without the confounding variation of different reviewers being replaced for each recommender.   ","meta":{"url":"http://arxiv.org/abs/2312.17236v1","data_type":"evaluation"},"label":"architectures","_input_hash":-109615240,"_task_hash":-1532664610,"_view_id":"classification","answer":"reject","_timestamp":1704741883,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"Combining recommenders, we develop the SofiaWL recommender that suggests experts with low active review workload when none of the files under review are known by only one developer.","meta":{"url":"http://arxiv.org/abs/2312.17236v1","data_type":"evaluation"},"label":"architectures","_input_hash":-1084946667,"_task_hash":1726214181,"_view_id":"classification","answer":"reject","_timestamp":1704741885,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"In contrast, when knowledge is concentrated on one developer, it sends the review to other reviewers to spread knowledge.","meta":{"url":"http://arxiv.org/abs/2312.17236v1","data_type":"evaluation"},"label":"architectures","_input_hash":-879612200,"_task_hash":-1029180565,"_view_id":"classification","answer":"reject","_timestamp":1704741887,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"For the projects we study, we are able to globally increase expertise during reviews, +3%, reduce workload concentration, -12%, and reduce the files at risk, -28%.","meta":{"url":"http://arxiv.org/abs/2312.17236v1","data_type":"evaluation"},"label":"architectures","_input_hash":1044671975,"_task_hash":1060462578,"_view_id":"classification","answer":"reject","_timestamp":1704741889,"_annotator_id":"2024-01-08_14-24-03","_session_id":"2024-01-08_14-24-03"}
{"text":"We present Generalized LoRA (GLoRA), an advanced approach for universal parameter-efficient fine-tuning tasks.","meta":{"distance":0.4480298758,"data_type":"evaluation"},"label":"architectures","_input_hash":872376773,"_task_hash":1832684961,"_view_id":"classification","answer":"accept","_timestamp":1704744879,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"In this paper, we propose a two-stage fine-tuning method, PAC-tuning, to address this optimization challenge.","meta":{"distance":0.4527113438,"data_type":"evaluation"},"label":"architectures","_input_hash":1133618440,"_task_hash":576187791,"_view_id":"classification","answer":"accept","_timestamp":1704744890,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"All the architecture-oriented optimization methods are elaborately designed from four levels to fully exploit the hardware efficiency of SW26010.","meta":{"distance":0.4545943141,"data_type":"evaluation"},"label":"architectures","_input_hash":1705914275,"_task_hash":-239157561,"_view_id":"classification","answer":"ignore","_timestamp":1704744904,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks.","meta":{"distance":0.4652230144,"data_type":"evaluation"},"label":"architectures","_input_hash":485540211,"_task_hash":504885867,"_view_id":"classification","answer":"ignore","_timestamp":1704744910,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"This paper proposes a Parameter-efficient prompt Tuning approach with Adaptive Optimization, i.e., FedPepTAO, to enable efficient and effective FL of LLMs.","meta":{"distance":0.4737365246,"data_type":"evaluation"},"label":"architectures","_input_hash":1945639730,"_task_hash":-1396121870,"_view_id":"classification","answer":"accept","_timestamp":1704744913,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"These optimization strategies contribute to the outstanding empirical performance of the LLM-Embedder.","meta":{"distance":0.4756900072,"data_type":"evaluation"},"label":"architectures","_input_hash":-1115513,"_task_hash":-553553915,"_view_id":"classification","answer":"accept","_timestamp":1704744916,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"Current LLM training frameworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on optimizing training within homogeneous cluster settings.","meta":{"distance":0.4910159111,"data_type":"evaluation"},"label":"architectures","_input_hash":-392295310,"_task_hash":-910539565,"_view_id":"classification","answer":"accept","_timestamp":1704744942,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"This innovative approach empowers the previously static LLM to seamlessly integrate and process image information, marking a step forward in optimizing R2Gen performance.","meta":{"distance":0.5067267418,"data_type":"evaluation"},"label":"architectures","_input_hash":798189583,"_task_hash":-370985902,"_view_id":"classification","answer":"accept","_timestamp":1704744957,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs' responses to instructions with various constraints.","meta":{"distance":0.5161943436,"data_type":"evaluation"},"label":"architectures","_input_hash":-2013112528,"_task_hash":-1604124173,"_view_id":"classification","answer":"ignore","_timestamp":1704744965,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}
{"text":"We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.","meta":{"distance":0.5170377493,"data_type":"evaluation"},"label":"architectures","_input_hash":1072091220,"_task_hash":1498428376,"_view_id":"classification","answer":"accept","_timestamp":1704744969,"_annotator_id":"2024-01-08_15-14-24","_session_id":"2024-01-08_15-14-24"}