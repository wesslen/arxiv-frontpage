{"text":"Moreover, their discrepancies indicate potential errors or inherent uncertainties that LLM often overlooks.","meta":{"url":"http://arxiv.org/abs/2401.02009v1","data_type":"evaluation"},"label":"hci","_input_hash":-61915034,"_task_hash":-916349104,"_view_id":"classification","answer":"reject","_timestamp":1704741501,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"This demonstrates that models exhibit polysemantic capacities and can blend old and new concepts in individual neurons.","meta":{"url":"http://arxiv.org/abs/2401.01814v1","data_type":"evaluation"},"label":"hci","_input_hash":-1817252113,"_task_hash":653174768,"_view_id":"classification","answer":"reject","_timestamp":1704741503,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity.","meta":{"url":"http://arxiv.org/abs/2401.01256v1","data_type":"evaluation"},"label":"hci","_input_hash":-1906694962,"_task_hash":196607929,"_view_id":"classification","answer":"reject","_timestamp":1704741506,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"Unfortunately, existing solutions fall short of satisfying these requirements.   ","meta":{"url":"http://arxiv.org/abs/2401.01280v1","data_type":"evaluation"},"label":"hci","_input_hash":1356463987,"_task_hash":-649419716,"_view_id":"classification","answer":"reject","_timestamp":1704741508,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular.","meta":{"url":"http://arxiv.org/abs/2401.01168v1","data_type":"evaluation"},"label":"hci","_input_hash":-1039846266,"_task_hash":-221510523,"_view_id":"classification","answer":"reject","_timestamp":1704741515,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"This study aims to reverse radar view angles in synthetic aperture radar (SAR) images given a target model.","meta":{"url":"http://arxiv.org/abs/2401.01165v1","data_type":"evaluation"},"label":"hci","_input_hash":-1510530739,"_task_hash":-208791913,"_view_id":"classification","answer":"reject","_timestamp":1704741516,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time.","meta":{"url":"http://arxiv.org/abs/2401.00690v1","data_type":"evaluation"},"label":"hci","_input_hash":-1635834026,"_task_hash":1938135749,"_view_id":"classification","answer":"reject","_timestamp":1704741533,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach.","meta":{"url":"http://arxiv.org/abs/2401.00434v1","data_type":"evaluation"},"label":"hci","_input_hash":-361651987,"_task_hash":-1921390021,"_view_id":"classification","answer":"reject","_timestamp":1704741541,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"More specifically, GeoGalactica is from further pre-training of Galactica.","meta":{"url":"http://arxiv.org/abs/2401.00434v1","data_type":"evaluation"},"label":"hci","_input_hash":-10445880,"_task_hash":1591980407,"_view_id":"classification","answer":"reject","_timestamp":1704741542,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"Our framework empowers InsActor to capture complex relationships between high-level human instructions and character motions by employing diffusion policies for flexibly conditioned motion planning.","meta":{"url":"http://arxiv.org/abs/2312.17135v1","data_type":"evaluation"},"label":"hci","_input_hash":-1551816305,"_task_hash":-1018354824,"_view_id":"classification","answer":"reject","_timestamp":1704741545,"_annotator_id":"2024-01-08_14-17-49","_session_id":"2024-01-08_14-17-49"}
{"text":"This paper introduces a novel human-LLM interaction framework, Low-code LLM.","meta":{"distance":0.4676497579,"data_type":"evaluation"},"label":"hci","_input_hash":940551055,"_task_hash":1421192259,"_view_id":"classification","answer":"accept","_timestamp":1704742836,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"We highlight three advantages of the low-code LLM: controllable generation results, user-friendly human-LLM interaction, and broadly applicable scenarios.","meta":{"distance":0.472645998,"data_type":"evaluation"},"label":"hci","_input_hash":388799325,"_task_hash":-30228428,"_view_id":"classification","answer":"accept","_timestamp":1704742839,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Experiment involves both qualitative analysis with real-world user dialogs and quantitative analysis with simulated dialogs.","meta":{"distance":0.4731102586,"data_type":"evaluation"},"label":"hci","_input_hash":1146819448,"_task_hash":2132062019,"_view_id":"classification","answer":"ignore","_timestamp":1704742849,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"We analyze the impact of different prompt designs, the benefits of in-context learning, and the advantages of offering high-level guidance to LLMs.","meta":{"distance":0.4818640351,"data_type":"evaluation"},"label":"hci","_input_hash":980786530,"_task_hash":724118270,"_view_id":"classification","answer":"ignore","_timestamp":1704742855,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"This overview sheds light on existing and missing research lines in the emerging field of LLMs, benefiting both public users and developers.","meta":{"distance":0.4826039076,"data_type":"evaluation"},"label":"hci","_input_hash":2146238236,"_task_hash":951044603,"_view_id":"classification","answer":"ignore","_timestamp":1704742863,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Through human-model interactions, LLMs can automatically understand human-issued instructions and output the expected contents, which can significantly increase working efficiency.","meta":{"distance":0.4892213345,"data_type":"evaluation"},"label":"hci","_input_hash":-768588439,"_task_hash":-1481101538,"_view_id":"classification","answer":"accept","_timestamp":1704742881,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"The LLM is thus able to compose the visual entities and relationships through the communication tokens.","meta":{"distance":0.4893799424,"data_type":"evaluation"},"label":"hci","_input_hash":1133993204,"_task_hash":-919099174,"_view_id":"classification","answer":"accept","_timestamp":1704742891,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.","meta":{"distance":0.4901511073,"data_type":"evaluation"},"label":"hci","_input_hash":1425898923,"_task_hash":-2037823764,"_view_id":"classification","answer":"ignore","_timestamp":1704742907,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations.","meta":{"distance":0.4910379648,"data_type":"evaluation"},"label":"hci","_input_hash":-1066678503,"_task_hash":1991217523,"_view_id":"classification","answer":"ignore","_timestamp":1704742913,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses.","meta":{"distance":0.4975833893,"data_type":"evaluation"},"label":"hci","_input_hash":133991797,"_task_hash":-598416169,"_view_id":"classification","answer":"ignore","_timestamp":1704742920,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Our results indicate that participants could assess the quality of prompts and respective images.","meta":{"distance":0.5023003817,"data_type":"evaluation"},"label":"hci","_input_hash":1275950074,"_task_hash":521637262,"_view_id":"classification","answer":"ignore","_timestamp":1704742926,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios.","meta":{"distance":0.5052344203,"data_type":"evaluation"},"label":"hci","_input_hash":-690116169,"_task_hash":-598593871,"_view_id":"classification","answer":"ignore","_timestamp":1704742947,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models.","meta":{"distance":0.5076978207,"data_type":"evaluation"},"label":"hci","_input_hash":268922109,"_task_hash":810243595,"_view_id":"classification","answer":"accept","_timestamp":1704742952,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
{"text":"To explore whether the capabilities of LLMs can be further enhanced for specific scenarios, we choose the writing-assistance scenario as the testbed, including seven writing tasks.","meta":{"distance":0.5079517365,"data_type":"evaluation"},"label":"hci","_input_hash":130978004,"_task_hash":1662800185,"_view_id":"classification","answer":"accept","_timestamp":1704742964,"_annotator_id":"2024-01-08_14-39-37","_session_id":"2024-01-08_14-39-37"}
