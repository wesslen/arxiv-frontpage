sections:
  # - name: Data Privacy in LLM Alignment
  #   instructions: >
  #     This label represents articles that explore challenges and considerations
  #     in maintaining privacy during the training and alignment of language
  #     models. It includes topics such as data anonymization, consent, and risks
  #     of data leakage. The focus is on how to protect data while effectively
  #     training language models.
  #   label: data-privacy-llm
  #   threshold: 0.7
  # - name: Ethical Considerations in LLM Safety
  #   instructions: >
  #     This label is for articles delving into the ethical implications of
  #     language model safety. It covers the responsible development and deployment
  #     of LLMs, focusing on fairness, accountability, transparency, and bias
  #     concerns. The goal is to highlight ethical challenges in LLM usage and
  #     management.
  #   label: ethical-llm-safety
  #   threshold: 0.7
  - name: Cybersecurity Challenges in LLM Development
    instructions: >
      This label pertains to articles discussing security risks in LLM
      development. Topics include adversarial attacks, data poisoning, model
      stealing, and strategies to mitigate these risks. The emphasis is on
      identifying and addressing security vulnerabilities in LLM systems.
    label: cybersecurity-llm
    threshold: 0.5
  # - name: Legal Frameworks for LLM Accountability
  #   instructions: >
  #     This label is used for articles examining legal and regulatory aspects of
  #     LLM accountability. It discusses liability for LLM-generated content,
  #     intellectual property issues, and government regulations in LLM
  #     development and usage. The focus is on legal structures surrounding LLMs.
  #   label: legal-llm-accountability
  #   threshold: 0.7
  # - name: Ensuring Fairness and Bias Mitigation in LLM Systems
  #   instructions: >
  #     This label applies to articles exploring fairness and bias mitigation in
  #     LLM systems. It covers dataset bias, algorithmic fairness, and the impacts
  #     of biased outputs. The goal is to discuss strategies for creating fair and
  #     unbiased LLM systems.
  #   label: fairness-bias-llm
  #   threshold: 0.7
  # - name: Robustness Tools in LLM Safety
  #   instructions: >
  #     This label designates articles focused on the robustness and safety
  #     testing of LLM systems. It examines challenges in robust LLM architectures
  #     and methodologies for evaluating performance and resilience against
  #     adversarial inputs. The focus is on ensuring LLM systems' robustness and
  #     safety. Examples include: guardrails, validation, safe-mode, adaptation.
  #   label: robustness-tools-llm
  #   threshold: 0.7
