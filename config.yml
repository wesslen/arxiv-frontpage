sections:
  - name: Prompt Engineering in Large Language Models
    instructions: >
      This label is for articles exploring different techniques in generating
      prompts for LLMs. It can cover different applications (e.g., prompt 
      engineering for legal or medical), general approaches like 
      chain-of-thought or ways to explore LLM's reasoning patterns.
    label: prompt-engineering
    threshold: 0.6
  - name: Robustness Tools in LLM Safety
    instructions: >
      This label designates articles focused on the robustness and safety
      testing of LLM systems. It examines challenges in robust LLM architectures
      and methodologies for evaluating performance and resilience against
      hallucinations or toxicity. The focus is on ensuring LLM systems' robustness
      and safety. Examples include: guardrails, validation, safe-mode, adaptation.
    label: robustness
    threshold: 0.6
  - name: Security Challenges in LLM Development
    instructions: >
      This label pertains to articles discussing security risks in LLM
      development. Topics include adversarial attacks, data poisoning, model
      stealing, and strategies to mitigate these risks. The emphasis is on
      identifying and addressing security vulnerabilities in LLM systems.
    label: security
    threshold: 0.58
  # - name: Legal Frameworks for LLM Accountability
  #   instructions: >
  #     This label is used for articles examining legal and regulatory aspects of
  #     LLM accountability. It discusses liability for LLM-generated content,
  #     intellectual property issues, and government regulations in LLM
  #     development and usage. The focus is on legal structures surrounding LLMs.
  #   label: legal
  #   threshold: 0.6
  - name: HCI in Large Language Models
    instructions: >
      This category encompasses research exploring the interaction between humans 
      and Large Language Models (LLMs). It includes studies on user experience, 
      interface design, and the accessibility of LLMs in various contexts. Papers 
      may cover topics like intuitive query design, effective response interpretation, 
      and the ergonomic integration of LLMs in everyday applications.
    label: hci
    threshold: 0.6
  - name: Large Language Models in Social Sciences
    instructions: >
      This label is for articles that explore the application of LLMs in social 
      sciences. Topics may include the use of LLMs in social research, understanding 
      social dynamics, and the impact of LLMs on societal issues like bias, 
      discrimination, and public opinion formation. Studies on ethical considerations 
      and social implications of LLM deployment are also pertinent.
    label: social-sciences
    threshold: 0.6
  - name: LLMs in Education Research
    instructions: >
      This label is dedicated to articles exploring the application of Large Language Models 
      (LLMs) in educational settings. Topics may include the use of LLMs in personalized 
      learning, curriculum development, student assessment, and teacher support. 
      Articles may also cover the ethical implications, effectiveness, and challenges 
      of integrating LLMs in education.
    label: education
    threshold: 0.6
  - name: LLMs as Recommender Systems
    instructions: >
      This category encompasses articles that investigate the use of LLMs in 
      recommender systems. It includes analysis of how LLMs enhance content 
      personalization, improve user engagement, and address challenges in 
      recommendation accuracy and bias. Discussions on algorithmic transparency 
      and user privacy in LLM-based recommender systems are also relevant.
    label: recommender
    threshold: 0.6
  # - name: Retriever Augmented Generation Systems
  #   instructions: >
  #     This label applies to articles studying Retriever Augmented Generation (RAG) 
  #     systems in LLMs. This includes exploring how RAG improves the accuracy and 
  #     relevance of information retrieval, enhances question-answering capabilities, 
  #     and impacts the efficiency of LLMs. Articles may also delve into the technical 
  #     implementation and challenges of integrating retriever mechanisms in LLMs.
  #   label: rag
  #   threshold: 0.6
  # - name: Open-source LLMs
  #   instructions: >
  #     This category is for articles focused on open-source Large Language Models. 
  #     Topics include the development, maintenance, and community engagement of 
  #     open-source LLMs. Discussions may also cover the challenges and benefits of 
  #     open-source models in terms of accessibility, collaboration, and innovation.
  #   label: open-source
  #   threshold: 0.6
  - name: Production workflows for LLMs
    instructions: >
      This label targets articles discussing the production workflows of Large 
      Language Models. This encompasses the entire lifecycle, from model design 
      and data preparation to training, deployment, and ongoing maintenance. 
      Emphasis may be placed on scalability, efficiency (quantization), data privacy,
      and best practices in operationalizing LLMs in various environments.
    label: production
    threshold: 0.6
  - name: LLM Model Architectures and Training Techniques
    instructions: >
      This label identifies articles that focus on the architectural designs and 
      training techniques of Large Language Models (LLMs). It covers a wide range 
      of topics including traditional and innovative LLM architectures like transformers, 
      their scaling laws, and specifics of model parallelism. Training techniques 
      such as Reinforcement Learning with Human Feedback (RLHF), instruction tuning, 
      and fine-tuning. Also relevant are discussions on data efficiency (e.g., distillation)
      in training, and approaches to improve computational efficiency and environmental 
      sustainability of LLMs.
    label: architectures
    threshold: 0.6
  - name: Programming applications of LLMs
    instructions: >
      This label is designated for articles that delve into the utilization of Large 
      Language Models (LLMs) in programming and software development. Topics of 
      interest include automated code generation, bug detection and correction, 
      code optimization, and the integration of LLMs into development environments. 
      Articles may also explore the impact of LLMs on developer productivity, the 
      evolution of programming paradigms, and the challenges and opportunities in 
      incorporating LLMs into the software development lifecycle.
    label: programming
    threshold: 0.64