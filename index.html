<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/@alpinejs/collapse@3.x.x/dist/cdn.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js"></script>
</head>
<body>
  <div class="relative mx-auto h-full max-w-2xl text-md">
    <table class="table-auto">
      <tbody>
        <tr>
          <td></td>
          <td>
            <h1 class="text-4xl pt-4 font-bold"><span class="underline">Ryan's</span> Arxiv FrontPage</h1>
            <br>
            <p>Generated on 2024-03-13.</p><br/>
            <p class="text-sm text-gray-500 pt-2">This frontpage is made by scraping arxiv and by running a sentence-model that detects if the abstract describes a paper about a topic of interest. One cool feature: it all pretty much runs via Github Actions. </p>
            <p class="text-sm text-gray-500 pt-2">This project was originally created by <a href="https://koaning.io/">Vincent Warmerdam</a>, modifying his original <a href="https://koaning.github.io/arxiv-frontpage/">frontpage</a> for different paper categories.</p>
            <br>
          </td>
        </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Prompt Engineering in Large Language Models</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align LLMs to human preferences.<span class='px-1 mx-1 bg-yellow-200'>In practice, multiple responses can exist for a given prompt with varying quality relative to each other. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.737</span></span><span class='px-1 mx-1 bg-yellow-200'>With availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.707</span></span>Our work focuses on systematically using the constructed multiple preference pair in DPO training via curriculum learning methodology.In particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria.We show detailed comparisons of our proposed approach to the standard single-pair DPO setting.Our method, which we call Curry-DPO consistently shows increased performance gains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set, highlighting its effectiveness.More specifically, Curry-DPO achieves a score of 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs with similar parameter size.Curry-DPO also achieves the highest adjusted win rates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and 87.9% respectively) in our experiments, with notable gains of upto 7.5% when compared to standard DPO technique.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07230v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07230v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Knowledge Graph Large Language Model (KG-LLM) for Link Prediction
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques.This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs.By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations.To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation.<span class='px-1 mx-1 bg-yellow-200'>Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.741</span></span>Our experimental findings discover that integrating ICL and CoT not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07311v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07311v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Process Modeling With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes.Traditional process modeling methods often require extensive expertise and can be time-consuming.This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users.We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions.<span class='px-1 mx-1 bg-yellow-200'>Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.664</span></span>Moreover, we instantiate a concrete system extending our framework.This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets.Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07541v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07541v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SIFiD: Reassess Summary Factual Inconsistency Detection with LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Ensuring factual consistency between the summary and the original document is paramount in summarization tasks.Consequently, considerable effort has been dedicated to detecting inconsistencies.<span class='px-1 mx-1 bg-yellow-200'>With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.603</span></span>However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology.In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4.To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07557v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07557v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Analyzing Adversarial Attacks on Sequence-to-Sequence Relevance Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Modern sequence-to-sequence relevance models like monoT5 can effectively capture complex textual interactions between queries and documents through cross-encoding.<span class='px-1 mx-1 bg-yellow-200'>However, the use of natural language tokens in prompts, such as Query, Document, and Relevant for monoT5, opens an attack vector for malicious documents to manipulate their relevance score through prompt injection, e.g., by adding target words such as true. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.723</span></span><span class='px-1 mx-1 bg-yellow-200'>Since such possibilities have not yet been considered in retrieval evaluation, we analyze the impact of query-independent prompt injection via manually constructed templates and LLM-based rewriting of documents on several existing relevance models. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.635</span></span>Our experiments on the TREC Deep Learning track show that adversarial documents can easily manipulate different sequence-to-sequence relevance models, while BM25 (as a typical lexical model) is not affected.<span class='px-1 mx-1 bg-yellow-200'>Remarkably, the attacks also affect encoder-only relevance models (which do not rely on natural language prompt tokens), albeit to a lesser extent. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.638</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07654v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07654v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration.<span class='px-1 mx-1 bg-yellow-200'>Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.6</span></span>It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance.In our approach we employ agents developed from large language models (LLM), each with distinct prototyping that considers behavioral elements, driven by strategies that stimulate the generation of knowledge based on the use case proposed in the scenario (role-play) business, using a discussion approach between agents (guided conversation).We demonstrate the potential of developing agents useful for organizational strategies, based on multi-agent system theories (SMA) and innovative uses based on large language models (LLM based), offering a differentiated and adaptable experiment to different applications, complexities, domains, and capabilities from LLM.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07769v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07769v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency.In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations.<span class='px-1 mx-1 bg-yellow-200'>To this end, we first present how to extract the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.722</span></span>Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency.We employ the actor-critic framework and modify the actor loss to regularize the policy learning towards the LLM-generated controller.RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL.We demonstrated that RLingua can significantly reduce the sample complexity of TD3 in the robot tasks of panda_gym and achieve high success rates in sparsely rewarded robot tasks in RLBench, where the standard TD3 fails.Additionally, We validated RLingua's effectiveness in real-world robot experiments through Sim2Real, demonstrating that the learned policies are effectively transferable to real robot tasks.Further details and videos about our work are available at our project website https://rlingua.github.io.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06420v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06420v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues.<span class='px-1 mx-1 bg-yellow-200'>The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.607</span></span>However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset.<span class='px-1 mx-1 bg-yellow-200'>To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.71</span></span>Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summarize the patterns indicating which types of users would be attracted by certain items.The retrieved collaborative evidence prompts the LLM to align its reasoning with the user-item interaction patterns in the dataset.However, since the capacity of the input prompt is limited, finding the minimally-sufficient collaborative information for recommendation tasks can be challenging.We propose to find the optimal interaction set through a sequential decision-making process and develop a retrieval policy learned through a reinforcement learning (RL) framework, CoRAL.Our experimental results show that CoRAL can significantly improve LLMs' reasoning abilities on specific recommendation tasks.Our analysis also reveals that CoRAL can more efficiently explore collaborative information through reinforcement learning.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06447v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06447v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.713</span></span>This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc.Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians.<span class='px-1 mx-1 bg-yellow-200'>This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.631</span></span><span class='px-1 mx-1 bg-yellow-200'>Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.62</span></span>However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians.In this study, we introduce a novel framework, In-Context Padding (ICP), designed to enhance LLMs with medical knowledge.<span class='px-1 mx-1 bg-yellow-200'>Specifically, we infer critical clinical reasoning elements (referred to as knowledge seeds) and use these as anchors to guide the generation process of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.622</span></span><span class='px-1 mx-1 bg-yellow-200'>Experiments on two clinical question datasets demonstrate that ICP significantly improves the clinical reasoning ability of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.632</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06609v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06609v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches.With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction.However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination.A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text.Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method.<span class='px-1 mx-1 bg-yellow-200'>In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.708</span></span>Experiments on public datasets and in-enterprise datasets validate the effectiveness of the proposed method.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06642v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06642v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Electrocardiograms (ECGs) are non-invasive diagnostic tools crucial for detecting cardiac arrhythmic diseases in clinical practice.While ECG Self-supervised Learning (eSSL) methods show promise in representation learning from unannotated ECG data, they often overlook the clinical knowledge that can be found in reports.This oversight and the requirement for annotated samples for downstream tasks limit eSSL's versatility.In this work, we address these issues with the Multimodal ECG Representation Learning (MERL}) framework.Through multimodal learning on ECG records and associated reports, MERL is capable of performing zero-shot ECG classification with text prompts, eliminating the need for training data in downstream tasks.<span class='px-1 mx-1 bg-yellow-200'>At test time, we propose the Clinical Knowledge Enhanced Prompt Engineering (CKEPE) approach, which uses Large Language Models (LLMs) to exploit external expert-verified clinical knowledge databases, generating more descriptive prompts and reducing hallucinations in LLM-generated content to boost zero-shot classification. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.821</span></span>Based on MERL, we perform the first benchmark across six public ECG datasets, showing the superior performance of MERL compared against eSSL methods.Notably, MERL achieves an average AUC score of 75.2% in zero-shot classification (without training data), 3.2% higher than linear probed eSSL methods with 10\% annotated training data, averaged across all six datasets.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06659v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06659v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language model (LLM) has achieved promising performance in multilingual machine translation tasks through zero/few-shot prompts or prompt-tuning.<span class='px-1 mx-1 bg-yellow-200'>However, due to the mixture of multilingual data during the pre-training of LLM, the LLM-based translation models face the off-target issue in both prompt-based methods, including a series of phenomena, namely instruction misunderstanding, translation with wrong language and over-generation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.709</span></span><span class='px-1 mx-1 bg-yellow-200'>For this issue, this paper introduces an \textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction \textbf{\underline{T}}urning mechanism for \textbf{\underline{M}}ultilingual \textbf{\underline{N}}eural \textbf{\underline{M}}achine \textbf{\underline{T}}ranslation (\model), which is a novel supervised fine-tuning mechanism and orthogonal to the traditional prompt-based methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.619</span></span>In this method, \model automatically constructs a constrained template in the target side by adding trigger tokens ahead of the ground truth.Furthermore, trigger tokens can be arranged and combined freely to represent different task semantics, and they can be iteratively updated to maximize the label likelihood.Experiments are performed on WMT test sets with multiple metrics, and the experimental results demonstrate that \model achieves substantially improved performance across multiple translation directions and reduce the off-target phenomena in the translation.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06745v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06745v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations).Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism.Existing solutions attempt to distill lengthy demonstrations into compact vectors.However, they often require task-specific retraining or compromise LLM's in-context learning performance.<span class='px-1 mx-1 bg-yellow-200'>To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.624</span></span>We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously.MEND is endowed with the meta-knowledge of distilling demonstrations through a two-stage training process, which includes meta-distillation pretraining and fine-tuning.Comprehensive evaluations across seven diverse ICL task partitions using decoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess.It not only matches but often outperforms the Vanilla ICL as well as other state-of-the-art distillation models, while significantly reducing the computational demands.This innovation promises enhanced scalability and efficiency for the practical deployment of large language models</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06914v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06914v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks.However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities.<span class='px-1 mx-1 bg-yellow-200'>These challenges arise from the presence of implicit relationships that demand multi-step reasoning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.6</span></span>In this paper, we propose a novel approach ERA-CoT, which aids LLMs in understanding context by capturing relationships between entities and supports the reasoning of diverse tasks through Chain-of-Thoughts (CoT).<span class='px-1 mx-1 bg-yellow-200'>Experimental results show that ERA-CoT demonstrates the superior performance of our proposed method compared to current CoT prompting methods, achieving a significant improvement of an average of 5.1\% on GPT3.5 compared to previous SOTA baselines. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.816</span></span>Our analysis indicates that ERA-CoT increases the LLM's understanding of entity relationships, significantly improves the accuracy of question answering, and enhances the reasoning ability of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06932v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06932v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Action Reimagined: Text-to-Pose Video Editing for Dynamic Human Actions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We introduce a novel text-to-pose video editing method, ReimaginedAct.While existing video editing tasks are limited to changes in attributes, backgrounds, and styles, our method aims to predict open-ended human action changes in video.<span class='px-1 mx-1 bg-yellow-200'>Moreover, our method can accept not only direct instructional text prompts but also `what if' questions to predict possible action changes. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.778</span></span>ReimaginedAct comprises video understanding, reasoning, and editing modules.First, an LLM is utilized initially to obtain a plausible answer for the instruction or question, which is then used for (1) prompting Grounded-SAM to produce bounding boxes of relevant individuals and (2) retrieving a set of pose videos that we have collected for editing human actions.The retrieved pose videos and the detected individuals are then utilized to alter the poses extracted from the original video.We also employ a timestep blending module to ensure the edited video retains its original content except where necessary modifications are needed.To facilitate research in text-to-pose video editing, we introduce a new evaluation dataset, WhatifVideo-1.0.This dataset includes videos of different scenarios spanning a range of difficulty levels, along with questions and text prompts.Experimental results demonstrate that existing video editing methods struggle with human action editing, while our approach can achieve effective action editing and even imaginary editing from counterfactual questions.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07198v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07198v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Reading, understanding and explaining code have traditionally been important skills for novices learning programming. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.764</span></span>As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code.<span class='px-1 mx-1 bg-yellow-200'>Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.687</span></span><span class='px-1 mx-1 bg-yellow-200'>Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.618</span></span><span class='px-1 mx-1 bg-yellow-200'>One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.688</span></span>However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake.In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation.<span class='px-1 mx-1 bg-yellow-200'>We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.803</span></span><span class='px-1 mx-1 bg-yellow-200'>We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.913</span></span><span class='px-1 mx-1 bg-yellow-200'>We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.652</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06050v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06050v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Automatically Score Proficiency of Written Essays?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness.Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks.In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays.We experimented with two popular LLMs, namely ChatGPT and Llama.We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait.<span class='px-1 mx-1 bg-yellow-200'>We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.837</span></span>Our experiments conducted on the ASAP dataset revealed several interesting observations.<span class='px-1 mx-1 bg-yellow-200'>First, choosing the right prompt depends highly on the model and nature of the task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.847</span></span>Second, the two LLMs exhibited comparable average performance in AES, with a slight advantage for ChatGPT.Finally, despite the performance gap between the two LLMs and SOTA models in terms of predictions, they provide feedback to enhance the quality of the essays, which can potentially help both teachers and students.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06149v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06149v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Are LLMs ready for Visualization?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Generative models have received a lot of attention in many areas of academia and the industry.Their capabilities span many areas, from the invention of images given a prompt to the generation of concrete code to solve a certain programming issue.These two paradigmatic cases fall within two distinct categories of requirements, ranging from "creativity" to "precision", as characterized by Bing Chat, which employs ChatGPT-4 as its backbone.Visualization practitioners and researchers have wondered to what end one of such systems could accomplish our work in a more efficient way.Several works in the literature have utilized them for the creation of visualizations.And some tools such as Lida, incorporate them as part of their pipeline.Nevertheless, to the authors' knowledge, no systematic approach for testing their capabilities has been published, which includes both extensive and in-depth evaluation.Our goal is to fill that gap with a systematic approach that analyzes three elements: whether Large Language Models are capable of correctly generating a large variety of charts, what libraries they can deal with effectively, and how far we can go to configure individual charts.To achieve this objective, we initially selected a diverse set of charts, which are commonly utilized in data visualization.<span class='px-1 mx-1 bg-yellow-200'>We then developed a set of generic prompts that could be used to generate them, and analyzed the performance of different LLMs and libraries. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.775</span></span>The results include both the set of prompts and the data sources, as well as an analysis of the performance with different configurations.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06158v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06158v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM's wide knowledge and text-understanding ability.Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples.Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent's overall performance in some sequential decision making tasks.However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context.In this paper, we propose a novel framework (TRAD) to address these issues.<span class='px-1 mx-1 bg-yellow-200'>TRAD first conducts Thought Retrieval, achieving step-level demonstration selection via thought matching, leading to more helpful demonstrations and less irrelevant input noise. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.711</span></span>Then, TRAD introduces Aligned Decision, complementing retrieved demonstration steps with their previous or subsequent steps, which enables tolerance for imperfect thought and provides a choice for balance between more context and less noise.Extensive experiments on ALFWorld and Mind2Web benchmarks show that TRAD not only outperforms state-of-the-art models but also effectively helps in reducing noise and promoting generalization.Furthermore, TRAD has been deployed in real-world scenarios of a global business insurance company and improves the success rate of robotic process automation.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06221v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06221v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.629</span></span>However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools.Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts.<span class='px-1 mx-1 bg-yellow-200'>In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.657</span></span>The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP.GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last.We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings.In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06254v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06254v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Developing an AI-Based Psychometric System for Assessing Learning Difficulties and Adaptive System to Overcome: A Qualitative and Conceptual Framework
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Learning difficulties pose significant challenges for students, impacting their academic performance and overall educational experience. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.66</span></span>These difficulties could sometimes put students into a downward spiral that lack of educational resources for personalized support consistently led to under-accommodation of students special needs, and the student lose opportunities in the longer term academic and work development.<span class='px-1 mx-1 bg-yellow-200'>This research aims to propose a conceptual framework for an adaptive AI-based virtual tutor system that incorporates psychometric assessment to support students with learning difficulties. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.665</span></span>This process involves the careful selection and integration of validated current mature psychometric scales that assess key dimensions of learning, such as cognitive abilities, learning styles, and academic skills.<span class='px-1 mx-1 bg-yellow-200'>By incorporating scales that specifically assess these difficulties, the psychometric test will provide a comprehensive understanding of each students unique learning profile and inform targeted interventions within the adaptive tutoring system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.612</span></span>The paper also proposes using autoencoders to identify the latent patterns to generate the students profile vector for collection of psychometric data, defining state space and action space representing the students desired combination of images, sound and text engagements, employing extended Bayesian knowledge tracing and hierarchical model and Metropolis-Hastings to continuously estimate and monitor the students performance in various psychometric constructs.The proposed system will leverage the capabilities of LLMs, visual generation models, and psychometric assessments to provide personalized instruction and support tailored to each students unique learning characteristics and needs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06284v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06284v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>There are two main barriers to using large language models (LLMs) in clinical reasoning.Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations.Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes.This leads to user distrust.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.637</span></span><span class='px-1 mx-1 bg-yellow-200'>ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.625</span></span>Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent arguments to support decision.<span class='px-1 mx-1 bg-yellow-200'>ArgMed-Agents enables LLMs to mimic the process of clinical argumentative reasoning by generating explanations of reasoning in a self-directed manner. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.752</span></span><span class='px-1 mx-1 bg-yellow-200'>The setup experiments show that ArgMed-Agents not only improves accuracy in complex clinical decision reasoning problems compared to other prompt methods, but more importantly, it provides users with decision explanations that increase their confidence. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.813</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06294v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06294v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Feedback-Generation for Programming Exercises With GPT-4
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education.<span class='px-1 mx-1 bg-yellow-200'>LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.695</span></span><span class='px-1 mx-1 bg-yellow-200'>This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.735</span></span><span class='px-1 mx-1 bg-yellow-200'>Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.728</span></span>The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material.Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements.For example, the output is more structured and consistent.GPT-4 Turbo can also accurately identify invalid casing in student programs' output.In some cases, the feedback also includes the output of the student program.At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed.The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04449v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04449v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks.In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task.Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world.To overcome this drawback, we construct and annotate a new more challenging dataset.In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells.<span class='px-1 mx-1 bg-yellow-200'>Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.793</span></span><span class='px-1 mx-1 bg-yellow-200'>We conduct experiments on prompting LLMs under various settings, where we use both random and similarity-based selection to choose the examples presented to the models. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.74</span></span>Our ablation study helps us gain insights into the impact of the few-shot examples.Additionally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed dataset.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04577v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04577v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Robustness Tools in LLM Safety</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Process Modeling With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes.Traditional process modeling methods often require extensive expertise and can be time-consuming.This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users.We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions.<span class='px-1 mx-1 bg-yellow-200'>Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.669</span></span>Moreover, we instantiate a concrete system extending our framework.This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets.Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07541v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07541v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Although large language models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by the untruthful context provided by users or knowledge argumentation tools, thereby producing hallucinations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.664</span></span>To alleviate the LLMs from being misled by untruthful information and take advantage of knowledge argumentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful context from the inputs.TACS begins by performing truth detection on the input context, leveraging the parameterized knowledge within the LLM.Subsequently, it constructs a corresponding attention mask based on the truthfulness of each position, selecting the truthful context and discarding the untruthful context.Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate, to further study the LLMs' ability to accept truthful information and resist untruthful information.Experimental results show that TACS can effectively filter information in context and significantly improve the overall quality of LLMs' responses when presented with misleading information.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07556v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07556v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space.<span class='px-1 mx-1 bg-yellow-200'>This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.679</span></span>This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing.Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect.Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods.However, our proposed methods, GORA and SORA, effectively identify and alleviate this issue, respectively, contributing to the advancement of LLM editing techniques.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07825v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07825v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring Safety Generalization Challenges of Large Language Models via Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse.While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains.This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs.<span class='px-1 mx-1 bg-yellow-200'>Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.677</span></span>Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages.These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07865v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07865v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency.In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations.To this end, we first present how to extract the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated.<span class='px-1 mx-1 bg-yellow-200'>Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.602</span></span>We employ the actor-critic framework and modify the actor loss to regularize the policy learning towards the LLM-generated controller.RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL.We demonstrated that RLingua can significantly reduce the sample complexity of TD3 in the robot tasks of panda_gym and achieve high success rates in sparsely rewarded robot tasks in RLBench, where the standard TD3 fails.Additionally, We validated RLingua's effectiveness in real-world robot experiments through Sim2Real, demonstrating that the learned policies are effectively transferable to real robot tasks.Further details and videos about our work are available at our project website https://rlingua.github.io.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06420v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06420v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.912</span></span><span class='px-1 mx-1 bg-yellow-200'>This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.953</span></span><span class='px-1 mx-1 bg-yellow-200'>Previous studies have mainly concentrated on post-processing techniques for hallucination detection, which tend to be computationally intensive and limited in effectiveness due to their separation from the LLM's inference process. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.833</span></span><span class='px-1 mx-1 bg-yellow-200'>To overcome these limitations, we introduce MIND, an unsupervised training framework that leverages the internal states of LLMs for real-time hallucination detection without requiring manual annotations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.807</span></span><span class='px-1 mx-1 bg-yellow-200'>Additionally, we present HELM, a new benchmark for evaluating hallucination detection across multiple LLMs, featuring diverse LLM outputs and the internal states of LLMs during their inference process. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.927</span></span><span class='px-1 mx-1 bg-yellow-200'>Our experiments demonstrate that MIND outperforms existing state-of-the-art methods in hallucination detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.864</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06448v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06448v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Due to the scale and complexity of cloud systems, a system failure would trigger an "alert storm", i.e., massive correlated alerts.<span class='px-1 mx-1 bg-yellow-200'>Although these alerts can be traced back to a few root causes, the overwhelming number makes it infeasible for manual handling. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.657</span></span>Alert aggregation is thus critical to help engineers concentrate on the root cause and facilitate failure resolution.Existing methods typically utilize semantic similarity-based methods or statistical methods to aggregate alerts.However, semantic similarity-based methods overlook the causal rationale of alerts, while statistical methods can hardly handle infrequent alerts.   To tackle these limitations, we introduce leveraging external knowledge, i.e., Standard Operation Procedure (SOP) of alerts as a supplement.We propose COLA, a novel hybrid approach based on correlation mining and LLM (Large Language Model) reasoning for online alert aggregation.The correlation mining module effectively captures the temporal and spatial relations between alerts, measuring their correlations in an efficient manner.Subsequently, only uncertain pairs with low confidence are forwarded to the LLM reasoning module for detailed analysis.This hybrid design harnesses both statistical evidence for frequent alerts and the reasoning capabilities of computationally intensive LLMs, ensuring the overall efficiency of COLA in handling large volumes of alerts in practical scenarios.We evaluate COLA on three datasets collected from the production environment of a large-scale cloud platform.The experimental results show COLA achieves F1-scores from 0.901 to 0.930, outperforming state-of-the-art methods and achieving comparable efficiency.We also share our experience in deploying COLA in our real-world cloud system, Cloud X.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06485v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06485v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients.This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc.Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians.This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches.Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning.<span class='px-1 mx-1 bg-yellow-200'>However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.763</span></span>In this study, we introduce a novel framework, In-Context Padding (ICP), designed to enhance LLMs with medical knowledge.Specifically, we infer critical clinical reasoning elements (referred to as knowledge seeds) and use these as anchors to guide the generation process of LLMs.Experiments on two clinical question datasets demonstrate that ICP significantly improves the clinical reasoning ability of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06609v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06609v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions.However, the application of LLMs in medical dialogue generation-a task more closely aligned with actual medical practice-has been less explored.This gap is attributed to the insufficient medical knowledge of LLMs, which leads to inaccuracies and hallucinated information in the generated medical responses.In this work, we introduce the Medical dialogue with Knowledge enhancement and clinical Pathway encoding (MedKP) framework, which integrates an external knowledge enhancement module through a medical knowledge graph and an internal clinical pathway encoding via medical entities and physician actions.<span class='px-1 mx-1 bg-yellow-200'>Evaluated with comprehensive metrics, our experiments on two large-scale, real-world online medical consultation datasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines and mitigates the incidence of hallucinations, achieving a new state-of-the-art. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.609</span></span>Extensive ablation studies further reveal the effectiveness of each component of MedKP.This enhancement advances the development of reliable, automated medical consultation responses using LLMs, thereby broadening the potential accessibility of precise and real-time medical assistance.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06611v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06611v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches.With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction.<span class='px-1 mx-1 bg-yellow-200'>However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.603</span></span>A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text.Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method.In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training.Experiments on public datasets and in-enterprise datasets validate the effectiveness of the proposed method.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06642v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06642v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Elephants Never Forget: Testing Language Models for Memorization of Tabular Data
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over.In this work, we address this concern for tabular data.Starting with simple qualitative tests for whether an LLM knows the names and values of features, we introduce a variety of different techniques to assess the degrees of contamination, including statistical tests for conditional distribution modeling and four tests that identify memorization.Our investigation reveals that LLMs are pre-trained on many popular tabular datasets.<span class='px-1 mx-1 bg-yellow-200'>This exposure can lead to invalid performance evaluation on downstream tasks because the LLMs have, in effect, been fit to the test set. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.722</span></span>Interestingly, we also identify a regime where the language model reproduces important statistics of the data, but fails to reproduce the dataset verbatim.On these datasets, although seen during training, good performance on downstream tasks might not be due to overfitting.Our findings underscore the need for ensuring data integrity in machine learning tasks with LLMs.To facilitate future research, we release an open-source tool that can perform various tests for memorization \url{https://github.com/interpretml/LLM-Tabular-Memorization-Checker}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06644v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06644v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                HILL: A Hallucination Identifier for Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.731</span></span><span class='px-1 mx-1 bg-yellow-200'>Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.896</span></span>To tackle the problem of overreliance, we propose HILL, the "Hallucination Identifier for Large Language Models".First, we identified design features for HILL with a Wizard of Oz approach with nine participants.Subsequently, we implemented HILL based on the identified design features and evaluated HILL's interface design by surveying 17 participants.<span class='px-1 mx-1 bg-yellow-200'>Further, we investigated HILL's functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.792</span></span><span class='px-1 mx-1 bg-yellow-200'>We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.844</span></span>With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06710v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06710v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Instruction-tuned Large Language Models (LLMs) have achieved breakthrough results, opening countless new possibilities for many practical applications.<span class='px-1 mx-1 bg-yellow-200'>However, LLMs lack elementary safety features that are established norms in other areas of computer science, such as the separation between instructions and data, causing them to malfunction or rendering them vulnerable to manipulation and interference by third parties e.g., via indirect prompt/command injection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.728</span></span>Even worse, so far, there is not even an established definition of what precisely such a separation would mean and how its violation could be tested.In this work, we aim to close this gap.We introduce a formal measure to quantify the phenomenon of instruction-data separation as well as an empirical variant of the measure that can be computed from a model`s black-box outputs.We also introduce a new dataset, SEP (Should it be Executed or Processed?), which allows estimating the measure, and we report results on several state-of-the-art open-source and closed LLMs.Finally, we quantitatively demonstrate that all evaluated LLMs fail to achieve a high amount of separation, according to our measure.The source code and SEP dataset are openly accessible at https://github.com/egozverev/Shold-It-Be-Executed-Or-Processed.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06833v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06833v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.615</span></span><span class='px-1 mx-1 bg-yellow-200'>While existing research has proposed multiple detection tools, the automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.601</span></span>Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of AC lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence.   Leveraging recent advancements in large language models (LLMs), we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX.The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality.To this end, ACFIX involves both offline and online phases.First, during the offline phase, ACFIX mines a tax- onomy of common Role-based Access Control (RBAC) practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 pairs mined.Second, during the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch.This patch will then undergo a validity and effectiveness check.To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them.This represents a significant improvement compared to the baseline GPT-4, which achieved only 52.54%.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06838v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06838v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>World models have demonstrated superiority in autonomous driving, particularly in the generation of multi-view driving videos.However, significant challenges still exist in generating customized driving videos.In this paper, we propose DriveDreamer-2, which builds upon the framework of DriveDreamer and incorporates a Large Language Model (LLM) to generate user-defined driving videos.Specifically, an LLM interface is initially incorporated to convert a user's query into agent trajectories.Subsequently, a HDMap, adhering to traffic regulations, is generated based on the trajectories.Ultimately, we propose the Unified Multi-View Model to enhance temporal and spatial coherence in the generated driving videos.DriveDreamer-2 is the first world model to generate customized driving videos, it can generate uncommon driving videos (e.g., vehicles abruptly cut in) in a user-friendly manner.Besides, experimental results demonstrate that the generated videos enhance the training of driving perception methods (e.g., 3D detection and tracking).<span class='px-1 mx-1 bg-yellow-200'>Furthermore, video generation quality of DriveDreamer-2 surpasses other state-of-the-art methods, showcasing FID and FVD scores of 11.2 and 55.7, representing relative improvements of 30% and 50%. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.625</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06845v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06845v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SPA: Towards A Computational Friendly Cloud-Base and On-Devices Collaboration Seq2seq Personalized Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models(LLMs) have shown its outperforming ability on various tasks and question answering.However, LLMs require high computation cost and large memory cost.<span class='px-1 mx-1 bg-yellow-200'>At the same time, LLMs may cause privacy leakage when training or prediction procedure contains sensitive information. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.669</span></span>In this paper, we propose SPA(Side Plugin Adaption), a lightweight architecture for fast on-devices inference and privacy retaining on the constraints of strict on-devices computation and memory constraints.Compared with other on-devices seq2seq generation, SPA could make a fast and stable inference on low-resource constraints, allowing it to obtain cost effiency.Our method establish an interaction between a pretrained LLMs on-cloud and additive parameters on-devices, which could provide the knowledge on both pretrained LLMs and private personal feature.Further more, SPA provides a framework to keep feature-base parameters on private guaranteed but low computational devices while leave the parameters containing general information on the high computational devices.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07088v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07088v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM).Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level.We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023.Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates.<span class='px-1 mx-1 bg-yellow-200'>The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.648</span></span>We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review.We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07183v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07183v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>There are two main barriers to using large language models (LLMs) in clinical reasoning.Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations.Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes.<span class='px-1 mx-1 bg-yellow-200'>This leads to user distrust. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.747</span></span>In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction.ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships.Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent arguments to support decision.ArgMed-Agents enables LLMs to mimic the process of clinical argumentative reasoning by generating explanations of reasoning in a self-directed manner.The setup experiments show that ArgMed-Agents not only improves accuracy in complex clinical decision reasoning problems compared to other prompt methods, but more importantly, it provides users with decision explanations that increase their confidence.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06294v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06294v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Reason and Plan?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.65</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04121v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04121v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring LLM-based Agents for Root Cause Analysis
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The growing complexity of cloud based software systems has resulted in incident management becoming an integral part of the software development lifecycle.Root cause analysis (RCA), a critical part of the incident management process, is a demanding task for on-call engineers, requiring deep domain knowledge and extensive experience with a team's specific services.Automation of RCA can result in significant savings of time, and ease the burden of incident management on on-call engineers.Recently, researchers have utilized Large Language Models (LLMs) to perform RCA, and have demonstrated promising results.<span class='px-1 mx-1 bg-yellow-200'>However, these approaches are not able to dynamically collect additional diagnostic information such as incident related logs, metrics or databases, severely restricting their ability to diagnose root causes. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.628</span></span>In this work, we explore the use of LLM based agents for RCA to address this limitation.We present a thorough empirical evaluation of a ReAct agent equipped with retrieval tools, on an out-of-distribution dataset of production incidents collected at Microsoft.Results show that ReAct performs competitively with strong retrieval and reasoning baselines, but with highly increased factual accuracy.We then extend this evaluation by incorporating discussions associated with incident reports as additional inputs for the models, which surprisingly does not yield significant performance improvements.Lastly, we conduct a case study with a team at Microsoft to equip the ReAct agent with tools that give it access to external diagnostic services that are used by the team for manual RCA.Our results show how agents can overcome the limitations of prior work, and practical considerations for implementing such a system in practice.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04123v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04123v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Hallucinations pose a significant challenge to the reliability of large language models (LLMs) in critical domains. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.843</span></span><span class='px-1 mx-1 bg-yellow-200'>Recent benchmarks designed to assess LLM hallucinations within conventional NLP tasks, such as knowledge-intensive question answering (QA) and summarization, are insufficient for capturing the complexities of user-LLM interactions in dynamic, real-world settings. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.756</span></span><span class='px-1 mx-1 bg-yellow-200'>To address this gap, we introduce HaluEval-Wild, the first benchmark specifically designed to evaluate LLM hallucinations in the wild. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.887</span></span>We meticulously collect challenging (adversarially filtered by Alpaca) user queries from existing real-world user-LLM interaction datasets, including ShareGPT, to evaluate the hallucination rates of various LLMs.<span class='px-1 mx-1 bg-yellow-200'>Upon analyzing the collected queries, we categorize them into five distinct types, which enables a fine-grained analysis of the types of hallucinations LLMs exhibit, and synthesize the reference answers with the powerful GPT-4 model and retrieval-augmented generation (RAG). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.786</span></span>Our benchmark offers a novel approach towards enhancing our comprehension and improvement of LLM reliability in scenarios reflective of real-world interactions.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04307v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04307v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Feedback-Generation for Programming Exercises With GPT-4
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education.LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale.This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input.Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions.The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material.Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements.For example, the output is more structured and consistent.<span class='px-1 mx-1 bg-yellow-200'>GPT-4 Turbo can also accurately identify invalid casing in student programs' output. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.624</span></span>In some cases, the feedback also includes the output of the student program.At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed.The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04449v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04449v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                QAQ: Quality Adaptive Quantization for LLM KV Cache
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP applications, particularly in domains such as question-answering systems and text generation.As the need for longer context grows, a significant bottleneck in model deployment emerges due to the linear expansion of the Key-Value (KV) cache with the context length.Existing methods primarily rely on various hypotheses, such as sorting the KV cache based on attention scores for replacement or eviction, to compress the KV cache and improve model throughput.<span class='px-1 mx-1 bg-yellow-200'>However, heuristics used by these strategies may wrongly evict essential KV cache, which can significantly degrade model performance. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.632</span></span>In this paper, we propose QAQ, a Quality Adaptive Quantization scheme for the KV cache.We theoretically demonstrate that key cache and value cache exhibit distinct sensitivities to quantization, leading to the formulation of separate quantization strategies for their non-uniform quantization.Through the integration of dedicated outlier handling, as well as an improved attention-aware approach, QAQ achieves up to 10x the compression ratio of the KV cache size with a neglectable impact on model performance.QAQ significantly reduces the practical hurdles of deploying LLMs, opening up new possibilities for longer-context applications.The code is available at github.com/ClubieDong/KVCacheQuantization.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04643v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04643v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.762</span></span><span class='px-1 mx-1 bg-yellow-200'>Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factual, making it extremely hard for the users to spot them. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.939</span></span><span class='px-1 mx-1 bg-yellow-200'>Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.691</span></span>Here, we aim to bridge this gap.<span class='px-1 mx-1 bg-yellow-200'>In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.611</span></span>Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output.Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what claim to generate on the current step and what surface form to use.Our method Claim Conditioned Probability (CCP) measures only the uncertainty of particular claim value expressed by the model.Experiments on the task of biography generation demonstrate strong improvements for CCP compared to the baselines for six different LLMs and three languages.Human evaluation reveals that the fact-checking pipeline based on uncertainty quantification is competitive with a fact-checking tool that leverages external knowledge.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04696v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04696v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments.Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools.However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained.<span class='px-1 mx-1 bg-yellow-200'>We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.639</span></span>We propose a biologically inspired method for tool-augmented LLMs, simulated trial and error (STE), that orchestrates three key mechanisms for successful tool use behaviors in the biological system: trial and error, imagination, and memory.Specifically, STE leverages an LLM's 'imagination' to simulate plausible scenarios for using a tool, after which the LLM interacts with the tool to learn from its execution feedback.Both short-term and long-term memory are employed to improve the depth and breadth of the exploration, respectively.Comprehensive experiments on ToolBench show that STE substantially improves tool learning for LLMs under both in-context learning and fine-tuning settings, bringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform GPT-4.We also show effective continual learning of tools via a simple experience replay strategy.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04746v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04746v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) are highly effective in various natural language processing (NLP) tasks.<span class='px-1 mx-1 bg-yellow-200'>However, they are susceptible to producing unreliable conjectures in ambiguous contexts called hallucination. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.781</span></span>This paper presents a new method for evaluating LLM hallucination in Question Answering (QA) based on the unanswerable math word problem (MWP).To support this approach, we innovatively develop a dataset called Unanswerable Math Word Problem (UMWP) which comprises 5200 questions across five categories.We developed an evaluation methodology combining text similarity and mathematical expression detection to determine whether LLM considers the question unanswerable.The results of extensive experiments conducted on 31 LLMs, including GPT-3, InstructGPT, LLaMA, and Claude, demonstrate that in-context learning and reinforcement learning with human feedback (RLHF) training significantly enhance the model's ability to avoid hallucination.<span class='px-1 mx-1 bg-yellow-200'>We show that utilizing MWP is a reliable and effective approach to assess hallucination. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.9</span></span>Our code and data are available at https://github.com/Yuki-Asuuna/UMWP.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03558v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03558v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks.Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document.<span class='px-1 mx-1 bg-yellow-200'>Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.88</span></span>However, these works primarily focus on English and recent multilingual approaches lack German data.<span class='px-1 mx-1 bg-yellow-200'>This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.685</span></span><span class='px-1 mx-1 bg-yellow-200'>We open-source and release the absinth dataset to foster further research on hallucination detection in German. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.862</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03750v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03750v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations.To address this critical need, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R) to measure LLMs' robustness to the user PPT task instruction and software version.Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels.To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings.Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs' API calls for task completion.We find that GPT-4 exhibits the highest performance and strong robustness in our benchmark, particularly in the version update and the multilingual settings.<span class='px-1 mx-1 bg-yellow-200'>However, we find that all LLMs lose their robustness when confronted with multiple challenges (e.g., multi-turn) simultaneously, leading to significant performance drops. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.64</span></span>We further analyze the robustness behavior and error reasons of LLMs in our benchmark, which provide valuable insights for researchers to understand the LLM's robustness in task completion and develop more robust LLMs and agents.We release the code and data at \url{https://github.com/ZekaiGalaxy/PPTCR}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03788v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03788v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>BusyBox, an open-source software bundling over 300 essential Linux commands into a single executable, is ubiquitous in Linux-based embedded devices.<span class='px-1 mx-1 bg-yellow-200'>Vulnerabilities in BusyBox can have far-reaching consequences, affecting a wide array of devices. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.612</span></span>This research, driven by the extensive use of BusyBox, delved into its analysis.The study revealed the prevalence of older BusyBox versions in real-world embedded products, prompting us to conduct fuzz testing on BusyBox.<span class='px-1 mx-1 bg-yellow-200'>Fuzzing, a pivotal software testing method, aims to induce crashes that are subsequently scrutinized to uncover vulnerabilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.616</span></span>Within this study, we introduce two techniques to fortify software testing.The first technique enhances fuzzing by leveraging Large Language Models (LLM) to generate target-specific initial seeds.<span class='px-1 mx-1 bg-yellow-200'>Our study showed a substantial increase in crashes when using LLM-generated initial seeds, highlighting the potential of LLM to efficiently tackle the typically labor-intensive task of generating target-specific initial seeds. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.651</span></span>The second technique involves repurposing previously acquired crash data from similar fuzzed targets before initiating fuzzing on a new target.This approach streamlines the time-consuming fuzz testing process by providing crash data directly to the new target before commencing fuzzing.<span class='px-1 mx-1 bg-yellow-200'>We successfully identified crashes in the latest BusyBox target without conducting traditional fuzzing, emphasizing the effectiveness of LLM and crash reuse techniques in enhancing software testing and improving vulnerability detection in embedded systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.655</span></span>Additionally, manual triaging was performed to identify the nature of crashes in the latest BusyBox.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03897v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03897v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Did Translation Models Get More Robust Without Anyone Even Noticing?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to "noisy" inputs, such as spelling errors, abbreviations, and other formatting issues.In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation.Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data.This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness.Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text.<span class='px-1 mx-1 bg-yellow-200'>We include an analysis of the circumstances in which source correction techniques can be used to mitigate the effects of noise. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.618</span></span>Altogether, we show that robustness to many types of noise has increased.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03923v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03923v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Security Challenges in LLM Development</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Process Modeling With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes.Traditional process modeling methods often require extensive expertise and can be time-consuming.This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users.We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions.<span class='px-1 mx-1 bg-yellow-200'>Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.64</span></span>Moreover, we instantiate a concrete system extending our framework.This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets.Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07541v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07541v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Analyzing Adversarial Attacks on Sequence-to-Sequence Relevance Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Modern sequence-to-sequence relevance models like monoT5 can effectively capture complex textual interactions between queries and documents through cross-encoding.<span class='px-1 mx-1 bg-yellow-200'>However, the use of natural language tokens in prompts, such as Query, Document, and Relevant for monoT5, opens an attack vector for malicious documents to manipulate their relevance score through prompt injection, e.g., by adding target words such as true. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.704</span></span>Since such possibilities have not yet been considered in retrieval evaluation, we analyze the impact of query-independent prompt injection via manually constructed templates and LLM-based rewriting of documents on several existing relevance models.Our experiments on the TREC Deep Learning track show that adversarial documents can easily manipulate different sequence-to-sequence relevance models, while BM25 (as a typical lexical model) is not affected.<span class='px-1 mx-1 bg-yellow-200'>Remarkably, the attacks also affect encoder-only relevance models (which do not rely on natural language prompt tokens), albeit to a lesser extent. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.697</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07654v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07654v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fine-tuning Large Language Models with Sequential Instructions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) struggle to follow a sequence of instructions in a single query as they may ignore or misinterpret part of it.This impairs their performance in complex problems whose solution requires multiple intermediate steps, such as multilingual (translate then answer) and multimodal (caption then answer) tasks.We empirically verify this with open-source LLMs as large as LLaMA-2 70B and Mixtral-8x7B. Targeting the scarcity of sequential instructions in present-day data, we propose sequential instruction tuning, a simple yet effective strategy to automatically augment instruction tuning data and equip LLMs with the ability to execute multiple sequential instructions.After exploring interleaving instructions in existing datasets, such as Alpaca, with a wide range of intermediate tasks, we find that sequential instruction-tuned models consistently outperform the conventional instruction-tuned baselines in downstream tasks involving reasoning, multilingual, and multimodal abilities.<span class='px-1 mx-1 bg-yellow-200'>To shed further light on our technique, we analyse how adversarial intermediate texts, unseen tasks, prompt verbalization, number of tasks, and prompt length affect SIT. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.798</span></span>We hope that this method will open new research avenues on instruction tuning for complex tasks.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07794v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07794v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring Safety Generalization Challenges of Large Language Models via Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse.While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains.<span class='px-1 mx-1 bg-yellow-200'>This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.796</span></span><span class='px-1 mx-1 bg-yellow-200'>Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.835</span></span><span class='px-1 mx-1 bg-yellow-200'>Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.712</span></span><span class='px-1 mx-1 bg-yellow-200'>These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.756</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07865v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07865v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Instruction-tuned Large Language Models (LLMs) have achieved breakthrough results, opening countless new possibilities for many practical applications.<span class='px-1 mx-1 bg-yellow-200'>However, LLMs lack elementary safety features that are established norms in other areas of computer science, such as the separation between instructions and data, causing them to malfunction or rendering them vulnerable to manipulation and interference by third parties e.g., via indirect prompt/command injection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.782</span></span>Even worse, so far, there is not even an established definition of what precisely such a separation would mean and how its violation could be tested.In this work, we aim to close this gap.We introduce a formal measure to quantify the phenomenon of instruction-data separation as well as an empirical variant of the measure that can be computed from a model`s black-box outputs.We also introduce a new dataset, SEP (Should it be Executed or Processed?), which allows estimating the measure, and we report results on several state-of-the-art open-source and closed LLMs.Finally, we quantitatively demonstrate that all evaluated LLMs fail to achieve a high amount of separation, according to our measure.The source code and SEP dataset are openly accessible at https://github.com/egozverev/Shold-It-Be-Executed-Or-Processed.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06833v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06833v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.79</span></span><span class='px-1 mx-1 bg-yellow-200'>While existing research has proposed multiple detection tools, the automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.744</span></span><span class='px-1 mx-1 bg-yellow-200'>Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of AC lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.684</span></span>Leveraging recent advancements in large language models (LLMs), we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX.The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality.To this end, ACFIX involves both offline and online phases.First, during the offline phase, ACFIX mines a tax- onomy of common Role-based Access Control (RBAC) practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 pairs mined.Second, during the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch.This patch will then undergo a validity and effectiveness check.To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them.This represents a significant improvement compared to the baseline GPT-4, which achieved only 52.54%.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06838v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06838v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Instruction tuning has proven essential for enhancing the performance of large language models (LLMs) in generating human-aligned responses.However, collecting diverse, high-quality instruction data for tuning poses challenges, particularly in privacy-sensitive domains.Federated instruction tuning (FedIT) has emerged as a solution, leveraging federated learning from multiple data owners while preserving privacy.<span class='px-1 mx-1 bg-yellow-200'>Yet, it faces challenges due to limited instruction data and vulnerabilities to training data extraction attacks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.657</span></span>To address these issues, we propose a novel federated algorithm, FedPIT, which utilizes LLMs' in-context learning capability to self-generate task-specific synthetic data for training autonomously.<span class='px-1 mx-1 bg-yellow-200'>Our method employs parameter-isolated training to maintain global parameters trained on synthetic data and local parameters trained on augmented local data, effectively thwarting data extraction attacks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.638</span></span>Extensive experiments on real-world medical data demonstrate the effectiveness of FedPIT in improving federated few-shot performance while preserving privacy and robustness against data heterogeneity.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06131v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06131v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-09</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) are susceptible to a variety of risks, from non-faithful output to biased and toxic generations.<span class='px-1 mx-1 bg-yellow-200'>Due to several limiting factors surrounding LLMs (training cost, API access, data availability, etc.), it may not always be feasible to impose direct safety constraints on a deployed model. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.645</span></span>Therefore, an efficient and reliable alternative is required.To this end, we present our ongoing efforts to create and deploy a library of detectors: compact and easy-to-build classification models that provide labels for various harms.In addition to the detectors themselves, we discuss a wide range of uses for these detector models - from acting as guardrails to enabling effective AI governance.We also deep dive into inherent challenges in their development and discuss future work aimed at making the detectors more reliable and broadening their scope.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06009v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06009v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations.To address this critical need, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R) to measure LLMs' robustness to the user PPT task instruction and software version.<span class='px-1 mx-1 bg-yellow-200'>Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.866</span></span>To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings.Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs' API calls for task completion.We find that GPT-4 exhibits the highest performance and strong robustness in our benchmark, particularly in the version update and the multilingual settings.However, we find that all LLMs lose their robustness when confronted with multiple challenges (e.g., multi-turn) simultaneously, leading to significant performance drops.We further analyze the robustness behavior and error reasons of LLMs in our benchmark, which provide valuable insights for researchers to understand the LLM's robustness in task completion and develop more robust LLMs and agents.We release the code and data at \url{https://github.com/ZekaiGalaxy/PPTCR}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03788v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03788v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>BusyBox, an open-source software bundling over 300 essential Linux commands into a single executable, is ubiquitous in Linux-based embedded devices.Vulnerabilities in BusyBox can have far-reaching consequences, affecting a wide array of devices.This research, driven by the extensive use of BusyBox, delved into its analysis.The study revealed the prevalence of older BusyBox versions in real-world embedded products, prompting us to conduct fuzz testing on BusyBox.<span class='px-1 mx-1 bg-yellow-200'>Fuzzing, a pivotal software testing method, aims to induce crashes that are subsequently scrutinized to uncover vulnerabilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.738</span></span>Within this study, we introduce two techniques to fortify software testing.The first technique enhances fuzzing by leveraging Large Language Models (LLM) to generate target-specific initial seeds.Our study showed a substantial increase in crashes when using LLM-generated initial seeds, highlighting the potential of LLM to efficiently tackle the typically labor-intensive task of generating target-specific initial seeds.The second technique involves repurposing previously acquired crash data from similar fuzzed targets before initiating fuzzing on a new target.This approach streamlines the time-consuming fuzz testing process by providing crash data directly to the new target before commencing fuzzing.<span class='px-1 mx-1 bg-yellow-200'>We successfully identified crashes in the latest BusyBox target without conducting traditional fuzzing, emphasizing the effectiveness of LLM and crash reuse techniques in enhancing software testing and improving vulnerability detection in embedded systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.683</span></span>Additionally, manual triaging was performed to identify the nature of crashes in the latest BusyBox.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03897v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03897v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites).<span class='px-1 mx-1 bg-yellow-200'>However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.725</span></span><span class='px-1 mx-1 bg-yellow-200'>Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.737</span></span><span class='px-1 mx-1 bg-yellow-200'>In this work, we introduce InjecAgent, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.794</span></span><span class='px-1 mx-1 bg-yellow-200'>InjecAgent comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.662</span></span><span class='px-1 mx-1 bg-yellow-200'>We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.776</span></span><span class='px-1 mx-1 bg-yellow-200'>We evaluate 30 different LLM agents and show that agents are vulnerable to IPI attacks, with ReAct-prompted GPT-4 vulnerable to attacks 24% of the time. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.746</span></span><span class='px-1 mx-1 bg-yellow-200'>Further investigation into an enhanced setting, where the attacker instructions are reinforced with a hacking prompt, shows additional increases in success rates, nearly doubling the attack success rate on the ReAct-prompted GPT-4. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.746</span></span>Our findings raise questions about the widespread deployment of LLM Agents.Our benchmark is available at https://github.com/uiuc-kang-lab/InjecAgent.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02691v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02691v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), with a focus on the issues of incomplete and corrupted data in preference datasets.We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs resilience against the issues.In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it.To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an {\epsilon}-optimal ranking with high probability while allowing as large as O(n) perturbed pairwise comparison results per model response.Furthermore, we show robust recovery results in the partially observed setting.<span class='px-1 mx-1 bg-yellow-200'>Our experiments confirm that our algorithms handle adversarial noise and unobserved comparisons well in both general and LLM preference dataset settings. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.674</span></span>This work contributes to the development and scaling of more reliable and ethically aligned AI models by equipping the dataset curation pipeline with the ability to handle missing and maliciously manipulated inputs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02745v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02745v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ImgTrojan: Jailbreaking Vision-Language Models with ONE Image
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>There has been an increasing interest in the alignment of large language models (LLMs) with human values.However, the safety issues of their integration with a vision module, or vision language models (VLMs), remain relatively underexplored.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a novel jailbreaking attack against VLMs, aiming to bypass their safety barrier when a user inputs harmful instructions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.891</span></span>A scenario where our poisoned (image, text) data pairs are included in the training data is assumed.<span class='px-1 mx-1 bg-yellow-200'>By replacing the original textual captions with malicious jailbreak prompts, our method can perform jailbreak attacks with the poisoned images. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.799</span></span><span class='px-1 mx-1 bg-yellow-200'>Moreover, we analyze the effect of poison ratios and positions of trainable parameters on our attack's success rate. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.716</span></span><span class='px-1 mx-1 bg-yellow-200'>For evaluation, we design two metrics to quantify the success rate and the stealthiness of our attack. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.711</span></span><span class='px-1 mx-1 bg-yellow-200'>Together with a list of curated harmful instructions, a benchmark for measuring attack efficacy is provided. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.844</span></span><span class='px-1 mx-1 bg-yellow-200'>We demonstrate the efficacy of our attack by comparing it with baseline methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.772</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02910v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02910v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.671</span></span><span class='px-1 mx-1 bg-yellow-200'>To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.735</span></span>However, current evaluations are private, preventing further research into mitigating risk.Furthermore, they focus on only a few, highly specific pathways for malicious use.To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security.WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release.WMDP serves two roles: first, as an evaluation for hazardous knowledge in LLMs, and second, as a benchmark for unlearning methods to remove such hazardous knowledge.To guide progress on unlearning, we develop CUT, a state-of-the-art unlearning method based on controlling model representations.CUT reduces model performance on WMDP while maintaining general capabilities in areas such as biology and computer science, suggesting that unlearning may be a concrete path towards reducing malicious use from LLMs.We release our benchmark and code publicly at https://wmdp.ai</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03218v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03218v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Unveiling Hidden Links Between Unseen Security Entities
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The proliferation of software vulnerabilities poses a significant challenge for security databases and analysts tasked with their timely identification, classification, and remediation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.75</span></span><span class='px-1 mx-1 bg-yellow-200'>With the National Vulnerability Database (NVD) reporting an ever-increasing number of vulnerabilities, the traditional manual analysis becomes untenably time-consuming and prone to errors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.635</span></span><span class='px-1 mx-1 bg-yellow-200'>This paper introduces VulnScopper, an innovative approach that utilizes multi-modal representation learning, combining Knowledge Graphs (KG) and Natural Language Processing (NLP), to automate and enhance the analysis of software vulnerabilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.749</span></span>Leveraging ULTRA, a knowledge graph foundation model, combined with a Large Language Model (LLM), VulnScopper effectively handles unseen entities, overcoming the limitations of previous KG approaches.<span class='px-1 mx-1 bg-yellow-200'>We evaluate VulnScopper on two major security datasets, the NVD and the Red Hat CVE database. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.72</span></span><span class='px-1 mx-1 bg-yellow-200'>Our method significantly improves the link prediction accuracy between Common Vulnerabilities and Exposures (CVEs), Common Weakness Enumeration (CWEs), and Common Platform Enumerations (CPEs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.607</span></span>Our results show that VulnScopper outperforms existing methods, achieving up to 78% Hits@10 accuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement over large language models in predicting CWE labels based on the Red Hat database.Based on the NVD, only 6.37% of the linked CPEs are being published during the first 30 days; many of them are related to critical and high-risk vulnerabilities which, according to multiple compliance frameworks (such as CISA and PCI), should be remediated within 15-30 days.<span class='px-1 mx-1 bg-yellow-200'>Our model can uncover new products linked to vulnerabilities, reducing remediation time and improving vulnerability management. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.68</span></span>We analyzed several CVEs from 2023 to showcase this ability.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02014v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02014v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.621</span></span>Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach.However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base.To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand.KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner.A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML.To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text.Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos.We evaluate KnowPhish and KPD on a manually validated dataset, and on a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02253v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02253v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Enhancing LLM Safety via Constrained Direct Preference Optimization
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rapidly increasing capabilities of large language models (LLMs) raise an urgent need to align AI systems with diverse human preferences to simultaneously enhance their usefulness and safety, despite the often conflicting nature of these goals.To address this important problem, a promising approach is to enforce a safety constraint at the fine-tuning stage through a constrained Reinforcement Learning from Human Feedback (RLHF) framework.This approach, however, is computationally expensive and often unstable.In this work, we introduce Constrained DPO (C-DPO), a novel extension of the recently proposed Direct Preference Optimization (DPO) approach for fine-tuning LLMs that is both efficient and lightweight.<span class='px-1 mx-1 bg-yellow-200'>By integrating dual gradient descent and DPO, our method identifies a nearly optimal trade-off between helpfulness and harmlessness without using reinforcement learning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.636</span></span><span class='px-1 mx-1 bg-yellow-200'>Empirically, our approach provides a safety guarantee to LLMs that is missing in DPO while achieving significantly higher rewards under the same safety constraint compared to a recently proposed safe RLHF approach.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.608</span></span>Warning:This paper contains example data that may be offensive or harmful.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02475v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02475v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Balancing Enhancement, Harmlessness, and General Capabilities: Enhancing Conversational LLMs with Direct RLHF
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In recent advancements in Conversational Large Language Models (LLMs), a concerning trend has emerged, showing that many new base LLMs experience a knowledge reduction in their foundational capabilities following Supervised Fine-Tuning (SFT).This process often leads to issues such as forgetting or a decrease in the base model's abilities.<span class='px-1 mx-1 bg-yellow-200'>Moreover, fine-tuned models struggle to align with user preferences, inadvertently increasing the generation of toxic outputs when specifically prompted. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.635</span></span>To overcome these challenges, we adopted an innovative approach by completely bypassing SFT and directly implementing Harmless Reinforcement Learning from Human Feedback (RLHF).Our method not only preserves the base model's general capabilities but also significantly enhances its conversational abilities, while notably reducing the generation of toxic outputs.Our approach holds significant implications for fields that demand a nuanced understanding and generation of responses, such as customer service.We applied this methodology to Mistral, the most popular base model, thereby creating Mistral-Plus.Our validation across 11 general tasks demonstrates that Mistral-Plus outperforms similarly sized open-source base models and their corresponding instruct versions.Importantly, the conversational abilities of Mistral-Plus were significantly improved, indicating a substantial advancement over traditional SFT models in both safety and user preference alignment.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02513v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02513v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-03</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Using LLMs for Tabletop Exercises within the Security Domain
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Tabletop exercises are a crucial component of many company's strategy to test and evaluate its preparedness for security incidents in a realistic way.Traditionally led by external firms specializing in cybersecurity, these exercises can be costly, time-consuming, and may not always align precisely with the client's specific needs.Large Language Models (LLMs) like ChatGPT offer a compelling alternative.They enable faster iteration, provide rich and adaptable simulations, and offer infinite patience in handling feedback and recommendations.<span class='px-1 mx-1 bg-yellow-200'>This approach can enhances the efficiency and relevance of security preparedness exercises. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.659</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.01626v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.01626v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks.However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning.One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly.This motivates us to evaluate the robustness of LLMs' math reasoning capability by testing a wide range of question variations.<span class='px-1 mx-1 bg-yellow-200'>We introduce the adversarial grade school math (\datasetname) dataset, an extension of GSM8K augmented with various mathematical perturbations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.701</span></span>Our experiments on 25 LLMs and 4 prompting techniques show that while LLMs exhibit different levels of math reasoning abilities, their performances are far from robust.In particular, even for problems that have been solved in GSM8K, LLMs can make mistakes when new statements are added or the question targets are altered.We also explore whether more robust performance can be achieved by composing existing prompting methods, in which we try an iterative method that generates and verifies each intermediate thought based on its reasoning goal and calculation result.Code and data are available at \url{https://github.com/qtli/GSM-Plus}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.19255v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.19255v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Watermark Stealing in Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment.<span class='px-1 mx-1 bg-yellow-200'>In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.726</span></span><span class='px-1 mx-1 bg-yellow-200'>We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.863</span></span>We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings.<span class='px-1 mx-1 bg-yellow-200'>We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.908</span></span>Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes.We make all our code and additional examples available at https://watermark-stealing.org.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.19361v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.19361v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Curiosity-driven Red-teaming for Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content.To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs.However, relying solely on human testers is expensive and time-consuming.Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM.However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM.To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty.Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods.<span class='px-1 mx-1 bg-yellow-200'>Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.602</span></span>Code is available at \url{https://github.com/Improbable-AI/curiosity_redteam}</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.19464v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.19464v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">HCI in Large Language Models</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CKERC : Joint Large Language Models with Commonsense Knowledge for Emotion Recognition in Conversation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Emotion recognition in conversation (ERC) is a task which predicts the emotion of an utterance in the context of a conversation.It tightly depends on dialogue context, speaker identity information, multiparty dialogue scenario and so on.However, the state-of-the-art method (instructERC) solely identifying speaker, and ignores commonsense knowledge(i.e., reaction of the listeners and intention of the speaker, etc.)behind speakers during a conversation, which can deeply mine speaker information.<span class='px-1 mx-1 bg-yellow-200'>To this end, we propose a novel joint large language models with commonsense knowledge framework for emotion recognition in conversation, namely CKERC.We design prompts to generate interlocutors' commonsense based on historical utterances with large language model. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.658</span></span>And we use the interlocutor commonsense identification task for LLM pre-training to fine-tune speaker implicit clues information.By solving above challenge, our method achieve state-of-the-art.We extensive experiment on three widely-used datasets, i.e., IEMOCAP, MELD, EmoryNLP, demonstrate our method superiority.Also, we conduct in-depth analysis and further demonstrate the effectiveness of commonsense knowledge in ERC task in large language model.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07260v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07260v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Knowledge Graph Large Language Model (KG-LLM) for Link Prediction
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques.<span class='px-1 mx-1 bg-yellow-200'>This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.675</span></span>By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations.To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation.Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts.Our experimental findings discover that integrating ICL and CoT not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07311v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07311v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Process Modeling With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes.Traditional process modeling methods often require extensive expertise and can be time-consuming.<span class='px-1 mx-1 bg-yellow-200'>This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.618</span></span>We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions.Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism.Moreover, we instantiate a concrete system extending our framework.This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets.Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07541v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07541v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Personality detection aims to detect one's personality traits underlying in social media posts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.614</span></span><span class='px-1 mx-1 bg-yellow-200'>One challenge of this task is the scarcity of ground-truth personality traits which are collected from self-report questionnaires. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.627</span></span>Most existing methods learn post features directly by fine-tuning the pre-trained language models under the supervision of limited personality labels.This leads to inferior quality of post features and consequently affects the performance.In addition, they treat personality traits as one-hot classification labels, overlooking the semantic information within them.In this paper, we propose a large language model (LLM) based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection, even when the LLM fails in this task.<span class='px-1 mx-1 bg-yellow-200'>Specifically, we enable LLM to generate post analyses (augmentations) from the aspects of semantic, sentiment, and linguistic, which are critical for personality detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.633</span></span>By using contrastive learning to pull them together in the embedding space, the post encoder can better capture the psycho-linguistic information within the post representations, thus improving personality detection.Furthermore, we utilize the LLM to enrich the information of personality labels for enhancing the detection performance.Experimental results on the benchmark datasets demonstrate that our model outperforms the state-of-the-art methods on personality detection.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07581v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07581v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.822</span></span>Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving.It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance.<span class='px-1 mx-1 bg-yellow-200'>In our approach we employ agents developed from large language models (LLM), each with distinct prototyping that considers behavioral elements, driven by strategies that stimulate the generation of knowledge based on the use case proposed in the scenario (role-play) business, using a discussion approach between agents (guided conversation). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.806</span></span><span class='px-1 mx-1 bg-yellow-200'>We demonstrate the potential of developing agents useful for organizational strategies, based on multi-agent system theories (SMA) and innovative uses based on large language models (LLM based), offering a differentiated and adaptable experiment to different applications, complexities, domains, and capabilities from LLM. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.627</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07769v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07769v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues.<span class='px-1 mx-1 bg-yellow-200'>The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.679</span></span>However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset.To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts.Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summarize the patterns indicating which types of users would be attracted by certain items.The retrieved collaborative evidence prompts the LLM to align its reasoning with the user-item interaction patterns in the dataset.However, since the capacity of the input prompt is limited, finding the minimally-sufficient collaborative information for recommendation tasks can be challenging.We propose to find the optimal interaction set through a sequential decision-making process and develop a retrieval policy learned through a reinforcement learning (RL) framework, CoRAL.Our experimental results show that CoRAL can significantly improve LLMs' reasoning abilities on specific recommendation tasks.Our analysis also reveals that CoRAL can more efficiently explore collaborative information through reinforcement learning.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06447v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06447v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models.However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training.Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers.Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise.Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human activities.<span class='px-1 mx-1 bg-yellow-200'>In this work, we propose ContextGPT: a novel prompt engineering approach to retrieve from LLMs common-sense knowledge about the relationship between human activities and the context in which they are performed. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.72</span></span>Unlike ontologies, ContextGPT requires limited human effort and expertise.An extensive evaluation carried out on two public datasets shows how a NeSy model obtained by infusing common-sense knowledge from ContextGPT is effective in data scarcity scenarios, leading to similar (and sometimes better) recognition rates than logic-based approaches with a fraction of the effort.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06586v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06586v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Academically intelligent LLMs are not necessarily socially intelligent
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The academic intelligence of large language models (LLMs) has made remarkable progress in recent times, but their social intelligence performance remains unclear.Inspired by established human social intelligence frameworks, particularly Daniel Goleman's social intelligence theory, we have developed a standardized social intelligence test based on real-world social scenarios to comprehensively assess the social intelligence of LLMs, termed as the Situational Evaluation of Social Intelligence (SESI).We conducted an extensive evaluation with 13 recent popular and state-of-art LLM agents on SESI.The results indicate the social intelligence of LLMs still has significant room for improvement, with superficially friendliness as a primary reason for errors.<span class='px-1 mx-1 bg-yellow-200'>Moreover, there exists a relatively low correlation between the social intelligence and academic intelligence exhibited by LLMs, suggesting that social intelligence is distinct from academic intelligence for LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.636</span></span><span class='px-1 mx-1 bg-yellow-200'>Additionally, while it is observed that LLMs can't ``understand'' what social intelligence is, their social intelligence, similar to that of humans, is influenced by social factors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.826</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06591v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06591v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Decoding Complexity: Exploring Human-AI Concordance in Qualitative Coding
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Qualitative data analysis provides insight into the underlying perceptions and experiences within unstructured data.However, the time-consuming nature of the coding process, especially for larger datasets, calls for innovative approaches, such as the integration of Large Language Models (LLMs).This short paper presents initial findings from a study investigating the integration of LLMs for coding tasks of varying complexity in a real-world dataset.Our results highlight the challenges inherent in coding with extensive codebooks and contexts, both for human coders and LLMs, and suggest that the integration of LLMs into the coding process requires a task-by-task evaluation.<span class='px-1 mx-1 bg-yellow-200'>We examine factors influencing the complexity of coding tasks and initiate a discussion on the usefulness and limitations of incorporating LLMs in qualitative research. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.769</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06607v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06607v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients.This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc.Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians.This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches.<span class='px-1 mx-1 bg-yellow-200'>Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.696</span></span>However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians.In this study, we introduce a novel framework, In-Context Padding (ICP), designed to enhance LLMs with medical knowledge.Specifically, we infer critical clinical reasoning elements (referred to as knowledge seeds) and use these as anchors to guide the generation process of LLMs.Experiments on two clinical question datasets demonstrate that ICP significantly improves the clinical reasoning ability of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06609v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06609v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                FashionReGen: LLM-Empowered Fashion Report Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Fashion analysis refers to the process of examining and evaluating trends, styles, and elements within the fashion industry to understand and interpret its current state, generating fashion reports. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.643</span></span>It is traditionally performed by fashion professionals based on their expertise and experience, which requires high labour cost and may also produce biased results for relying heavily on a small group of people.<span class='px-1 mx-1 bg-yellow-200'>In this paper, to tackle the Fashion Report Generation (FashionReGen) task, we propose an intelligent Fashion Analyzing and Reporting system based the advanced Large Language Models (LLMs), debbed as GPT-FAR. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.603</span></span>Specifically, it tries to deliver FashionReGen based on effective catwalk analysis, which is equipped with several key procedures, namely, catwalk understanding, collective organization and analysis, and report generation.By posing and exploring such an open-ended, complex and domain-specific task of FashionReGen, it is able to test the general capability of LLMs in fashion domain.It also inspires the explorations of more high-level tasks with industrial significance in other domains.Video illustration and more materials of GPT-FAR can be found in https://github.com/CompFashion/FashionReGen.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06660v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06660v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The internet has brought both benefits and harms to society.A prime example of the latter is misinformation, including conspiracy theories, which flood the web.Recent advances in natural language processing, particularly the emergence of large language models (LLMs), have improved the prospects of accurate misinformation detection.However, most LLM-based approaches to conspiracy theory detection focus only on binary classification and fail to account for the important relationship between misinformation and affective features (i.e., sentiment and emotions).Driven by a comprehensive analysis of conspiracy text that reveals its distinctive affective features, we propose ConspEmoLLM, the first open-source LLM that integrates affective information and is able to perform diverse tasks relating to conspiracy theories.These tasks include not only conspiracy theory detection, but also classification of theory type and detection of related discussion (e.g., opinions towards theories).<span class='px-1 mx-1 bg-yellow-200'>ConspEmoLLM is fine-tuned based on an emotion-oriented LLM using our novel ConDID dataset, which includes five tasks to support LLM instruction tuning and evaluation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.616</span></span>We demonstrate that when applied to these tasks, ConspEmoLLM largely outperforms several open-source general domain LLMs and ChatGPT, as well as an LLM that has been fine-tuned using ConDID, but which does not use affective features.This project will be released on https://github.com/lzw108/ConspEmoLLM/.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06765v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06765v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks.<span class='px-1 mx-1 bg-yellow-200'>However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.606</span></span>These challenges arise from the presence of implicit relationships that demand multi-step reasoning.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a novel approach ERA-CoT, which aids LLMs in understanding context by capturing relationships between entities and supports the reasoning of diverse tasks through Chain-of-Thoughts (CoT). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.602</span></span>Experimental results show that ERA-CoT demonstrates the superior performance of our proposed method compared to current CoT prompting methods, achieving a significant improvement of an average of 5.1\% on GPT3.5 compared to previous SOTA baselines.Our analysis indicates that ERA-CoT increases the LLM's understanding of entity relationships, significantly improves the accuracy of question answering, and enhances the reasoning ability of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06932v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06932v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM).Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level.We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023.Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates.The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals.We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review.<span class='px-1 mx-1 bg-yellow-200'>We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.677</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07183v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07183v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.624</span></span>Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost.Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance.Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs.Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models.While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend in model performances as the model is iteratively finetuned, leading to less accurate predictions and suboptimal model selections.   In this paper, we propose a time-increasing bandit algorithm TI-UCB, which effectively predicts the increase of model performances due to finetuning and efficiently balances exploration and exploitation in model selection.To further capture the converging points of models, we develop a change detection mechanism by comparing consecutive increase predictions.We theoretically prove that our algorithm achieves a logarithmic regret upper bound in a typical increasing bandit setting, which implies a fast convergence rate.The advantage of our method is also empirically validated through extensive experiments on classification model selection and online selection of LLMs.Our results highlight the importance of utilizing increasing-then-converging pattern for more efficient and economic model selection in the deployment of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07213v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07213v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Simulating Family Conversations using LLMs: Demonstration of Parenting Styles
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>This study presents a framework for conducting psychological and linguistic research through simulated conversations using large language models (LLMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.947</span></span>The proposed methodology offers significant advantages, particularly for simulating human interactions involving potential unethical language or behaviors that would be impermissible in traditional experiments with human participants.<span class='px-1 mx-1 bg-yellow-200'>As a demonstration, we employed LLMs to simulate family conversations across four parenting styles (authoritarian, authoritative, permissive, and uninvolved). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.788</span></span><span class='px-1 mx-1 bg-yellow-200'>In general, we observed that the characteristics of the four parenting styles were portrayed in the simulated conversations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.892</span></span>Several strategies could be used to improve the simulation quality, such as including context awareness, employing a few-shot prompting approach or fine-tuning models to cater to specific simulation requirements.<span class='px-1 mx-1 bg-yellow-200'>Overall, this study introduces a promising methodology for conducting psychological and linguistic research through simulated conversations, while acknowledging the current limitations and proposing potential solutions for future refinement and improvement. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.933</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06144v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06144v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Automatically Score Proficiency of Written Essays?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness.Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks.In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays.<span class='px-1 mx-1 bg-yellow-200'>We experimented with two popular LLMs, namely ChatGPT and Llama. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.732</span></span>We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait.We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task.Our experiments conducted on the ASAP dataset revealed several interesting observations.First, choosing the right prompt depends highly on the model and nature of the task.Second, the two LLMs exhibited comparable average performance in AES, with a slight advantage for ChatGPT.Finally, despite the performance gap between the two LLMs and SOTA models in terms of predictions, they provide feedback to enhance the quality of the essays, which can potentially help both teachers and students.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06149v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06149v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-09</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs).Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process.<span class='px-1 mx-1 bg-yellow-200'>This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.749</span></span>Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06039v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06039v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Conversational systems often rely on embedding models for intent classification and intent clustering tasks.<span class='px-1 mx-1 bg-yellow-200'>The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for these downstream conversational tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.603</span></span>However, traditional evaluation benchmarks rely solely on task metrics that don't particularly measure gaps related to semantic understanding.Thus, we propose an intent semantic toolkit that gives a more holistic view of intent embedding models by considering three tasks-- (1) intent classification, (2) intent clustering, and (3) a novel triplet task.The triplet task gauges the model's understanding of two semantic concepts paramount in real-world conversational systems-- negation and implicature.We observe that current embedding models fare poorly in semantic understanding of these concepts.To address this, we propose a pre-training approach to improve the embedding model by leveraging augmentation with data generated by an auto-regressive model and a contrastive loss term.Our approach improves the semantic understanding of the intent embedding model on the aforementioned linguistic dimensions while slightly effecting their performance on downstream task metrics.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04314v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04314v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Privacy-preserving Fine-tuning of Large Language Models through Flatness
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The privacy concerns associated with the use of Large Language Models (LLMs) have grown recently with the development of LLMs such as ChatGPT. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.618</span></span>Differential Privacy (DP) techniques are explored in existing work to mitigate their privacy risks at the cost of generalization degradation.Our paper reveals that the flatness of DP-trained models' loss landscape plays an essential role in the trade-off between their privacy and generalization.We further propose a holistic framework to enforce appropriate weight flatness, which substantially improves model generalization with competitive privacy preservation.It innovates from three coarse-to-grained levels, including perturbation-aware min-max optimization on model weights within a layer, flatness-guided sparse prefix-tuning on weights across layers, and weight knowledge distillation between DP \& non-DP weights copies.Comprehensive experiments of both black-box and white-box scenarios are conducted to demonstrate the effectiveness of our proposal in enhancing generalization and maintaining DP characteristics.For instance, on text classification dataset QNLI, DP-Flat achieves similar performance with non-private full fine-tuning but with DP guarantee under privacy budget $\epsilon=3$, and even better performance given higher privacy budgets.Codes are provided in the supplement.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04124v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04124v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges.<span class='px-1 mx-1 bg-yellow-200'>To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.685</span></span>Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing.The platform has been operational for several months, amassing over 240K votes.This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models.We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters.<span class='px-1 mx-1 bg-yellow-200'>These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.623</span></span><span class='px-1 mx-1 bg-yellow-200'>Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.73</span></span>Our demo is publicly available at \url{https://chat.lmsys.org}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04132v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04132v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Conversational systems often rely on embedding models for intent classification and intent clustering tasks.<span class='px-1 mx-1 bg-yellow-200'>The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for these downstream conversational tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.603</span></span>However, traditional evaluation benchmarks rely solely on task metrics that don't particularly measure gaps related to semantic understanding.Thus, we propose an intent semantic toolkit that gives a more holistic view of intent embedding models by considering three tasks -- (1) intent classification, (2) intent clustering, and (3) a novel triplet task.The triplet task gauges the model's understanding of two semantic concepts paramount in real-world conversational systems -- negation and implicature.We observe that current embedding models fare poorly in semantic understanding of these concepts.To address this, we propose a pre-training approach to improve the embedding model by leveraging augmentation with data generated by an auto-regressive model and a contrastive loss term.Our approach improves the semantic understanding of the intent embedding model on the aforementioned linguistic dimensions while slightly effecting their performance on downstream task metrics.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04314v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04314v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Acceleron: A Tool to Accelerate Research Ideation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Several tools have recently been proposed for assisting researchers during various stages of the research life-cycle.However, these primarily concentrate on tasks such as retrieving and recommending relevant literature, reviewing and critiquing the draft, and writing of research manuscripts.Our investigation reveals a significant gap in availability of tools specifically designed to assist researchers during the challenging ideation phase of the research life-cycle.To aid with research ideation, we propose `Acceleron', a research accelerator for different phases of the research life cycle, and which is specially designed to aid the ideation process.Acceleron guides researchers through the formulation of a comprehensive research proposal, encompassing a novel research problem.The proposals motivation is validated for novelty by identifying gaps in the existing literature and suggesting a plausible list of techniques to solve the proposed problem.<span class='px-1 mx-1 bg-yellow-200'>We leverage the reasoning and domain-specific skills of Large Language Models (LLMs) to create an agent-based architecture incorporating colleague and mentor personas for LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.6</span></span><span class='px-1 mx-1 bg-yellow-200'>The LLM agents emulate the ideation process undertaken by researchers, engaging researchers in an interactive fashion to aid in the development of the research proposal. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.794</span></span>Notably, our tool addresses challenges inherent in LLMs, such as hallucinations, implements a two-stage aspect-based retrieval to manage precision-recall trade-offs, and tackles issues of unanswerability.As evaluation, we illustrate the execution of our motivation validation and method synthesis workflows on proposals from the ML and NLP domain, given by 3 distinct researchers.Our observations and evaluations provided by the researchers illustrate the efficacy of the tool in terms of assisting researchers with appropriate inputs at distinct stages and thus leading to improved time efficiency.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04382v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04382v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Conversational recommender system is an emerging area that has garnered an increasing interest in the community, especially with the advancements in large language models (LLMs) that enable diverse reasoning over conversational input. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.612</span></span>Despite the progress, the field has many aspects left to explore.The currently available public datasets for conversational recommendation lack specific user preferences and explanations for recommendations, hindering high-quality recommendations.<span class='px-1 mx-1 bg-yellow-200'>To address such challenges, we present a novel conversational recommendation dataset named PEARL, synthesized with persona- and knowledge-augmented LLM simulators. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.719</span></span><span class='px-1 mx-1 bg-yellow-200'>We obtain detailed persona and knowledge from real-world reviews and construct a large-scale dataset with over 57k dialogues. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.646</span></span>Our experimental results demonstrate that utterances in PEARL include more specific user preferences, show expertise in the target domain, and provide recommendations more relevant to the dialogue context than those in prior datasets.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04460v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04460v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing.Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform.Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods.To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously.Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction.To validate our approach, we deployed iScore with three learning engineers over the course of a month.We present a case study where interacting with iScore led a learning engineer to improve their LLM's score accuracy by three percentage points.<span class='px-1 mx-1 bg-yellow-200'>Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.659</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04760v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04760v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Genetic Programming Trees using Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Genetic programming (GP) has the potential to generate explainable results, especially when used for dimensionality reduction.In this research, we investigate the potential of leveraging eXplainable AI (XAI) and large language models (LLMs) like ChatGPT to improve the interpretability of GP-based non-linear dimensionality reduction.<span class='px-1 mx-1 bg-yellow-200'>Our study introduces a novel XAI dashboard named GP4NLDR, the first approach to combine state-of-the-art GP with an LLM-powered chatbot to provide comprehensive, user-centred explanations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.648</span></span>We showcase the system's ability to provide intuitive and insightful narratives on high-dimensional data reduction processes through case studies.Our study highlights the importance of prompt engineering in eliciting accurate and pertinent responses from LLMs.We also address important considerations around data privacy, hallucinatory outputs, and the rapid advancements in generative AI.Our findings demonstrate its potential in advancing the explainability of GP algorithms.This opens the door for future research into explaining GP models with LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03397v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03397v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Human vs. Machine: Language Models and Wargames
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Wargames have a long history in the development of military strategy and the response of nations to threats or attacks.The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness.<span class='px-1 mx-1 bg-yellow-200'>However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.623</span></span>To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses.<span class='px-1 mx-1 bg-yellow-200'>We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.708</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03407v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03407v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>This study investigates the generation of synthetic disinformation by OpenAI's Large Language Models (LLMs) through prompt engineering and explores their responsiveness to emotional prompting. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span>Leveraging various LLM iterations using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed experiments to assess their success in producing disinformation.<span class='px-1 mx-1 bg-yellow-200'>Our findings, based on a corpus of 19,800 synthetic disinformation social media posts, reveal that all LLMs by OpenAI can successfully produce disinformation, and that they effectively respond to emotional prompting, indicating their nuanced understanding of emotional cues in text generation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.635</span></span>When prompted politely, all examined LLMs consistently generate disinformation at a high frequency.Conversely, when prompted impolitely, the frequency of disinformation production diminishes, as the models often refuse to generate disinformation and instead caution users that the tool is not intended for such purposes.This research contributes to the ongoing discourse surrounding responsible development and application of AI technologies, particularly in mitigating the spread of disinformation and promoting transparency in AI-generated content.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03550v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03550v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                GPTopic: Dynamic and Interactive Topic Representations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Topic modeling seems to be almost synonymous with generating lists of top words to represent topics within large text corpora.However, deducing a topic from such list of individual terms can require substantial expertise and experience, making topic modelling less accessible to people unfamiliar with the particularities and pitfalls of top-word interpretation.A topic representation limited to top-words might further fall short of offering a comprehensive and easily accessible characterization of the various aspects, facets and nuances a topic might have.To address these challenges, we introduce GPTopic, a software package that leverages Large Language Models (LLMs) to create dynamic, interactive topic representations.<span class='px-1 mx-1 bg-yellow-200'>GPTopic provides an intuitive chat interface for users to explore, analyze, and refine topics interactively, making topic modeling more accessible and comprehensive. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.631</span></span>The corresponding code is available here: https://github. com/05ec6602be/GPTopic.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03628v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03628v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                "It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Autistic adults often experience stigma and discrimination at work, leading them to seek social communication support from coworkers, friends, and family despite emotional risks.Large language models (LLMs) are increasingly considered an alternative.<span class='px-1 mx-1 bg-yellow-200'>In this work, we investigate the phenomenon of LLM use by autistic adults at work and explore opportunities and risks of LLMs as a source of social communication advice. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.846</span></span><span class='px-1 mx-1 bg-yellow-200'>We asked 11 autistic participants to present questions about their own workplace-related social difficulties to (1) a GPT-4-based chatbot and (2) a disguised human confederate. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.826</span></span>Our evaluation shows that participants strongly preferred LLM over confederate interactions.<span class='px-1 mx-1 bg-yellow-200'>However, a coach specializing in supporting autistic job-seekers raised concerns that the LLM was dispensing questionable advice. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.618</span></span><span class='px-1 mx-1 bg-yellow-200'>We highlight how this divergence in participant and practitioner attitudes reflects existing schisms in HCI on the relative privileging of end-user wants versus normative good and propose design considerations for LLMs to center autistic experiences. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.721</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03297v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03297v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Large Language Models in Social Sciences</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Personality detection aims to detect one's personality traits underlying in social media posts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.839</span></span><span class='px-1 mx-1 bg-yellow-200'>One challenge of this task is the scarcity of ground-truth personality traits which are collected from self-report questionnaires. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.659</span></span><span class='px-1 mx-1 bg-yellow-200'>Most existing methods learn post features directly by fine-tuning the pre-trained language models under the supervision of limited personality labels. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.655</span></span>This leads to inferior quality of post features and consequently affects the performance.<span class='px-1 mx-1 bg-yellow-200'>In addition, they treat personality traits as one-hot classification labels, overlooking the semantic information within them. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.748</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a large language model (LLM) based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection, even when the LLM fails in this task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.719</span></span><span class='px-1 mx-1 bg-yellow-200'>Specifically, we enable LLM to generate post analyses (augmentations) from the aspects of semantic, sentiment, and linguistic, which are critical for personality detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.731</span></span><span class='px-1 mx-1 bg-yellow-200'>By using contrastive learning to pull them together in the embedding space, the post encoder can better capture the psycho-linguistic information within the post representations, thus improving personality detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.781</span></span>Furthermore, we utilize the LLM to enrich the information of personality labels for enhancing the detection performance.<span class='px-1 mx-1 bg-yellow-200'>Experimental results on the benchmark datasets demonstrate that our model outperforms the state-of-the-art methods on personality detection. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.755</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07581v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07581v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation.However, the considered output candidates of the underlying search algorithm are under-explored and under-explained.We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs.To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities.Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data.<span class='px-1 mx-1 bg-yellow-200'>Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.812</span></span>Additionally, we demonstrate the applicability of our approach in a qualitative user study.Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07627v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07627v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Rethinking Generative Large Language Model Evaluation for Semantic Comprehension
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Despite their sophisticated capabilities, large language models (LLMs) encounter a major hurdle in effective assessment. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.665</span></span>This paper first revisits the prevalent evaluation method-multiple choice question answering (MCQA), which allows for straightforward accuracy measurement.Through a comprehensive evaluation of 24 models across 11 benchmarks, we highlight several potential drawbacks of MCQA, for instance, the inconsistency between the MCQA evaluation and the generation of open-ended responses in practical scenarios.In response, we introduce an RWQ-Elo rating system, engaging 24 LLMs such as GPT-4, GPT-3.5, Google-Gemini-Pro and LLaMA-1/-2, in a two-player competitive format, with GPT-4 serving as the judge.Each LLM receives an Elo rating thereafter.This system is designed to mirror real-world usage, and for this purpose, we have compiled a new benchmark called ``Real-world questions'' (RWQ), comprising 20,772 authentic user inquiries.Additionally, we thoroughly analyze the characteristics of our system and compare it with prior leaderboards like AlpacaEval and MT-Bench.Our analysis reveals the stability of our RWQ-Elo system, the feasibility of registering new models, and its potential to reshape LLM leaderboards.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07872v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07872v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in Korean
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Despite the rapid development of large language models (LLMs) for the Korean language, there remains an obvious lack of benchmark datasets that test the requisite Korean cultural and linguistic knowledge.<span class='px-1 mx-1 bg-yellow-200'>Because many existing Korean benchmark datasets are derived from the English counterparts through translation, they often overlook the different cultural contexts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.742</span></span><span class='px-1 mx-1 bg-yellow-200'>For the few benchmark datasets that are sourced from Korean data capturing cultural knowledge, only narrow tasks such as bias and hate speech detection are offered. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.705</span></span><span class='px-1 mx-1 bg-yellow-200'>To address this gap, we introduce a benchmark of Cultural and Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.746</span></span>CLIcK sources its data from official Korean exams and textbooks, partitioning the questions into eleven categories under the two main categories of language and culture.For each instance in CLIcK, we provide fine-grained annotation of which cultural and linguistic knowledge is required to answer the question correctly.Using CLIcK, we test 13 language models to assess their performance.Our evaluation uncovers insights into their performances across the categories, as well as the diverse factors affecting their comprehension.CLIcK offers the first large-scale comprehensive Korean-centric analysis of LLMs' proficiency in Korean culture and language.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06412v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06412v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Evolving Knowledge Distillation with Large Language Models and Active Learning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have demonstrated remarkable capabilities across various NLP tasks.However, their computational costs are prohibitively high.To address this issue, previous research has attempted to distill the knowledge of LLMs into smaller models by generating annotated data.Nonetheless, these works have mainly focused on the direct use of LLMs for text generation and labeling, without fully exploring their potential to comprehend the target task and acquire valuable knowledge.In this paper, we propose EvoKD: Evolving Knowledge Distillation, which leverages the concept of active learning to interactively enhance the process of data generation using large language models, simultaneously improving the task capabilities of small domain model (student model).Different from previous work, we actively analyze the student model's weaknesses, and then synthesize labeled samples based on the analysis.In addition, we provide iterative feedback to the LLMs regarding the student model's performance to continuously construct diversified and challenging samples.<span class='px-1 mx-1 bg-yellow-200'>Experiments and analysis on different NLP tasks, namely, text classification and named entity recognition show the effectiveness of EvoKD. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.632</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06414v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06414v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Academically intelligent LLMs are not necessarily socially intelligent
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The academic intelligence of large language models (LLMs) has made remarkable progress in recent times, but their social intelligence performance remains unclear. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.807</span></span><span class='px-1 mx-1 bg-yellow-200'>Inspired by established human social intelligence frameworks, particularly Daniel Goleman's social intelligence theory, we have developed a standardized social intelligence test based on real-world social scenarios to comprehensively assess the social intelligence of LLMs, termed as the Situational Evaluation of Social Intelligence (SESI). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.652</span></span>We conducted an extensive evaluation with 13 recent popular and state-of-art LLM agents on SESI.<span class='px-1 mx-1 bg-yellow-200'>The results indicate the social intelligence of LLMs still has significant room for improvement, with superficially friendliness as a primary reason for errors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.775</span></span><span class='px-1 mx-1 bg-yellow-200'>Moreover, there exists a relatively low correlation between the social intelligence and academic intelligence exhibited by LLMs, suggesting that social intelligence is distinct from academic intelligence for LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.851</span></span><span class='px-1 mx-1 bg-yellow-200'>Additionally, while it is observed that LLMs can't ``understand'' what social intelligence is, their social intelligence, similar to that of humans, is influenced by social factors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.871</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06591v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06591v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Authorship and the Politics and Ethics of LLM Watermarks
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Recently, watermarking schemes for large language models (LLMs) have been proposed to distinguish text generated by machines and by humans.The present paper explores philosophical, political, and ethical ramifications of implementing and using watermarking schemes.A definition of authorship that includes both machines (LLMs) and humans is proposed to serve as a backdrop.It is argued that private watermarks may provide private companies with sweeping rights to determine authorship, which is incompatible with traditional standards of authorship determination.Then, possible ramifications of the so-called entropy dependence of watermarking mechanisms are explored.<span class='px-1 mx-1 bg-yellow-200'>It is argued that entropy may vary for different, socially salient groups. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.789</span></span>This could lead to group dependent rates at which machine generated text is detected.Specifically, groups more interested in low entropy text may face the challenge that it is harder to detect machine generated text that is of interest to them.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06593v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06593v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients.This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc.Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians.This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches.<span class='px-1 mx-1 bg-yellow-200'>Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span>However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians.In this study, we introduce a novel framework, In-Context Padding (ICP), designed to enhance LLMs with medical knowledge.Specifically, we infer critical clinical reasoning elements (referred to as knowledge seeds) and use these as anchors to guide the generation process of LLMs.Experiments on two clinical question datasets demonstrate that ICP significantly improves the clinical reasoning ability of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06609v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06609v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions.<span class='px-1 mx-1 bg-yellow-200'>However, the application of LLMs in medical dialogue generation-a task more closely aligned with actual medical practice-has been less explored. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.656</span></span>This gap is attributed to the insufficient medical knowledge of LLMs, which leads to inaccuracies and hallucinated information in the generated medical responses.In this work, we introduce the Medical dialogue with Knowledge enhancement and clinical Pathway encoding (MedKP) framework, which integrates an external knowledge enhancement module through a medical knowledge graph and an internal clinical pathway encoding via medical entities and physician actions.Evaluated with comprehensive metrics, our experiments on two large-scale, real-world online medical consultation datasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines and mitigates the incidence of hallucinations, achieving a new state-of-the-art.Extensive ablation studies further reveal the effectiveness of each component of MedKP.This enhancement advances the development of reliable, automated medical consultation responses using LLMs, thereby broadening the potential accessibility of precise and real-time medical assistance.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06611v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06611v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ALaRM: Align Language Models via Hierarchical Rewards Modeling
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences.The framework addresses the limitations of current alignment approaches, which often struggle with the inconsistency and sparsity of human supervision signals, by integrating holistic rewards with aspect-specific rewards.This integration enables more precise and consistent guidance of language models towards desired outcomes, particularly in complex and open text generation tasks.By employing a methodology that filters and combines multiple rewards based on their consistency, the framework provides a reliable mechanism for improving model alignment.We validate our approach through applications in long-form question answering and machine translation tasks, employing gpt-3.5-turbo for pairwise comparisons, and demonstrate improvements over existing baselines.<span class='px-1 mx-1 bg-yellow-200'>Our work underscores the effectiveness of hierarchical rewards modeling in refining LLM training processes for better human preference alignment. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.646</span></span>We release our code at https://ALaRM-fdu.github.io.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06754v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06754v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Argument Structure Constructions (ASCs) are one of the most well-studied construction groups, providing a unique opportunity to demonstrate the usefulness of Construction Grammar (CxG).For example, the caused-motion construction (CMC, ``She sneezed the foam off her cappuccino'') demonstrates that constructions must carry meaning, otherwise the fact that ``sneeze'' in this context causes movement cannot be explained.We form the hypothesis that this remains challenging even for state-of-the-art Large Language Models (LLMs), for which we devise a test based on substituting the verb with a prototypical motion verb.<span class='px-1 mx-1 bg-yellow-200'>To be able to perform this test at statistically significant scale, in the absence of adequate CxG corpora, we develop a novel pipeline of NLP-assisted collection of linguistically annotated text. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.665</span></span>We show how dependency parsing and GPT-3.5 can be used to significantly reduce annotation cost and thus enable the annotation of rare phenomena at scale.We then evaluate GPT, Gemini, Llama2 and Mistral models for their understanding of the CMC using the newly collected corpus.We find that all models struggle with understanding the motion component that the CMC adds to a sentence.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06965v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06965v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reading, understanding and explaining code have traditionally been important skills for novices learning programming.As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code.Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM.Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs.One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code.<span class='px-1 mx-1 bg-yellow-200'>However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.625</span></span>In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation.We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel.We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions.We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06050v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06050v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present CNER-UAV, a fine-grained \textbf{C}hinese \textbf{N}ame \textbf{E}ntity \textbf{R}ecognition dataset specifically designed for the task of address resolution in \textbf{U}nmanned \textbf{A}erial \textbf{V}ehicle delivery systems.The dataset encompasses a diverse range of five categories, enabling comprehensive training and evaluation of NER models.To construct this dataset, we sourced the data from a real-world UAV delivery system and conducted a rigorous data cleaning and desensitization process to ensure privacy and data integrity.<span class='px-1 mx-1 bg-yellow-200'>The resulting dataset, consisting of around 12,000 annotated samples, underwent human experts and \textbf{L}arge \textbf{L}anguage \textbf{M}odel annotation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.6</span></span>We evaluated classical NER models on our dataset and provided in-depth analysis.The dataset and models are publicly available at \url{https://github.com/zhhvvv/CNER-UAV}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06097v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06097v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The effectiveness of central bank communication is a crucial aspect of monetary policy transmission.<span class='px-1 mx-1 bg-yellow-200'>While recent research has examined the influence of policy communication by the chairs of the Federal Reserve on various financial variables, much of the literature relies on rule-based or dictionary-based methods in parsing the language of the chairs, leaving nuanced information about policy stance contained in nonverbal emotion out of the analysis. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.777</span></span>In the current study, we propose the Fine-Grained Monetary Policy Analysis Framework (FMPAF), a novel approach that integrates large language models (LLMs) with regression analysis to provide a comprehensive analysis of the impact of the press-conference communications of chairs of the Federal Reserve on financial markets.We conduct extensive comparisons of model performance under different levels of granularity, modalities, and communication scenarios.<span class='px-1 mx-1 bg-yellow-200'>Based on our preferred specification, a one-unit increase in the sentiment score is associated with an increase of the price of S\&P 500 Exchange-Traded Fund by approximately 500 basis points, a 15-basis-point decrease in the policy interest rate, while not leading to a significant response in exchange rates. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.692</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06115v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06115v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Simulating Family Conversations using LLMs: Demonstration of Parenting Styles
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>This study presents a framework for conducting psychological and linguistic research through simulated conversations using large language models (LLMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.77</span></span><span class='px-1 mx-1 bg-yellow-200'>The proposed methodology offers significant advantages, particularly for simulating human interactions involving potential unethical language or behaviors that would be impermissible in traditional experiments with human participants. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.721</span></span>As a demonstration, we employed LLMs to simulate family conversations across four parenting styles (authoritarian, authoritative, permissive, and uninvolved).<span class='px-1 mx-1 bg-yellow-200'>In general, we observed that the characteristics of the four parenting styles were portrayed in the simulated conversations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.773</span></span>Several strategies could be used to improve the simulation quality, such as including context awareness, employing a few-shot prompting approach or fine-tuning models to cater to specific simulation requirements.<span class='px-1 mx-1 bg-yellow-200'>Overall, this study introduces a promising methodology for conducting psychological and linguistic research through simulated conversations, while acknowledging the current limitations and proposing potential solutions for future refinement and improvement. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.925</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06144v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06144v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Automatically Score Proficiency of Written Essays?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.617</span></span>Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.671</span></span>We experimented with two popular LLMs, namely ChatGPT and Llama.We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait.We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task.Our experiments conducted on the ASAP dataset revealed several interesting observations.First, choosing the right prompt depends highly on the model and nature of the task.Second, the two LLMs exhibited comparable average performance in AES, with a slight advantage for ChatGPT.Finally, despite the performance gap between the two LLMs and SOTA models in terms of predictions, they provide feedback to enhance the quality of the essays, which can potentially help both teachers and students.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06149v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06149v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                No Language is an Island: Unifying Chinese and English in Financial Large Language Models, Instruction Data, and Benchmarks
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>While the progression of Large Language Models (LLMs) has notably propelled financial analysis, their application has largely been confined to singular language realms, leaving untapped the potential of bilingual Chinese-English capacity.To bridge this chasm, we introduce ICE-PIXIU, seamlessly amalgamating the ICE-INTENT model and ICE-FLARE benchmark for bilingual financial analysis.ICE-PIXIU uniquely integrates a spectrum of Chinese tasks, alongside translated and original English datasets, enriching the breadth and depth of bilingual financial modeling.It provides unrestricted access to diverse model variants, a substantial compilation of diverse cross-lingual and multi-modal instruction data, and an evaluation benchmark with expert annotations, comprising 10 NLP tasks, 20 bilingual specific tasks, totaling 1,185k datasets.Our thorough evaluation emphasizes the advantages of incorporating these bilingual datasets, especially in translation tasks and utilizing original English data, enhancing both linguistic flexibility and analytical acuity in financial contexts.<span class='px-1 mx-1 bg-yellow-200'>Notably, ICE-INTENT distinguishes itself by showcasing significant enhancements over conventional LLMs and existing financial LLMs in bilingual milieus, underscoring the profound impact of robust bilingual data on the accuracy and efficacy of financial NLP. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.721</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06249v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06249v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>There are two main barriers to using large language models (LLMs) in clinical reasoning.<span class='px-1 mx-1 bg-yellow-200'>Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span><span class='px-1 mx-1 bg-yellow-200'>Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.656</span></span>This leads to user distrust.In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction.ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships.Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent arguments to support decision.ArgMed-Agents enables LLMs to mimic the process of clinical argumentative reasoning by generating explanations of reasoning in a self-directed manner.The setup experiments show that ArgMed-Agents not only improves accuracy in complex clinical decision reasoning problems compared to other prompt methods, but more importantly, it provides users with decision explanations that increase their confidence.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06294v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06294v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Reason and Plan?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.61</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04121v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04121v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Genetic Programming Trees using Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Genetic programming (GP) has the potential to generate explainable results, especially when used for dimensionality reduction.<span class='px-1 mx-1 bg-yellow-200'>In this research, we investigate the potential of leveraging eXplainable AI (XAI) and large language models (LLMs) like ChatGPT to improve the interpretability of GP-based non-linear dimensionality reduction. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.607</span></span>Our study introduces a novel XAI dashboard named GP4NLDR, the first approach to combine state-of-the-art GP with an LLM-powered chatbot to provide comprehensive, user-centred explanations.We showcase the system's ability to provide intuitive and insightful narratives on high-dimensional data reduction processes through case studies.Our study highlights the importance of prompt engineering in eliciting accurate and pertinent responses from LLMs.We also address important considerations around data privacy, hallucinatory outputs, and the rapid advancements in generative AI.Our findings demonstrate its potential in advancing the explainability of GP algorithms.This opens the door for future research into explaining GP models with LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03397v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03397v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Human vs. Machine: Language Models and Wargames
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Wargames have a long history in the development of military strategy and the response of nations to threats or attacks.The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness.<span class='px-1 mx-1 bg-yellow-200'>However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.744</span></span>To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses.<span class='px-1 mx-1 bg-yellow-200'>We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.678</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03407v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03407v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>This study investigates the generation of synthetic disinformation by OpenAI's Large Language Models (LLMs) through prompt engineering and explores their responsiveness to emotional prompting.Leveraging various LLM iterations using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed experiments to assess their success in producing disinformation.<span class='px-1 mx-1 bg-yellow-200'>Our findings, based on a corpus of 19,800 synthetic disinformation social media posts, reveal that all LLMs by OpenAI can successfully produce disinformation, and that they effectively respond to emotional prompting, indicating their nuanced understanding of emotional cues in text generation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.639</span></span>When prompted politely, all examined LLMs consistently generate disinformation at a high frequency.Conversely, when prompted impolitely, the frequency of disinformation production diminishes, as the models often refuse to generate disinformation and instead caution users that the tool is not intended for such purposes.This research contributes to the ongoing discourse surrounding responsible development and application of AI technologies, particularly in mitigating the spread of disinformation and promoting transparency in AI-generated content.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03550v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03550v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The creation of instruction data and evaluation benchmarks for serving Large language models often involves enormous human annotation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.627</span></span>This issue becomes particularly pronounced when rapidly developing such resources for a non-English language like Japanese.Instead of following the popular practice of directly translating existing English resources into Japanese (e.g., Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4.We first translate a small amount of English instructions into Japanese and post-edit them to obtain native-level quality.GPT-4 then utilizes them as demonstrations to automatically generate Japanese instruction data.We also construct an evaluation benchmark containing 80 questions across 8 categories, using GPT-4 to automatically assess the response quality of LLMs without human references.The empirical results suggest that the models fine-tuned on our GPT-4 self-instruct data significantly outperformed the Japanese-Alpaca across all three base pre-trained models.Our GPT-4 self-instruct data allowed the LLaMA 13B model to defeat GPT-3.5 (Davinci-003) with a 54.37\% win-rate.<span class='px-1 mx-1 bg-yellow-200'>The human evaluation exhibits the consistency between GPT-4's assessments and human preference. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.863</span></span>Our high-quality instruction data and evaluation benchmark have been released here.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03690v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03690v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                "It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Autistic adults often experience stigma and discrimination at work, leading them to seek social communication support from coworkers, friends, and family despite emotional risks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.833</span></span>Large language models (LLMs) are increasingly considered an alternative.<span class='px-1 mx-1 bg-yellow-200'>In this work, we investigate the phenomenon of LLM use by autistic adults at work and explore opportunities and risks of LLMs as a source of social communication advice. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.75</span></span><span class='px-1 mx-1 bg-yellow-200'>We asked 11 autistic participants to present questions about their own workplace-related social difficulties to (1) a GPT-4-based chatbot and (2) a disguised human confederate. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.75</span></span><span class='px-1 mx-1 bg-yellow-200'>Our evaluation shows that participants strongly preferred LLM over confederate interactions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.687</span></span><span class='px-1 mx-1 bg-yellow-200'>However, a coach specializing in supporting autistic job-seekers raised concerns that the LLM was dispensing questionable advice. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.687</span></span><span class='px-1 mx-1 bg-yellow-200'>We highlight how this divergence in participant and practitioner attitudes reflects existing schisms in HCI on the relative privileging of end-user wants versus normative good and propose design considerations for LLMs to center autistic experiences. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.647</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03297v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03297v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>In this paper, we develop an LLM-powered framework for the curation and evaluation of emerging opinion mining in online health communities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.626</span></span>We formulate emerging opinion mining as a pairwise stance detection problem between (title, comment) pairs sourced from Reddit, where post titles contain emerging health-related claims on a topic that is not predefined.The claims are either explicitly or implicitly expressed by the user.We detail (i) a method of claim identification -- the task of identifying if a post title contains a claim and (ii) an opinion mining-driven evaluation framework for stance detection using LLMs.   We facilitate our exploration by releasing a novel test dataset, Long COVID-Stance, or LC-stance, which can be used to evaluate LLMs on the tasks of claim identification and stance detection in online health communities.Long Covid is an emerging post-COVID disorder with uncertain and complex treatment guidelines, thus making it a suitable use case for our task.LC-Stance contains long COVID treatment related discourse sourced from a Reddit community.Our evaluation shows that GPT-4 significantly outperforms prior works on zero-shot stance detection.We then perform thorough LLM model diagnostics, identifying the role of claim type (i.e. implicit vs explicit claims) and comment length as sources of model error.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03336v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03336v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">LLMs in Education Research</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MoAI: Mixture of All Intelligence for Large Language and Vision Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rise of large language models (LLMs) and instruction tuning has led to the current trend of instruction-tuned large language and vision models (LLVMs).This trend involves either meticulously curating numerous instruction tuning datasets tailored to specific objectives or enlarging LLVMs to manage vast amounts of vision language (VL) data.However, current LLVMs have disregarded the detailed and comprehensive real-world scene understanding available from specialized computer vision (CV) models in visual perception tasks such as segmentation, detection, scene graph generation (SGG), and optical character recognition (OCR).Instead, the existing LLVMs rely mainly on the large capacity and emergent capabilities of their LLM backbones.Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models.MoAI operates through two newly introduced modules: MoAI-Compressor and MoAI-Mixer.After verbalizing the outputs of the external CV models, the MoAI-Compressor aligns and condenses them to efficiently use relevant auxiliary visual information for VL tasks.MoAI-Mixer then blends three types of intelligence (1) visual features, (2) auxiliary features from the external CV models, and (3) language features by utilizing the concept of Mixture of Experts.<span class='px-1 mx-1 bg-yellow-200'>Through this integration, MoAI significantly outperforms both open-source and closed-source LLVMs in numerous zero-shot VL tasks, particularly those related to real-world scene understanding such as object existence, positions, relations, and OCR without enlarging the model size or curating extra visual instruction tuning datasets. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.515</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07508v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07508v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We study the use of large language model-based agents for interacting with software via web browsers.Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems.To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform.We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations.Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation.<span class='px-1 mx-1 bg-yellow-200'>Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.521</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07718v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07718v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>To thoroughly assess the mathematical reasoning abilities of Large Language Models (LLMs), we need to carefully curate evaluation datasets covering diverse mathematical concepts and mathematical problems at different difficulty levels.In pursuit of this objective, we propose FineMath in this paper, a fine-grained mathematical evaluation benchmark dataset for assessing Chinese LLMs.<span class='px-1 mx-1 bg-yellow-200'>FineMath is created to cover the major key mathematical concepts taught in elementary school math, which are further divided into 17 categories of math word problems, enabling in-depth analysis of mathematical reasoning abilities of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.608</span></span>All the 17 categories of math word problems are manually annotated with their difficulty levels according to the number of reasoning steps required to solve these problems.<span class='px-1 mx-1 bg-yellow-200'>We conduct extensive experiments on a wide range of LLMs on FineMath and find that there is still considerable room for improvements in terms of mathematical reasoning capability of Chinese LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.514</span></span>We also carry out an in-depth analysis on the evaluation process and methods that have been overlooked previously.These two factors significantly influence the model results and our understanding of their mathematical reasoning capabilities.The dataset will be publicly available soon.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07747v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07747v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in Korean
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Despite the rapid development of large language models (LLMs) for the Korean language, there remains an obvious lack of benchmark datasets that test the requisite Korean cultural and linguistic knowledge.Because many existing Korean benchmark datasets are derived from the English counterparts through translation, they often overlook the different cultural contexts.For the few benchmark datasets that are sourced from Korean data capturing cultural knowledge, only narrow tasks such as bias and hate speech detection are offered.To address this gap, we introduce a benchmark of Cultural and Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs.<span class='px-1 mx-1 bg-yellow-200'>CLIcK sources its data from official Korean exams and textbooks, partitioning the questions into eleven categories under the two main categories of language and culture. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.52</span></span>For each instance in CLIcK, we provide fine-grained annotation of which cultural and linguistic knowledge is required to answer the question correctly.Using CLIcK, we test 13 language models to assess their performance.Our evaluation uncovers insights into their performances across the categories, as well as the diverse factors affecting their comprehension.<span class='px-1 mx-1 bg-yellow-200'>CLIcK offers the first large-scale comprehensive Korean-centric analysis of LLMs' proficiency in Korean culture and language. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.527</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06412v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06412v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Evolving Knowledge Distillation with Large Language Models and Active Learning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have demonstrated remarkable capabilities across various NLP tasks.However, their computational costs are prohibitively high.To address this issue, previous research has attempted to distill the knowledge of LLMs into smaller models by generating annotated data.Nonetheless, these works have mainly focused on the direct use of LLMs for text generation and labeling, without fully exploring their potential to comprehend the target task and acquire valuable knowledge.In this paper, we propose EvoKD: Evolving Knowledge Distillation, which leverages the concept of active learning to interactively enhance the process of data generation using large language models, simultaneously improving the task capabilities of small domain model (student model).<span class='px-1 mx-1 bg-yellow-200'>Different from previous work, we actively analyze the student model's weaknesses, and then synthesize labeled samples based on the analysis. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.53</span></span>In addition, we provide iterative feedback to the LLMs regarding the student model's performance to continuously construct diversified and challenging samples.Experiments and analysis on different NLP tasks, namely, text classification and named entity recognition show the effectiveness of EvoKD.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06414v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06414v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency.In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations.<span class='px-1 mx-1 bg-yellow-200'>To this end, we first present how to extract the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.505</span></span>Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency.We employ the actor-critic framework and modify the actor loss to regularize the policy learning towards the LLM-generated controller.RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL.We demonstrated that RLingua can significantly reduce the sample complexity of TD3 in the robot tasks of panda_gym and achieve high success rates in sparsely rewarded robot tasks in RLBench, where the standard TD3 fails.Additionally, We validated RLingua's effectiveness in real-world robot experiments through Sim2Real, demonstrating that the learned policies are effectively transferable to real robot tasks.Further details and videos about our work are available at our project website https://rlingua.github.io.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06420v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06420v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Given the importance of ancient Chinese in capturing the essence of rich historical and cultural heritage, the rapid advancements in Large Language Models (LLMs) necessitate benchmarks that can effectively evaluate their understanding of ancient contexts.To meet this need, we present AC-EVAL, an innovative benchmark designed to assess the advanced knowledge and reasoning capabilities of LLMs within the context of ancient Chinese.AC-EVAL is structured across three levels of difficulty reflecting different facets of language comprehension: general historical knowledge, short text understanding, and long text comprehension.The benchmark comprises 13 tasks, spanning historical facts, geography, social customs, art, philosophy, classical poetry and prose, providing a comprehensive assessment framework.<span class='px-1 mx-1 bg-yellow-200'>Our extensive evaluation of top-performing LLMs, tailored for both English and Chinese, reveals a substantial potential for enhancing ancient text comprehension. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.523</span></span>By highlighting the strengths and weaknesses of LLMs, AC-EVAL aims to promote their development and application forward in the realms of ancient Chinese language education and scholarly research.The AC-EVAL data and evaluation code are available at https://github.com/yuting-wei/AC-EVAL.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06574v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06574v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions.<span class='px-1 mx-1 bg-yellow-200'>However, the application of LLMs in medical dialogue generation-a task more closely aligned with actual medical practice-has been less explored. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.583</span></span>This gap is attributed to the insufficient medical knowledge of LLMs, which leads to inaccuracies and hallucinated information in the generated medical responses.In this work, we introduce the Medical dialogue with Knowledge enhancement and clinical Pathway encoding (MedKP) framework, which integrates an external knowledge enhancement module through a medical knowledge graph and an internal clinical pathway encoding via medical entities and physician actions.Evaluated with comprehensive metrics, our experiments on two large-scale, real-world online medical consultation datasets (MedDG and KaMed) demonstrate that MedKP surpasses multiple baselines and mitigates the incidence of hallucinations, achieving a new state-of-the-art.Extensive ablation studies further reveal the effectiveness of each component of MedKP.This enhancement advances the development of reliable, automated medical consultation responses using LLMs, thereby broadening the potential accessibility of precise and real-time medical assistance.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06611v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06611v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches.With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction.However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination.A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text.Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method.<span class='px-1 mx-1 bg-yellow-200'>In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.539</span></span>Experiments on public datasets and in-enterprise datasets validate the effectiveness of the proposed method.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06642v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06642v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations).Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism.<span class='px-1 mx-1 bg-yellow-200'>Existing solutions attempt to distill lengthy demonstrations into compact vectors. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.509</span></span>However, they often require task-specific retraining or compromise LLM's in-context learning performance.To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task.We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously.MEND is endowed with the meta-knowledge of distilling demonstrations through a two-stage training process, which includes meta-distillation pretraining and fine-tuning.Comprehensive evaluations across seven diverse ICL task partitions using decoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess.It not only matches but often outperforms the Vanilla ICL as well as other state-of-the-art distillation models, while significantly reducing the computational demands.This innovation promises enhanced scalability and efficiency for the practical deployment of large language models</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06914v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06914v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM).Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level.We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023.Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates.The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals.We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review.<span class='px-1 mx-1 bg-yellow-200'>We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.547</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07183v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07183v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Action Reimagined: Text-to-Pose Video Editing for Dynamic Human Actions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We introduce a novel text-to-pose video editing method, ReimaginedAct.While existing video editing tasks are limited to changes in attributes, backgrounds, and styles, our method aims to predict open-ended human action changes in video.<span class='px-1 mx-1 bg-yellow-200'>Moreover, our method can accept not only direct instructional text prompts but also `what if' questions to predict possible action changes. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.532</span></span>ReimaginedAct comprises video understanding, reasoning, and editing modules.<span class='px-1 mx-1 bg-yellow-200'>First, an LLM is utilized initially to obtain a plausible answer for the instruction or question, which is then used for (1) prompting Grounded-SAM to produce bounding boxes of relevant individuals and (2) retrieving a set of pose videos that we have collected for editing human actions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.518</span></span>The retrieved pose videos and the detected individuals are then utilized to alter the poses extracted from the original video.We also employ a timestep blending module to ensure the edited video retains its original content except where necessary modifications are needed.To facilitate research in text-to-pose video editing, we introduce a new evaluation dataset, WhatifVideo-1.0.This dataset includes videos of different scenarios spanning a range of difficulty levels, along with questions and text prompts.Experimental results demonstrate that existing video editing methods struggle with human action editing, while our approach can achieve effective action editing and even imaginary editing from counterfactual questions.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07198v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07198v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Reading, understanding and explaining code have traditionally been important skills for novices learning programming. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.571</span></span>As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code.Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM.<span class='px-1 mx-1 bg-yellow-200'>Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.633</span></span><span class='px-1 mx-1 bg-yellow-200'>One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.623</span></span>However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake.In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation.<span class='px-1 mx-1 bg-yellow-200'>We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.633</span></span><span class='px-1 mx-1 bg-yellow-200'>We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.699</span></span><span class='px-1 mx-1 bg-yellow-200'>We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.751</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06050v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06050v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Simulating Family Conversations using LLMs: Demonstration of Parenting Styles
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>This study presents a framework for conducting psychological and linguistic research through simulated conversations using large language models (LLMs).The proposed methodology offers significant advantages, particularly for simulating human interactions involving potential unethical language or behaviors that would be impermissible in traditional experiments with human participants.<span class='px-1 mx-1 bg-yellow-200'>As a demonstration, we employed LLMs to simulate family conversations across four parenting styles (authoritarian, authoritative, permissive, and uninvolved). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.622</span></span><span class='px-1 mx-1 bg-yellow-200'>In general, we observed that the characteristics of the four parenting styles were portrayed in the simulated conversations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.508</span></span>Several strategies could be used to improve the simulation quality, such as including context awareness, employing a few-shot prompting approach or fine-tuning models to cater to specific simulation requirements.Overall, this study introduces a promising methodology for conducting psychological and linguistic research through simulated conversations, while acknowledging the current limitations and proposing potential solutions for future refinement and improvement.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06144v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06144v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Large Language Models Automatically Score Proficiency of Written Essays?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness.Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks.In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays.<span class='px-1 mx-1 bg-yellow-200'>We experimented with two popular LLMs, namely ChatGPT and Llama. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.514</span></span>We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait.We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task.Our experiments conducted on the ASAP dataset revealed several interesting observations.First, choosing the right prompt depends highly on the model and nature of the task.Second, the two LLMs exhibited comparable average performance in AES, with a slight advantage for ChatGPT.<span class='px-1 mx-1 bg-yellow-200'>Finally, despite the performance gap between the two LLMs and SOTA models in terms of predictions, they provide feedback to enhance the quality of the essays, which can potentially help both teachers and students. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.545</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06149v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06149v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.509</span></span>However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools.<span class='px-1 mx-1 bg-yellow-200'>Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.624</span></span><span class='px-1 mx-1 bg-yellow-200'>In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.708</span></span>The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP.GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last.<span class='px-1 mx-1 bg-yellow-200'>We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.637</span></span><span class='px-1 mx-1 bg-yellow-200'>In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.515</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06254v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06254v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Editing Conceptual Knowledge for Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs).Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear.This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation.The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance.<span class='px-1 mx-1 bg-yellow-200'>We anticipate this can inspire further progress in better understanding LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.534</span></span>Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06259v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06259v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Developing an AI-Based Psychometric System for Assessing Learning Difficulties and Adaptive System to Overcome: A Qualitative and Conceptual Framework
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Learning difficulties pose significant challenges for students, impacting their academic performance and overall educational experience. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.675</span></span><span class='px-1 mx-1 bg-yellow-200'>These difficulties could sometimes put students into a downward spiral that lack of educational resources for personalized support consistently led to under-accommodation of students special needs, and the student lose opportunities in the longer term academic and work development. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.539</span></span><span class='px-1 mx-1 bg-yellow-200'>This research aims to propose a conceptual framework for an adaptive AI-based virtual tutor system that incorporates psychometric assessment to support students with learning difficulties. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.77</span></span>This process involves the careful selection and integration of validated current mature psychometric scales that assess key dimensions of learning, such as cognitive abilities, learning styles, and academic skills.<span class='px-1 mx-1 bg-yellow-200'>By incorporating scales that specifically assess these difficulties, the psychometric test will provide a comprehensive understanding of each students unique learning profile and inform targeted interventions within the adaptive tutoring system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.563</span></span>The paper also proposes using autoencoders to identify the latent patterns to generate the students profile vector for collection of psychometric data, defining state space and action space representing the students desired combination of images, sound and text engagements, employing extended Bayesian knowledge tracing and hierarchical model and Metropolis-Hastings to continuously estimate and monitor the students performance in various psychometric constructs.<span class='px-1 mx-1 bg-yellow-200'>The proposed system will leverage the capabilities of LLMs, visual generation models, and psychometric assessments to provide personalized instruction and support tailored to each students unique learning characteristics and needs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06284v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06284v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-09</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs).Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process.<span class='px-1 mx-1 bg-yellow-200'>This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.517</span></span>Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06039v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06039v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Feedback-Generation for Programming Exercises With GPT-4
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.502</span></span><span class='px-1 mx-1 bg-yellow-200'>LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.675</span></span><span class='px-1 mx-1 bg-yellow-200'>This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.613</span></span><span class='px-1 mx-1 bg-yellow-200'>Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.59</span></span>The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material.Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements.For example, the output is more structured and consistent.GPT-4 Turbo can also accurately identify invalid casing in student programs' output.In some cases, the feedback also includes the output of the student program.At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed.<span class='px-1 mx-1 bg-yellow-200'>The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.703</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04449v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04449v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Evaluating and enhancing the general capabilities of large language models (LLMs) has been an important research topic.Graph is a common data structure in the real world, and understanding graph data is a crucial part for advancing general intelligence.To evaluate and enhance the graph understanding abilities of LLMs, in this paper, we propose a benchmark named GraphInstruct, which comprehensively includes 21 classical graph reasoning tasks, providing diverse graph generation pipelines and detailed reasoning steps.<span class='px-1 mx-1 bg-yellow-200'>Based on GraphInstruct, we further construct GraphLM through efficient instruction-tuning, which shows prominent graph understanding capability. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.502</span></span>In order to enhance the LLM with graph reasoning capability as well, we propose a step mask training strategy, and construct a model named GraphLM+.As one of the pioneering efforts to enhance the graph understanding and reasoning abilities of LLMs, extensive experiments have demonstrated the superiority of GraphLM and GraphLM+ over other LLMs.We look forward to more researchers exploring the potential of LLMs in the graph data mining domain through GraphInstruct.Our code for generating GraphInstruct is released publicly at: https://github.com/CGCL-codes/GraphInstruct.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04483v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04483v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                How Far Are We from Intelligent Visual Deductive Reasoning?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks.We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs.Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues.We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN.<span class='px-1 mx-1 bg-yellow-200'>The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.512</span></span><span class='px-1 mx-1 bg-yellow-200'>We found that certain standard strategies that are effective when applied to LLMs do not seamlessly translate to the challenges presented by visual reasoning tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.508</span></span><span class='px-1 mx-1 bg-yellow-200'>Moreover, a detailed analysis reveals that VLMs struggle to solve these tasks mainly because they are unable to perceive and comprehend multiple, confounding abstract patterns in RPM examples. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.519</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04732v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04732v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Vision-extended LLMs have made significant strides in Visual Question Answering (VQA). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.51</span></span>Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses.In this work, we introduce a novel evaluative benchmark named \textbf{SnapNTell}, specifically tailored for entity-centric VQA.This task aims to test the models' capabilities in identifying entities and providing detailed, entity-specific knowledge.We have developed the \textbf{SnapNTell Dataset}, distinct from traditional VQA datasets: (1) It encompasses a wide range of categorized entities, each represented by images and explicitly named in the answers; (2) It features QA pairs that require extensive knowledge for accurate responses.The dataset is organized into 22 major categories, containing 7,568 unique entities in total.For each entity, we curated 10 illustrative images and crafted 10 knowledge-intensive QA pairs.To address this novel task, we devised a scalable, efficient, and transparent retrieval-augmented multimodal LLM.Our approach markedly outperforms existing methods on the SnapNTell dataset, achieving a 66.5\% improvement in the BELURT score.We will soon make the dataset and the source code publicly accessible.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04735v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04735v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing.<span class='px-1 mx-1 bg-yellow-200'>Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.538</span></span>Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods.<span class='px-1 mx-1 bg-yellow-200'>To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.565</span></span>Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction.<span class='px-1 mx-1 bg-yellow-200'>To validate our approach, we deployed iScore with three learning engineers over the course of a month. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.561</span></span><span class='px-1 mx-1 bg-yellow-200'>We present a case study where interacting with iScore led a learning engineer to improve their LLM's score accuracy by three percentage points. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.537</span></span><span class='px-1 mx-1 bg-yellow-200'>Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.569</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04760v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04760v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">LLMs as Recommender Systems</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Towards Graph Foundation Models for Personalization
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions.In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FMs).While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval.In this paper, we present a graph-based foundation modeling approach tailored to personalization.Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types.To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity.To facilitate practical generalization, we further couple the HGNN with an adaptation mechanism based on a two-tower (2T) architecture, which also operates agnostically to content type.This multi-stage approach ensures high scalability; while the HGNN produces general purpose embeddings, the 2T component models in a continuous space the sheer size of user-item interaction data.<span class='px-1 mx-1 bg-yellow-200'>Our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.601</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07478v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07478v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.715</span></span>The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions.However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset.<span class='px-1 mx-1 bg-yellow-200'>To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.633</span></span><span class='px-1 mx-1 bg-yellow-200'>Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summarize the patterns indicating which types of users would be attracted by certain items. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.619</span></span>The retrieved collaborative evidence prompts the LLM to align its reasoning with the user-item interaction patterns in the dataset.<span class='px-1 mx-1 bg-yellow-200'>However, since the capacity of the input prompt is limited, finding the minimally-sufficient collaborative information for recommendation tasks can be challenging. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.623</span></span>We propose to find the optimal interaction set through a sequential decision-making process and develop a retrieval policy learned through a reinforcement learning (RL) framework, CoRAL.<span class='px-1 mx-1 bg-yellow-200'>Our experimental results show that CoRAL can significantly improve LLMs' reasoning abilities on specific recommendation tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.725</span></span>Our analysis also reveals that CoRAL can more efficiently explore collaborative information through reinforcement learning.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06447v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06447v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.794</span></span><span class='px-1 mx-1 bg-yellow-200'>RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.738</span></span><span class='px-1 mx-1 bg-yellow-200'>The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.833</span></span>We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems.The source code of RecAI is available at \url{https://github.com/microsoft/RecAI}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06465v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06465v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.631</span></span><span class='px-1 mx-1 bg-yellow-200'>With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.798</span></span>However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination.A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text.Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method.In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training.Experiments on public datasets and in-enterprise datasets validate the effectiveness of the proposed method.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06642v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06642v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Federated Recommendation via Hybrid Retrieval Augmented Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.626</span></span>However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to the data sparsity and heterogeneity in FR.<span class='px-1 mx-1 bg-yellow-200'>On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.773</span></span><span class='px-1 mx-1 bg-yellow-200'>Yet, LLM-based recommenders encounter challenges such as low inference efficiency and potential hallucination, compromising their performance in real-world scenarios. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.722</span></span><span class='px-1 mx-1 bg-yellow-200'>To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.788</span></span>GPT-FedRec is a two-stage solution.The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features.Next, the retrieved results are converted into text prompts and fed into GPT for re-ranking.Our proposed hybrid retrieval mechanism and LLM-based re-rank aims to extract generalized features from data and exploit pretrained knowledge within LLM, overcoming data sparsity and heterogeneity in FR.<span class='px-1 mx-1 bg-yellow-200'>In addition, the RAG approach also prevents LLM hallucination, improving the recommendation performance for real-world users. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.641</span></span>Experimental results on diverse benchmark datasets demonstrate the superior performance of GPT-FedRec against state-of-the-art baseline methods.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04256v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04256v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Can Small Language Models be Good Reasoners for Sequential Recommendation?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.739</span></span>However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs.Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses.<span class='px-1 mx-1 bg-yellow-200'>Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.675</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.799</span></span>We introduce CoT prompting based on user behavior sequences for the larger teacher model.The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g., LLaMA2-7B).In this way, the student model acquires the step-by-step reasoning capabilities in recommendation tasks.<span class='px-1 mx-1 bg-yellow-200'>We encode the generated rationales from the student model into a dense vector, which empowers recommendation in both ID-based and ID-agnostic scenarios. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.61</span></span><span class='px-1 mx-1 bg-yellow-200'>Extensive experiments demonstrate the effectiveness of SLIM over state-of-the-art baselines, and further analysis showcasing its ability to generate meaningful recommendation reasoning at affordable costs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.837</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04260v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04260v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Conversational recommender system is an emerging area that has garnered an increasing interest in the community, especially with the advancements in large language models (LLMs) that enable diverse reasoning over conversational input. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.814</span></span>Despite the progress, the field has many aspects left to explore.<span class='px-1 mx-1 bg-yellow-200'>The currently available public datasets for conversational recommendation lack specific user preferences and explanations for recommendations, hindering high-quality recommendations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.626</span></span><span class='px-1 mx-1 bg-yellow-200'>To address such challenges, we present a novel conversational recommendation dataset named PEARL, synthesized with persona- and knowledge-augmented LLM simulators. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.754</span></span>We obtain detailed persona and knowledge from real-world reviews and construct a large-scale dataset with over 57k dialogues.Our experimental results demonstrate that utterances in PEARL include more specific user preferences, show expertise in the target domain, and provide recommendations more relevant to the dialogue context than those in prior datasets.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04460v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04460v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Generative News Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Most existing news recommendation methods tackle this task by conducting semantic matching between candidate news and user representation produced by historical clicked news. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.817</span></span>However, they overlook the high-level connections among different news articles and also ignore the profound relationship between these news articles and users.And the definition of these methods dictates that they can only deliver news articles as-is.On the contrary, integrating several relevant news articles into a coherent narrative would assist users in gaining a quicker and more comprehensive understanding of events.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a novel generative news recommendation paradigm that includes two steps: (1) Leveraging the internal knowledge and reasoning capabilities of the Large Language Model (LLM) to perform high-level matching between candidate news and user representation; (2) Generating a coherent and logically structured narrative based on the associations between related news and user interests, thus engaging users in further reading of the news. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.788</span></span><span class='px-1 mx-1 bg-yellow-200'>Specifically, we propose GNR to implement the generative news recommendation paradigm. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.641</span></span>First, we compose the dual-level representation of news and users by leveraging LLM to generate theme-level representations and combine them with semantic-level representations.Next, in order to generate a coherent narrative, we explore the news relation and filter the related news according to the user preference.Finally, we propose a novel training method named UIFT to train the LLM to fuse multiple news articles in a coherent narrative.<span class='px-1 mx-1 bg-yellow-200'>Extensive experiments show that GNR can improve recommendation accuracy and eventually generate more personalized and factually consistent narratives. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.678</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03424v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03424v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Towards Efficient and Effective Unlearning of Large Language Models for Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The significant advancements in large language models (LLMs) give rise to a promising research direction, i.e., leveraging LLMs as recommenders (LLMRec). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.752</span></span>The efficacy of LLMRec arises from the open-world knowledge and reasoning capabilities inherent in LLMs.<span class='px-1 mx-1 bg-yellow-200'>LLMRec acquires the recommendation capabilities through instruction tuning based on user interaction data. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.815</span></span>However, in order to protect user privacy and optimize utility, it is also crucial for LLMRec to intentionally forget specific user data, which is generally referred to as recommendation unlearning.<span class='px-1 mx-1 bg-yellow-200'>In the era of LLMs, recommendation unlearning poses new challenges for LLMRec in terms of \textit{inefficiency} and \textit{ineffectiveness}. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.689</span></span>Existing unlearning methods require updating billions of parameters in LLMRec, which is costly and time-consuming.Besides, they always impact the model utility during the unlearning process.To this end, we propose \textbf{E2URec}, the first \underline{E}fficient and \underline{E}ffective \underline{U}nlearning method for LLM\underline{Rec}.Our proposed E2URec enhances the unlearning efficiency by updating only a few additional LoRA parameters, and improves the unlearning effectiveness by employing a teacher-student framework, where we maintain multiple teacher networks to guide the unlearning process.Extensive experiments show that E2URec outperforms state-of-the-art baselines on two real-world datasets.Specifically, E2URec can efficiently forget specific data without affecting recommendation performance.The source code is at \url{https://github.com/justarter/E2URec}.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03536v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03536v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>With the boom of e-commerce and web applications, recommender systems have become an important part of our daily lives, providing personalized recommendations based on the user's preferences. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.806</span></span><span class='px-1 mx-1 bg-yellow-200'>Although deep neural networks (DNNs) have made significant progress in improving recommendation systems by simulating the interaction between users and items and incorporating their textual information, these DNN-based approaches still have some limitations, such as the difficulty of effectively understanding users' interests and capturing textual information. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.779</span></span>It is not possible to generalize to different seen/unseen recommendation scenarios and reason about their predictions.At the same time, the emergence of large language models (LLMs), represented by ChatGPT and GPT-4, has revolutionized the fields of natural language processing (NLP) and artificial intelligence (AI) due to their superior capabilities in the basic tasks of language understanding and generation, and their impressive generalization and reasoning capabilities.<span class='px-1 mx-1 bg-yellow-200'>As a result, recent research has sought to harness the power of LLM to improve recommendation systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.823</span></span><span class='px-1 mx-1 bg-yellow-200'>Given the rapid development of this research direction in the field of recommendation systems, there is an urgent need for a systematic review of existing LLM-driven recommendation systems for researchers and practitioners in related fields to gain insight into. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.891</span></span>More specifically, we first introduced a representative approach to learning user and item representations using LLM as a feature encoder.<span class='px-1 mx-1 bg-yellow-200'>We then reviewed the latest advances in LLMs techniques for collaborative filtering enhanced recommendation systems from the three paradigms of pre-training, fine-tuning, and prompting. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.82</span></span>Finally, we had a comprehensive discussion on the future direction of this emerging field.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02760v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02760v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of a great value to enhance the learner's understanding and engagement with the recommended learning content. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.636</span></span>Large language models (LLMs) and generative AI in general have recently opened new doors for generating human-like explanations, for and along learning recommendations.However, their precision is still far away from acceptable in a sensitive field like education.To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context, for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context.<span class='px-1 mx-1 bg-yellow-200'>We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.755</span></span>With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM.Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner.We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners.Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03008v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03008v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                NoteLLM: A Retrievable Large Language Model for Note Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>People enjoy sharing "notes" including their experiences within online communities.<span class='px-1 mx-1 bg-yellow-200'>Therefore, recommending notes aligned with user interests has become a crucial task. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.74</span></span>Existing online methods only input notes into BERT-based models to generate note embeddings for assessing similarity.However, they may underutilize some important cues, e.g., hashtags or categories, which represent the key concepts of notes.Indeed, learning to generate hashtags/categories can potentially enhance note embeddings, both of which compress key note information into limited content.Besides, Large Language Models (LLMs) have significantly outperformed BERT in understanding natural languages.<span class='px-1 mx-1 bg-yellow-200'>It is promising to introduce LLMs into note recommendation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.662</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we propose a novel unified framework called NoteLLM, which leverages LLMs to address the item-to-item (I2I) note recommendation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.718</span></span>Specifically, we utilize Note Compression Prompt to compress a note into a single special token, and further learn the potentially related notes' embeddings via a contrastive learning approach.Moreover, we use NoteLLM to summarize the note and generate the hashtag/category automatically through instruction tuning.<span class='px-1 mx-1 bg-yellow-200'>Extensive validations on real scenarios demonstrate the effectiveness of our proposed method compared with the online baseline and show major improvements in the recommendation system of Xiaohongshu. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.703</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.01744v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.01744v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Automated Program Repair (APR) aims to automatically generate patches for rectifying software bugs.<span class='px-1 mx-1 bg-yellow-200'>Recent strides in Large Language Models (LLM), such as ChatGPT, have yielded encouraging outcomes in APR, especially within the conversation-driven APR framework. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.6</span></span>Nevertheless, the efficacy of conversation-driven APR is contingent on the quality of the feedback information.In this paper, we propose ContrastRepair, a novel conversation-based APR approach that augments conversation-driven APR by providing LLMs with contrastive test pairs.A test pair consists of a failing test and a passing test, which offer contrastive feedback to the LLM.Our key insight is to minimize the difference between the generated passing test and the given failing test, which can better isolate the root causes of bugs.By providing informative and specific feedback, ContrastRepair enables the LLM to produce effective bug fixes.The implementation of ContrastRepair is based on the state-of-the-art LLM, ChatGPT, and it iteratively interacts with ChatGPT until plausible patches are generated.We evaluate ContrastRepair on multiple benchmark datasets, including Defects4j, QuixBugs, and HumanEval-Java.The results demonstrate that ContrastRepair significantly outperforms existing methods, achieving a new state-of-the-art in program repair.For instance, among Defects4j 1.2 and 2.0, ContrastRepair correctly repairs 143 out of all 337 bug cases, while the best-performing baseline fixes 124 bugs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.01971v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.01971v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Aligning Language Models for Versatile Text-based Item Retrieval
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>This paper addresses the gap between general-purpose text embeddings and the specific demands of item retrieval tasks.We demonstrate the shortcomings of existing models in capturing the nuances necessary for zero-shot performance on item retrieval tasks.To overcome these limitations, we propose generate in-domain dataset from ten tasks tailored to unlocking models' representation ability for item retrieval.Our empirical studies demonstrate that fine-tuning embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks.<span class='px-1 mx-1 bg-yellow-200'>We also illustrate the practical application of our refined model in a conversational setting, where it enhances the capabilities of LLM-based Recommender Agents like Chat-Rec. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.626</span></span>Our code is available at https://github.com/microsoft/RecAI.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.18899v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.18899v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Compositional API Recommendation for Library-Oriented Code Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) have achieved exceptional performance in code generation.However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs.<span class='px-1 mx-1 bg-yellow-200'>Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.625</span></span>However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs.This granularity inconsistency makes API recommendation a challenging task.To address this, we propose CAPIR (Compositional API Recommendation), which adopts a "divide-and-conquer" strategy to recommend APIs for coarse-grained requirements.Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks.Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask.Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation.To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation).Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines.Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%.On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.19431v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.19431v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-28</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Prospect Personalized Recommendation on Large Language Model-based Agent Platform
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The new kind of Agent-oriented information system, exemplified by GPTs, urges us to inspect the information system infrastructure to support Agent-level information processing and to adapt to the characteristics of Large Language Model (LLM)-based Agents, such as interactivity.<span class='px-1 mx-1 bg-yellow-200'>In this work, we envisage the prospect of the recommender system on LLM-based Agent platforms and introduce a novel recommendation paradigm called Rec4Agentverse, comprised of Agent Items and Agent Recommender. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.707</span></span><span class='px-1 mx-1 bg-yellow-200'>Rec4Agentverse emphasizes the collaboration between Agent Items and Agent Recommender, thereby promoting personalized information services and enhancing the exchange of information beyond the traditional user-recommender feedback loop. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.605</span></span>Additionally, we prospect the evolution of Rec4Agentverse and conceptualize it into three stages based on the enhancement of the interaction and information exchange among Agent Items, Agent Recommender, and the user.A preliminary study involving several cases of Rec4Agentverse validates its significant potential for application.Lastly, we discuss potential issues and promising directions for future research.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.18240v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.18240v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-26</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Integrating Large Language Models with Graphical Session-Based Recommendation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>With the rapid development of Large Language Models (LLMs), various explorations have arisen to utilize LLMs capability of context understanding on recommender systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.751</span></span><span class='px-1 mx-1 bg-yellow-200'>While pioneering strategies have primarily transformed traditional recommendation tasks into challenges of natural language generation, there has been a relative scarcity of exploration in the domain of session-based recommendation (SBR) due to its specificity. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.739</span></span>SBR has been primarily dominated by Graph Neural Networks, which have achieved many successful outcomes due to their ability to capture both the implicit and explicit relationships between adjacent behaviors.The structural nature of graphs contrasts with the essence of natural language, posing a significant adaptation gap for LLMs.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we introduce large language models with graphical Session-Based recommendation, named LLMGR, an effective framework that bridges the aforementioned gap by harmoniously integrating LLMs with Graph Neural Networks (GNNs) for SBR tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.846</span></span><span class='px-1 mx-1 bg-yellow-200'>This integration seeks to leverage the complementary strengths of LLMs in natural language understanding and GNNs in relational data processing, leading to a more powerful session-based recommender system that can understand and recommend items within a session. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.749</span></span>Moreover, to endow the LLM with the capability to empower SBR tasks, we design a series of prompts for both auxiliary and major instruction tuning tasks.These prompts are crafted to assist the LLM in understanding graph-structured data and align textual information with nodes, effectively translating nuanced user interactions into a format that can be understood and utilized by LLM architectures.Extensive experiments on three real-world datasets demonstrate that LLMGR outperforms several competitive baselines, indicating its effectiveness in enhancing SBR tasks and its potential as a research direction for future exploration.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.16539v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.16539v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Production workflows for LLMs</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Couler: Unified Machine Learning Workflow Optimization in Cloud
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Machine Learning (ML) has become ubiquitous, fueling data-driven applications across various organizations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.393</span></span>Contrary to the traditional perception of ML in research, ML workflows can be complex, resource-intensive, and time-consuming.<span class='px-1 mx-1 bg-yellow-200'>Expanding an ML workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.513</span></span><span class='px-1 mx-1 bg-yellow-200'>Currently, numerous workflow engines are available (with over ten being widely recognized). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.39</span></span><span class='px-1 mx-1 bg-yellow-200'>This variety poses a challenge for end-users in terms of mastering different engine APIs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.428</span></span><span class='px-1 mx-1 bg-yellow-200'>While efforts have primarily focused on optimizing ML Operations (MLOps) for a specific workflow engine, current methods largely overlook workflow optimization across different engines.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.342</span></span><span class='px-1 mx-1 bg-yellow-200'>In this work, we design and implement Couler, a system designed for unified ML workflow optimization in the cloud. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.615</span></span>Our main insight lies in the ability to generate an ML workflow using natural language (NL) descriptions.<span class='px-1 mx-1 bg-yellow-200'>We integrate Large Language Models (LLMs) into workflow generation, and provide a unified programming interface for various workflow engines. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.387</span></span><span class='px-1 mx-1 bg-yellow-200'>This approach alleviates the need to understand various workflow engines' APIs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.369</span></span><span class='px-1 mx-1 bg-yellow-200'>Moreover, Couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.41</span></span><span class='px-1 mx-1 bg-yellow-200'>These enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.438</span></span><span class='px-1 mx-1 bg-yellow-200'>Couler is extensively deployed in real-world production scenarios at Ant Group, handling approximately 22k workflows daily, and has successfully improved the CPU/Memory utilization by more than 15% and the workflow completion rate by around 17%. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.388</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07608v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07608v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.407</span></span>However, the considered output candidates of the underlying search algorithm are under-explored and under-explained.We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs.To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities.Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data.Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods.Additionally, we demonstrate the applicability of our approach in a qualitative user study.Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07627v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07627v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Characterization of Large Language Model Development in the Datacenter
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models (LLMs) have presented impressive performance across several transformative tasks.<span class='px-1 mx-1 bg-yellow-200'>However, it is non-trivial to efficiently utilize large-scale cluster resources to develop LLMs, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.669</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we present an in-depth characterization study of a six-month LLM development workload trace collected from our GPU datacenter Acme. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.72</span></span><span class='px-1 mx-1 bg-yellow-200'>Specifically, we investigate discrepancies between LLMs and prior task-specific Deep Learning (DL) workloads, explore resource utilization patterns, and identify the impact of various job failures. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.418</span></span><span class='px-1 mx-1 bg-yellow-200'>Our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.435</span></span><span class='px-1 mx-1 bg-yellow-200'>Furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through LLM-involved failure diagnosis and automatic recovery. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.445</span></span><span class='px-1 mx-1 bg-yellow-200'>(2) decoupled scheduling for evaluation, which achieves timely performance feedback via trial decomposition and scheduling optimization. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.402</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07648v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07648v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Analyzing Adversarial Attacks on Sequence-to-Sequence Relevance Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Modern sequence-to-sequence relevance models like monoT5 can effectively capture complex textual interactions between queries and documents through cross-encoding.However, the use of natural language tokens in prompts, such as Query, Document, and Relevant for monoT5, opens an attack vector for malicious documents to manipulate their relevance score through prompt injection, e.g., by adding target words such as true.<span class='px-1 mx-1 bg-yellow-200'>Since such possibilities have not yet been considered in retrieval evaluation, we analyze the impact of query-independent prompt injection via manually constructed templates and LLM-based rewriting of documents on several existing relevance models. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.367</span></span><span class='px-1 mx-1 bg-yellow-200'>Our experiments on the TREC Deep Learning track show that adversarial documents can easily manipulate different sequence-to-sequence relevance models, while BM25 (as a typical lexical model) is not affected. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.389</span></span>Remarkably, the attacks also affect encoder-only relevance models (which do not rely on natural language prompt tokens), albeit to a lesser extent.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07654v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07654v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reinforcement learning from human feedback (RLHF) is the mainstream paradigm used to align large language models (LLMs) with human preferences.<span class='px-1 mx-1 bg-yellow-200'>Yet existing RLHF heavily relies on accurate and informative reward models, which are vulnerable and sensitive to noise from various sources, e.g. human labeling errors, making the pipeline fragile. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.433</span></span>In this work, we improve the effectiveness of the reward model by introducing a penalty term on the reward, named as \textit{contrastive rewards}.%Contrastive rewards Our approach involves two steps: (1) an offline sampling step to obtain responses to prompts that serve as baseline calculation and (2) a contrastive reward calculated using the baseline responses and used in the Proximal Policy Optimization (PPO) step.<span class='px-1 mx-1 bg-yellow-200'>We show that contrastive rewards enable the LLM to penalize reward uncertainty, improve robustness, encourage improvement over baselines, calibrate according to task difficulty, and reduce variance in PPO. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.305</span></span>We show empirically contrastive rewards can improve RLHF substantially, evaluated by both GPTs and humans, and our method consistently outperforms strong baselines.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07708v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07708v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.322</span></span><span class='px-1 mx-1 bg-yellow-200'>Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.405</span></span><span class='px-1 mx-1 bg-yellow-200'>However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.519</span></span><span class='px-1 mx-1 bg-yellow-200'>To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.556</span></span><span class='px-1 mx-1 bg-yellow-200'>The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.412</span></span><span class='px-1 mx-1 bg-yellow-200'>Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.391</span></span><span class='px-1 mx-1 bg-yellow-200'>Experimental results demonstrate the stability of StableToolBench, and further discuss the effectiveness of API simulators, the caching system, and the evaluator system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.51</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07714v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07714v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We study the use of large language model-based agents for interacting with software via web browsers.Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems.<span class='px-1 mx-1 bg-yellow-200'>To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.466</span></span>We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations.Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation.<span class='px-1 mx-1 bg-yellow-200'>Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.317</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07718v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07718v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>To thoroughly assess the mathematical reasoning abilities of Large Language Models (LLMs), we need to carefully curate evaluation datasets covering diverse mathematical concepts and mathematical problems at different difficulty levels.<span class='px-1 mx-1 bg-yellow-200'>In pursuit of this objective, we propose FineMath in this paper, a fine-grained mathematical evaluation benchmark dataset for assessing Chinese LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.37</span></span>FineMath is created to cover the major key mathematical concepts taught in elementary school math, which are further divided into 17 categories of math word problems, enabling in-depth analysis of mathematical reasoning abilities of LLMs.All the 17 categories of math word problems are manually annotated with their difficulty levels according to the number of reasoning steps required to solve these problems.We conduct extensive experiments on a wide range of LLMs on FineMath and find that there is still considerable room for improvements in terms of mathematical reasoning capability of Chinese LLMs.We also carry out an in-depth analysis on the evaluation process and methods that have been overlooked previously.These two factors significantly influence the model results and our understanding of their mathematical reasoning capabilities.The dataset will be publicly available soon.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07747v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07747v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The creation of high-quality human-labeled image-caption datasets presents a significant bottleneck in the development of Visual-Language Models (VLMs).We propose a novel approach that leverages the strengths of Large Language Models (LLMs) and image generation models to create synthetic image-text pairs for efficient and effective VLM training.Our method employs pretraining a text-to-image model to synthesize image embeddings starting from captions generated by an LLM.These synthetic pairs are then used to train a VLM.Extensive experiments demonstrate that the VLM trained with synthetic data exhibits comparable performance on image captioning, while requiring a fraction of the data used by models trained solely on human-annotated data.In particular, we outperform the baseline by 17% through augmentation with a synthetic dataset.Furthermore, we show that synthesizing in the image embedding space is 25% faster than in the pixel space.<span class='px-1 mx-1 bg-yellow-200'>This research introduces a promising technique for generating large-scale, customizable image datasets, leading to enhanced VLM performance and wider applicability across various domains, all with improved data efficiency and resource utilization. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.316</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07750v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07750v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fine-tuning Large Language Models with Sequential Instructions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) struggle to follow a sequence of instructions in a single query as they may ignore or misinterpret part of it. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.435</span></span>This impairs their performance in complex problems whose solution requires multiple intermediate steps, such as multilingual (translate then answer) and multimodal (caption then answer) tasks.<span class='px-1 mx-1 bg-yellow-200'>We empirically verify this with open-source LLMs as large as LLaMA-2 70B and Mixtral-8x7B. Targeting the scarcity of sequential instructions in present-day data, we propose sequential instruction tuning, a simple yet effective strategy to automatically augment instruction tuning data and equip LLMs with the ability to execute multiple sequential instructions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.543</span></span>After exploring interleaving instructions in existing datasets, such as Alpaca, with a wide range of intermediate tasks, we find that sequential instruction-tuned models consistently outperform the conventional instruction-tuned baselines in downstream tasks involving reasoning, multilingual, and multimodal abilities.To shed further light on our technique, we analyse how adversarial intermediate texts, unseen tasks, prompt verbalization, number of tasks, and prompt length affect SIT.We hope that this method will open new research avenues on instruction tuning for complex tasks.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07794v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07794v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>We investigate efficient methods for training Large Language Models (LLMs) to possess capabilities in multiple specialized domains, such as coding, math reasoning and world knowledge. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.324</span></span><span class='px-1 mx-1 bg-yellow-200'>Our method, named Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts in embarrassingly parallel fashion with high throughput and reduced communication cost. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.37</span></span><span class='px-1 mx-1 bg-yellow-200'>After individual experts are asynchronously trained, BTX brings together their feedforward parameters as experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed by an MoE-finetuning stage to learn token-level routing. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.465</span></span><span class='px-1 mx-1 bg-yellow-200'>BTX generalizes two special cases, the Branch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and sparse upcycling, which omits the stage of training experts asynchronously. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.457</span></span><span class='px-1 mx-1 bg-yellow-200'>Compared to alternative approaches, BTX achieves the best accuracy-efficiency tradeoff. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.418</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07816v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07816v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space.This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance.This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing.<span class='px-1 mx-1 bg-yellow-200'>Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.493</span></span><span class='px-1 mx-1 bg-yellow-200'>Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.431</span></span>However, our proposed methods, GORA and SORA, effectively identify and alleviate this issue, respectively, contributing to the advancement of LLM editing techniques.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07825v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07825v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring Safety Generalization Challenges of Large Language Models via Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.308</span></span>While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains.This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs.Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time.Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages.<span class='px-1 mx-1 bg-yellow-200'>These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.342</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07865v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07865v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Rethinking Generative Large Language Model Evaluation for Semantic Comprehension
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Despite their sophisticated capabilities, large language models (LLMs) encounter a major hurdle in effective assessment.This paper first revisits the prevalent evaluation method-multiple choice question answering (MCQA), which allows for straightforward accuracy measurement.<span class='px-1 mx-1 bg-yellow-200'>Through a comprehensive evaluation of 24 models across 11 benchmarks, we highlight several potential drawbacks of MCQA, for instance, the inconsistency between the MCQA evaluation and the generation of open-ended responses in practical scenarios. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.419</span></span><span class='px-1 mx-1 bg-yellow-200'>In response, we introduce an RWQ-Elo rating system, engaging 24 LLMs such as GPT-4, GPT-3.5, Google-Gemini-Pro and LLaMA-1/-2, in a two-player competitive format, with GPT-4 serving as the judge. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.364</span></span><span class='px-1 mx-1 bg-yellow-200'>Each LLM receives an Elo rating thereafter. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.341</span></span><span class='px-1 mx-1 bg-yellow-200'>This system is designed to mirror real-world usage, and for this purpose, we have compiled a new benchmark called ``Real-world questions'' (RWQ), comprising 20,772 authentic user inquiries. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.438</span></span><span class='px-1 mx-1 bg-yellow-200'>Additionally, we thoroughly analyze the characteristics of our system and compare it with prior leaderboards like AlpacaEval and MT-Bench. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.312</span></span><span class='px-1 mx-1 bg-yellow-200'>Our analysis reveals the stability of our RWQ-Elo system, the feasibility of registering new models, and its potential to reshape LLM leaderboards. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.627</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07872v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07872v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Beyond Text: Frozen Large Language Models in Visual Signal Comprehension
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In this work, we investigate the potential of a large language model (LLM) to directly comprehend visual signals without the necessity of fine-tuning on multi-modal datasets.The foundational concept of our method views an image as a linguistic entity, and translates it to a set of discrete words derived from the LLM's vocabulary.To achieve this, we present the Vision-to-Language Tokenizer, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model.With this innovative image encoding, the LLM gains the ability not only for visual comprehension but also for image denoising and restoration in an auto-regressive fashion-crucially, without any fine-tuning.We undertake rigorous experiments to validate our method, encompassing understanding tasks like image recognition, image captioning, and visual question answering, as well as image denoising tasks like inpainting, outpainting, deblurring, and shift restoration.<span class='px-1 mx-1 bg-yellow-200'>Code and models are available at https://github.com/zh460045050/V2L-Tokenizer. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.403</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07874v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07874v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">LLM Model Architectures and Training Techniques</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Towards Graph Foundation Models for Personalization
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions.In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FMs).While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval.In this paper, we present a graph-based foundation modeling approach tailored to personalization.Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types.To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity.<span class='px-1 mx-1 bg-yellow-200'>To facilitate practical generalization, we further couple the HGNN with an adaptation mechanism based on a two-tower (2T) architecture, which also operates agnostically to content type. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.428</span></span>This multi-stage approach ensures high scalability; while the HGNN produces general purpose embeddings, the 2T component models in a continuous space the sheer size of user-item interaction data.Our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07478v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07478v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MoAI: Mixture of All Intelligence for Large Language and Vision Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The rise of large language models (LLMs) and instruction tuning has led to the current trend of instruction-tuned large language and vision models (LLVMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.457</span></span><span class='px-1 mx-1 bg-yellow-200'>This trend involves either meticulously curating numerous instruction tuning datasets tailored to specific objectives or enlarging LLVMs to manage vast amounts of vision language (VL) data. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.544</span></span>However, current LLVMs have disregarded the detailed and comprehensive real-world scene understanding available from specialized computer vision (CV) models in visual perception tasks such as segmentation, detection, scene graph generation (SGG), and optical character recognition (OCR).<span class='px-1 mx-1 bg-yellow-200'>Instead, the existing LLVMs rely mainly on the large capacity and emergent capabilities of their LLM backbones. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.469</span></span>Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models.MoAI operates through two newly introduced modules: MoAI-Compressor and MoAI-Mixer.After verbalizing the outputs of the external CV models, the MoAI-Compressor aligns and condenses them to efficiently use relevant auxiliary visual information for VL tasks.MoAI-Mixer then blends three types of intelligence (1) visual features, (2) auxiliary features from the external CV models, and (3) language features by utilizing the concept of Mixture of Experts.<span class='px-1 mx-1 bg-yellow-200'>Through this integration, MoAI significantly outperforms both open-source and closed-source LLVMs in numerous zero-shot VL tasks, particularly those related to real-world scene understanding such as object existence, positions, relations, and OCR without enlarging the model size or curating extra visual instruction tuning datasets. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.411</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07508v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07508v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Process Modeling With Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes.Traditional process modeling methods often require extensive expertise and can be time-consuming.This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users.<span class='px-1 mx-1 bg-yellow-200'>We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.617</span></span><span class='px-1 mx-1 bg-yellow-200'>Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.48</span></span>Moreover, we instantiate a concrete system extending our framework.<span class='px-1 mx-1 bg-yellow-200'>This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.412</span></span><span class='px-1 mx-1 bg-yellow-200'>Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.492</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07541v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07541v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Although large language models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by the untruthful context provided by users or knowledge argumentation tools, thereby producing hallucinations.<span class='px-1 mx-1 bg-yellow-200'>To alleviate the LLMs from being misled by untruthful information and take advantage of knowledge argumentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful context from the inputs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.425</span></span>TACS begins by performing truth detection on the input context, leveraging the parameterized knowledge within the LLM.Subsequently, it constructs a corresponding attention mask based on the truthfulness of each position, selecting the truthful context and discarding the untruthful context.<span class='px-1 mx-1 bg-yellow-200'>Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate, to further study the LLMs' ability to accept truthful information and resist untruthful information. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.431</span></span>Experimental results show that TACS can effectively filter information in context and significantly improve the overall quality of LLMs' responses when presented with misleading information.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07556v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07556v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SIFiD: Reassess Summary Factual Inconsistency Detection with LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Ensuring factual consistency between the summary and the original document is paramount in summarization tasks.<span class='px-1 mx-1 bg-yellow-200'>Consequently, considerable effort has been dedicated to detecting inconsistencies. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.413</span></span>With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection.However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology.<span class='px-1 mx-1 bg-yellow-200'>In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.427</span></span>To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07557v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07557v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Personality detection aims to detect one's personality traits underlying in social media posts.One challenge of this task is the scarcity of ground-truth personality traits which are collected from self-report questionnaires.Most existing methods learn post features directly by fine-tuning the pre-trained language models under the supervision of limited personality labels.<span class='px-1 mx-1 bg-yellow-200'>This leads to inferior quality of post features and consequently affects the performance. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.458</span></span>In addition, they treat personality traits as one-hot classification labels, overlooking the semantic information within them.In this paper, we propose a large language model (LLM) based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection, even when the LLM fails in this task.Specifically, we enable LLM to generate post analyses (augmentations) from the aspects of semantic, sentiment, and linguistic, which are critical for personality detection.By using contrastive learning to pull them together in the embedding space, the post encoder can better capture the psycho-linguistic information within the post representations, thus improving personality detection.Furthermore, we utilize the LLM to enrich the information of personality labels for enhancing the detection performance.Experimental results on the benchmark datasets demonstrate that our model outperforms the state-of-the-art methods on personality detection.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07581v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07581v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Couler: Unified Machine Learning Workflow Optimization in Cloud
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Machine Learning (ML) has become ubiquitous, fueling data-driven applications across various organizations.Contrary to the traditional perception of ML in research, ML workflows can be complex, resource-intensive, and time-consuming.Expanding an ML workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs.<span class='px-1 mx-1 bg-yellow-200'>Currently, numerous workflow engines are available (with over ten being widely recognized). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.452</span></span><span class='px-1 mx-1 bg-yellow-200'>This variety poses a challenge for end-users in terms of mastering different engine APIs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.412</span></span><span class='px-1 mx-1 bg-yellow-200'>While efforts have primarily focused on optimizing ML Operations (MLOps) for a specific workflow engine, current methods largely overlook workflow optimization across different engines.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.581</span></span><span class='px-1 mx-1 bg-yellow-200'>In this work, we design and implement Couler, a system designed for unified ML workflow optimization in the cloud. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.444</span></span>Our main insight lies in the ability to generate an ML workflow using natural language (NL) descriptions.<span class='px-1 mx-1 bg-yellow-200'>We integrate Large Language Models (LLMs) into workflow generation, and provide a unified programming interface for various workflow engines. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.432</span></span><span class='px-1 mx-1 bg-yellow-200'>This approach alleviates the need to understand various workflow engines' APIs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.438</span></span><span class='px-1 mx-1 bg-yellow-200'>Moreover, Couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.58</span></span><span class='px-1 mx-1 bg-yellow-200'>These enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.503</span></span><span class='px-1 mx-1 bg-yellow-200'>Couler is extensively deployed in real-world production scenarios at Ant Group, handling approximately 22k workflows daily, and has successfully improved the CPU/Memory utilization by more than 15% and the workflow completion rate by around 17%. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.512</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07608v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07608v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation.However, the considered output candidates of the underlying search algorithm are under-explored and under-explained.We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs.To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities.<span class='px-1 mx-1 bg-yellow-200'>Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.437</span></span>Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods.Additionally, we demonstrate the applicability of our approach in a qualitative user study.Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07627v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07627v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Characterization of Large Language Model Development in the Datacenter
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models (LLMs) have presented impressive performance across several transformative tasks.<span class='px-1 mx-1 bg-yellow-200'>However, it is non-trivial to efficiently utilize large-scale cluster resources to develop LLMs, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.521</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we present an in-depth characterization study of a six-month LLM development workload trace collected from our GPU datacenter Acme. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.602</span></span><span class='px-1 mx-1 bg-yellow-200'>Specifically, we investigate discrepancies between LLMs and prior task-specific Deep Learning (DL) workloads, explore resource utilization patterns, and identify the impact of various job failures. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.573</span></span><span class='px-1 mx-1 bg-yellow-200'>Our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.582</span></span><span class='px-1 mx-1 bg-yellow-200'>Furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through LLM-involved failure diagnosis and automatic recovery. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.569</span></span><span class='px-1 mx-1 bg-yellow-200'>(2) decoupled scheduling for evaluation, which achieves timely performance feedback via trial decomposition and scheduling optimization. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.559</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07648v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07648v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Reinforcement learning from human feedback (RLHF) is the mainstream paradigm used to align large language models (LLMs) with human preferences.<span class='px-1 mx-1 bg-yellow-200'>Yet existing RLHF heavily relies on accurate and informative reward models, which are vulnerable and sensitive to noise from various sources, e.g. human labeling errors, making the pipeline fragile. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.459</span></span>In this work, we improve the effectiveness of the reward model by introducing a penalty term on the reward, named as \textit{contrastive rewards}.%Contrastive rewards Our approach involves two steps: (1) an offline sampling step to obtain responses to prompts that serve as baseline calculation and (2) a contrastive reward calculated using the baseline responses and used in the Proximal Policy Optimization (PPO) step.We show that contrastive rewards enable the LLM to penalize reward uncertainty, improve robustness, encourage improvement over baselines, calibrate according to task difficulty, and reduce variance in PPO.We show empirically contrastive rewards can improve RLHF substantially, evaluated by both GPTs and humans, and our method consistently outperforms strong baselines.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07708v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07708v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges.<span class='px-1 mx-1 bg-yellow-200'>Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.563</span></span>However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status.<span class='px-1 mx-1 bg-yellow-200'>To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.518</span></span><span class='px-1 mx-1 bg-yellow-200'>The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.449</span></span><span class='px-1 mx-1 bg-yellow-200'>Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.534</span></span><span class='px-1 mx-1 bg-yellow-200'>Experimental results demonstrate the stability of StableToolBench, and further discuss the effectiveness of API simulators, the caching system, and the evaluator system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.467</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07714v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07714v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We study the use of large language model-based agents for interacting with software via web browsers.Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems.To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform.We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations.Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation.<span class='px-1 mx-1 bg-yellow-200'>Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.454</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07718v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07718v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Fine-tuning Large Language Models with Sequential Instructions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) struggle to follow a sequence of instructions in a single query as they may ignore or misinterpret part of it.This impairs their performance in complex problems whose solution requires multiple intermediate steps, such as multilingual (translate then answer) and multimodal (caption then answer) tasks.<span class='px-1 mx-1 bg-yellow-200'>We empirically verify this with open-source LLMs as large as LLaMA-2 70B and Mixtral-8x7B. Targeting the scarcity of sequential instructions in present-day data, we propose sequential instruction tuning, a simple yet effective strategy to automatically augment instruction tuning data and equip LLMs with the ability to execute multiple sequential instructions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.653</span></span><span class='px-1 mx-1 bg-yellow-200'>After exploring interleaving instructions in existing datasets, such as Alpaca, with a wide range of intermediate tasks, we find that sequential instruction-tuned models consistently outperform the conventional instruction-tuned baselines in downstream tasks involving reasoning, multilingual, and multimodal abilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.411</span></span>To shed further light on our technique, we analyse how adversarial intermediate texts, unseen tasks, prompt verbalization, number of tasks, and prompt length affect SIT.<span class='px-1 mx-1 bg-yellow-200'>We hope that this method will open new research avenues on instruction tuning for complex tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.62</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07794v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07794v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We investigate efficient methods for training Large Language Models (LLMs) to possess capabilities in multiple specialized domains, such as coding, math reasoning and world knowledge.Our method, named Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts in embarrassingly parallel fashion with high throughput and reduced communication cost.After individual experts are asynchronously trained, BTX brings together their feedforward parameters as experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed by an MoE-finetuning stage to learn token-level routing.BTX generalizes two special cases, the Branch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and sparse upcycling, which omits the stage of training experts asynchronously.<span class='px-1 mx-1 bg-yellow-200'>Compared to alternative approaches, BTX achieves the best accuracy-efficiency tradeoff. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.439</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07816v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07816v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space.<span class='px-1 mx-1 bg-yellow-200'>This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.433</span></span><span class='px-1 mx-1 bg-yellow-200'>This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.427</span></span><span class='px-1 mx-1 bg-yellow-200'>Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.512</span></span>Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods.<span class='px-1 mx-1 bg-yellow-200'>However, our proposed methods, GORA and SORA, effectively identify and alleviate this issue, respectively, contributing to the advancement of LLM editing techniques. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.496</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07825v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07825v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Large language models (LLMs) can provide rich physical descriptions of most worldly objects, allowing robots to achieve more informed and capable grasping.We leverage LLMs' common sense physical reasoning and code-writing abilities to infer an object's physical characteristics--mass $m$, friction coefficient $\mu$, and spring constant $k$--from a semantic description, and then translate those characteristics into an executable adaptive grasp policy.Using a current-controllable, two-finger gripper with a built-in depth camera, we demonstrate that LLM-generated, physically-grounded grasp policies outperform traditional grasp policies on a custom benchmark of 12 delicate and deformable items including food, produce, toys, and other everyday items, spanning two orders of magnitude in mass and required pick-up force.<span class='px-1 mx-1 bg-yellow-200'>We also demonstrate how compliance feedback from DeliGrasp policies can aid in downstream tasks such as measuring produce ripeness. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.417</span></span>Our code and videos are available at: https://deligrasp.github.io</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07832v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07832v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring Safety Generalization Challenges of Large Language Models via Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse.While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains.<span class='px-1 mx-1 bg-yellow-200'>This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.489</span></span><span class='px-1 mx-1 bg-yellow-200'>Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.478</span></span>Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages.<span class='px-1 mx-1 bg-yellow-200'>These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.605</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07865v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07865v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Rethinking Generative Large Language Model Evaluation for Semantic Comprehension
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Despite their sophisticated capabilities, large language models (LLMs) encounter a major hurdle in effective assessment.This paper first revisits the prevalent evaluation method-multiple choice question answering (MCQA), which allows for straightforward accuracy measurement.Through a comprehensive evaluation of 24 models across 11 benchmarks, we highlight several potential drawbacks of MCQA, for instance, the inconsistency between the MCQA evaluation and the generation of open-ended responses in practical scenarios.In response, we introduce an RWQ-Elo rating system, engaging 24 LLMs such as GPT-4, GPT-3.5, Google-Gemini-Pro and LLaMA-1/-2, in a two-player competitive format, with GPT-4 serving as the judge.Each LLM receives an Elo rating thereafter.This system is designed to mirror real-world usage, and for this purpose, we have compiled a new benchmark called ``Real-world questions'' (RWQ), comprising 20,772 authentic user inquiries.Additionally, we thoroughly analyze the characteristics of our system and compare it with prior leaderboards like AlpacaEval and MT-Bench.<span class='px-1 mx-1 bg-yellow-200'>Our analysis reveals the stability of our RWQ-Elo system, the feasibility of registering new models, and its potential to reshape LLM leaderboards. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.401</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07872v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07872v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Programming applications of LLMs</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Couler: Unified Machine Learning Workflow Optimization in Cloud
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Machine Learning (ML) has become ubiquitous, fueling data-driven applications across various organizations.Contrary to the traditional perception of ML in research, ML workflows can be complex, resource-intensive, and time-consuming.Expanding an ML workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs.Currently, numerous workflow engines are available (with over ten being widely recognized).This variety poses a challenge for end-users in terms of mastering different engine APIs.While efforts have primarily focused on optimizing ML Operations (MLOps) for a specific workflow engine, current methods largely overlook workflow optimization across different engines.   In this work, we design and implement Couler, a system designed for unified ML workflow optimization in the cloud.Our main insight lies in the ability to generate an ML workflow using natural language (NL) descriptions.<span class='px-1 mx-1 bg-yellow-200'>We integrate Large Language Models (LLMs) into workflow generation, and provide a unified programming interface for various workflow engines. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.681</span></span>This approach alleviates the need to understand various workflow engines' APIs.Moreover, Couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning.These enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training.Couler is extensively deployed in real-world production scenarios at Ant Group, handling approximately 22k workflows daily, and has successfully improved the CPU/Memory utilization by more than 15% and the workflow completion rate by around 17%.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07608v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07608v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.657</span></span>However, the considered output candidates of the underlying search algorithm are under-explored and under-explained.We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs.To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities.Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data.Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods.Additionally, we demonstrate the applicability of our approach in a qualitative user study.Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07627v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07627v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.664</span></span>Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks.However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status.To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system.The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status.Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation.Experimental results demonstrate the stability of StableToolBench, and further discuss the effectiveness of API simulators, the caching system, and the evaluator system.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07714v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07714v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-12</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Exploring Safety Generalization Challenges of Large Language Models via Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse.While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains.<span class='px-1 mx-1 bg-yellow-200'>This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.645</span></span>Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time.Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages.These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07865v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07865v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) like GPT-4 and LLaMA have shown incredible proficiency at natural language processing tasks and have even begun to excel at tasks across other modalities such as vision and audio. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.702</span></span>Despite their success, LLMs often struggle to perform well on low-resource languages because there is so little training data available.This shortcoming is especially prevalent with open source models.In this work, we explore training LLaMA-2 to speak Amharic, a language which is spoken by over 50 million people world wide, but has orders of magnitude less data available than languages like English.We employ methods previously used for training LLMs on other languages with data scarcity, and use open source translation models to perform data augmentation and grow our dataset from millions of tokens to billions.We further enhance the capabilities of our model by connecting an image encoder and training on a translated visual instruction tuning dataset in the same manner as LLaVA, resulting in a multimodal Amharic LLM that can understand images along with text.We introduce an Amharic version of a popular benchmarking dataset to evaluate our work.Our models and dataset are open sourced and available on GitHub.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06354v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06354v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Decoding Complexity: Exploring Human-AI Concordance in Qualitative Coding
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Qualitative data analysis provides insight into the underlying perceptions and experiences within unstructured data.<span class='px-1 mx-1 bg-yellow-200'>However, the time-consuming nature of the coding process, especially for larger datasets, calls for innovative approaches, such as the integration of Large Language Models (LLMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.753</span></span>This short paper presents initial findings from a study investigating the integration of LLMs for coding tasks of varying complexity in a real-world dataset.Our results highlight the challenges inherent in coding with extensive codebooks and contexts, both for human coders and LLMs, and suggest that the integration of LLMs into the coding process requires a task-by-task evaluation.We examine factors influencing the complexity of coding tasks and initiate a discussion on the usefulness and limitations of incorporating LLMs in qualitative research.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06607v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06607v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Materials science in the era of large language models: a perspective
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have garnered considerable interest due to their impressive natural language capabilities, which in conjunction with various emergent properties make them versatile tools in workflows ranging from complex code generation to heuristic finding for combinatorial problems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.73</span></span>In this paper we offer a perspective on their applicability to materials science research, arguing their ability to handle ambiguous requirements across a range of tasks and disciplines mean they could be a powerful tool to aid researchers.We qualitatively examine basic LLM theory, connecting it to relevant properties and techniques in the literature before providing two case studies that demonstrate their use in task automation and knowledge extraction at-scale.At their current stage of development, we argue LLMs should be viewed less as oracles of novel insight, and more as tireless workers that can accelerate and unify exploration across domains.It is our hope that this paper can familiarise material science researchers with the concepts needed to leverage these tools in their own research.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06949v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06949v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-11</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                From English to ASIC: Hardware Implementation with Large Language Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the realm of ASIC engineering, the landscape has been significantly reshaped by the rapid development of LLM, paralleled by an increase in the complexity of modern digital circuits.This complexity has escalated the requirements for HDL coding, necessitating a higher degree of precision and sophistication.<span class='px-1 mx-1 bg-yellow-200'>However, challenges have been faced due to the less-than-optimal performance of modern language models in generating hardware description code, a situation further exacerbated by the scarcity of the corresponding high-quality code datasets. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.654</span></span>These challenges have highlighted the gap between the potential of LLMs to revolutionize digital circuit design and their current capabilities in accurately interpreting and implementing hardware specifications.To address these challenges, a strategy focusing on the fine-tuning of the leading-edge nature language model and the reshuffling of the HDL code dataset has been developed.The fine-tuning aims to enhance models' proficiency in generating precise and efficient ASIC design, while the dataset reshuffling is intended to broaden the scope and improve the quality of training material.The model demonstrated significant improvements compared to the base model, with approximately 10% to 20% increase in accuracy across a wide range of temperature for the pass@1 metric.This approach is expected to facilitate a simplified and more efficient LLM-assisted framework for complex circuit design, leveraging their capabilities to meet the sophisticated demands of HDL coding and thus streamlining the ASIC development process.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.07039v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.07039v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Reading, understanding and explaining code have traditionally been important skills for novices learning programming. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.738</span></span><span class='px-1 mx-1 bg-yellow-200'>As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.826</span></span>Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM.<span class='px-1 mx-1 bg-yellow-200'>Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.729</span></span>One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code.However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.796</span></span><span class='px-1 mx-1 bg-yellow-200'>We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.825</span></span><span class='px-1 mx-1 bg-yellow-200'>We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span>We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06050v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06050v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-10</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.885</span></span>However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools.Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts.In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT).The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP.GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last.<span class='px-1 mx-1 bg-yellow-200'>We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.746</span></span>In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.06254v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.06254v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                ProMoAI: Process Modeling with Generative AI
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>ProMoAI is a novel tool that leverages Large Language Models (LLMs) to automatically generate process models from textual descriptions, incorporating advanced prompt engineering, error handling, and code generation techniques. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.686</span></span>Beyond automating the generation of complex process models, ProMoAI also supports process model optimization.Users can interact with the tool by providing feedback on the generated model, which is then used for refining the process model.ProMoAI utilizes the capabilities LLMs to offer a novel, AI-driven approach to process modeling, significantly reducing the barrier to entry for users without deep technical knowledge in process modeling.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04327v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04327v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Feedback-Generation for Programming Exercises With GPT-4
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education.<span class='px-1 mx-1 bg-yellow-200'>LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.871</span></span><span class='px-1 mx-1 bg-yellow-200'>This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.666</span></span>Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions.The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material.Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements.For example, the output is more structured and consistent.GPT-4 Turbo can also accurately identify invalid casing in student programs' output.In some cases, the feedback also includes the output of the student program.At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed.The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04449v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04449v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-07</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.695</span></span>Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform.Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods.To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously.Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction.To validate our approach, we deployed iScore with three learning engineers over the course of a month.We present a case study where interacting with iScore led a learning engineer to improve their LLM's score accuracy by three percentage points.Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.04760v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.04760v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Guiding Enumerative Program Synthesis with Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Pre-trained Large Language Models (LLMs) are beginning to dominate the discourse around automatic code generation with natural language specifications. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.891</span></span>In contrast, the best-performing synthesizers in the domain of formal synthesis with precise logical specifications are still based on enumerative algorithms.In this paper, we evaluate the abilities of LLMs to solve formal synthesis benchmarks by carefully crafting a library of prompts for the domain.When one-shot synthesis fails, we propose a novel enumerative synthesis algorithm, which integrates calls to an LLM into a weighted probabilistic search.This allows the synthesizer to provide the LLM with information about the progress of the enumerator, and the LLM to provide the enumerator with syntactic guidance in an iterative loop.We evaluate our techniques on benchmarks from the Syntax-Guided Synthesis (SyGuS) competition.We find that GPT-3.5 as a stand-alone tool for formal synthesis is easily outperformed by state-of-the-art formal synthesis algorithms, but our approach integrating the LLM into an enumerative synthesis algorithm shows significant performance gains over both the LLM and the enumerative synthesizer alone and the winning SyGuS competition tool.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03997v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03997v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Magic Markup: Maintaining Document-External Markup with an LLM
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Text documents, including programs, typically have human-readable semantic structure.Historically, programmatic access to these semantics has required explicit in-document tagging.Especially in systems where the text has an execution semantics, this means it is an opt-in feature that is hard to support properly.Today, language models offer a new method: metadata can be bound to entities in changing text using a model's human-like understanding of semantics, with no requirements on the document structure.This method expands the applications of document annotation, a fundamental operation in program writing, debugging, maintenance, and presentation.<span class='px-1 mx-1 bg-yellow-200'>We contribute a system that employs an intelligent agent to re-tag modified programs, enabling rich annotations to automatically follow code as it evolves. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.651</span></span>We also contribute a formal problem definition, an empirical synthetic benchmark suite, and our benchmark generator.Our system achieves an accuracy of 90% on our benchmarks and can replace a document's tags in parallel at a rate of 5 seconds per tag.While there remains significant room for improvement, we find performance reliable enough to justify further exploration of applications.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03481v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03481v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Spreadsheet manipulation is widely existing in most daily works and significantly improves working efficiency.<span class='px-1 mx-1 bg-yellow-200'>Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.653</span></span>To bridge the gap with the real-world requirements, we introduce $\textbf{SheetRM}$, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges.To mitigate the above challenges, we further propose $\textbf{SheetAgent}$, a novel autonomous agent that utilizes the power of LLMs.SheetAgent consists of three collaborative modules: $\textit{Planner}$, $\textit{Informer}$, and $\textit{Retriever}$, achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection.Extensive experiments demonstrate that SheetAgent delivers 20-30% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities.More details and visualizations are available at https://sheetagent.github.io.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03636v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03636v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-06</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Towards Safe and Aligned Large Language Models for Medicine
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.707</span></span>While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights.To this end, we carry out the first safety evaluation for medical LLMs.Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale approaches used by the machine learning community to develop safe and aligned LLMs.We hope that this work casts light on the safety and alignment of medical LLMs and motivates future work to study it and develop additional mitigation strategies, minimizing the risks of harm of LLMs in medicine.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03744v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03744v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Eliciting Better Multilingual Structured Reasoning from LLMs through Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Development of large language models (LLM) have shown progress on reasoning, though studies have been limited to English or simple reasoning tasks.We thus introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across six languages.xSTREETexposes a gap in base LLM performance between English and non-English reasoning tasks.We then propose two methods to remedy this gap, building on the insight that LLMs trained on code are better reasoners.<span class='px-1 mx-1 bg-yellow-200'>First, at training time, we augment a code dataset with multi-lingual comments using machine translation while keeping program code as-is. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.662</span></span>Second, at inference time, we bridge the gap between training and inference by employing a prompt structure that incorporates step-by-step code primitives to derive new facts and find a solution.Our methods show improved multilingual performance on xSTREET, most notably on the scientific commonsense reasoning subtask.Furthermore, the models show no regression on non-reasoning tasks, thus showing our techniques maintain general-purpose abilities.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02567v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02567v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.693</span></span>Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks.Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs.Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task.These findings offer valuable insights for enhancing the development of LLM-based Text-to-SQL systems.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02951v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02951v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                MathScale: Scaling Instruction Tuning for Mathematical Reasoning
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) have demonstrated remarkable capabilities in problem-solving. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.642</span></span>However, their proficiency in solving mathematical problems remains inadequate.We propose MathScale, a simple and scalable method to create high-quality mathematical reasoning data using frontier LLMs (e.g., {\tt GPT-3.5}).Inspired by the cognitive mechanism in human mathematical learning, it first extracts topics and knowledge points from seed math questions and then build a concept graph, which is subsequently used to generate new math questions.MathScale exhibits effective scalability along the size axis of the math dataset that we generate.As a result, we create a mathematical reasoning dataset (MathScaleQA) containing two million math question-answer pairs.To evaluate mathematical reasoning abilities of LLMs comprehensively, we construct {\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten datasets (including GSM8K and MATH) covering K-12, college, and competition level math problems.We apply MathScaleQA to fine-tune open-source LLMs (e.g., LLaMA-2 and Mistral), resulting in significantly improved capabilities in mathematical reasoning.Evaluated on {\sc MwpBench}, MathScale-7B achieves state-of-the-art performance across all datasets, surpassing its best peers of equivalent size by 42.9\% in micro average accuracy and 43.7\% in macro average accuracy, respectively.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02884v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02884v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.693</span></span>Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks.Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs.Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task.These findings offer valuable insights for enhancing the development of LLM-based Text-to-SQL systems.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02951v2' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02951v2' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Localized Zeroth-Order Prompt Optimization
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>The efficacy of large language models (LLMs) in understanding and generating natural language has aroused a wide interest in developing prompt-based methods to harness the power of black-box LLMs. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.687</span></span>Existing methodologies usually prioritize a global optimization for finding the global optimum, which however will perform poorly in certain tasks.This thus motivates us to re-think the necessity of finding a global optimum in prompt optimization.To answer this, we conduct a thorough empirical study on prompt optimization and draw two major insights.Contrasting with the rarity of global optimum, local optima are usually prevalent and well-performed, which can be more worthwhile for efficient prompt optimization (Insight I).The choice of the input domain, covering both the generation and the representation of prompts, affects the identification of well-performing local optima (Insight II).Inspired by these insights, we propose a novel algorithm, namely localized zeroth-order prompt optimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived Gaussian process into standard zeroth-order optimization for an efficient search of well-performing local optima in prompt optimization.Remarkably, ZOPO outperforms existing baselines in terms of both the optimization performance and the query efficiency, which we demonstrate through extensive experiments.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02993v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02993v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.65</span></span>This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination.To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge.Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents.Experimental results on HotpotQA and ALFWorld based on various backbone models demonstrate that KnowAgent can achieve comparable or superior performance to existing baselines.Further analysis indicates the effectiveness of KnowAgent in terms of planning hallucinations mitigation.Code is available in https://github.com/zjunlp/KnowAgent.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03101v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03101v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-05</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The increasing use of information technology has led to a significant share of energy consumption and carbon emissions from data centers.These contributions are expected to rise with the growing demand for big data analytics, increasing digitization, and the development of large artificial intelligence (AI) models.The need to address the environmental impact of software development has led to increased interest in green (sustainable) coding and claims that the use of AI models can lead to energy efficiency gains.Here, we provide an empirical study on green code and an overview of green coding practices, as well as metrics used to quantify the sustainability awareness of AI models.<span class='px-1 mx-1 bg-yellow-200'>In this framework, we evaluate the sustainability of auto-generated code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.683</span></span><span class='px-1 mx-1 bg-yellow-200'>The auto-generate codes considered in this study are produced by generative commercial AI language models, GitHub Copilot, OpenAI ChatGPT-3, and Amazon CodeWhisperer. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.848</span></span>Within our methodology, in order to quantify the sustainability awareness of these AI models, we propose a definition of the code's "green capacity", based on certain sustainability metrics.<span class='px-1 mx-1 bg-yellow-200'>We compare the performance and green capacity of human-generated code and code generated by the three AI language models in response to easy-to-hard problem statements. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.713</span></span>Our findings shed light on the current capacity of AI models to contribute to sustainable software development.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.03344v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.03344v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.895</span></span>Evaluation based on such $\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems.However, in this context, current evaluation methods are either limited in task coverage or lack standardization.To address this issue, we propose using category theory as a framework for evaluation.<span class='px-1 mx-1 bg-yellow-200'>Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.702</span></span><span class='px-1 mx-1 bg-yellow-200'>We present an automatic evaluation framework called $\textbf{CatCode}$ ($\textbf{Cat}$egory $\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.74</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.01784v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.01784v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>A common way of assessing language learners' mastery of vocabulary is via multiple-choice cloze (i.e., fill-in-the-blank) questions.But the creation of test items can be laborious for individual teachers or in large-scale language programs.<span class='px-1 mx-1 bg-yellow-200'>In this paper, we evaluate a new method for automatically generating these types of questions using large language models (LLM). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.685</span></span>The VocaTT (vocabulary teaching and training) engine is written in Python and comprises three basic steps: pre-processing target word lists, generating sentences and candidate word options using GPT, and finally selecting suitable word options.To test the efficiency of this system, 60 questions were generated targeting academic words.The generated items were reviewed by expert reviewers who judged the well-formedness of the sentences and word options, adding comments to items judged not well-formed.Results showed a 75% rate of well-formedness for sentences and 66.85% rate for suitable word options.This is a marked improvement over the generator used earlier in our research which did not take advantage of GPT's capabilities.Post-hoc qualitative analysis reveals several points for improvement in future work including cross-referencing part-of-speech tagging, better sentence validation, and improving GPT prompts.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02078v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02078v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Ivie: Lightweight Anchored Explanations of Just-Generated Code
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.731</span></span><span class='px-1 mx-1 bg-yellow-200'>In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.767</span></span><span class='px-1 mx-1 bg-yellow-200'>We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.67</span></span><span class='px-1 mx-1 bg-yellow-200'>When using Ivie, a programmer's generated code is instantly accompanied by explanations positioned just adjacent to the code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.663</span></span>Our design was optimized for extremely low-cost invocation and dismissal.Explanations are compact and informative.<span class='px-1 mx-1 bg-yellow-200'>They describe meaningful expressions, from individual variables to entire blocks of code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.664</span></span><span class='px-1 mx-1 bg-yellow-200'>We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.661</span></span><span class='px-1 mx-1 bg-yellow-200'>In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.746</span></span><span class='px-1 mx-1 bg-yellow-200'>Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction, desirable complement to the programming assistant. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.677</span></span></p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02491v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02491v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>In recent years, large language models (LLMs) have become increasingly prevalent, offering remarkable text generation capabilities. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.716</span></span>However, a pressing challenge is their tendency to make confidently wrong predictions, highlighting the critical need for uncertainty quantification (UQ) in LLMs.While previous works have mainly focused on addressing aleatoric uncertainty, the full spectrum of uncertainties, including epistemic, remains inadequately explored.Motivated by this gap, we introduce a novel UQ method, sampling with perturbation for UQ (SPUQ), designed to tackle both aleatoric and epistemic uncertainties.The method entails generating a set of perturbations for LLM inputs, sampling outputs for each perturbation, and incorporating an aggregation module that generalizes the sampling uncertainty approach for text generation tasks.Through extensive experiments on various datasets, we investigated different perturbation and aggregation techniques.Our findings show a substantial improvement in model uncertainty calibration, with a reduction in Expected Calibration Error (ECE) by 50\% on average.Our findings suggest that our proposed UQ method offers promising steps toward enhancing the reliability and trustworthiness of LLMs.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02509v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02509v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-04</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Data analysis is a crucial analytical process to generate in-depth studies and conclusive insights to comprehensively answer a given user query for tabular data.In this work, we aim to propose new resources and benchmarks to inspire future research on this crucial yet challenging and under-explored task.However, collecting data analysis annotations curated by experts can be prohibitively expensive.<span class='px-1 mx-1 bg-yellow-200'>We propose to automatically generate high-quality answer annotations leveraging the code-generation capabilities of LLMs with a multi-turn prompting technique. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.818</span></span>We construct the DACO dataset, containing (1) 440 databases (of tabular data) collected from real-world scenarios, (2) ~2k query-answer pairs that can serve as weak supervision for model training, and (3) a concentrated but high-quality test set with human refined annotations that serves as our main evaluation benchmark.We train a 6B supervised fine-tuning (SFT) model on DACO dataset, and find that the SFT model learns reasonable data analysis capabilities.To further align the models with human preference, we use reinforcement learning to encourage generating analysis perceived by human as helpful, and design a set of dense rewards to propagate the sparse human preference reward to intermediate code generation steps.Our DACO-RL algorithm is evaluated by human annotators to produce more helpful answers than SFT model in 57.72% cases, validating the effectiveness of our proposed algorithm.Data and code are released at https://github.com/shirley-wu/daco</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.02528v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.02528v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-03-03</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Improving LLM Code Generation with Grammar Augmentation
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>We present SynCode a novel framework for efficient and general syntactical decoding of code with large language models (LLMs). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.796</span></span>SynCode leverages the grammar of a programming language, utilizing an offline-constructed efficient lookup table called DFA mask store based on language grammar terminals.We demonstrate SynCode's soundness and completeness given the context-free grammar (CFG) of the programming language, presenting its ability to retain syntactically valid tokens while rejecting invalid ones.The framework seamlessly integrates with any language defined by CFG, as evidenced by experiments on CFGs for Python and Go.<span class='px-1 mx-1 bg-yellow-200'>The results underscore the significant reduction of 96.07% of syntax errors achieved when SynCode is combined with state-of-the-art LLMs, showcasing its substantial impact on enhancing syntactical precision in code generation.    <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.881</span></span>Our code is available at https://github.com/uiuc-focal-lab/syncode.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2403.01632v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2403.01632v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-02-29</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Questions combine our mastery of language with our remarkable facility for reasoning about uncertainty.How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources?We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship.<span class='px-1 mx-1 bg-yellow-200'>Our language-informed program sampling (LIPS) model uses large language models (LLMs) to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.742</span></span>We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios.In contrast, LLM-only baselines struggle to ground questions in the board state; notably, GPT-4V provides no improvement over non-visual baselines.Our results illustrate how Bayesian models of question-asking can leverage the statistics of language to capture human priors, while highlighting some shortcomings of pure LLMs as grounded reasoners.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2402.19471v1' target="_blank">
                  link
                </a>
                <br>
                <a href='http://arxiv.org/abs/2402.19471v1' onclick="extractGSUrl(this.href)" class="underline decoration-2 text-green-600 text-md pt-2">
                  Google Scholar
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr></tbody>
  </table>
  <br><br>
</div>
</div>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      // customised options
      //  auto-render specific keys, e.g.:
      delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false},
      {left: '\\(', right: '\\)', display: false},
      {left: '\\[', right: '\\]', display: true}
      ],
      //  rendering keys, e.g.:
      throwOnError : false
    });
  });
  function extractGSUrl(url) {
            var regex = /\/([^/]+?)(?:v\d+)?$/;
            var matches = url.match(regex);

            if (matches) {
                var endOfUrl = matches[1];
                var prefix = "https://scholar.google.com/scholar_lookup?arxiv_id=";
                var finalUrl = prefix + endOfUrl;
                console.log("Final URL: " + finalUrl);
                
                // You can open the final URL in a new tab/window
                window.open(finalUrl, "_blank");
            } else {
                console.log("No match found");
            }
        };
</script>
</body>
</html>