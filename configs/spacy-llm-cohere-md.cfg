[nlp]
lang = "en"
pipeline = ["llm"]

[components]

[components.llm]
factory = "llm"
save_io = True 

[components.llm.task]
@llm_tasks = "spacy.TextCat.v3"
labels = ["CYBERSECURITY_LLM"]

[components.llm.task.label_definitions]
CYBERSECURITY_LLM = "Clear indication that the topic of the abstract is Cybersecurity for LLMs (e.g., prompt injection, jailbreaking, adversarial attacks)"

[components.llm.model]
@llm_models = "spacy.Command.v1"
name = "command"
config = {"temperature": 0.3}

[components.llm.cache]
@llm_misc = "spacy.BatchCache.v1"
path = "configs/cohere-cache-md"
batch_size = 3
max_batches_in_mem = 4
