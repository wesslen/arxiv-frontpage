[
  {
    "text": "We propose a new automatic framework that leverages LLMs themselves to generate effective jailbreak prompts.",
    "answer": "CYBERSECURITY_LLM"
  },
  {
    "text": "In this paper we explore ",
    "answer": "CYBERSECURITY_LLM"
  },
  {
    "text": "This benchmark demonstrates state of the art performance on five datasets.",
    "answer": "==NONE=="
  }
]